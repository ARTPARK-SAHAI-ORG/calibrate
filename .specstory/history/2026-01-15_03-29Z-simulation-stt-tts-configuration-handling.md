<!-- Generated by SpecStory, Markdown v2.1.0 -->

<!-- cursor Session 33a486d0-c9fe-456e-b467-c647f2c0b1c5 (2026-01-15 03:29Z) -->

# Simulation STT TTS configuration handling (2026-01-15 03:29Z)

_**User (2026-01-15 01:14Z)**_

@pense/agent/run_simulation.py to take in stt tts config from config json and pass that to start_bot

---

_**Agent (model composer-1, mode Agent)**_



---


Checking `STTConfig` and `TTSConfig` definitions to understand their structure.


---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: pense/agent/bot.py</summary>

</details>
</tool-use>

---

<tool-use data-tool-type="search" data-tool-name="codebase_search">
<details>
                <summary>Tool use: **codebase_search** â€¢ Searched codebase "What is the structure of STTConfig and TTSConfig classes?" â€¢ **14** results</summary>
            
| File | Lines |
|------|-------|
| `pense/agent/test.py` | L123-178 |
| `pense/agent/test.py` | L99-128 |
| `pense/agent/test.py` | L131-513 |
| `pense/agent/bot.py` | L114-129 |
| `pense/agent/bot.py` | L94-124 |
| `pense/agent/test.py` | L78-120 |
| `pense/agent/bot.py` | L129-560 |
| `pense/agent/test.py` | L178-513 |
| `pense/agent/bot.py` | L127-560 |
| `pense/agent/examples/test/config.json` | L82-106 |
| `pense/agent/test.py` | L107-138 |
| `pense/agent/bot.py` | L120-560 |
| `pense/agent/bot.py` | L58 |
| `pense/agent/test.py` | L141-513 |

</details>
</tool-use>

---



---


Checking example config files to understand the expected structure:


---

<tool-use data-tool-type="generic" data-tool-name="glob_file_search">
<details>
<summary>Tool use: **glob_file_search** â€¢ Searched codebase "**/examples/**/config.json" â€¢ **3** results in **1** directory</summary>

Directory: **/Users/aman/Documents/repos/artpark/agentloop** (3 files)

| File |
|------|
| `pense/llm/examples/simulation/config.json` |
| `pense/llm/examples/tests/config.json` |
| `pense/agent/examples/test/config.json` |

</details>
</tool-use>

---

<tool-use data-tool-type="generic" data-tool-name="glob_file_search">
<details>
<summary>Tool use: **glob_file_search** â€¢ Searched codebase "**/examples/**/*.json" â€¢ **29** results in **1** directory</summary>

Directory: **/Users/aman/Documents/repos/artpark/agentloop** (29 files)

| File |
|------|
| `pense/agent/examples/simulation/sample_short.json` |
| `pense/llm/examples/simulation/config.json` |
| `pense/agent/examples/simulation/sample_long.json` |
| `pense/llm/examples/tests/config.json` |
| `pense/agent/examples/test/config.json` |
| `pense/agent/examples/simulation/sample_output/simulation_persona_1_scenario_4/transcripts.json` |
| `pense/agent/examples/simulation/sample_output/simulation_persona_1_scenario_4/tool_calls.json` |
| `pense/agent/examples/simulation/sample_output/simulation_persona_1_scenario_4/stt_outputs.json` |
| `pense/agent/examples/simulation/sample_output/simulation_persona_1_scenario_4/metrics.json` |
| `pense/agent/examples/simulation/sample_output/simulation_persona_1_scenario_3/transcripts.json` |
| `pense/agent/examples/simulation/sample_output/simulation_persona_1_scenario_3/tool_calls.json` |
| `pense/agent/examples/simulation/sample_output/simulation_persona_1_scenario_3/stt_outputs.json` |
| `pense/agent/examples/simulation/sample_output/simulation_persona_1_scenario_3/metrics.json` |
| `pense/agent/examples/simulation/sample_output/simulation_persona_1_scenario_2/transcripts.json` |
| `pense/agent/examples/simulation/sample_output/simulation_persona_1_scenario_2/tool_calls.json` |
| `pense/agent/examples/simulation/sample_output/simulation_persona_1_scenario_2/stt_outputs.json` |
| `pense/agent/examples/simulation/sample_output/simulation_persona_1_scenario_2/metrics.json` |
| `pense/agent/examples/simulation/sample_output/simulation_persona_1_scenario_1/transcripts.json` |
| `pense/agent/examples/simulation/sample_output/simulation_persona_1_scenario_1/tool_calls.json` |
| `pense/agent/examples/simulation/sample_output/simulation_persona_1_scenario_1/stt_outputs.json` |
| `pense/agent/examples/simulation/sample_output/simulation_persona_1_scenario_1/metrics.json` |
| `pense/llm/examples/simulation/sample_output/simulation_persona_1_scenario_3/transcript.json` |
| `pense/llm/examples/simulation/sample_output/simulation_persona_1_scenario_2/transcript.json` |
| `pense/llm/examples/simulation/sample_output/simulation_persona_1_scenario_1/transcript.json` |
| `pense/stt/examples/sample_output/metrics.json` |
| `pense/llm/examples/simulation/sample_output/metrics.json` |
| `pense/llm/examples/tests/sample_output/config/gpt-4.1/results.json` |
| `pense/tts/examples/sample_output/metrics.json` |
| `pense/stt/examples/sample_input/gt.json` |

</details>
</tool-use>

---



---





---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: pense/agent/examples/simulation/sample_short.json</summary>

</details>
</tool-use>

---



---


Updating `run_single_simulation_task` to extract STT and TTS configs from the config JSON and pass them to `start_bot`:


---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: pense/agent/run_simulation.py</summary>

</details>
</tool-use>

---



---


Updating the code to extract STT and TTS configs from the config JSON and pass them to `start_bot`:


---

Model performed no edit

---

<tool-use data-tool-type="write" data-tool-name="search_replace">

<details><summary>Tool use: **search_replace** â€¢ Edit file: pense/agent/run_simulation.py</summary>

**Chunk 1**
Lines added: 18, lines removed: undefined

```diff
@@ -1148,4 +1148,22 @@
          log_and_print(f"\033[93mPort:\033[0m {port}")
          log_and_print("--------------------------------")
+ 
+         # Extract STT and TTS configs from config dict
+         stt_config_data = config.get("stt", {})
+         stt_config = STTConfig(
+             provider=stt_config_data.get("provider", "deepgram")
+         )
+ 
+         tts_config_data = config.get("tts", {})
+         tts_config = TTSConfig(
+             provider=tts_config_data.get("provider", "google"),
+             instructions=tts_config_data.get("instructions")
+         )
+ 
+         llm_config_data = config.get("llm", {})
+         llm_config = LLMConfig(
+             provider=llm_config_data.get("provider", "openrouter"),
+             model=llm_config_data.get("model", "openai/gpt-4.1")
+         )
  
          simulation_result = None
```

**Chunk 2**
Lines added: 3, lines removed: undefined

```diff
@@ -1158,4 +1176,7 @@
                      language,
                      port=port,
+                     stt_config=stt_config,
+                     tts_config=tts_config,
+                     llm_config=llm_config,
                  )
              )
```

</details>

</tool-use>

---



---


Checking for linting errors:


---

<tool-use data-tool-type="generic" data-tool-name="read_lints">
<details>
          <summary>Tool use: **read_lints** â€¢ Read lints for 1 file</summary>
      
Lint paths:

- `pense/agent/run_simulation.py`

Lint results

Lint errors for `pense/agent/run_simulation.py`


| Message | Range | Severity |
|-------|-------|----------|
| Import "datetime" is not accessed | 8:22-8:30 | DIAGNOSTIC_SEVERITY_HINT |
| Import "List" is not accessed | 10:25-10:29 | DIAGNOSTIC_SEVERITY_HINT |
| Import "Tuple" is not accessed | 10:41-10:46 | DIAGNOSTIC_SEVERITY_HINT |
| Import "LiveOptions" is not accessed | 13:22-13:33 | DIAGNOSTIC_SEVERITY_HINT |
| Import "ImageFile" is not accessed | 15:27-15:36 | DIAGNOSTIC_SEVERITY_HINT |
| Import "dataclass" is not accessed | 16:25-16:34 | DIAGNOSTIC_SEVERITY_HINT |
| Import "FunctionSchema" is not accessed | 45:54-45:68 | DIAGNOSTIC_SEVERITY_HINT |
| Import "ToolsSchema" is not accessed | 46:51-46:62 | DIAGNOSTIC_SEVERITY_HINT |
| Import "AggregatedTextFrame" is not accessed | 53:5-53:24 | DIAGNOSTIC_SEVERITY_HINT |
| Import "LLMContextFrame" is not accessed | 54:5-54:20 | DIAGNOSTIC_SEVERITY_HINT |
| Import "StopFrame" is not accessed | 55:5-55:14 | DIAGNOSTIC_SEVERITY_HINT |
| Import "BotStartedSpeakingFrame" is not accessed | 62:5-62:28 | DIAGNOSTIC_SEVERITY_HINT |
| Import "BotStoppedSpeakingFrame" is not accessed | 63:5-63:28 | DIAGNOSTIC_SEVERITY_HINT |
| Import "InputAudioRawFrame" is not accessed | 66:5-66:23 | DIAGNOSTIC_SEVERITY_HINT |
| Import "LLMMessagesAppendFrame" is not accessed | 68:5-68:27 | DIAGNOSTIC_SEVERITY_HINT |
| Import "LLMFullResponseEndFrame" is not accessed | 70:5-70:28 | DIAGNOSTIC_SEVERITY_HINT |
| Import "TextFrame" is not accessed | 71:5-71:14 | DIAGNOSTIC_SEVERITY_HINT |
| Import "Frame" is not accessed | 74:5-74:10 | DIAGNOSTIC_SEVERITY_HINT |
| Import "InterruptionFrame" is not accessed | 75:5-75:22 | DIAGNOSTIC_SEVERITY_HINT |
| Import "CartesiaTTSService" is not accessed | 88:43-88:61 | DIAGNOSTIC_SEVERITY_HINT |
| Import "DeepgramSTTService" is not accessed | 89:43-89:61 | DIAGNOSTIC_SEVERITY_HINT |
| Import "FunctionCallParams" is not accessed | 90:42-90:60 | DIAGNOSTIC_SEVERITY_HINT |
| Function "on_user_turn_audio_data" is not accessed | 864:15-864:38 | DIAGNOSTIC_SEVERITY_HINT |
| "buffer" is not accessed | 864:39-864:45 | DIAGNOSTIC_SEVERITY_HINT |
| Function "on_bot_turn_audio_data" is not accessed | 873:15-873:37 | DIAGNOSTIC_SEVERITY_HINT |
| "buffer" is not accessed | 873:38-873:44 | DIAGNOSTIC_SEVERITY_HINT |
| Function "on_connected" is not accessed | 882:15-882:27 | DIAGNOSTIC_SEVERITY_HINT |
| "transport" is not accessed | 882:28-882:37 | DIAGNOSTIC_SEVERITY_HINT |
| "client" is not accessed | 882:39-882:45 | DIAGNOSTIC_SEVERITY_HINT |
| Function "on_disconnected" is not accessed | 893:15-893:30 | DIAGNOSTIC_SEVERITY_HINT |
| "transport" is not accessed | 893:31-893:40 | DIAGNOSTIC_SEVERITY_HINT |
| "client" is not accessed | 893:42-893:48 | DIAGNOSTIC_SEVERITY_HINT |
| Function "handle_transcript_update" is not accessed | 898:15-898:39 | DIAGNOSTIC_SEVERITY_HINT |
| "processor" is not accessed | 898:40-898:49 | DIAGNOSTIC_SEVERITY_HINT |


</details>
</tool-use>

---



---


Verifying the changes:


---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: pense/agent/run_simulation.py</summary>

</details>
</tool-use>

---



---





---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: pense/agent/run_simulation.py</summary>

</details>
</tool-use>

---



---


## Summary

Modified `run_single_simulation_task` in `pense/agent/run_simulation.py` to:

1. Extract STT, TTS, and LLM configs from the config JSON (with defaults if missing)
2. Create `STTConfig`, `TTSConfig`, and `LLMConfig` objects from the config data
3. Pass these configs to `start_bot`

The changes are at lines 1151-1167. The code now:
- Extracts `stt`, `tts`, and `llm` from the config dict
- Uses defaults if not provided:
  - STT: `provider` defaults to `"deepgram"`
  - TTS: `provider` defaults to `"google"`, `instructions` is optional
  - LLM: `provider` defaults to `"openrouter"`, `model` defaults to `"openai/gpt-4.1"`
- Passes all three configs to `start_bot` (lines 1178-1180)

You can now configure STT, TTS, and LLM providers in your config JSON like this:

```json
{
  "stt": {
    "provider": "deepgram"
  },
  "tts": {
    "provider": "google",
    "instructions": "optional instructions"
  },
  "llm": {
    "provider": "openrouter",
    "model": "openai/gpt-4.1"
  }
}
```

If these sections are omitted, the defaults above will be used.

---

_**User (2026-01-15 01:14Z)**_

update @README.md with this info about config

---

_**Agent (model composer-1, mode Agent)**_



---


Updating README.md to document STT, TTS, and LLM configuration in the config JSON for agent simulations.


---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: README.md</summary>

</details>
</tool-use>

---



---


Updating README.md to include STT, TTS, and LLM configuration options:


---

<tool-use data-tool-type="write" data-tool-name="search_replace">

<details><summary>Tool use: **search_replace** â€¢ Edit file: README.md</summary>

**Chunk 1**
Lines added: 10, lines removed: undefined

```diff
@@ -840,4 +840,14 @@
  {
    "system_prompt": "You are a helpful nurse speaking to a pregnant mother who has come for an Antenatal visit (ANC visit).\n\nYou are helping her with filling the ANC visit form which has the following questions:\n\n1: Name of patient (string)\n2: Address (string)\n3: Telephone (number)\n\nYour goal is to get the answer for all these questions from the user. Ask the questions sequentially, one at a time. Make sure to always speak out the next question for the user. They don't know what the next question will be. It is your responsibility to ask them the next question.\n\nDo not repeat the user's answer back to them.\n\nExcept for the questions where a type has been explicitly given beside it, the rest of the questions are boolean questions (yes/no).\n\nIf the user gives an answer that is not valid for a question, then, don't call the &#96;plan_next_question&#96; tool at all.\n\nOnly if the user gives a valid answer to a question, then, call the &#96;plan_next_question&#96; tool.\n\nOnce all the questions have been answered, end the call by calling the &#96;end_call&#96; tool immediately without asking or saying anything else to the user.\n\n# Important instructions\nFor each field, you must make sure that you get valid and complete answers from the user.\n\nName: the full name including both the first name and last name (users might have initials as part of their name - don't ask them to expand it)\nAddress: the full address of the user's specific place of residence\nTelephone: must be a valid 10-digit phone number (don't bug the user to say the number in 10 digits or without spaces or without hyphens or to repeat it as long you can infer the number from your message, irrespective of whatever format it may have been given in - asking for repeating information that is already clear is not a good user experience)\n\nUntil you get a valid and complete response for a specific question from the user, keep probing for more details until you have extracted all the details required to meet the criteria of completeness for that question.\n\nFor the boolean questions, just look for whether the user has that symptom or not. If the user is not able to give a definitive answer to any the boolean questions, try probing once to help them arrive at a definitive answer. If they are still not able to give a definitive true/false answer, mark that response as null.\n\n# Skipping already answered questions\nIt is possible that even though you have asked a particular question, the user's response may end up answering some of the future questions you were going to ask. If the user's response already definitively answers those questions, then, don't repeat those questions again and skip them to move to the next unanswered question.\n\nAfter every valid and complete response given by the user to a question, call the &#96;plan_next_question&#96; tool with the indices of the questions in the list of questions above that the user's response has already answered and the index of the next unanswered question that you are going to ask.\n\nIf the user's response only answers the exact question you asked, then, call &#96;plan_next_question&#96; with &#96;questions_answered&#96; as &#96;[&lt;index_of_that_question&gt;]&#96; and &#96;next_unanswered_question_index&#96; as the index of the next unanswered question based on the conversation history so far.\n\nIf the user's response answers more questions beyond the question you asked, then, call &#96;plan_next_question&#96; with &#96;questions_answered&#96; as &#96;[&lt;index_of_the_first_question_answered&gt;, &lt;index_of_the_second_question_answered&gt;, ....]&#96; and &#96;next_unanswered_question_index&#96; as the index of the next unanswered question based on the conversation history so far.\n\nIf the user's response answers some other question from the form but not the question you asked, then, call &#96;plan_next_question&#96; with &#96;questions_answered&#96; as &#96;[&lt;index_of_the_question_answered&gt;]&#96; and &#96;next_unanswered_question_index&#96; as the index of the question you had originally asked but the user did not answer.\n\nIf the user's response is completely irrelevant to any of the questions in the form, don't call this tool and steer the user back to the conversation.\n\nUse the same index values as mentioned in the list above: from 1-22. So, 1-indexed. Not, 0-indexed.\n\n# Ensuring completion of all questions\n- If the user insists on skipping any question when you asked it, make sure to ask it again later. Before ending the call, make sure to ask all the questions that you asked. Only when all the questions have been asked and answered, then, call the &#96;end_call&#96; tool.\n\n# Style\n- Keep the conversation clear, warm, friendly and empathetic. It should feel like a natural and realistic conversation between a nurse and a mother who is pregnant. Make sure each question that you ask is concise and to the point.\n- Speak in an empathetic, friendly tone like a nurse at a government hospital.\n- Always stay gender neutral and don't say anything that might indicate any gender or name for you or anthropomorphise you in any way.\n", // prompt for the voice agent
+   "stt": {
+     "provider": "google" // optional: STT provider to use. Supported: deepgram, google, openai, cartesia, smallest, elevenlabs, sarvam. Default: google
+   },
+   "tts": {
+     "provider": "google" // optional: TTS provider to use. Supported: cartesia, google, openai, smallest, elevenlabs, sarvam. Default: google
+   },
+   "llm": {
+     "provider": "openrouter", // optional: LLM provider to use. Supported: openai, openrouter. Default: openrouter
+     "model": "openai/gpt-4.1" // optional: model name. For openai provider, use OpenAI model names (e.g., "gpt-4.1", "gpt-4o"). For openrouter provider, use OpenRouter model names (e.g., "openai/gpt-4.1", "anthropic/claude-3-opus"). Default: openai/gpt-4.1
+   },
    "tools": [
      {
```

</details>

</tool-use>

---

<tool-use data-tool-type="write" data-tool-name="search_replace">

<details><summary>Tool use: **search_replace** â€¢ Edit file: README.md</summary>

**Chunk 1**
Lines added: 28, lines removed: 3

```diff
@@ -913,13 +913,38 @@
  &#96;&#96;&#96;
  
- The voice agent is defined in &#96;pense/agent/bot.py&#96;. For now, the default configuration of the bot uses Deepgram for STT, OpenAI for LLM, and Google for TTS. You can configure the bot to use different providers for STT, LLM, and TTS by modifying the &#96;STTConfig&#96;, &#96;LLMConfig&#96;, and &#96;TTSConfig&#96; classes in &#96;pense/agent/bot.py&#96;. We will soon add support for changing the configuration for each provider for each component to override the defaults.
+ You can configure the STT, TTS, and LLM providers directly in the config JSON file using the &#96;stt&#96;, &#96;tts&#96;, and &#96;llm&#96; sections. If these sections are omitted, the defaults are Google for STT, Google for TTS, and OpenRouter for LLM.
+ 
+ **Supported Providers:**
+ 
+ - **STT**: deepgram, google, openai, elevenlabs, sarvam, cartesia, smallest
+ - **TTS**: cartesia, google, openai, smallest, elevenlabs, sarvam
+ - **LLM**: openrouter, openai
  
  Set the required environment variables for the providers you want to use:
  
  &#96;&#96;&#96;bash
- # For the default configuration (Deepgram STT + OpenAI LLM + Google TTS)
+ # For Deepgram STT
  export DEEPGRAM_API_KEY=your_key
- export OPENAI_API_KEY=your_key
+ 
+ # For Google STT/TTS
  export GOOGLE_APPLICATION_CREDENTIALS=/path/to/credentials.json
+ 
+ # For OpenAI STT/LLM/TTS
+ export OPENAI_API_KEY=your_key
+ 
+ # For OpenRouter LLM
+ export OPENROUTER_API_KEY=your_key
+ 
+ # For Cartesia STT/TTS
+ export CARTESIA_API_KEY=your_key
+ 
+ # For ElevenLabs STT/TTS
+ export ELEVENLABS_API_KEY=your_key
+ 
+ # For Sarvam STT/TTS
+ export SARVAM_API_KEY=your_key
+ 
+ # For Smallest STT/TTS
+ export SMALLEST_API_KEY=your_key
  &#96;&#96;&#96;
  
```

</details>

</tool-use>

---



---





---

<tool-use data-tool-type="generic" data-tool-name="read_lints">
<details>
          <summary>Tool use: **read_lints** â€¢ Read lints for 1 file</summary>
      
Lint paths:

- `README.md`

Lint results


**No lint errors found**
</details>
</tool-use>

---



---


Updated README.md with STT, TTS, and LLM configuration details. Changes:

1. Added `stt`, `tts`, and `llm` sections to the example JSON config with comments explaining supported providers and defaults.
2. Updated the text to state that providers can be configured directly in the config JSON (removed the outdated note about modifying classes).
3. Expanded the environment variables section to list all supported providers and their required API keys.

The README now documents that users can configure STT, TTS, and LLM providers in the config JSON, with defaults if omitted (Google for STT/TTS, OpenRouter for LLM).

---

_**User (2026-01-15 01:14Z)**_

s speak in hindi. You must generate values like numbers, proper nouns, etc. in such a way that they can compatible with text-to-speech generation systems (e.g. write a phone number as individual digits instead of a full string or an email address like firstname.lastname@example.com as 'firstname dot lastname at example dot com') without ever mentioning in the generation that you are doing so for the TTS system..\n\nBegin the conversation by saying 'Hello' to the agent."}] at 0.00s
2026-01-15 10:20:46.774 | DEBUG    | [EVAL-SYS] | OpenAILLMService#0: Generating chat from universal context [{'role': 'system', 'content': "You are a user speaking to an agent. This is your persona:\n\nYou are a mother; name is Geeta Prasad, 39 years old lives at Flat 302, Sri Venkateshwara Nilaya, near Hanuman Temple, Indiranagar. Phone number is plus nine one, nine eight triple three, forty-seven twenty-nine zero; never had a stillbirth or a baby who died soon after birth, but has had one baby who died on the third day after delivery; never had three or more miscarriages in a row; in her last pregnancy she wasn't admitted for high blood pressure or eclampsia; only carrying one baby as per the scan; blood group is O positive, so there are no Rh-related issues; did experience light vaginal spotting once during this pregnancy but otherwise no pelvic mass or complications; uncertain about her exact blood-pressure reading, but recalls that it was around 150/95 mmHg at booking; does not have diabetes, heart disease, kidney disease, or epilepsy; does have asthma and uses an inhaler daily; has never had tuberculosis or any other serious medical condition; longer drinks alcohol or uses substances, having stopped completely after learning she was pregnant; is very shy and reserved and uses short answers to questions\n\nYour gender is female.\n\nThe following scenario will be played out: the mother answers all the questions and completes the form, don't ask any further questions after the form is filled. Make sure to respond to the agent to match the given scenario as per the given persona for you. You always speak in hindi. You must generate values like numbers, proper nouns, etc. in such a way that they can compatible with text-to-speech generation systems (e.g. write a phone number as individual digits instead of a full string or an email address like firstname.lastname@example.com as 'firstname dot lastname at example dot com') without ever mentioning in the generation that you are doing so for the TTS system..\n\nBegin the conversation by saying 'Hello' to the agent."}]
2026-01-15 10:20:46.911 | DEBUG    | [EVAL-SYS] | ðŸ§  OpenAILLMService#0 â†’ LLM START RESPONSE at 0.00s
2026-01-15 10:20:47.757 | DEBUG    | [EVAL-SYS] | ðŸ§  OpenAILLMService#0 â†’ LLM GENERATING: 'Nam' at 0.98s
2026-01-15 10:20:47.757 | DEBUG    | [EVAL-SYS] | ðŸ§  OpenAILLMService#0 â†’ LLM GENERATING: 'aste' at 0.99s
2026-01-15 10:20:47.757 | DEBUG    | [EVAL-SYS] | ðŸ§  OpenAILLMService#0 â†’ LLM GENERATING: '.' at 0.99s
2026-01-15 10:20:47.758 | DEBUG    | [EVAL-SYS] | ðŸ§  OpenAILLMService#0 â†’ LLM END RESPONSE at 0.99s
2026-01-15 10:20:47.758 | DEBUG    | [EVAL-SYS] | GoogleTTSService#1: Generating TTS [Namaste.]
2026-01-15 10:20:48.239 | DEBUG    | [EVAL-SYS] | Bot started speaking
2026-01-15 10:20:48.246 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#0(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.247 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#0(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.247 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.248 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.281 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#2(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.282 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#2(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.299 | INFO     | [EVAL-SYS] | [94m[User][0m: Namaste.[0m
2026-01-15 10:20:48.322 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#3(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.323 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#3(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.361 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#4(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.362 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#4(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.402 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#5(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.403 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#5(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.442 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#6(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.443 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#6(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.483 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#7(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.484 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#7(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.524 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#8(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.525 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#8(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.562 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#9(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.562 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#9(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.602 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#10(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.603 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#10(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.641 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#11(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.642 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#11(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.682 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#12(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.683 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#12(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.722 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#13(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.723 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#13(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.762 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#14(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.763 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#14(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.805 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#15(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.806 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#15(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.846 | DEBUG    | [BOT-SYS] | User started speaking
2026-01-15 10:20:48.846 | DEBUG    | [BOT-SYS] | PipelineTask#0: received interruption task frame InterruptionTaskFrame#0
2026-01-15 10:20:48.847 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#1(message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'})
2026-01-15 10:20:48.847 | INFO     | [BOT-SYS] | input bot frame: VADUserStartedSpeakingFrame#0
2026-01-15 10:20:48.847 | INFO     | [BOT-SYS] | input bot frame: UserStartedSpeakingFrame#0
2026-01-15 10:20:48.848 | INFO     | [BOT-SYS] | input bot frame: InterruptionFrame#0
2026-01-15 10:20:48.848 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#0
2026-01-15 10:20:48.848 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#16(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.849 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#1(message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'})
2026-01-15 10:20:48.849 | INFO     | [BOT-SYS] | output bot frame: VADUserStartedSpeakingFrame#0
2026-01-15 10:20:48.849 | INFO     | [BOT-SYS] | output bot frame: UserStartedSpeakingFrame#0
2026-01-15 10:20:48.850 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#0(message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'})
2026-01-15 10:20:48.852 | INFO     | [BOT-SYS] | output bot frame: InterruptionFrame#0
2026-01-15 10:20:48.853 | INFO     | [BOT-SYS] | output bot frame: UserSpeakingFrame#0
2026-01-15 10:20:48.853 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#16(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.853 | WARNING  | [BOT-SYS] | Frame type <class 'pipecat.frames.frames.InterruptionFrame'> is not serializable
2026-01-15 10:20:48.883 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#2
2026-01-15 10:20:48.883 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#17(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.885 | INFO     | [BOT-SYS] | output bot frame: UserSpeakingFrame#2
2026-01-15 10:20:48.885 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#17(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.925 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#4
2026-01-15 10:20:48.925 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#18(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.926 | INFO     | [BOT-SYS] | output bot frame: UserSpeakingFrame#4
2026-01-15 10:20:48.926 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#18(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.964 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#6
2026-01-15 10:20:48.964 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#19(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:48.965 | INFO     | [BOT-SYS] | output bot frame: UserSpeakingFrame#6
2026-01-15 10:20:48.965 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#19(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:49.003 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#8
2026-01-15 10:20:49.003 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#20(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:49.004 | INFO     | [BOT-SYS] | output bot frame: UserSpeakingFrame#8
2026-01-15 10:20:49.004 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#20(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:49.011 | DEBUG    | [BOT-SYS] | Received response: type='events' data=EventsData(event_type=None, timestamp=None, signal_type='START_SPEECH', occured_at=1768452649.0263512)
2026-01-15 10:20:49.011 | DEBUG    | [BOT-SYS] | VAD Signal: START_SPEECH, Occurred at: 1768452649.0263512
2026-01-15 10:20:49.011 | DEBUG    | [BOT-SYS] | User started speaking
2026-01-15 10:20:49.046 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#10
2026-01-15 10:20:49.046 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#21(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:49.048 | INFO     | [BOT-SYS] | output bot frame: UserSpeakingFrame#10
2026-01-15 10:20:49.048 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#21(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:49.087 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#12
2026-01-15 10:20:49.087 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#22(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:49.089 | INFO     | [BOT-SYS] | output bot frame: UserSpeakingFrame#12
2026-01-15 10:20:49.090 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#22(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:49.128 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#14
2026-01-15 10:20:49.128 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#23(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:49.131 | INFO     | [BOT-SYS] | output bot frame: UserSpeakingFrame#14
2026-01-15 10:20:49.131 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#23(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:49.165 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#16
2026-01-15 10:20:49.165 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#24(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:49.168 | INFO     | [BOT-SYS] | output bot frame: UserSpeakingFrame#16
2026-01-15 10:20:49.168 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#24(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:49.206 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#18
2026-01-15 10:20:49.206 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#25(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:49.208 | INFO     | [BOT-SYS] | output bot frame: UserSpeakingFrame#18
2026-01-15 10:20:49.208 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#25(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:49.245 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#20
2026-01-15 10:20:49.245 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#26(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:49.247 | INFO     | [BOT-SYS] | output bot frame: UserSpeakingFrame#20
2026-01-15 10:20:49.247 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#26(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:49.286 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#22
2026-01-15 10:20:49.286 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#27(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:49.288 | INFO     | [BOT-SYS] | output bot frame: UserSpeakingFrame#22
2026-01-15 10:20:49.288 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#27(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:49.326 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#24
2026-01-15 10:20:49.326 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#28(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:49.327 | INFO     | [BOT-SYS] | output bot frame: UserSpeakingFrame#24
2026-01-15 10:20:49.328 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#28(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:20:49.712 | DEBUG    | [EVAL-SYS] | Bot stopped speaking
2026-01-15 10:20:49.712 | INFO     | [EVAL] | Audio data received - user
2026-01-15 10:20:49.712 | INFO     | [EVAL] | [user] turn index: 0
2026-01-15 10:20:49.713 | INFO     | [EVAL-SYS] | [92mCreating new audio file at /Users/aman/Documents/repos/artpark/voice-ai/agentloop/test/outputs/agent_simulation_output_4/simulation_persona_1_scenario_1/audios/0_user.wav[0m
2026-01-15 10:20:49.827 | WARNING  | [BOT-SYS] | Forcing user stopped speaking due to timeout receiving audio frame!
2026-01-15 10:20:49.827 | DEBUG    | [BOT-SYS] | User stopped speaking
2026-01-15 10:20:49.827 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#2(message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'})
2026-01-15 10:20:49.827 | INFO     | [BOT-SYS] | input bot frame: UserStoppedSpeakingFrame#0
2026-01-15 10:20:49.828 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#2(message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'})
2026-01-15 10:20:49.828 | INFO     | [BOT-SYS] | output bot frame: UserStoppedSpeakingFrame#0
2026-01-15 10:20:49.829 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#1(message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'})


when stt is sarvam, it is getting stuck - logs are added above

@bot.py (116-120) 

figure out why

@pense/agent/run_simulation.py 

---

_**Agent (model composer-1, mode Agent)**_



---


Investigating why Sarvam STT gets stuck. Checking how Sarvam STT is configured in `bot.py` and how it's used in the simulation.


---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: pense/agent/bot.py</summary>

</details>
</tool-use>

---

<tool-use data-tool-type="search" data-tool-name="grep">
<details>
<summary>Tool use: **grep** â€¢ Grep for "sarvam|Sarvam" in "pense/agent" â€¢ 26 matches</summary>

Output mode: content


| File | Content | Line |
|------|------|------|
| `pense/agent/bot.py` | `from pipecat.services.sarvam.stt import SarvamSTTService` | L67 |
| `pense/agent/bot.py` | `from pipecat.services.sarvam.tts import SarvamTTSService` | L68 |
| `pense/agent/bot.py` | `"deepgram", "google", "openai", "cartesia", "groq", "elevenlabs", "sarvam"` | L119 |
| `pense/agent/bot.py` | `"cartesia", "google", "openai", "groq", "elevenlabs", "sarvam"` | L125 |
| `pense/agent/bot.py` | `elif stt_config.provider == "sarvam":` | L192 |
| `pense/agent/bot.py` | `stt = SarvamSTTService(` | L198 |
| `pense/agent/bot.py` | `api_key=os.getenv("SARVAM_API_KEY"),` | L199 |
| `pense/agent/bot.py` | `params=SarvamSTTService.InputParams(language=stt_language.value),` | L200 |
| `pense/agent/bot.py` | `elif tts_config.provider == "sarvam":` | L270 |
| `pense/agent/bot.py` | `tts = SarvamTTSService(` | L276 |
| `pense/agent/bot.py` | `api_key=os.getenv("SARVAM_API_KEY"),` | L277 |
| `pense/agent/bot.py` | `params=SarvamTTSService.InputParams(language=tts_language),` | L280 |
| `pense/agent/test.py` | `from pipecat.services.sarvam.stt import SarvamSTTService` | L51 |
| `pense/agent/test.py` | `from pipecat.services.sarvam.tts import SarvamTTSService` | L52 |
| `pense/agent/test.py` | `"deepgram", "google", "openai", "elevenlabs", "sarvam", "cartesia", "smallest"` | L103 |
| `pense/agent/test.py` | `"sarvam",` | L117 |
| `pense/agent/test.py` | `elif stt_config.provider == "sarvam":` | L225 |
| `pense/agent/test.py` | `sarvam_lang = (` | L226 |
| `pense/agent/test.py` | `stt = SarvamSTTService(` | L231 |
| `pense/agent/test.py` | `api_key=os.getenv("SARVAM_API_KEY"),` | L232 |
| `pense/agent/test.py` | `params=SarvamSTTService.InputParams(language=sarvam_lang.value),` | L233 |
| `pense/agent/test.py` | `elif tts_config.provider == "sarvam":` | L309 |
| `pense/agent/test.py` | `sarvam_lang = (` | L310 |
| `pense/agent/test.py` | `tts = SarvamTTSService(` | L315 |
| `pense/agent/test.py` | `api_key=os.getenv("SARVAM_API_KEY"),` | L316 |
| `pense/agent/test.py` | `params=SarvamTTSService.InputParams(language=sarvam_lang),` | L319 |


</details>
</tool-use>

---



---


Checking the Sarvam STT configuration and how it handles audio:


---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: pense/agent/bot.py</summary>

</details>
</tool-use>

---

<tool-use data-tool-type="search" data-tool-name="codebase_search">
<details>
                <summary>Tool use: **codebase_search** â€¢ Searched codebase "How does SarvamSTTService handle audio frames and what are its requirements?" â€¢ **12** results</summary>
            
| File | Lines |
|------|-------|
| `pense/integrations/smallest/stt.py` | L33-386 |
| `pense/stt/eval.py` | L238-646 |
| `pense/integrations/smallest/stt.py` | L31-386 |
| `pense/stt/eval.py` | L77-238 |
| `pense/agent/bot.py` | L131-575 |
| `pense/integrations/smallest/tts.py` | L70-277 |
| `pense/stt/eval.py` | L56 |
| `pense/agent/bot.py` | L58 |
| `pense/agent/test.py` | L141-513 |
| `pense/tts/eval.py` | L335-623 |
| `README.md` | L87-151 |
| `pense/agent/run_simulation.py` | L183-463 |

</details>
</tool-use>

---



---


Checking if Sarvam STT requires additional configuration parameters, especially sample_rate:


---

<tool-use data-tool-type="search" data-tool-name="grep">
<details>
<summary>Tool use: **grep** â€¢ Grep for "sample_rate|sampleRate" in "pense/agent/bot.py" â€¢ 3 matches</summary>

Output mode: content


| File | Content | Line |
|------|------|------|
| `pense/agent/bot.py` | `sample_rate=16000,` | L170 |
| `pense/agent/bot.py` | `audio_in_sample_rate=16000,` | L536 |
| `pense/agent/bot.py` | `audio_out_sample_rate=16000,` | L537 |


</details>
</tool-use>

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: pense/agent/bot.py</summary>

</details>
</tool-use>

---



---


Checking how Sarvam STT is configured in the working STT eval code to see if sample_rate is needed:


---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: pense/stt/eval.py</summary>

</details>
</tool-use>

---

<tool-use data-tool-type="search" data-tool-name="web_search">
<details>
            <summary>Tool use: **web_search** â€¢ Searched web `pipecat SarvamSTTService sample_rate parameter requirements` â€¢ **1** results</summary>
        
| Title | URL | Chunk |
|-------|-----|-------|
| Web Search Results |  | To address the issue where the speech-to-text (STT) system, Sarvam, is getting stuck during the simulation, we need to investigate the relevant sections of the code and logs. Here's a step-by-step approach to diagnose and potentially resolve the problem:<br/><br/>1. **Review the Logs:**<br/>   - Examine the logs you've provided to identify any error messages, warnings, or patterns that indicate where the process is failing. Look for timestamps, function calls, and any exceptions that might be raised.<br/><br/>2. **Inspect `bot.py` (Lines 116-120):**<br/>   - Navigate to the specified lines in `bot.py` to understand what operations are being performed. Pay close attention to any interactions with the STT system, especially Sarvam.<br/>   - Check for any conditions or loops that might cause the program to hang or get stuck.<br/><br/>3. **Analyze `pense/agent/run_simulation.py`:**<br/>   - Review the code in `run_simulation.py` to see how the STT configuration is being set up and utilized.<br/>   - Ensure that the STT system is correctly initialized and that all necessary parameters are being passed.<br/><br/>4. **Verify STT Configuration:**<br/>   - Confirm that the configuration for Sarvam in your JSON config file is correct. This includes checking the provider name, API keys, and any other required settings.<br/>   - Ensure that the configuration aligns with the expected structure in your codebase.<br/><br/>5. **Test with Different STT Providers:**<br/>   - If possible, switch to a different STT provider (e.g., Google) to see if the issue persists. This can help determine if the problem is specific to Sarvam or a more general issue in the code.<br/><br/>6. **Check for Updates or Known Issues:**<br/>   - Look for any updates or known issues related to the Sarvam STT system. There might be patches or workarounds available.<br/><br/>7. **Debugging:**<br/>   - Add debug statements around the areas where the code interacts with the STT system to pinpoint where it might be getting stuck.<br/>   - Use tools like breakpoints or profilers to monitor the execution flow.<br/><br/>By systematically following these steps, you should be able to identify the root cause of the issue with the Sarvam STT system and implement a solution. |

</details>
</tool-use>

---



---


Checking the Sarvam STT service initialization and whether it needs a sample_rate parameter:


---

<tool-use data-tool-type="search" data-tool-name="grep">
<details>
<summary>Tool use: **grep** â€¢ Grep for "class SarvamSTTService|def __init__" in "pense" â€¢ 24 matches</summary>

Output mode: content


| File | Content | Line |
|------|------|------|
| `pense/agent/bot.py` | `def __init__(` | L427 |
| `pense/agent/bot.py` | `def __init__(self):` | L457 |
| `pense/agent/bot.py` | `def __init__(self):` | L468 |
| `pense/agent/run_simulation.py` | `def __init__(` | L188 |
| `pense/agent/run_simulation.py` | `def __init__(` | L468 |
| `pense/agent/run_simulation.py` | `def __init__(self, stt_outputs: list[str], rtvi_adapter):` | L503 |
| `pense/agent/run_simulation.py` | `def __init__(` | L534 |
| `pense/agent/run_simulation.py` | `def __init__(self, max_turns: int, rtvi_adapter, context: LLMContext):` | L553 |
| `pense/agent/run_simulation.py` | `def __init__(self, tool_calls: list[dict], context: LLMContext):` | L581 |
| `pense/stt/eval.py` | `def __init__(self, position: str):` | L101 |
| `pense/stt/eval.py` | `def __init__(` | L276 |
| `pense/stt/eval.py` | `def __init__(` | L345 |
| `pense/stt/eval.py` | `def __init__(self):` | L594 |
| `pense/llm/run_simulation.py` | `def __init__(self, max_turns: int):` | L49 |
| `pense/llm/run_simulation.py` | `def __init__(` | L94 |
| `pense/llm/run_tests.py` | `def __init__(` | L43 |
| `pense/utils.py` | `def __init__(` | L131 |
| `pense/tts/eval.py` | `def __init__(self):` | L112 |
| `pense/tts/eval.py` | `def __init__(self):` | L126 |
| `pense/tts/eval.py` | `def __init__(self):` | L149 |
| `pense/tts/eval.py` | `def __init__(` | L376 |
| `pense/tts/eval.py` | `def __init__(self):` | L574 |
| `pense/integrations/smallest/tts.py` | `def __init__(` | L83 |
| `pense/integrations/smallest/stt.py` | `def __init__(` | L77 |


</details>
</tool-use>

---

<tool-use data-tool-type="search" data-tool-name="codebase_search">
<details>
                <summary>Tool use: **codebase_search** â€¢ Searched codebase "What parameters does SarvamSTTService constructor accept and does it need sample_rate?" â€¢ **13** results</summary>
            
| File | Lines |
|------|-------|
| `pense/agent/test.py` | L141-513 |
| `pense/stt/eval.py` | L77-238 |
| `pense/agent/bot.py` | L131-575 |
| `pense/integrations/smallest/stt.py` | L31-386 |
| `pense/agent/bot.py` | L129-575 |
| `pense/integrations/smallest/stt.py` | L33-386 |
| `pense/tts/eval.py` | L87-623 |
| `pense/stt/eval.py` | L77-646 |
| `pense/agent/test.py` | L178-513 |
| `pense/integrations/smallest/tts.py` | L66-277 |
| `pense/agent/test.py` | L78-120 |
| `pense/agent/test.py` | L40-80 |
| `README.md` | L898-960 |

</details>
</tool-use>

---



---


Reviewing the logs: the timeout "Forcing user stopped speaking due to timeout receiving audio frame!" suggests Sarvam STT isn't processing audio or returning transcriptions. Checking if Sarvam STT needs special handling for interruptions or connection setup:


---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: pense/agent/run_simulation.py</summary>

</details>
</tool-use>

---

<tool-use data-tool-type="search" data-tool-name="grep">
<details>
<summary>Tool use: **grep** â€¢ Grep for "SarvamSTTService|sarvam" in "pense/agent/run_simulation.py" â€¢ 0 matches</summary>

Output mode: content


_No matches found_

</details>
</tool-use>

---



---


The timeout suggests Sarvam STT isn't processing audio. Checking if Sarvam STT needs a `sample_rate` parameter like Google STT. Reviewing the STTConfig definition and comparing with other providers:


---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: pense/agent/bot.py</summary>

</details>
</tool-use>

---

<tool-use data-tool-type="search" data-tool-name="grep">
<details>
<summary>Tool use: **grep** â€¢ Grep for "groq" in "pense/agent/bot.py" â€¢ 11 matches</summary>

Output mode: content


| File | Content | Line |
|------|------|------|
| `pense/agent/bot.py` | `from pipecat.services.groq.llm import GroqLLMService` | L59 |
| `pense/agent/bot.py` | `from pipecat.services.groq.stt import GroqSTTService` | L60 |
| `pense/agent/bot.py` | `from pipecat.services.groq.tts import GroqTTSService` | L61 |
| `pense/agent/bot.py` | `"deepgram", "google", "openai", "cartesia", "groq", "elevenlabs", "sarvam"` | L119 |
| `pense/agent/bot.py` | `"cartesia", "google", "openai", "groq", "elevenlabs", "sarvam"` | L125 |
| `pense/agent/bot.py` | `elif stt_config.provider == "groq":` | L162 |
| `pense/agent/bot.py` | `stt = GroqSTTService(` | L163 |
| `pense/agent/bot.py` | `api_key=os.getenv("GROQ_API_KEY"),` | L164 |
| `pense/agent/bot.py` | `elif tts_config.provider == "groq":` | L244 |
| `pense/agent/bot.py` | `tts = GroqTTSService(` | L245 |
| `pense/agent/bot.py` | `api_key=os.getenv("GROQ_API_KEY"),` | L246 |


</details>
</tool-use>

---



---


The timeout suggests Sarvam STT isn't processing audio or returning transcriptions. Checking if Sarvam STT needs explicit connection handling or additional parameters. Adding error handling and ensuring proper initialization:


---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: pense/agent/bot.py</summary>

</details>
</tool-use>

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: pense/agent/bot.py</summary>

</details>
</tool-use>

---



---


The timeout suggests Sarvam STT isn't processing audio. Checking if Sarvam STT needs explicit connection handling or additional parameters. Adding logging and verifying the configuration. Checking if Sarvam STT requires a `sample_rate` parameter:


---

<tool-use data-tool-type="write" data-tool-name="search_replace">

<details><summary>Tool use: **search_replace** â€¢ Edit file: pense/agent/bot.py</summary>

**Chunk 1**
Lines added: 1, lines removed: undefined

```diff
@@ -199,4 +199,5 @@
              api_key=os.getenv("SARVAM_API_KEY"),
              params=SarvamSTTService.InputParams(language=stt_language.value),
+             sample_rate=16000,
          )
      elif stt_config.provider == "cartesia":
```

</details>

</tool-use>

---



---


Checking for linting errors and verifying if `sample_rate` is a valid parameter:


---

<tool-use data-tool-type="generic" data-tool-name="read_lints">
<details>
          <summary>Tool use: **read_lints** â€¢ Read lints for 1 file</summary>
      
Lint paths:

- `pense/agent/bot.py`

Lint results

Lint errors for `pense/agent/bot.py`


| Message | Range | Severity |
|-------|-------|----------|
| Import "InterruptionTaskFrame" is not accessed | 12:5-12:26 | DIAGNOSTIC_SEVERITY_HINT |
| Import "LLMRunFrame" is not accessed | 13:5-13:16 | DIAGNOSTIC_SEVERITY_HINT |
| Import "InputAudioRawFrame" is not accessed | 16:5-16:23 | DIAGNOSTIC_SEVERITY_HINT |
| Import "VADUserStartedSpeakingFrame" is not accessed | 17:5-17:32 | DIAGNOSTIC_SEVERITY_HINT |
| Import "VADUserStoppedSpeakingFrame" is not accessed | 18:5-18:32 | DIAGNOSTIC_SEVERITY_HINT |
| Import "InterruptionFrame" is not accessed | 19:5-19:22 | DIAGNOSTIC_SEVERITY_HINT |
| Import "OutputAudioRawFrame" is not accessed | 20:5-20:24 | DIAGNOSTIC_SEVERITY_HINT |
| Import "OutputTransportMessageUrgentFrame" is not accessed | 21:5-21:38 | DIAGNOSTIC_SEVERITY_HINT |
| Import "InputTransportMessageFrame" is not accessed | 22:5-22:31 | DIAGNOSTIC_SEVERITY_HINT |
| Import "create_transport" is not accessed | 43:34-43:50 | DIAGNOSTIC_SEVERITY_HINT |
| Import "GroqLLMService" is not accessed | 59:39-59:53 | DIAGNOSTIC_SEVERITY_HINT |
| Import "GoogleLLMService" is not accessed | 63:41-63:57 | DIAGNOSTIC_SEVERITY_HINT |
| Import "TransportParams" is not accessed | 76:62-76:77 | DIAGNOSTIC_SEVERITY_HINT |
| Code is unreachable | 209:9-215:10 | DIAGNOSTIC_SEVERITY_HINT |
| Code is unreachable | 259:9-261:10 | DIAGNOSTIC_SEVERITY_HINT |
| Code is unreachable | 293:9-299:10 | DIAGNOSTIC_SEVERITY_HINT |
| Function "on_client_connected" is not accessed | 549:15-549:34 | DIAGNOSTIC_SEVERITY_HINT |
| "transport" is not accessed | 549:35-549:44 | DIAGNOSTIC_SEVERITY_HINT |
| "client" is not accessed | 549:46-549:52 | DIAGNOSTIC_SEVERITY_HINT |
| Function "on_client_disconnected" is not accessed | 558:15-558:37 | DIAGNOSTIC_SEVERITY_HINT |
| "transport" is not accessed | 558:38-558:47 | DIAGNOSTIC_SEVERITY_HINT |
| "client" is not accessed | 558:49-558:55 | DIAGNOSTIC_SEVERITY_HINT |
| Function "handle_transcript_update" is not accessed | 563:15-563:39 | DIAGNOSTIC_SEVERITY_HINT |
| "processor" is not accessed | 563:40-563:49 | DIAGNOSTIC_SEVERITY_HINT |
| Function "on_client_ready" is not accessed | 572:15-572:30 | DIAGNOSTIC_SEVERITY_HINT |


</details>
</tool-use>

---



---


No linting errors. The `sample_rate` parameter may help, but the issue likely involves Sarvam STT connection handling. Checking if Sarvam STT needs explicit connection management or if there's an issue with how it processes audio during interruptions. Reviewing the logs more closely:


---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: pense/agent/run_simulation.py</summary>

</details>
</tool-use>

---



---


The timeout suggests Sarvam STT isn't processing audio or returning transcriptions. Added `sample_rate=16000` to match the pipeline. If that doesn't resolve it, the issue may be connection handling or how Sarvam STT processes audio during interruptions.

Checking if Sarvam STT needs explicit connection retry logic or error handling. Verifying the change and adding a comment:


---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: pense/agent/bot.py</summary>

</details>
</tool-use>

---



---


Added `sample_rate=16000` to the Sarvam STT initialization to match the pipeline's audio sample rate. This may resolve the issue if Sarvam STT requires an explicit sample rate.

## Summary

The timeout "Forcing user stopped speaking due to timeout receiving audio frame!" suggests Sarvam STT isn't processing audio or returning transcriptions. Added `sample_rate=16000` to the Sarvam STT initialization in `bot.py` (line 201) to match the pipeline's audio configuration.

**Changes made:**
- Added `sample_rate=16000` parameter to `SarvamSTTService` initialization in `pense/agent/bot.py`

**If the issue persists**, possible causes:
1. Connection handling: Sarvam STT may need explicit WebSocket connection management
2. Audio format: There may be a mismatch in audio encoding/format
3. Interruption handling: Sarvam STT may not handle interruptions correctly
4. Service response: The service may not be responding to audio frames

Test with this change. If it still fails, check:
- Sarvam STT WebSocket connection logs
- Whether audio frames are being sent to Sarvam STT
- Whether Sarvam STT is sending transcription frames back

The `sample_rate` parameter should help if Sarvam STT requires an explicit sample rate configuration.

---

_**User (2026-01-15 01:14Z)**_

not working still 

@pense/stt/eval.py the way it is done in eval stt is working - figure out why?

2026-01-15 10:31:04.547 | INFO     | [UNKNOWN-SYS] | Running on port: 8765
2026-01-15 10:31:04.547 | INFO     | [UNKNOWN-SYS] | --------------------------------
2026-01-15 10:31:04.547 | INFO     | [UNKNOWN-SYS] | [33mRunning command[0m: pense --provider sarvam --language english --input-dir /Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english --output-dir /Users/aman/Documents/repos/artpark/voice-ai/agentloop/test/output/stt_output/sarvam --input-file-name stt.csv --debug_count 5 --port 8765
2026-01-15 10:31:04.550 | INFO     | [UNKNOWN-SYS] | Loading audio files: [PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_1_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_1_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_1_english_speak_closer.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_1_english_repeat_same_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_3_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_3_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_5_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_5_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_7_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_7_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_9_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_9_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_9_english_repeat_other_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_11_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_11_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_13_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_13_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_15_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_15_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_17_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_17_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_19_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_19_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_19_english_speak_farther_away.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_21_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_21_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_23_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_23_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_23_english_repeat_same_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_23_english_repeat_other_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_25_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_25_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_27_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_27_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_29_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_29_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_29_english_speak_farther_away.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_29_english_repeat_same_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_31_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_31_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_31_english_speak_closer.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_33_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_33_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_35_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_35_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_35_english_filler_words.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_37_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_37_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_37_english_speak_closer.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_39_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_39_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_41_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_41_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_41_english_filler_words.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_43_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_43_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_43_english_speak_closer.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_45_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_45_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_45_english_speak_closer.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_47_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_47_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_1_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_1_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_3_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_3_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_5_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_5_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_5_english_speak_farther_away.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_7_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_7_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_9_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_9_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_9_english_speak_closer.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_9_english_repeat_other_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_11_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_11_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_13_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_13_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_13_english_repeat_other_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_15_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_15_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_17_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_17_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_19_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_19_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_19_english_speak_farther_away.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_19_english_repeat_same_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_21_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_21_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_21_english_speak_farther_away.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_23_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_23_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_25_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_25_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_27_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_27_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_27_english_filler_words.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_29_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_29_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_31_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_31_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_31_english_speak_farther_away.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_33_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_33_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_33_english_repeat_same_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_35_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_35_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_37_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_37_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_37_english_speak_farther_away.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_39_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_39_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_41_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_41_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_43_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_43_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_45_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_45_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_45_english_repeat_other_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_47_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_47_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_47_english_repeat_other_speaker.wav')]
2026-01-15 10:31:04.550 | INFO     | [UNKNOWN-SYS] | audio_files: [PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_1_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_1_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_1_english_speak_closer.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_1_english_repeat_same_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_3_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_3_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_5_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_5_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_7_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_7_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_9_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_9_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_9_english_repeat_other_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_11_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_11_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_13_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_13_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_15_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_15_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_17_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_17_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_19_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_19_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_19_english_speak_farther_away.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_21_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_21_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_23_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_23_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_23_english_repeat_same_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_23_english_repeat_other_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_25_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_25_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_27_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_27_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_29_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_29_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_29_english_speak_farther_away.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_29_english_repeat_same_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_31_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_31_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_31_english_speak_closer.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_33_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_33_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_35_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_35_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_35_english_filler_words.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_37_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_37_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_37_english_speak_closer.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_39_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_39_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_41_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_41_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_41_english_filler_words.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_43_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_43_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_43_english_speak_closer.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_45_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_45_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_45_english_speak_closer.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_47_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_47_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_1_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_1_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_3_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_3_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_5_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_5_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_5_english_speak_farther_away.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_7_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_7_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_9_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_9_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_9_english_speak_closer.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_9_english_repeat_other_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_11_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_11_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_13_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_13_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_13_english_repeat_other_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_15_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_15_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_17_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_17_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_19_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_19_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_19_english_speak_farther_away.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_19_english_repeat_same_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_21_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_21_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_21_english_speak_farther_away.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_23_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_23_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_25_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_25_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_27_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_27_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_27_english_filler_words.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_29_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_29_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_31_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_31_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_31_english_speak_farther_away.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_33_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_33_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_33_english_repeat_same_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_35_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_35_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_37_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_37_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_37_english_speak_farther_away.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_39_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_39_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_41_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_41_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_43_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_43_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_45_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_45_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_45_english_repeat_other_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_47_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_47_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_47_english_repeat_other_speaker.wav')]
2026-01-15 10:31:04.551 | DEBUG    | [BOT-SYS] | Loading Silero VAD model...
2026-01-15 10:31:04.599 | DEBUG    | [BOT-SYS] | Loaded Silero VAD
2026-01-15 10:31:04.600 | DEBUG    | [BOT-SYS] | Loading Local Smart Turn v3.x model from /Users/aman/Documents/repos/artpark/agentloop/.venv/lib/python3.11/site-packages/pipecat/audio/turn/smart_turn/data/smart-turn-v3.1-cpu.onnx...
2026-01-15 10:31:04.629 | DEBUG    | [BOT-SYS] | Loaded Local Smart Turn v3.x
2026-01-15 10:31:04.644 | DEBUG    | [BOT-SYS] | Linking Pipeline#0::Source -> WebsocketServerInputTransport#0
2026-01-15 10:31:04.644 | DEBUG    | [BOT-SYS] | Linking WebsocketServerInputTransport#0 -> RTVIProcessor#0
2026-01-15 10:31:04.644 | DEBUG    | [BOT-SYS] | Linking RTVIProcessor#0 -> IOLogger#0
2026-01-15 10:31:04.644 | DEBUG    | [BOT-SYS] | Linking IOLogger#0 -> SarvamSTTService#0
2026-01-15 10:31:04.644 | DEBUG    | [BOT-SYS] | Linking SarvamSTTService#0 -> UserTranscriptProcessor#0
2026-01-15 10:31:04.644 | DEBUG    | [BOT-SYS] | Linking UserTranscriptProcessor#0 -> IOLogger#1
2026-01-15 10:31:04.644 | DEBUG    | [BOT-SYS] | Linking IOLogger#1 -> WebsocketServerOutputTransport#0
2026-01-15 10:31:04.644 | DEBUG    | [BOT-SYS] | Linking WebsocketServerOutputTransport#0 -> Pipeline#0::Sink
2026-01-15 10:31:04.645 | DEBUG    | [BOT-SYS] | Linking PipelineTask#0::Source -> Pipeline#0
2026-01-15 10:31:04.645 | DEBUG    | [BOT-SYS] | Linking Pipeline#0 -> PipelineTask#0::Sink
2026-01-15 10:31:04.645 | INFO     | [BOT-SYS] | STT bot ready and waiting for connections
2026-01-15 10:31:04.645 | DEBUG    | [BOT-SYS] | Runner PipelineRunner#0 started running PipelineTask#0
2026-01-15 10:31:04.646 | DEBUG    | [BOT-SYS] | PipelineTask#0: Starting. Waiting for StartFrame#0 to reach the end of the pipeline...
2026-01-15 10:31:04.646 | DEBUG    | [BOT-SYS] | PipelineTask#0::Source â†’ Pipeline#0: StartFrame id: 35, name: 'StartFrame#0', metadata: {}, audio_in_sample_rate: 16000, audio_out_sample_rate: 24000, allow_interruptions: True, enable_metrics: True, enable_tracing: True, enable_usage_metrics: False, interruption_strategies: [], report_only_initial_ttfb: False at 0.00s
2026-01-15 10:31:04.646 | DEBUG    | [BOT-SYS] | Pipeline#0::Source â†’ WebsocketServerInputTransport#0: StartFrame id: 35, name: 'StartFrame#0', metadata: {}, audio_in_sample_rate: 16000, audio_out_sample_rate: 24000, allow_interruptions: True, enable_metrics: True, enable_tracing: True, enable_usage_metrics: False, interruption_strategies: [], report_only_initial_ttfb: False at 0.00s
2026-01-15 10:31:04.646 | DEBUG    | [BOT-SYS] | Setting VAD params to: confidence=0.7 start_secs=0.2 stop_secs=0.2 min_volume=0.6
2026-01-15 10:31:04.646 | DEBUG    | [BOT-SYS] | Generated new conversation ID: c89d8f47-1ed7-4649-8b45-b173edc3550f
2026-01-15 10:31:04.646 | DEBUG    | [BOT-SYS] | Started tracing for Conversation c89d8f47-1ed7-4649-8b45-b173edc3550f
2026-01-15 10:31:04.646 | DEBUG    | [BOT-SYS] | Started tracing for Turn 1
2026-01-15 10:31:04.646 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: StartFrame id: 35, name: 'StartFrame#0', metadata: {}, audio_in_sample_rate: 16000, audio_out_sample_rate: 24000, allow_interruptions: True, enable_metrics: True, enable_tracing: True, enable_usage_metrics: False, interruption_strategies: [], report_only_initial_ttfb: False at 0.00s
2026-01-15 10:31:04.646 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: SpeechControlParamsFrame id: 36, name: 'SpeechControlParamsFrame#0', metadata: {}, vad_params: confidence=0.7 start_secs=0.2 stop_secs=0.2 min_volume=0.6, turn_params: stop_secs=3 pre_speech_ms=0 max_duration_secs=8 at 0.00s
2026-01-15 10:31:04.646 | INFO     | [BOT-SYS] | Starting websocket server on localhost:8765
2026-01-15 10:31:04.647 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: StartFrame id: 35, name: 'StartFrame#0', metadata: {}, audio_in_sample_rate: 16000, audio_out_sample_rate: 24000, allow_interruptions: True, enable_metrics: True, enable_tracing: True, enable_usage_metrics: False, interruption_strategies: [], report_only_initial_ttfb: False at 0.00s
2026-01-15 10:31:04.647 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: SpeechControlParamsFrame id: 36, name: 'SpeechControlParamsFrame#0', metadata: {}, vad_params: confidence=0.7 start_secs=0.2 stop_secs=0.2 min_volume=0.6, turn_params: stop_secs=3 pre_speech_ms=0 max_duration_secs=8 at 0.00s
2026-01-15 10:31:04.647 | INFO     | [BOT-SYS] | input bot frame: StartFrame#0
2026-01-15 10:31:04.647 | INFO     | [BOT-SYS] | input bot frame: SpeechControlParamsFrame#0
2026-01-15 10:31:04.647 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: StartFrame id: 35, name: 'StartFrame#0', metadata: {}, audio_in_sample_rate: 16000, audio_out_sample_rate: 24000, allow_interruptions: True, enable_metrics: True, enable_tracing: True, enable_usage_metrics: False, interruption_strategies: [], report_only_initial_ttfb: False at 0.00s
2026-01-15 10:31:04.647 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: SpeechControlParamsFrame id: 36, name: 'SpeechControlParamsFrame#0', metadata: {}, vad_params: confidence=0.7 start_secs=0.2 stop_secs=0.2 min_volume=0.6, turn_params: stop_secs=3 pre_speech_ms=0 max_duration_secs=8 at 0.00s
2026-01-15 10:31:04.647 | DEBUG    | [BOT-SYS] | Connecting to Sarvam
2026-01-15 10:31:04.828 | INFO     | [BOT-SYS] | Connected to Sarvam successfully
2026-01-15 10:31:04.828 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: StartFrame id: 35, name: 'StartFrame#0', metadata: {}, audio_in_sample_rate: 16000, audio_out_sample_rate: 24000, allow_interruptions: True, enable_metrics: True, enable_tracing: True, enable_usage_metrics: False, interruption_strategies: [], report_only_initial_ttfb: False at 0.18s
2026-01-15 10:31:04.828 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: SpeechControlParamsFrame id: 36, name: 'SpeechControlParamsFrame#0', metadata: {}, vad_params: confidence=0.7 start_secs=0.2 stop_secs=0.2 min_volume=0.6, turn_params: stop_secs=3 pre_speech_ms=0 max_duration_secs=8 at 0.18s
2026-01-15 10:31:04.828 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: StartFrame id: 35, name: 'StartFrame#0', metadata: {}, audio_in_sample_rate: 16000, audio_out_sample_rate: 24000, allow_interruptions: True, enable_metrics: True, enable_tracing: True, enable_usage_metrics: False, interruption_strategies: [], report_only_initial_ttfb: False at 0.18s
2026-01-15 10:31:04.828 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: SpeechControlParamsFrame id: 36, name: 'SpeechControlParamsFrame#0', metadata: {}, vad_params: confidence=0.7 start_secs=0.2 stop_secs=0.2 min_volume=0.6, turn_params: stop_secs=3 pre_speech_ms=0 max_duration_secs=8 at 0.18s
2026-01-15 10:31:04.828 | INFO     | [BOT-SYS] | output bot frame: StartFrame#0
2026-01-15 10:31:04.828 | INFO     | [BOT-SYS] | output bot frame: SpeechControlParamsFrame#0
2026-01-15 10:31:04.828 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: StartFrame id: 35, name: 'StartFrame#0', metadata: {}, audio_in_sample_rate: 16000, audio_out_sample_rate: 24000, allow_interruptions: True, enable_metrics: True, enable_tracing: True, enable_usage_metrics: False, interruption_strategies: [], report_only_initial_ttfb: False at 0.18s
2026-01-15 10:31:04.828 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: SpeechControlParamsFrame id: 36, name: 'SpeechControlParamsFrame#0', metadata: {}, vad_params: confidence=0.7 start_secs=0.2 stop_secs=0.2 min_volume=0.6, turn_params: stop_secs=3 pre_speech_ms=0 max_duration_secs=8 at 0.18s
2026-01-15 10:31:04.829 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: StartFrame id: 35, name: 'StartFrame#0', metadata: {}, audio_in_sample_rate: 16000, audio_out_sample_rate: 24000, allow_interruptions: True, enable_metrics: True, enable_tracing: True, enable_usage_metrics: False, interruption_strategies: [], report_only_initial_ttfb: False at 0.18s
2026-01-15 10:31:04.829 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: StartFrame id: 35, name: 'StartFrame#0', metadata: {}, audio_in_sample_rate: 16000, audio_out_sample_rate: 24000, allow_interruptions: True, enable_metrics: True, enable_tracing: True, enable_usage_metrics: False, interruption_strategies: [], report_only_initial_ttfb: False at 0.18s
2026-01-15 10:31:04.829 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â† IOLogger#1: OutputTransportReadyFrame id: 37, name: 'OutputTransportReadyFrame#0', metadata: {} at 0.18s
2026-01-15 10:31:04.829 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: SpeechControlParamsFrame id: 36, name: 'SpeechControlParamsFrame#0', metadata: {}, vad_params: confidence=0.7 start_secs=0.2 stop_secs=0.2 min_volume=0.6, turn_params: stop_secs=3 pre_speech_ms=0 max_duration_secs=8 at 0.18s
2026-01-15 10:31:04.829 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: SpeechControlParamsFrame id: 36, name: 'SpeechControlParamsFrame#0', metadata: {}, vad_params: confidence=0.7 start_secs=0.2 stop_secs=0.2 min_volume=0.6, turn_params: stop_secs=3 pre_speech_ms=0 max_duration_secs=8 at 0.18s
2026-01-15 10:31:04.829 | DEBUG    | [BOT-SYS] | PipelineTask#0: StartFrame#0 reached the end of the pipeline, pipeline is now ready.
2026-01-15 10:31:04.829 | DEBUG    | [BOT-SYS] | PipelineTask#0::Source â†’ Pipeline#0: MetricsFrame id: 38, name: 'MetricsFrame#0', metadata: {}, data: [TTFBMetricsData(processor='SarvamSTTService#0', model=None, value=0.0), ProcessingMetricsData(processor='SarvamSTTService#0', model=None, value=0.0)] at 0.18s
2026-01-15 10:31:04.829 | DEBUG    | [BOT-SYS] | Pipeline#0::Source â†’ WebsocketServerInputTransport#0: MetricsFrame id: 38, name: 'MetricsFrame#0', metadata: {}, data: [TTFBMetricsData(processor='SarvamSTTService#0', model=None, value=0.0), ProcessingMetricsData(processor='SarvamSTTService#0', model=None, value=0.0)] at 0.18s
2026-01-15 10:31:04.829 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 39, name: 'OutputTransportMessageUrgentFrame#0', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'ttfb': [{'processor': 'SarvamSTTService#0', 'value': 0.0}], 'processing': [{'processor': 'SarvamSTTService#0', 'value': 0.0}]}} at 0.18s
2026-01-15 10:31:04.830 | INFO     | [BOT-SYS] | output bot frame: OutputTransportReadyFrame#0
2026-01-15 10:31:04.830 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#0(message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'ttfb': [{'processor': 'SarvamSTTService#0', 'value': 0.0}], 'processing': [{'processor': 'SarvamSTTService#0', 'value': 0.0}]}})
2026-01-15 10:31:04.830 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: MetricsFrame id: 38, name: 'MetricsFrame#0', metadata: {}, data: [TTFBMetricsData(processor='SarvamSTTService#0', model=None, value=0.0), ProcessingMetricsData(processor='SarvamSTTService#0', model=None, value=0.0)] at 0.18s
2026-01-15 10:31:04.830 | DEBUG    | [BOT-SYS] | IOLogger#1 â† UserTranscriptProcessor#0: OutputTransportReadyFrame id: 37, name: 'OutputTransportReadyFrame#0', metadata: {} at 0.18s
2026-01-15 10:31:04.830 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 39, name: 'OutputTransportMessageUrgentFrame#0', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'ttfb': [{'processor': 'SarvamSTTService#0', 'value': 0.0}], 'processing': [{'processor': 'SarvamSTTService#0', 'value': 0.0}]}} at 0.18s
2026-01-15 10:31:04.830 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: MetricsFrame id: 38, name: 'MetricsFrame#0', metadata: {}, data: [TTFBMetricsData(processor='SarvamSTTService#0', model=None, value=0.0), ProcessingMetricsData(processor='SarvamSTTService#0', model=None, value=0.0)] at 0.18s
2026-01-15 10:31:04.830 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 39, name: 'OutputTransportMessageUrgentFrame#0', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'ttfb': [{'processor': 'SarvamSTTService#0', 'value': 0.0}], 'processing': [{'processor': 'SarvamSTTService#0', 'value': 0.0}]}} at 0.18s
2026-01-15 10:31:04.830 | INFO     | [BOT-SYS] | input bot frame: MetricsFrame#0
2026-01-15 10:31:04.830 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: MetricsFrame id: 38, name: 'MetricsFrame#0', metadata: {}, data: [TTFBMetricsData(processor='SarvamSTTService#0', model=None, value=0.0), ProcessingMetricsData(processor='SarvamSTTService#0', model=None, value=0.0)] at 0.18s
2026-01-15 10:31:04.830 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â† SarvamSTTService#0: OutputTransportReadyFrame id: 37, name: 'OutputTransportReadyFrame#0', metadata: {} at 0.18s
2026-01-15 10:31:04.830 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 39, name: 'OutputTransportMessageUrgentFrame#0', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'ttfb': [{'processor': 'SarvamSTTService#0', 'value': 0.0}], 'processing': [{'processor': 'SarvamSTTService#0', 'value': 0.0}]}} at 0.18s
2026-01-15 10:31:04.830 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#0(message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'ttfb': [{'processor': 'SarvamSTTService#0', 'value': 0.0}], 'processing': [{'processor': 'SarvamSTTService#0', 'value': 0.0}]}})
2026-01-15 10:31:04.830 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: MetricsFrame id: 38, name: 'MetricsFrame#0', metadata: {}, data: [TTFBMetricsData(processor='SarvamSTTService#0', model=None, value=0.0), ProcessingMetricsData(processor='SarvamSTTService#0', model=None, value=0.0)] at 0.18s
2026-01-15 10:31:04.830 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 39, name: 'OutputTransportMessageUrgentFrame#0', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'ttfb': [{'processor': 'SarvamSTTService#0', 'value': 0.0}], 'processing': [{'processor': 'SarvamSTTService#0', 'value': 0.0}]}} at 0.18s
2026-01-15 10:31:04.831 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: MetricsFrame id: 38, name: 'MetricsFrame#0', metadata: {}, data: [TTFBMetricsData(processor='SarvamSTTService#0', model=None, value=0.0), ProcessingMetricsData(processor='SarvamSTTService#0', model=None, value=0.0)] at 0.18s
2026-01-15 10:31:04.831 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â† IOLogger#0: OutputTransportReadyFrame id: 37, name: 'OutputTransportReadyFrame#0', metadata: {} at 0.18s
2026-01-15 10:31:04.831 | INFO     | [BOT-SYS] | output bot frame: MetricsFrame#0
2026-01-15 10:31:04.831 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: MetricsFrame id: 38, name: 'MetricsFrame#0', metadata: {}, data: [TTFBMetricsData(processor='SarvamSTTService#0', model=None, value=0.0), ProcessingMetricsData(processor='SarvamSTTService#0', model=None, value=0.0)] at 0.19s
2026-01-15 10:31:04.831 | INFO     | [BOT-SYS] | input bot frame: OutputTransportReadyFrame#0
2026-01-15 10:31:04.831 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: MetricsFrame id: 38, name: 'MetricsFrame#0', metadata: {}, data: [TTFBMetricsData(processor='SarvamSTTService#0', model=None, value=0.0), ProcessingMetricsData(processor='SarvamSTTService#0', model=None, value=0.0)] at 0.19s
2026-01-15 10:31:04.831 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: MetricsFrame id: 38, name: 'MetricsFrame#0', metadata: {}, data: [TTFBMetricsData(processor='SarvamSTTService#0', model=None, value=0.0), ProcessingMetricsData(processor='SarvamSTTService#0', model=None, value=0.0)] at 0.19s
2026-01-15 10:31:04.831 | DEBUG    | [BOT-SYS] | IOLogger#0 â† RTVIProcessor#0: OutputTransportReadyFrame id: 37, name: 'OutputTransportReadyFrame#0', metadata: {} at 0.19s
2026-01-15 10:31:04.831 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â† WebsocketServerInputTransport#0: OutputTransportReadyFrame id: 37, name: 'OutputTransportReadyFrame#0', metadata: {} at 0.19s
2026-01-15 10:31:04.831 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: OutputTransportReadyFrame id: 37, name: 'OutputTransportReadyFrame#0', metadata: {} at 0.19s
2026-01-15 10:31:04.831 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: OutputTransportReadyFrame id: 37, name: 'OutputTransportReadyFrame#0', metadata: {} at 0.19s
2026-01-15 10:31:05.554 | DEBUG    | [EVAL-SYS] | Linking Pipeline#2::Source -> WebsocketClientInputTransport#0
2026-01-15 10:31:05.554 | DEBUG    | [EVAL-SYS] | Linking WebsocketClientInputTransport#0 -> IOLogger#2
2026-01-15 10:31:05.554 | DEBUG    | [EVAL-SYS] | Linking IOLogger#2 -> TranscriptionWriter
2026-01-15 10:31:05.555 | DEBUG    | [EVAL-SYS] | Linking TranscriptionWriter -> MetricsLogger
2026-01-15 10:31:05.555 | DEBUG    | [EVAL-SYS] | Linking MetricsLogger -> BotTurnAudioStreamer
2026-01-15 10:31:05.555 | DEBUG    | [EVAL-SYS] | Linking BotTurnAudioStreamer -> WebsocketClientOutputTransport#0
2026-01-15 10:31:05.555 | DEBUG    | [EVAL-SYS] | Linking WebsocketClientOutputTransport#0 -> Pipeline#2::Sink
2026-01-15 10:31:05.555 | DEBUG    | [EVAL-SYS] | Linking PipelineTask#1::Source -> Pipeline#2
2026-01-15 10:31:05.555 | DEBUG    | [EVAL-SYS] | Linking Pipeline#2 -> PipelineTask#1::Sink
2026-01-15 10:31:05.555 | DEBUG    | [EVAL-SYS] | Runner PipelineRunner#1 started running PipelineTask#1
2026-01-15 10:31:05.556 | DEBUG    | [EVAL-SYS] | PipelineTask#1: Starting. Waiting for StartFrame#1 to reach the end of the pipeline...
2026-01-15 10:31:05.557 | DEBUG    | [EVAL-SYS] | PipelineTask#1::Source â†’ Pipeline#2: StartFrame id: 72, name: 'StartFrame#1', metadata: {}, audio_in_sample_rate: 16000, audio_out_sample_rate: 16000, allow_interruptions: True, enable_metrics: False, enable_tracing: True, enable_usage_metrics: False, interruption_strategies: [], report_only_initial_ttfb: False at 0.00s
2026-01-15 10:31:05.557 | DEBUG    | [EVAL-SYS] | Pipeline#2::Source â†’ WebsocketClientInputTransport#0: StartFrame id: 72, name: 'StartFrame#1', metadata: {}, audio_in_sample_rate: 16000, audio_out_sample_rate: 16000, allow_interruptions: True, enable_metrics: False, enable_tracing: True, enable_usage_metrics: False, interruption_strategies: [], report_only_initial_ttfb: False at 0.00s
2026-01-15 10:31:05.559 | DEBUG    | [EVAL-SYS] | Generated new conversation ID: 2bc3594b-faeb-45e6-8c7f-369fa5ad5eb0
2026-01-15 10:31:05.559 | DEBUG    | [EVAL-SYS] | Started tracing for Conversation 2bc3594b-faeb-45e6-8c7f-369fa5ad5eb0
2026-01-15 10:31:05.559 | DEBUG    | [EVAL-SYS] | Started tracing for Turn 1
2026-01-15 10:31:05.559 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: StartFrame id: 72, name: 'StartFrame#1', metadata: {}, audio_in_sample_rate: 16000, audio_out_sample_rate: 16000, allow_interruptions: True, enable_metrics: False, enable_tracing: True, enable_usage_metrics: False, interruption_strategies: [], report_only_initial_ttfb: False at 0.00s
2026-01-15 10:31:05.559 | INFO     | [EVAL-SYS] | eval frame: StartFrame#1
2026-01-15 10:31:05.559 | INFO     | [EVAL-SYS] | frame transcription logger: StartFrame#1
2026-01-15 10:31:05.560 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:05.560 | INFO     | [EVAL-SYS] | state: waiting_for_new_stream
2026-01-15 10:31:05.560 | INFO     | [EVAL-SYS] | --------------------------------
2026-01-15 10:31:05.560 | INFO     | [EVAL-SYS] | [93mCreated new user transcript[0m
2026-01-15 10:31:05.560 | INFO     | [EVAL-SYS] | transcripts length: 1
2026-01-15 10:31:05.560 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: StartFrame id: 72, name: 'StartFrame#1', metadata: {}, audio_in_sample_rate: 16000, audio_out_sample_rate: 16000, allow_interruptions: True, enable_metrics: False, enable_tracing: True, enable_usage_metrics: False, interruption_strategies: [], report_only_initial_ttfb: False at 0.00s
2026-01-15 10:31:05.560 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: StartFrame id: 72, name: 'StartFrame#1', metadata: {}, audio_in_sample_rate: 16000, audio_out_sample_rate: 16000, allow_interruptions: True, enable_metrics: False, enable_tracing: True, enable_usage_metrics: False, interruption_strategies: [], report_only_initial_ttfb: False at 0.00s
2026-01-15 10:31:05.560 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: StartFrame id: 72, name: 'StartFrame#1', metadata: {}, audio_in_sample_rate: 16000, audio_out_sample_rate: 16000, allow_interruptions: True, enable_metrics: False, enable_tracing: True, enable_usage_metrics: False, interruption_strategies: [], report_only_initial_ttfb: False at 0.00s
2026-01-15 10:31:05.560 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: StartFrame id: 72, name: 'StartFrame#1', metadata: {}, audio_in_sample_rate: 16000, audio_out_sample_rate: 16000, allow_interruptions: True, enable_metrics: False, enable_tracing: True, enable_usage_metrics: False, interruption_strategies: [], report_only_initial_ttfb: False at 0.00s
2026-01-15 10:31:05.561 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: StartFrame id: 72, name: 'StartFrame#1', metadata: {}, audio_in_sample_rate: 16000, audio_out_sample_rate: 16000, allow_interruptions: True, enable_metrics: False, enable_tracing: True, enable_usage_metrics: False, interruption_strategies: [], report_only_initial_ttfb: False at 0.00s
2026-01-15 10:31:05.561 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: StartFrame id: 72, name: 'StartFrame#1', metadata: {}, audio_in_sample_rate: 16000, audio_out_sample_rate: 16000, allow_interruptions: True, enable_metrics: False, enable_tracing: True, enable_usage_metrics: False, interruption_strategies: [], report_only_initial_ttfb: False at 0.00s
2026-01-15 10:31:05.561 | DEBUG    | [EVAL-SYS] | PipelineTask#1: StartFrame#1 reached the end of the pipeline, pipeline is now ready.
2026-01-15 10:31:05.562 | INFO     | [BOT-SYS] | New client connection from ('::1', 52905, 0, 0)
2026-01-15 10:31:05.562 | INFO     | [BOT-SYS] | Client connected to STT bot
2026-01-15 10:31:05.563 | INFO     | [EVAL-SYS] | WebSocket connected
2026-01-15 10:31:05.563 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:05.563 | INFO     | [EVAL-SYS] | state: streaming
2026-01-15 10:31:05.563 | INFO     | [EVAL-SYS] | frame transcription logger: OutputTransportReadyFrame#1
2026-01-15 10:31:05.563 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â† BotTurnAudioStreamer: OutputTransportReadyFrame id: 73, name: 'OutputTransportReadyFrame#1', metadata: {} at 0.01s
2026-01-15 10:31:05.563 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â† MetricsLogger: OutputTransportReadyFrame id: 73, name: 'OutputTransportReadyFrame#1', metadata: {} at 0.01s
2026-01-15 10:31:05.563 | DEBUG    | [EVAL-SYS] | MetricsLogger â† TranscriptionWriter: OutputTransportReadyFrame id: 73, name: 'OutputTransportReadyFrame#1', metadata: {} at 0.01s
2026-01-15 10:31:05.563 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â† IOLogger#2: OutputTransportReadyFrame id: 73, name: 'OutputTransportReadyFrame#1', metadata: {} at 0.01s
2026-01-15 10:31:05.563 | INFO     | [EVAL-SYS] | Starting new audio streaming 1/123: /Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_1_english_baseline.wav
2026-01-15 10:31:05.564 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 74, name: 'OutputAudioRawFrame#0', metadata: {} at 0.01s
2026-01-15 10:31:05.564 | INFO     | [EVAL-SYS] | eval frame: OutputTransportReadyFrame#1
2026-01-15 10:31:05.564 | DEBUG    | [EVAL-SYS] | IOLogger#2 â† WebsocketClientInputTransport#0: OutputTransportReadyFrame id: 73, name: 'OutputTransportReadyFrame#1', metadata: {} at 0.01s
2026-01-15 10:31:05.565 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â† Pipeline#2::Source: OutputTransportReadyFrame id: 73, name: 'OutputTransportReadyFrame#1', metadata: {} at 0.01s
2026-01-15 10:31:05.565 | DEBUG    | [EVAL-SYS] | Pipeline#2 â† PipelineTask#1::Source: OutputTransportReadyFrame id: 73, name: 'OutputTransportReadyFrame#1', metadata: {} at 0.01s
2026-01-15 10:31:05.565 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 75, name: 'OutputAudioRawFrame#1', metadata: {} at 0.01s
2026-01-15 10:31:05.566 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 75, name: 'OutputAudioRawFrame#1', metadata: {} at 0.01s
2026-01-15 10:31:05.566 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 77, name: 'OutputAudioRawFrame#3', metadata: {} at 0.01s
2026-01-15 10:31:05.567 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 83, name: 'OutputAudioRawFrame#7', metadata: {} at 0.01s
2026-01-15 10:31:05.568 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 76, name: 'OutputAudioRawFrame#2', metadata: {} at 0.92s
2026-01-15 10:31:05.568 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 76, name: 'OutputAudioRawFrame#2', metadata: {} at 0.92s
2026-01-15 10:31:05.568 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#2(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:05.568 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 76, name: 'OutputAudioRawFrame#2', metadata: {} at 0.92s
2026-01-15 10:31:05.569 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 86, name: 'OutputAudioRawFrame#10', metadata: {} at 0.01s
2026-01-15 10:31:05.570 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 76, name: 'OutputAudioRawFrame#2', metadata: {} at 0.92s
2026-01-15 10:31:05.570 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 76, name: 'OutputAudioRawFrame#2', metadata: {} at 0.92s
2026-01-15 10:31:05.570 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#2(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:05.570 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 76, name: 'OutputAudioRawFrame#2', metadata: {} at 0.92s
2026-01-15 10:31:05.571 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 88, name: 'OutputAudioRawFrame#12', metadata: {} at 0.01s
2026-01-15 10:31:05.571 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 76, name: 'OutputAudioRawFrame#2', metadata: {} at 0.92s
2026-01-15 10:31:05.571 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 76, name: 'OutputAudioRawFrame#2', metadata: {} at 0.92s
2026-01-15 10:31:05.571 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 81, name: 'OutputAudioRawFrame#6', metadata: {} at 0.93s
2026-01-15 10:31:05.571 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 81, name: 'OutputAudioRawFrame#6', metadata: {} at 0.93s
2026-01-15 10:31:05.571 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#6(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:05.571 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 81, name: 'OutputAudioRawFrame#6', metadata: {} at 0.93s
2026-01-15 10:31:05.572 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 81, name: 'OutputAudioRawFrame#6', metadata: {} at 0.93s
2026-01-15 10:31:05.572 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 81, name: 'OutputAudioRawFrame#6', metadata: {} at 0.93s
2026-01-15 10:31:05.572 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#6(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:05.572 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 81, name: 'OutputAudioRawFrame#6', metadata: {} at 0.93s
2026-01-15 10:31:05.572 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 91, name: 'OutputAudioRawFrame#15', metadata: {} at 0.02s
2026-01-15 10:31:05.572 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 81, name: 'OutputAudioRawFrame#6', metadata: {} at 0.93s
2026-01-15 10:31:05.572 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 81, name: 'OutputAudioRawFrame#6', metadata: {} at 0.93s
2026-01-15 10:31:05.573 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 94, name: 'OutputAudioRawFrame#18', metadata: {} at 0.02s
2026-01-15 10:31:05.576 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 98, name: 'OutputAudioRawFrame#22', metadata: {} at 0.02s
2026-01-15 10:31:05.577 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 101, name: 'OutputAudioRawFrame#25', metadata: {} at 0.02s
2026-01-15 10:31:05.579 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 104, name: 'OutputAudioRawFrame#28', metadata: {} at 0.02s
2026-01-15 10:31:05.580 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 106, name: 'OutputAudioRawFrame#30', metadata: {} at 0.02s
2026-01-15 10:31:05.581 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 109, name: 'OutputAudioRawFrame#33', metadata: {} at 0.02s
2026-01-15 10:31:05.582 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 112, name: 'OutputAudioRawFrame#36', metadata: {} at 0.03s
2026-01-15 10:31:05.583 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 116, name: 'OutputAudioRawFrame#40', metadata: {} at 0.03s
2026-01-15 10:31:05.585 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 119, name: 'OutputAudioRawFrame#43', metadata: {} at 0.03s
2026-01-15 10:31:05.586 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 122, name: 'OutputAudioRawFrame#46', metadata: {} at 0.03s
2026-01-15 10:31:05.587 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 124, name: 'OutputAudioRawFrame#48', metadata: {} at 0.03s
2026-01-15 10:31:05.588 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 127, name: 'OutputAudioRawFrame#51', metadata: {} at 0.03s
2026-01-15 10:31:05.589 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 130, name: 'OutputAudioRawFrame#54', metadata: {} at 0.03s
2026-01-15 10:31:05.590 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 133, name: 'OutputAudioRawFrame#57', metadata: {} at 0.03s
2026-01-15 10:31:05.592 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 137, name: 'OutputAudioRawFrame#61', metadata: {} at 0.04s
2026-01-15 10:31:05.593 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 140, name: 'OutputAudioRawFrame#64', metadata: {} at 0.04s
2026-01-15 10:31:05.594 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 142, name: 'OutputAudioRawFrame#66', metadata: {} at 0.04s
2026-01-15 10:31:05.595 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 145, name: 'OutputAudioRawFrame#69', metadata: {} at 0.04s
2026-01-15 10:31:05.596 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 148, name: 'OutputAudioRawFrame#72', metadata: {} at 0.04s
2026-01-15 10:31:05.598 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 151, name: 'OutputAudioRawFrame#75', metadata: {} at 0.04s
2026-01-15 10:31:05.599 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 155, name: 'OutputAudioRawFrame#79', metadata: {} at 0.04s
2026-01-15 10:31:05.600 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 158, name: 'OutputAudioRawFrame#82', metadata: {} at 0.04s
2026-01-15 10:31:05.601 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 161, name: 'OutputAudioRawFrame#85', metadata: {} at 0.04s
2026-01-15 10:31:05.602 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 163, name: 'OutputAudioRawFrame#87', metadata: {} at 0.05s
2026-01-15 10:31:05.603 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 166, name: 'OutputAudioRawFrame#90', metadata: {} at 0.05s
2026-01-15 10:31:05.605 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 169, name: 'OutputAudioRawFrame#93', metadata: {} at 0.05s
2026-01-15 10:31:05.606 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 78, name: 'OutputAudioRawFrame#4', metadata: {} at 0.05s
2026-01-15 10:31:05.606 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 78, name: 'OutputAudioRawFrame#4', metadata: {} at 0.05s
2026-01-15 10:31:05.606 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 173, name: 'OutputAudioRawFrame#97', metadata: {} at 0.05s
2026-01-15 10:31:05.607 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 174, name: 'OutputAudioRawFrame#98', metadata: {} at 0.96s
2026-01-15 10:31:05.607 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 178, name: 'OutputAudioRawFrame#101', metadata: {} at 0.05s
2026-01-15 10:31:05.607 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 174, name: 'OutputAudioRawFrame#98', metadata: {} at 0.96s
2026-01-15 10:31:05.607 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#98(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:05.608 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 174, name: 'OutputAudioRawFrame#98', metadata: {} at 0.96s
2026-01-15 10:31:05.608 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 174, name: 'OutputAudioRawFrame#98', metadata: {} at 0.96s
2026-01-15 10:31:05.608 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 174, name: 'OutputAudioRawFrame#98', metadata: {} at 0.96s
2026-01-15 10:31:05.608 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#98(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:05.608 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 174, name: 'OutputAudioRawFrame#98', metadata: {} at 0.96s
2026-01-15 10:31:05.608 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 181, name: 'OutputAudioRawFrame#104', metadata: {} at 0.05s
2026-01-15 10:31:05.609 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 174, name: 'OutputAudioRawFrame#98', metadata: {} at 0.96s
2026-01-15 10:31:05.609 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 174, name: 'OutputAudioRawFrame#98', metadata: {} at 0.96s
2026-01-15 10:31:05.610 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 183, name: 'OutputAudioRawFrame#106', metadata: {} at 0.05s
2026-01-15 10:31:05.611 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 186, name: 'OutputAudioRawFrame#109', metadata: {} at 0.05s
2026-01-15 10:31:05.612 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 189, name: 'OutputAudioRawFrame#112', metadata: {} at 0.06s
2026-01-15 10:31:05.613 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 193, name: 'OutputAudioRawFrame#116', metadata: {} at 0.06s
2026-01-15 10:31:05.614 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 196, name: 'OutputAudioRawFrame#119', metadata: {} at 0.06s
2026-01-15 10:31:05.615 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 199, name: 'OutputAudioRawFrame#122', metadata: {} at 0.06s
2026-01-15 10:31:05.617 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 201, name: 'OutputAudioRawFrame#124', metadata: {} at 0.06s
2026-01-15 10:31:05.618 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 204, name: 'OutputAudioRawFrame#127', metadata: {} at 0.06s
2026-01-15 10:31:05.619 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 207, name: 'OutputAudioRawFrame#130', metadata: {} at 0.06s
2026-01-15 10:31:05.620 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 211, name: 'OutputAudioRawFrame#134', metadata: {} at 0.06s
2026-01-15 10:31:05.621 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 214, name: 'OutputAudioRawFrame#137', metadata: {} at 0.07s
2026-01-15 10:31:05.623 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 217, name: 'OutputAudioRawFrame#140', metadata: {} at 0.07s
2026-01-15 10:31:05.624 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 219, name: 'OutputAudioRawFrame#142', metadata: {} at 0.07s
2026-01-15 10:31:05.625 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 222, name: 'OutputAudioRawFrame#145', metadata: {} at 0.07s
2026-01-15 10:31:05.626 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 225, name: 'OutputAudioRawFrame#148', metadata: {} at 0.07s
2026-01-15 10:31:05.627 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 229, name: 'OutputAudioRawFrame#152', metadata: {} at 0.07s
2026-01-15 10:31:05.628 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 232, name: 'OutputAudioRawFrame#155', metadata: {} at 0.07s
2026-01-15 10:31:05.630 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 235, name: 'OutputAudioRawFrame#158', metadata: {} at 0.07s
2026-01-15 10:31:05.631 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 237, name: 'OutputAudioRawFrame#160', metadata: {} at 0.07s
2026-01-15 10:31:05.632 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 240, name: 'OutputAudioRawFrame#163', metadata: {} at 0.08s
2026-01-15 10:31:05.633 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 243, name: 'OutputAudioRawFrame#166', metadata: {} at 0.08s
2026-01-15 10:31:05.634 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 247, name: 'OutputAudioRawFrame#170', metadata: {} at 0.08s
2026-01-15 10:31:05.635 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 250, name: 'OutputAudioRawFrame#173', metadata: {} at 0.08s
2026-01-15 10:31:05.637 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 253, name: 'OutputAudioRawFrame#176', metadata: {} at 0.08s
2026-01-15 10:31:05.638 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 255, name: 'OutputAudioRawFrame#178', metadata: {} at 0.08s
2026-01-15 10:31:05.639 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 258, name: 'OutputAudioRawFrame#181', metadata: {} at 0.08s
2026-01-15 10:31:05.640 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 261, name: 'OutputAudioRawFrame#184', metadata: {} at 0.08s
2026-01-15 10:31:05.641 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 265, name: 'OutputAudioRawFrame#188', metadata: {} at 0.09s
2026-01-15 10:31:05.643 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 268, name: 'OutputAudioRawFrame#191', metadata: {} at 0.09s
2026-01-15 10:31:05.644 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 271, name: 'OutputAudioRawFrame#194', metadata: {} at 0.09s
2026-01-15 10:31:05.645 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 273, name: 'OutputAudioRawFrame#196', metadata: {} at 0.09s
2026-01-15 10:31:05.646 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 79, name: 'OutputAudioRawFrame#5', metadata: {} at 0.09s
2026-01-15 10:31:05.646 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 79, name: 'OutputAudioRawFrame#5', metadata: {} at 0.09s
2026-01-15 10:31:05.646 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 278, name: 'OutputAudioRawFrame#200', metadata: {} at 0.09s
2026-01-15 10:31:05.647 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 276, name: 'OutputAudioRawFrame#199', metadata: {} at 1.00s
2026-01-15 10:31:05.647 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 281, name: 'OutputAudioRawFrame#203', metadata: {} at 0.09s
2026-01-15 10:31:05.647 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 276, name: 'OutputAudioRawFrame#199', metadata: {} at 1.00s
2026-01-15 10:31:05.648 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#199(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:05.648 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 276, name: 'OutputAudioRawFrame#199', metadata: {} at 1.00s
2026-01-15 10:31:05.648 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 276, name: 'OutputAudioRawFrame#199', metadata: {} at 1.00s
2026-01-15 10:31:05.648 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 276, name: 'OutputAudioRawFrame#199', metadata: {} at 1.00s
2026-01-15 10:31:05.648 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#199(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:05.648 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 276, name: 'OutputAudioRawFrame#199', metadata: {} at 1.00s
2026-01-15 10:31:05.649 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 276, name: 'OutputAudioRawFrame#199', metadata: {} at 1.00s
2026-01-15 10:31:05.649 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 276, name: 'OutputAudioRawFrame#199', metadata: {} at 1.00s
2026-01-15 10:31:05.649 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 285, name: 'OutputAudioRawFrame#207', metadata: {} at 0.09s
2026-01-15 10:31:05.650 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 288, name: 'OutputAudioRawFrame#210', metadata: {} at 0.09s
2026-01-15 10:31:05.651 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 291, name: 'OutputAudioRawFrame#213', metadata: {} at 0.09s
2026-01-15 10:31:05.652 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 293, name: 'OutputAudioRawFrame#215', metadata: {} at 0.10s
2026-01-15 10:31:05.653 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 296, name: 'OutputAudioRawFrame#218', metadata: {} at 0.10s
2026-01-15 10:31:05.654 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 299, name: 'OutputAudioRawFrame#221', metadata: {} at 0.10s
2026-01-15 10:31:05.656 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 302, name: 'OutputAudioRawFrame#224', metadata: {} at 0.10s
2026-01-15 10:31:05.657 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 306, name: 'OutputAudioRawFrame#228', metadata: {} at 0.10s
2026-01-15 10:31:05.658 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 309, name: 'OutputAudioRawFrame#231', metadata: {} at 0.10s
2026-01-15 10:31:05.659 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 311, name: 'OutputAudioRawFrame#233', metadata: {} at 0.10s
2026-01-15 10:31:05.660 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 314, name: 'OutputAudioRawFrame#236', metadata: {} at 0.10s
2026-01-15 10:31:05.662 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 317, name: 'OutputAudioRawFrame#239', metadata: {} at 0.11s
2026-01-15 10:31:05.663 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 320, name: 'OutputAudioRawFrame#242', metadata: {} at 0.11s
2026-01-15 10:31:05.664 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 324, name: 'OutputAudioRawFrame#246', metadata: {} at 0.11s
2026-01-15 10:31:05.665 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 327, name: 'OutputAudioRawFrame#249', metadata: {} at 0.11s
2026-01-15 10:31:05.666 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 330, name: 'OutputAudioRawFrame#252', metadata: {} at 0.11s
2026-01-15 10:31:05.668 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 332, name: 'OutputAudioRawFrame#254', metadata: {} at 0.11s
2026-01-15 10:31:05.669 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 335, name: 'OutputAudioRawFrame#257', metadata: {} at 0.11s
2026-01-15 10:31:05.670 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 338, name: 'OutputAudioRawFrame#260', metadata: {} at 0.11s
2026-01-15 10:31:05.671 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 342, name: 'OutputAudioRawFrame#264', metadata: {} at 0.11s
2026-01-15 10:31:05.672 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 345, name: 'OutputAudioRawFrame#267', metadata: {} at 0.12s
2026-01-15 10:31:05.673 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 348, name: 'OutputAudioRawFrame#270', metadata: {} at 0.12s
2026-01-15 10:31:05.674 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 350, name: 'OutputAudioRawFrame#272', metadata: {} at 0.12s
2026-01-15 10:31:05.676 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 353, name: 'OutputAudioRawFrame#275', metadata: {} at 0.12s
2026-01-15 10:31:05.677 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 356, name: 'OutputAudioRawFrame#278', metadata: {} at 0.12s
2026-01-15 10:31:05.678 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 360, name: 'OutputAudioRawFrame#282', metadata: {} at 0.12s
2026-01-15 10:31:05.679 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 363, name: 'OutputAudioRawFrame#285', metadata: {} at 0.12s
2026-01-15 10:31:05.686 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 84, name: 'OutputAudioRawFrame#8', metadata: {} at 0.13s
2026-01-15 10:31:05.686 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 84, name: 'OutputAudioRawFrame#8', metadata: {} at 0.13s
2026-01-15 10:31:05.687 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 366, name: 'OutputAudioRawFrame#288', metadata: {} at 1.04s
2026-01-15 10:31:05.687 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 366, name: 'OutputAudioRawFrame#288', metadata: {} at 1.04s
2026-01-15 10:31:05.687 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#288(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:05.687 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 366, name: 'OutputAudioRawFrame#288', metadata: {} at 1.04s
2026-01-15 10:31:05.688 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 366, name: 'OutputAudioRawFrame#288', metadata: {} at 1.04s
2026-01-15 10:31:05.688 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 366, name: 'OutputAudioRawFrame#288', metadata: {} at 1.04s
2026-01-15 10:31:05.688 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#288(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:05.688 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 366, name: 'OutputAudioRawFrame#288', metadata: {} at 1.04s
2026-01-15 10:31:05.688 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 366, name: 'OutputAudioRawFrame#288', metadata: {} at 1.04s
2026-01-15 10:31:05.688 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 366, name: 'OutputAudioRawFrame#288', metadata: {} at 1.04s
2026-01-15 10:31:05.720 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 368, name: 'OutputAudioRawFrame#289', metadata: {} at 0.16s
2026-01-15 10:31:05.726 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 85, name: 'OutputAudioRawFrame#9', metadata: {} at 0.17s
2026-01-15 10:31:05.726 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 85, name: 'OutputAudioRawFrame#9', metadata: {} at 0.17s
2026-01-15 10:31:05.728 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 370, name: 'OutputAudioRawFrame#291', metadata: {} at 1.08s
2026-01-15 10:31:05.728 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 370, name: 'OutputAudioRawFrame#291', metadata: {} at 1.08s
2026-01-15 10:31:05.728 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#291(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:05.728 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 370, name: 'OutputAudioRawFrame#291', metadata: {} at 1.08s
2026-01-15 10:31:05.728 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 370, name: 'OutputAudioRawFrame#291', metadata: {} at 1.08s
2026-01-15 10:31:05.728 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 370, name: 'OutputAudioRawFrame#291', metadata: {} at 1.08s
2026-01-15 10:31:05.728 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#291(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:05.729 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 370, name: 'OutputAudioRawFrame#291', metadata: {} at 1.08s
2026-01-15 10:31:05.729 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 370, name: 'OutputAudioRawFrame#291', metadata: {} at 1.08s
2026-01-15 10:31:05.729 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 370, name: 'OutputAudioRawFrame#291', metadata: {} at 1.08s
2026-01-15 10:31:05.761 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 372, name: 'OutputAudioRawFrame#292', metadata: {} at 0.20s
2026-01-15 10:31:05.766 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 87, name: 'OutputAudioRawFrame#11', metadata: {} at 0.21s
2026-01-15 10:31:05.766 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 87, name: 'OutputAudioRawFrame#11', metadata: {} at 0.21s
2026-01-15 10:31:05.768 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 375, name: 'OutputAudioRawFrame#295', metadata: {} at 1.12s
2026-01-15 10:31:05.768 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 375, name: 'OutputAudioRawFrame#295', metadata: {} at 1.12s
2026-01-15 10:31:05.768 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#295(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:05.768 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 375, name: 'OutputAudioRawFrame#295', metadata: {} at 1.12s
2026-01-15 10:31:05.769 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 375, name: 'OutputAudioRawFrame#295', metadata: {} at 1.12s
2026-01-15 10:31:05.769 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 375, name: 'OutputAudioRawFrame#295', metadata: {} at 1.12s
2026-01-15 10:31:05.769 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#295(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:05.769 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 375, name: 'OutputAudioRawFrame#295', metadata: {} at 1.12s
2026-01-15 10:31:05.769 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 375, name: 'OutputAudioRawFrame#295', metadata: {} at 1.12s
2026-01-15 10:31:05.769 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 375, name: 'OutputAudioRawFrame#295', metadata: {} at 1.12s
2026-01-15 10:31:05.803 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 377, name: 'OutputAudioRawFrame#296', metadata: {} at 0.25s
2026-01-15 10:31:05.806 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 89, name: 'OutputAudioRawFrame#13', metadata: {} at 0.25s
2026-01-15 10:31:05.806 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 89, name: 'OutputAudioRawFrame#13', metadata: {} at 0.25s
2026-01-15 10:31:05.812 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 380, name: 'OutputAudioRawFrame#299', metadata: {} at 1.17s
2026-01-15 10:31:05.812 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 380, name: 'OutputAudioRawFrame#299', metadata: {} at 1.17s
2026-01-15 10:31:05.812 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#299(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:05.812 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 380, name: 'OutputAudioRawFrame#299', metadata: {} at 1.17s
2026-01-15 10:31:05.813 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 380, name: 'OutputAudioRawFrame#299', metadata: {} at 1.17s
2026-01-15 10:31:05.813 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 380, name: 'OutputAudioRawFrame#299', metadata: {} at 1.17s
2026-01-15 10:31:05.813 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#299(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:05.813 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 380, name: 'OutputAudioRawFrame#299', metadata: {} at 1.17s
2026-01-15 10:31:05.813 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 380, name: 'OutputAudioRawFrame#299', metadata: {} at 1.17s
2026-01-15 10:31:05.813 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 380, name: 'OutputAudioRawFrame#299', metadata: {} at 1.17s
2026-01-15 10:31:05.844 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 382, name: 'OutputAudioRawFrame#300', metadata: {} at 0.29s
2026-01-15 10:31:05.846 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 90, name: 'OutputAudioRawFrame#14', metadata: {} at 0.29s
2026-01-15 10:31:05.846 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 90, name: 'OutputAudioRawFrame#14', metadata: {} at 0.29s
2026-01-15 10:31:05.850 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 386, name: 'OutputAudioRawFrame#304', metadata: {} at 1.20s
2026-01-15 10:31:05.850 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 386, name: 'OutputAudioRawFrame#304', metadata: {} at 1.20s
2026-01-15 10:31:05.850 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#304(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:05.850 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 386, name: 'OutputAudioRawFrame#304', metadata: {} at 1.20s
2026-01-15 10:31:05.852 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 386, name: 'OutputAudioRawFrame#304', metadata: {} at 1.21s
2026-01-15 10:31:05.852 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 386, name: 'OutputAudioRawFrame#304', metadata: {} at 1.21s
2026-01-15 10:31:05.852 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#304(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:05.852 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 386, name: 'OutputAudioRawFrame#304', metadata: {} at 1.21s
2026-01-15 10:31:05.852 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 386, name: 'OutputAudioRawFrame#304', metadata: {} at 1.21s
2026-01-15 10:31:05.852 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 386, name: 'OutputAudioRawFrame#304', metadata: {} at 1.21s
2026-01-15 10:31:05.884 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 388, name: 'OutputAudioRawFrame#305', metadata: {} at 0.33s
2026-01-15 10:31:05.886 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 92, name: 'OutputAudioRawFrame#16', metadata: {} at 0.33s
2026-01-15 10:31:05.886 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 92, name: 'OutputAudioRawFrame#16', metadata: {} at 0.33s
2026-01-15 10:31:05.889 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 391, name: 'OutputAudioRawFrame#308', metadata: {} at 1.24s
2026-01-15 10:31:05.889 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 391, name: 'OutputAudioRawFrame#308', metadata: {} at 1.24s
2026-01-15 10:31:05.889 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#308(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:05.889 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 391, name: 'OutputAudioRawFrame#308', metadata: {} at 1.24s
2026-01-15 10:31:05.890 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 391, name: 'OutputAudioRawFrame#308', metadata: {} at 1.24s
2026-01-15 10:31:05.891 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 391, name: 'OutputAudioRawFrame#308', metadata: {} at 1.24s
2026-01-15 10:31:05.891 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#308(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:05.891 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 391, name: 'OutputAudioRawFrame#308', metadata: {} at 1.25s
2026-01-15 10:31:05.891 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 391, name: 'OutputAudioRawFrame#308', metadata: {} at 1.25s
2026-01-15 10:31:05.891 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 391, name: 'OutputAudioRawFrame#308', metadata: {} at 1.25s
2026-01-15 10:31:05.926 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 393, name: 'OutputAudioRawFrame#309', metadata: {} at 0.37s
2026-01-15 10:31:05.927 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 93, name: 'OutputAudioRawFrame#17', metadata: {} at 0.37s
2026-01-15 10:31:05.927 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 93, name: 'OutputAudioRawFrame#17', metadata: {} at 0.37s
2026-01-15 10:31:05.930 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 396, name: 'OutputAudioRawFrame#312', metadata: {} at 1.28s
2026-01-15 10:31:05.930 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 396, name: 'OutputAudioRawFrame#312', metadata: {} at 1.28s
2026-01-15 10:31:05.930 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#312(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:05.930 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 396, name: 'OutputAudioRawFrame#312', metadata: {} at 1.28s
2026-01-15 10:31:05.931 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 396, name: 'OutputAudioRawFrame#312', metadata: {} at 1.29s
2026-01-15 10:31:05.932 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 396, name: 'OutputAudioRawFrame#312', metadata: {} at 1.29s
2026-01-15 10:31:05.932 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#312(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:05.932 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 396, name: 'OutputAudioRawFrame#312', metadata: {} at 1.29s
2026-01-15 10:31:05.932 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 396, name: 'OutputAudioRawFrame#312', metadata: {} at 1.29s
2026-01-15 10:31:05.932 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 396, name: 'OutputAudioRawFrame#312', metadata: {} at 1.29s
2026-01-15 10:31:05.966 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 95, name: 'OutputAudioRawFrame#19', metadata: {} at 0.41s
2026-01-15 10:31:05.967 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 95, name: 'OutputAudioRawFrame#19', metadata: {} at 0.41s
2026-01-15 10:31:05.967 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 398, name: 'OutputAudioRawFrame#313', metadata: {} at 0.41s
2026-01-15 10:31:05.972 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 400, name: 'OutputAudioRawFrame#315', metadata: {} at 1.33s
2026-01-15 10:31:05.972 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 400, name: 'OutputAudioRawFrame#315', metadata: {} at 1.33s
2026-01-15 10:31:05.972 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#315(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:05.972 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 400, name: 'OutputAudioRawFrame#315', metadata: {} at 1.33s
2026-01-15 10:31:05.974 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 400, name: 'OutputAudioRawFrame#315', metadata: {} at 1.33s
2026-01-15 10:31:05.974 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 400, name: 'OutputAudioRawFrame#315', metadata: {} at 1.33s
2026-01-15 10:31:05.974 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#315(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:05.974 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 400, name: 'OutputAudioRawFrame#315', metadata: {} at 1.33s
2026-01-15 10:31:05.974 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 400, name: 'OutputAudioRawFrame#315', metadata: {} at 1.33s
2026-01-15 10:31:05.974 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 400, name: 'OutputAudioRawFrame#315', metadata: {} at 1.33s
2026-01-15 10:31:06.007 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 96, name: 'OutputAudioRawFrame#20', metadata: {} at 0.45s
2026-01-15 10:31:06.007 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 96, name: 'OutputAudioRawFrame#20', metadata: {} at 0.45s
2026-01-15 10:31:06.007 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 402, name: 'OutputAudioRawFrame#316', metadata: {} at 0.45s
2026-01-15 10:31:06.011 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 405, name: 'OutputAudioRawFrame#319', metadata: {} at 1.37s
2026-01-15 10:31:06.012 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 405, name: 'OutputAudioRawFrame#319', metadata: {} at 1.37s
2026-01-15 10:31:06.012 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#319(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.012 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 405, name: 'OutputAudioRawFrame#319', metadata: {} at 1.37s
2026-01-15 10:31:06.013 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 405, name: 'OutputAudioRawFrame#319', metadata: {} at 1.37s
2026-01-15 10:31:06.013 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 405, name: 'OutputAudioRawFrame#319', metadata: {} at 1.37s
2026-01-15 10:31:06.013 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#319(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.014 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 405, name: 'OutputAudioRawFrame#319', metadata: {} at 1.37s
2026-01-15 10:31:06.014 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 405, name: 'OutputAudioRawFrame#319', metadata: {} at 1.37s
2026-01-15 10:31:06.014 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 405, name: 'OutputAudioRawFrame#319', metadata: {} at 1.37s
2026-01-15 10:31:06.047 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 97, name: 'OutputAudioRawFrame#21', metadata: {} at 0.49s
2026-01-15 10:31:06.047 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 97, name: 'OutputAudioRawFrame#21', metadata: {} at 0.49s
2026-01-15 10:31:06.049 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 408, name: 'OutputAudioRawFrame#321', metadata: {} at 0.49s
2026-01-15 10:31:06.052 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 407, name: 'OutputAudioRawFrame#320', metadata: {} at 1.41s
2026-01-15 10:31:06.052 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 407, name: 'OutputAudioRawFrame#320', metadata: {} at 1.41s
2026-01-15 10:31:06.053 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#320(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.053 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 407, name: 'OutputAudioRawFrame#320', metadata: {} at 1.41s
2026-01-15 10:31:06.054 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 407, name: 'OutputAudioRawFrame#320', metadata: {} at 1.41s
2026-01-15 10:31:06.054 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 407, name: 'OutputAudioRawFrame#320', metadata: {} at 1.41s
2026-01-15 10:31:06.055 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#320(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.055 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 407, name: 'OutputAudioRawFrame#320', metadata: {} at 1.41s
2026-01-15 10:31:06.055 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 407, name: 'OutputAudioRawFrame#320', metadata: {} at 1.41s
2026-01-15 10:31:06.055 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 407, name: 'OutputAudioRawFrame#320', metadata: {} at 1.41s
2026-01-15 10:31:06.087 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 99, name: 'OutputAudioRawFrame#23', metadata: {} at 0.53s
2026-01-15 10:31:06.087 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 99, name: 'OutputAudioRawFrame#23', metadata: {} at 0.53s
2026-01-15 10:31:06.089 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 413, name: 'OutputAudioRawFrame#325', metadata: {} at 0.53s
2026-01-15 10:31:06.092 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 412, name: 'OutputAudioRawFrame#324', metadata: {} at 1.45s
2026-01-15 10:31:06.092 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 412, name: 'OutputAudioRawFrame#324', metadata: {} at 1.45s
2026-01-15 10:31:06.092 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#324(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.092 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 412, name: 'OutputAudioRawFrame#324', metadata: {} at 1.45s
2026-01-15 10:31:06.094 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 412, name: 'OutputAudioRawFrame#324', metadata: {} at 1.45s
2026-01-15 10:31:06.094 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 412, name: 'OutputAudioRawFrame#324', metadata: {} at 1.45s
2026-01-15 10:31:06.094 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#324(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.094 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 412, name: 'OutputAudioRawFrame#324', metadata: {} at 1.45s
2026-01-15 10:31:06.095 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 412, name: 'OutputAudioRawFrame#324', metadata: {} at 1.45s
2026-01-15 10:31:06.095 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 412, name: 'OutputAudioRawFrame#324', metadata: {} at 1.45s
2026-01-15 10:31:06.127 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 100, name: 'OutputAudioRawFrame#24', metadata: {} at 0.57s
2026-01-15 10:31:06.127 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 100, name: 'OutputAudioRawFrame#24', metadata: {} at 0.57s
2026-01-15 10:31:06.129 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 420, name: 'OutputAudioRawFrame#330', metadata: {} at 0.57s
2026-01-15 10:31:06.131 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 418, name: 'OutputAudioRawFrame#329', metadata: {} at 1.49s
2026-01-15 10:31:06.131 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 418, name: 'OutputAudioRawFrame#329', metadata: {} at 1.49s
2026-01-15 10:31:06.131 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#329(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.131 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 418, name: 'OutputAudioRawFrame#329', metadata: {} at 1.49s
2026-01-15 10:31:06.132 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 418, name: 'OutputAudioRawFrame#329', metadata: {} at 1.49s
2026-01-15 10:31:06.132 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 418, name: 'OutputAudioRawFrame#329', metadata: {} at 1.49s
2026-01-15 10:31:06.132 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#329(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.132 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 418, name: 'OutputAudioRawFrame#329', metadata: {} at 1.49s
2026-01-15 10:31:06.133 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 418, name: 'OutputAudioRawFrame#329', metadata: {} at 1.49s
2026-01-15 10:31:06.133 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 418, name: 'OutputAudioRawFrame#329', metadata: {} at 1.49s
2026-01-15 10:31:06.166 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 102, name: 'OutputAudioRawFrame#26', metadata: {} at 0.61s
2026-01-15 10:31:06.167 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 102, name: 'OutputAudioRawFrame#26', metadata: {} at 0.61s
2026-01-15 10:31:06.169 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 423, name: 'OutputAudioRawFrame#333', metadata: {} at 1.52s
2026-01-15 10:31:06.170 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 423, name: 'OutputAudioRawFrame#333', metadata: {} at 1.52s
2026-01-15 10:31:06.170 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#333(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.170 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 425, name: 'OutputAudioRawFrame#334', metadata: {} at 0.61s
2026-01-15 10:31:06.170 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 423, name: 'OutputAudioRawFrame#333', metadata: {} at 1.52s
2026-01-15 10:31:06.171 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 423, name: 'OutputAudioRawFrame#333', metadata: {} at 1.53s
2026-01-15 10:31:06.171 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 423, name: 'OutputAudioRawFrame#333', metadata: {} at 1.53s
2026-01-15 10:31:06.171 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#333(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.171 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 423, name: 'OutputAudioRawFrame#333', metadata: {} at 1.53s
2026-01-15 10:31:06.172 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 423, name: 'OutputAudioRawFrame#333', metadata: {} at 1.53s
2026-01-15 10:31:06.172 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 423, name: 'OutputAudioRawFrame#333', metadata: {} at 1.53s
2026-01-15 10:31:06.206 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 103, name: 'OutputAudioRawFrame#27', metadata: {} at 0.65s
2026-01-15 10:31:06.206 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 103, name: 'OutputAudioRawFrame#27', metadata: {} at 0.65s
2026-01-15 10:31:06.207 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 428, name: 'OutputAudioRawFrame#337', metadata: {} at 1.56s
2026-01-15 10:31:06.207 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 428, name: 'OutputAudioRawFrame#337', metadata: {} at 1.56s
2026-01-15 10:31:06.207 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#337(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.207 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 428, name: 'OutputAudioRawFrame#337', metadata: {} at 1.56s
2026-01-15 10:31:06.208 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 428, name: 'OutputAudioRawFrame#337', metadata: {} at 1.56s
2026-01-15 10:31:06.208 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 428, name: 'OutputAudioRawFrame#337', metadata: {} at 1.56s
2026-01-15 10:31:06.208 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#337(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.208 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 428, name: 'OutputAudioRawFrame#337', metadata: {} at 1.56s
2026-01-15 10:31:06.208 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 428, name: 'OutputAudioRawFrame#337', metadata: {} at 1.56s
2026-01-15 10:31:06.208 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 428, name: 'OutputAudioRawFrame#337', metadata: {} at 1.56s
2026-01-15 10:31:06.210 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 430, name: 'OutputAudioRawFrame#338', metadata: {} at 0.65s
2026-01-15 10:31:06.247 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 105, name: 'OutputAudioRawFrame#29', metadata: {} at 0.69s
2026-01-15 10:31:06.247 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 105, name: 'OutputAudioRawFrame#29', metadata: {} at 0.69s
2026-01-15 10:31:06.248 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 432, name: 'OutputAudioRawFrame#340', metadata: {} at 1.60s
2026-01-15 10:31:06.248 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 432, name: 'OutputAudioRawFrame#340', metadata: {} at 1.60s
2026-01-15 10:31:06.248 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#340(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.248 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 432, name: 'OutputAudioRawFrame#340', metadata: {} at 1.60s
2026-01-15 10:31:06.248 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 432, name: 'OutputAudioRawFrame#340', metadata: {} at 1.60s
2026-01-15 10:31:06.249 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 432, name: 'OutputAudioRawFrame#340', metadata: {} at 1.60s
2026-01-15 10:31:06.249 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#340(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.249 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 432, name: 'OutputAudioRawFrame#340', metadata: {} at 1.60s
2026-01-15 10:31:06.249 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 432, name: 'OutputAudioRawFrame#340', metadata: {} at 1.60s
2026-01-15 10:31:06.249 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 432, name: 'OutputAudioRawFrame#340', metadata: {} at 1.60s
2026-01-15 10:31:06.250 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 434, name: 'OutputAudioRawFrame#341', metadata: {} at 0.69s
2026-01-15 10:31:06.287 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 107, name: 'OutputAudioRawFrame#31', metadata: {} at 0.73s
2026-01-15 10:31:06.287 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 107, name: 'OutputAudioRawFrame#31', metadata: {} at 0.73s
2026-01-15 10:31:06.289 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 437, name: 'OutputAudioRawFrame#344', metadata: {} at 1.64s
2026-01-15 10:31:06.289 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 437, name: 'OutputAudioRawFrame#344', metadata: {} at 1.64s
2026-01-15 10:31:06.289 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#344(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.289 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 437, name: 'OutputAudioRawFrame#344', metadata: {} at 1.64s
2026-01-15 10:31:06.289 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 437, name: 'OutputAudioRawFrame#344', metadata: {} at 1.64s
2026-01-15 10:31:06.289 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 437, name: 'OutputAudioRawFrame#344', metadata: {} at 1.64s
2026-01-15 10:31:06.290 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#344(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.290 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 437, name: 'OutputAudioRawFrame#344', metadata: {} at 1.64s
2026-01-15 10:31:06.290 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 437, name: 'OutputAudioRawFrame#344', metadata: {} at 1.64s
2026-01-15 10:31:06.290 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 437, name: 'OutputAudioRawFrame#344', metadata: {} at 1.64s
2026-01-15 10:31:06.290 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 439, name: 'OutputAudioRawFrame#345', metadata: {} at 0.73s
2026-01-15 10:31:06.327 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 108, name: 'OutputAudioRawFrame#32', metadata: {} at 0.77s
2026-01-15 10:31:06.327 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 108, name: 'OutputAudioRawFrame#32', metadata: {} at 0.77s
2026-01-15 10:31:06.330 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 442, name: 'OutputAudioRawFrame#348', metadata: {} at 1.68s
2026-01-15 10:31:06.331 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 442, name: 'OutputAudioRawFrame#348', metadata: {} at 1.69s
2026-01-15 10:31:06.331 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#348(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.331 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 444, name: 'OutputAudioRawFrame#349', metadata: {} at 0.77s
2026-01-15 10:31:06.331 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 442, name: 'OutputAudioRawFrame#348', metadata: {} at 1.69s
2026-01-15 10:31:06.333 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 442, name: 'OutputAudioRawFrame#348', metadata: {} at 1.69s
2026-01-15 10:31:06.333 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 442, name: 'OutputAudioRawFrame#348', metadata: {} at 1.69s
2026-01-15 10:31:06.333 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#348(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.333 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 442, name: 'OutputAudioRawFrame#348', metadata: {} at 1.69s
2026-01-15 10:31:06.334 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 442, name: 'OutputAudioRawFrame#348', metadata: {} at 1.69s
2026-01-15 10:31:06.334 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 442, name: 'OutputAudioRawFrame#348', metadata: {} at 1.69s
2026-01-15 10:31:06.367 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 110, name: 'OutputAudioRawFrame#34', metadata: {} at 0.81s
2026-01-15 10:31:06.367 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 110, name: 'OutputAudioRawFrame#34', metadata: {} at 0.81s
2026-01-15 10:31:06.370 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 448, name: 'OutputAudioRawFrame#353', metadata: {} at 1.72s
2026-01-15 10:31:06.370 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 448, name: 'OutputAudioRawFrame#353', metadata: {} at 1.72s
2026-01-15 10:31:06.371 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#353(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.371 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 448, name: 'OutputAudioRawFrame#353', metadata: {} at 1.72s
2026-01-15 10:31:06.372 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 448, name: 'OutputAudioRawFrame#353', metadata: {} at 1.73s
2026-01-15 10:31:06.372 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 448, name: 'OutputAudioRawFrame#353', metadata: {} at 1.73s
2026-01-15 10:31:06.372 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#353(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.372 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 448, name: 'OutputAudioRawFrame#353', metadata: {} at 1.73s
2026-01-15 10:31:06.372 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 450, name: 'OutputAudioRawFrame#354', metadata: {} at 0.82s
2026-01-15 10:31:06.372 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 448, name: 'OutputAudioRawFrame#353', metadata: {} at 1.73s
2026-01-15 10:31:06.372 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 448, name: 'OutputAudioRawFrame#353', metadata: {} at 1.73s
2026-01-15 10:31:06.406 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 111, name: 'OutputAudioRawFrame#35', metadata: {} at 0.85s
2026-01-15 10:31:06.406 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 111, name: 'OutputAudioRawFrame#35', metadata: {} at 0.85s
2026-01-15 10:31:06.409 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 453, name: 'OutputAudioRawFrame#357', metadata: {} at 1.76s
2026-01-15 10:31:06.409 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 453, name: 'OutputAudioRawFrame#357', metadata: {} at 1.76s
2026-01-15 10:31:06.409 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#357(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.410 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 453, name: 'OutputAudioRawFrame#357', metadata: {} at 1.76s
2026-01-15 10:31:06.410 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 453, name: 'OutputAudioRawFrame#357', metadata: {} at 1.76s
2026-01-15 10:31:06.411 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 453, name: 'OutputAudioRawFrame#357', metadata: {} at 1.77s
2026-01-15 10:31:06.411 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#357(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.411 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 453, name: 'OutputAudioRawFrame#357', metadata: {} at 1.77s
2026-01-15 10:31:06.411 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 453, name: 'OutputAudioRawFrame#357', metadata: {} at 1.77s
2026-01-15 10:31:06.411 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 453, name: 'OutputAudioRawFrame#357', metadata: {} at 1.77s
2026-01-15 10:31:06.412 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 455, name: 'OutputAudioRawFrame#358', metadata: {} at 0.86s
2026-01-15 10:31:06.447 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 113, name: 'OutputAudioRawFrame#37', metadata: {} at 0.89s
2026-01-15 10:31:06.447 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 113, name: 'OutputAudioRawFrame#37', metadata: {} at 0.89s
2026-01-15 10:31:06.450 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 458, name: 'OutputAudioRawFrame#361', metadata: {} at 1.80s
2026-01-15 10:31:06.450 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 458, name: 'OutputAudioRawFrame#361', metadata: {} at 1.80s
2026-01-15 10:31:06.450 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#361(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.450 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 458, name: 'OutputAudioRawFrame#361', metadata: {} at 1.80s
2026-01-15 10:31:06.451 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 458, name: 'OutputAudioRawFrame#361', metadata: {} at 1.81s
2026-01-15 10:31:06.451 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 458, name: 'OutputAudioRawFrame#361', metadata: {} at 1.81s
2026-01-15 10:31:06.451 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#361(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.451 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 458, name: 'OutputAudioRawFrame#361', metadata: {} at 1.81s
2026-01-15 10:31:06.451 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 458, name: 'OutputAudioRawFrame#361', metadata: {} at 1.81s
2026-01-15 10:31:06.451 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 458, name: 'OutputAudioRawFrame#361', metadata: {} at 1.81s
2026-01-15 10:31:06.452 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 460, name: 'OutputAudioRawFrame#362', metadata: {} at 0.90s
2026-01-15 10:31:06.486 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 114, name: 'OutputAudioRawFrame#38', metadata: {} at 0.93s
2026-01-15 10:31:06.486 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 114, name: 'OutputAudioRawFrame#38', metadata: {} at 0.93s
2026-01-15 10:31:06.487 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 462, name: 'OutputAudioRawFrame#364', metadata: {} at 1.84s
2026-01-15 10:31:06.487 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 462, name: 'OutputAudioRawFrame#364', metadata: {} at 1.84s
2026-01-15 10:31:06.487 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#364(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.487 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 462, name: 'OutputAudioRawFrame#364', metadata: {} at 1.84s
2026-01-15 10:31:06.488 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 462, name: 'OutputAudioRawFrame#364', metadata: {} at 1.84s
2026-01-15 10:31:06.488 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 462, name: 'OutputAudioRawFrame#364', metadata: {} at 1.84s
2026-01-15 10:31:06.488 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#364(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.488 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 462, name: 'OutputAudioRawFrame#364', metadata: {} at 1.84s
2026-01-15 10:31:06.488 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 462, name: 'OutputAudioRawFrame#364', metadata: {} at 1.84s
2026-01-15 10:31:06.488 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 462, name: 'OutputAudioRawFrame#364', metadata: {} at 1.84s
2026-01-15 10:31:06.493 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 464, name: 'OutputAudioRawFrame#365', metadata: {} at 0.94s
2026-01-15 10:31:06.527 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 115, name: 'OutputAudioRawFrame#39', metadata: {} at 0.97s
2026-01-15 10:31:06.527 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 115, name: 'OutputAudioRawFrame#39', metadata: {} at 0.97s
2026-01-15 10:31:06.529 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 467, name: 'OutputAudioRawFrame#368', metadata: {} at 1.88s
2026-01-15 10:31:06.529 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 467, name: 'OutputAudioRawFrame#368', metadata: {} at 1.88s
2026-01-15 10:31:06.529 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#368(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.529 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 467, name: 'OutputAudioRawFrame#368', metadata: {} at 1.88s
2026-01-15 10:31:06.530 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 467, name: 'OutputAudioRawFrame#368', metadata: {} at 1.88s
2026-01-15 10:31:06.530 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 467, name: 'OutputAudioRawFrame#368', metadata: {} at 1.88s
2026-01-15 10:31:06.530 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#368(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.530 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 467, name: 'OutputAudioRawFrame#368', metadata: {} at 1.88s
2026-01-15 10:31:06.530 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 467, name: 'OutputAudioRawFrame#368', metadata: {} at 1.88s
2026-01-15 10:31:06.530 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 467, name: 'OutputAudioRawFrame#368', metadata: {} at 1.88s
2026-01-15 10:31:06.533 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 469, name: 'OutputAudioRawFrame#369', metadata: {} at 0.98s
2026-01-15 10:31:06.567 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 117, name: 'OutputAudioRawFrame#41', metadata: {} at 1.01s
2026-01-15 10:31:06.567 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 117, name: 'OutputAudioRawFrame#41', metadata: {} at 1.01s
2026-01-15 10:31:06.568 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 472, name: 'OutputAudioRawFrame#372', metadata: {} at 1.92s
2026-01-15 10:31:06.568 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 472, name: 'OutputAudioRawFrame#372', metadata: {} at 1.92s
2026-01-15 10:31:06.569 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#372(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.569 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 472, name: 'OutputAudioRawFrame#372', metadata: {} at 1.92s
2026-01-15 10:31:06.569 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 472, name: 'OutputAudioRawFrame#372', metadata: {} at 1.92s
2026-01-15 10:31:06.569 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 472, name: 'OutputAudioRawFrame#372', metadata: {} at 1.92s
2026-01-15 10:31:06.569 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#372(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.569 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 472, name: 'OutputAudioRawFrame#372', metadata: {} at 1.92s
2026-01-15 10:31:06.570 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 472, name: 'OutputAudioRawFrame#372', metadata: {} at 1.92s
2026-01-15 10:31:06.570 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 472, name: 'OutputAudioRawFrame#372', metadata: {} at 1.92s
2026-01-15 10:31:06.574 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 474, name: 'OutputAudioRawFrame#373', metadata: {} at 1.02s
2026-01-15 10:31:06.606 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 118, name: 'OutputAudioRawFrame#42', metadata: {} at 1.05s
2026-01-15 10:31:06.606 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 118, name: 'OutputAudioRawFrame#42', metadata: {} at 1.05s
2026-01-15 10:31:06.609 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 478, name: 'OutputAudioRawFrame#377', metadata: {} at 1.96s
2026-01-15 10:31:06.609 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 478, name: 'OutputAudioRawFrame#377', metadata: {} at 1.96s
2026-01-15 10:31:06.609 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#377(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.609 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 478, name: 'OutputAudioRawFrame#377', metadata: {} at 1.96s
2026-01-15 10:31:06.609 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 478, name: 'OutputAudioRawFrame#377', metadata: {} at 1.96s
2026-01-15 10:31:06.610 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 478, name: 'OutputAudioRawFrame#377', metadata: {} at 1.96s
2026-01-15 10:31:06.610 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#377(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.610 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 478, name: 'OutputAudioRawFrame#377', metadata: {} at 1.96s
2026-01-15 10:31:06.610 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 478, name: 'OutputAudioRawFrame#377', metadata: {} at 1.96s
2026-01-15 10:31:06.610 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 478, name: 'OutputAudioRawFrame#377', metadata: {} at 1.96s
2026-01-15 10:31:06.614 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 480, name: 'OutputAudioRawFrame#378', metadata: {} at 1.06s
2026-01-15 10:31:06.646 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 120, name: 'OutputAudioRawFrame#44', metadata: {} at 1.09s
2026-01-15 10:31:06.646 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 120, name: 'OutputAudioRawFrame#44', metadata: {} at 1.09s
2026-01-15 10:31:06.647 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 483, name: 'OutputAudioRawFrame#381', metadata: {} at 2.00s
2026-01-15 10:31:06.647 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 483, name: 'OutputAudioRawFrame#381', metadata: {} at 2.00s
2026-01-15 10:31:06.647 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#381(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.648 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 483, name: 'OutputAudioRawFrame#381', metadata: {} at 2.00s
2026-01-15 10:31:06.648 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 483, name: 'OutputAudioRawFrame#381', metadata: {} at 2.00s
2026-01-15 10:31:06.648 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 483, name: 'OutputAudioRawFrame#381', metadata: {} at 2.00s
2026-01-15 10:31:06.648 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#381(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.649 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 483, name: 'OutputAudioRawFrame#381', metadata: {} at 2.00s
2026-01-15 10:31:06.649 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 483, name: 'OutputAudioRawFrame#381', metadata: {} at 2.00s
2026-01-15 10:31:06.649 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 483, name: 'OutputAudioRawFrame#381', metadata: {} at 2.00s
2026-01-15 10:31:06.655 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 485, name: 'OutputAudioRawFrame#382', metadata: {} at 1.10s
2026-01-15 10:31:06.687 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 121, name: 'OutputAudioRawFrame#45', metadata: {} at 1.13s
2026-01-15 10:31:06.687 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 121, name: 'OutputAudioRawFrame#45', metadata: {} at 1.13s
2026-01-15 10:31:06.690 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 488, name: 'OutputAudioRawFrame#385', metadata: {} at 2.04s
2026-01-15 10:31:06.690 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 488, name: 'OutputAudioRawFrame#385', metadata: {} at 2.04s
2026-01-15 10:31:06.690 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#385(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.690 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 488, name: 'OutputAudioRawFrame#385', metadata: {} at 2.04s
2026-01-15 10:31:06.691 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 488, name: 'OutputAudioRawFrame#385', metadata: {} at 2.05s
2026-01-15 10:31:06.691 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 488, name: 'OutputAudioRawFrame#385', metadata: {} at 2.05s
2026-01-15 10:31:06.691 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#385(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.691 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 488, name: 'OutputAudioRawFrame#385', metadata: {} at 2.05s
2026-01-15 10:31:06.692 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 488, name: 'OutputAudioRawFrame#385', metadata: {} at 2.05s
2026-01-15 10:31:06.692 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 488, name: 'OutputAudioRawFrame#385', metadata: {} at 2.05s
2026-01-15 10:31:06.696 | INFO     | [EVAL-SYS] | Finished streaming audio: /Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_1_english_baseline.wav
2026-01-15 10:31:06.727 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 123, name: 'OutputAudioRawFrame#47', metadata: {} at 1.17s
2026-01-15 10:31:06.727 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 123, name: 'OutputAudioRawFrame#47', metadata: {} at 1.17s
2026-01-15 10:31:06.729 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 490, name: 'OutputAudioRawFrame#386', metadata: {} at 2.08s
2026-01-15 10:31:06.729 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 490, name: 'OutputAudioRawFrame#386', metadata: {} at 2.08s
2026-01-15 10:31:06.729 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#386(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.729 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 490, name: 'OutputAudioRawFrame#386', metadata: {} at 2.08s
2026-01-15 10:31:06.729 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 490, name: 'OutputAudioRawFrame#386', metadata: {} at 2.08s
2026-01-15 10:31:06.730 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 490, name: 'OutputAudioRawFrame#386', metadata: {} at 2.08s
2026-01-15 10:31:06.730 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#386(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.730 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 490, name: 'OutputAudioRawFrame#386', metadata: {} at 2.08s
2026-01-15 10:31:06.730 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 490, name: 'OutputAudioRawFrame#386', metadata: {} at 2.08s
2026-01-15 10:31:06.730 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 490, name: 'OutputAudioRawFrame#386', metadata: {} at 2.08s
2026-01-15 10:31:06.766 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 125, name: 'OutputAudioRawFrame#49', metadata: {} at 1.21s
2026-01-15 10:31:06.766 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 125, name: 'OutputAudioRawFrame#49', metadata: {} at 1.21s
2026-01-15 10:31:06.769 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 492, name: 'OutputAudioRawFrame#387', metadata: {} at 2.12s
2026-01-15 10:31:06.769 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 492, name: 'OutputAudioRawFrame#387', metadata: {} at 2.12s
2026-01-15 10:31:06.769 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#387(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.769 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 492, name: 'OutputAudioRawFrame#387', metadata: {} at 2.12s
2026-01-15 10:31:06.769 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 492, name: 'OutputAudioRawFrame#387', metadata: {} at 2.12s
2026-01-15 10:31:06.769 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 492, name: 'OutputAudioRawFrame#387', metadata: {} at 2.12s
2026-01-15 10:31:06.769 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#387(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.770 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 492, name: 'OutputAudioRawFrame#387', metadata: {} at 2.12s
2026-01-15 10:31:06.770 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 492, name: 'OutputAudioRawFrame#387', metadata: {} at 2.12s
2026-01-15 10:31:06.770 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 492, name: 'OutputAudioRawFrame#387', metadata: {} at 2.12s
2026-01-15 10:31:06.807 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 126, name: 'OutputAudioRawFrame#50', metadata: {} at 1.25s
2026-01-15 10:31:06.807 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 126, name: 'OutputAudioRawFrame#50', metadata: {} at 1.25s
2026-01-15 10:31:06.808 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 494, name: 'OutputAudioRawFrame#388', metadata: {} at 2.16s
2026-01-15 10:31:06.808 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 494, name: 'OutputAudioRawFrame#388', metadata: {} at 2.16s
2026-01-15 10:31:06.808 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#388(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.809 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 494, name: 'OutputAudioRawFrame#388', metadata: {} at 2.16s
2026-01-15 10:31:06.809 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 494, name: 'OutputAudioRawFrame#388', metadata: {} at 2.16s
2026-01-15 10:31:06.809 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 494, name: 'OutputAudioRawFrame#388', metadata: {} at 2.16s
2026-01-15 10:31:06.809 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#388(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.809 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 494, name: 'OutputAudioRawFrame#388', metadata: {} at 2.16s
2026-01-15 10:31:06.809 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 494, name: 'OutputAudioRawFrame#388', metadata: {} at 2.16s
2026-01-15 10:31:06.809 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 494, name: 'OutputAudioRawFrame#388', metadata: {} at 2.16s
2026-01-15 10:31:06.847 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 128, name: 'OutputAudioRawFrame#52', metadata: {} at 1.29s
2026-01-15 10:31:06.847 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 128, name: 'OutputAudioRawFrame#52', metadata: {} at 1.29s
2026-01-15 10:31:06.850 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 496, name: 'OutputAudioRawFrame#389', metadata: {} at 2.20s
2026-01-15 10:31:06.850 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 496, name: 'OutputAudioRawFrame#389', metadata: {} at 2.20s
2026-01-15 10:31:06.851 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#389(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.851 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 496, name: 'OutputAudioRawFrame#389', metadata: {} at 2.20s
2026-01-15 10:31:06.852 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 496, name: 'OutputAudioRawFrame#389', metadata: {} at 2.21s
2026-01-15 10:31:06.852 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 496, name: 'OutputAudioRawFrame#389', metadata: {} at 2.21s
2026-01-15 10:31:06.852 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#389(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.852 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 496, name: 'OutputAudioRawFrame#389', metadata: {} at 2.21s
2026-01-15 10:31:06.852 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 496, name: 'OutputAudioRawFrame#389', metadata: {} at 2.21s
2026-01-15 10:31:06.852 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 496, name: 'OutputAudioRawFrame#389', metadata: {} at 2.21s
2026-01-15 10:31:06.887 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 129, name: 'OutputAudioRawFrame#53', metadata: {} at 1.33s
2026-01-15 10:31:06.887 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 129, name: 'OutputAudioRawFrame#53', metadata: {} at 1.33s
2026-01-15 10:31:06.890 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 498, name: 'OutputAudioRawFrame#390', metadata: {} at 2.24s
2026-01-15 10:31:06.890 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 498, name: 'OutputAudioRawFrame#390', metadata: {} at 2.24s
2026-01-15 10:31:06.890 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#390(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.890 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 498, name: 'OutputAudioRawFrame#390', metadata: {} at 2.24s
2026-01-15 10:31:06.891 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 498, name: 'OutputAudioRawFrame#390', metadata: {} at 2.25s
2026-01-15 10:31:06.891 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 498, name: 'OutputAudioRawFrame#390', metadata: {} at 2.25s
2026-01-15 10:31:06.892 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#390(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.892 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 498, name: 'OutputAudioRawFrame#390', metadata: {} at 2.25s
2026-01-15 10:31:06.892 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 498, name: 'OutputAudioRawFrame#390', metadata: {} at 2.25s
2026-01-15 10:31:06.892 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 498, name: 'OutputAudioRawFrame#390', metadata: {} at 2.25s
2026-01-15 10:31:06.927 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 131, name: 'OutputAudioRawFrame#55', metadata: {} at 1.37s
2026-01-15 10:31:06.927 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 131, name: 'OutputAudioRawFrame#55', metadata: {} at 1.37s
2026-01-15 10:31:06.930 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 500, name: 'OutputAudioRawFrame#391', metadata: {} at 2.28s
2026-01-15 10:31:06.931 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 500, name: 'OutputAudioRawFrame#391', metadata: {} at 2.28s
2026-01-15 10:31:06.931 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#391(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.931 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 500, name: 'OutputAudioRawFrame#391', metadata: {} at 2.29s
2026-01-15 10:31:06.932 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 500, name: 'OutputAudioRawFrame#391', metadata: {} at 2.29s
2026-01-15 10:31:06.932 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 500, name: 'OutputAudioRawFrame#391', metadata: {} at 2.29s
2026-01-15 10:31:06.932 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#391(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.932 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 500, name: 'OutputAudioRawFrame#391', metadata: {} at 2.29s
2026-01-15 10:31:06.932 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 500, name: 'OutputAudioRawFrame#391', metadata: {} at 2.29s
2026-01-15 10:31:06.933 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 500, name: 'OutputAudioRawFrame#391', metadata: {} at 2.29s
2026-01-15 10:31:06.967 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 132, name: 'OutputAudioRawFrame#56', metadata: {} at 1.41s
2026-01-15 10:31:06.967 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 132, name: 'OutputAudioRawFrame#56', metadata: {} at 1.41s
2026-01-15 10:31:06.970 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 502, name: 'OutputAudioRawFrame#392', metadata: {} at 2.32s
2026-01-15 10:31:06.971 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 502, name: 'OutputAudioRawFrame#392', metadata: {} at 2.32s
2026-01-15 10:31:06.971 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#392(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.971 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 502, name: 'OutputAudioRawFrame#392', metadata: {} at 2.33s
2026-01-15 10:31:06.973 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 502, name: 'OutputAudioRawFrame#392', metadata: {} at 2.33s
2026-01-15 10:31:06.973 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 502, name: 'OutputAudioRawFrame#392', metadata: {} at 2.33s
2026-01-15 10:31:06.974 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#392(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:06.974 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 502, name: 'OutputAudioRawFrame#392', metadata: {} at 2.33s
2026-01-15 10:31:06.974 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 502, name: 'OutputAudioRawFrame#392', metadata: {} at 2.33s
2026-01-15 10:31:06.974 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 502, name: 'OutputAudioRawFrame#392', metadata: {} at 2.33s
2026-01-15 10:31:07.007 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 134, name: 'OutputAudioRawFrame#58', metadata: {} at 1.45s
2026-01-15 10:31:07.007 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 134, name: 'OutputAudioRawFrame#58', metadata: {} at 1.45s
2026-01-15 10:31:07.008 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 504, name: 'OutputAudioRawFrame#393', metadata: {} at 2.36s
2026-01-15 10:31:07.008 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 504, name: 'OutputAudioRawFrame#393', metadata: {} at 2.36s
2026-01-15 10:31:07.008 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#393(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.008 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 504, name: 'OutputAudioRawFrame#393', metadata: {} at 2.36s
2026-01-15 10:31:07.009 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 504, name: 'OutputAudioRawFrame#393', metadata: {} at 2.36s
2026-01-15 10:31:07.009 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 504, name: 'OutputAudioRawFrame#393', metadata: {} at 2.36s
2026-01-15 10:31:07.009 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#393(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.009 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 504, name: 'OutputAudioRawFrame#393', metadata: {} at 2.36s
2026-01-15 10:31:07.009 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 504, name: 'OutputAudioRawFrame#393', metadata: {} at 2.36s
2026-01-15 10:31:07.009 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 504, name: 'OutputAudioRawFrame#393', metadata: {} at 2.36s
2026-01-15 10:31:07.047 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 135, name: 'OutputAudioRawFrame#59', metadata: {} at 1.49s
2026-01-15 10:31:07.047 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 135, name: 'OutputAudioRawFrame#59', metadata: {} at 1.49s
2026-01-15 10:31:07.048 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 506, name: 'OutputAudioRawFrame#394', metadata: {} at 2.40s
2026-01-15 10:31:07.048 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 506, name: 'OutputAudioRawFrame#394', metadata: {} at 2.40s
2026-01-15 10:31:07.048 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#394(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.048 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 506, name: 'OutputAudioRawFrame#394', metadata: {} at 2.40s
2026-01-15 10:31:07.048 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 506, name: 'OutputAudioRawFrame#394', metadata: {} at 2.40s
2026-01-15 10:31:07.048 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 506, name: 'OutputAudioRawFrame#394', metadata: {} at 2.40s
2026-01-15 10:31:07.048 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#394(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.049 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 506, name: 'OutputAudioRawFrame#394', metadata: {} at 2.40s
2026-01-15 10:31:07.049 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 506, name: 'OutputAudioRawFrame#394', metadata: {} at 2.40s
2026-01-15 10:31:07.049 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 506, name: 'OutputAudioRawFrame#394', metadata: {} at 2.40s
2026-01-15 10:31:07.087 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 136, name: 'OutputAudioRawFrame#60', metadata: {} at 1.53s
2026-01-15 10:31:07.087 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 136, name: 'OutputAudioRawFrame#60', metadata: {} at 1.53s
2026-01-15 10:31:07.088 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 508, name: 'OutputAudioRawFrame#395', metadata: {} at 2.44s
2026-01-15 10:31:07.088 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 508, name: 'OutputAudioRawFrame#395', metadata: {} at 2.44s
2026-01-15 10:31:07.088 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#395(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.089 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 508, name: 'OutputAudioRawFrame#395', metadata: {} at 2.44s
2026-01-15 10:31:07.089 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 508, name: 'OutputAudioRawFrame#395', metadata: {} at 2.44s
2026-01-15 10:31:07.089 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 508, name: 'OutputAudioRawFrame#395', metadata: {} at 2.44s
2026-01-15 10:31:07.089 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#395(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.089 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 508, name: 'OutputAudioRawFrame#395', metadata: {} at 2.44s
2026-01-15 10:31:07.089 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 508, name: 'OutputAudioRawFrame#395', metadata: {} at 2.44s
2026-01-15 10:31:07.089 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 508, name: 'OutputAudioRawFrame#395', metadata: {} at 2.44s
2026-01-15 10:31:07.127 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 138, name: 'OutputAudioRawFrame#62', metadata: {} at 1.57s
2026-01-15 10:31:07.127 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 138, name: 'OutputAudioRawFrame#62', metadata: {} at 1.57s
2026-01-15 10:31:07.128 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 510, name: 'OutputAudioRawFrame#396', metadata: {} at 2.48s
2026-01-15 10:31:07.128 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 510, name: 'OutputAudioRawFrame#396', metadata: {} at 2.48s
2026-01-15 10:31:07.128 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#396(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.128 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 510, name: 'OutputAudioRawFrame#396', metadata: {} at 2.48s
2026-01-15 10:31:07.129 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 510, name: 'OutputAudioRawFrame#396', metadata: {} at 2.48s
2026-01-15 10:31:07.129 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 510, name: 'OutputAudioRawFrame#396', metadata: {} at 2.48s
2026-01-15 10:31:07.129 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#396(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.129 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 510, name: 'OutputAudioRawFrame#396', metadata: {} at 2.48s
2026-01-15 10:31:07.129 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 510, name: 'OutputAudioRawFrame#396', metadata: {} at 2.48s
2026-01-15 10:31:07.129 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 510, name: 'OutputAudioRawFrame#396', metadata: {} at 2.48s
2026-01-15 10:31:07.167 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 139, name: 'OutputAudioRawFrame#63', metadata: {} at 1.61s
2026-01-15 10:31:07.167 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 139, name: 'OutputAudioRawFrame#63', metadata: {} at 1.61s
2026-01-15 10:31:07.168 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 512, name: 'OutputAudioRawFrame#397', metadata: {} at 2.52s
2026-01-15 10:31:07.168 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 512, name: 'OutputAudioRawFrame#397', metadata: {} at 2.52s
2026-01-15 10:31:07.168 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#397(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.168 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 512, name: 'OutputAudioRawFrame#397', metadata: {} at 2.52s
2026-01-15 10:31:07.168 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 512, name: 'OutputAudioRawFrame#397', metadata: {} at 2.52s
2026-01-15 10:31:07.169 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 512, name: 'OutputAudioRawFrame#397', metadata: {} at 2.52s
2026-01-15 10:31:07.169 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#397(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.169 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 512, name: 'OutputAudioRawFrame#397', metadata: {} at 2.52s
2026-01-15 10:31:07.169 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 512, name: 'OutputAudioRawFrame#397', metadata: {} at 2.52s
2026-01-15 10:31:07.169 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 512, name: 'OutputAudioRawFrame#397', metadata: {} at 2.52s
2026-01-15 10:31:07.207 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 141, name: 'OutputAudioRawFrame#65', metadata: {} at 1.65s
2026-01-15 10:31:07.207 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 141, name: 'OutputAudioRawFrame#65', metadata: {} at 1.65s
2026-01-15 10:31:07.208 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 514, name: 'OutputAudioRawFrame#398', metadata: {} at 2.56s
2026-01-15 10:31:07.208 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 514, name: 'OutputAudioRawFrame#398', metadata: {} at 2.56s
2026-01-15 10:31:07.208 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#398(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.208 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 514, name: 'OutputAudioRawFrame#398', metadata: {} at 2.56s
2026-01-15 10:31:07.209 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 514, name: 'OutputAudioRawFrame#398', metadata: {} at 2.56s
2026-01-15 10:31:07.209 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 514, name: 'OutputAudioRawFrame#398', metadata: {} at 2.56s
2026-01-15 10:31:07.209 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#398(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.209 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 514, name: 'OutputAudioRawFrame#398', metadata: {} at 2.56s
2026-01-15 10:31:07.209 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 514, name: 'OutputAudioRawFrame#398', metadata: {} at 2.56s
2026-01-15 10:31:07.209 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 514, name: 'OutputAudioRawFrame#398', metadata: {} at 2.56s
2026-01-15 10:31:07.247 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 143, name: 'OutputAudioRawFrame#67', metadata: {} at 1.69s
2026-01-15 10:31:07.247 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 143, name: 'OutputAudioRawFrame#67', metadata: {} at 1.69s
2026-01-15 10:31:07.251 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 516, name: 'OutputAudioRawFrame#399', metadata: {} at 2.61s
2026-01-15 10:31:07.251 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 516, name: 'OutputAudioRawFrame#399', metadata: {} at 2.61s
2026-01-15 10:31:07.251 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#399(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.252 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 516, name: 'OutputAudioRawFrame#399', metadata: {} at 2.61s
2026-01-15 10:31:07.253 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 516, name: 'OutputAudioRawFrame#399', metadata: {} at 2.61s
2026-01-15 10:31:07.253 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 516, name: 'OutputAudioRawFrame#399', metadata: {} at 2.61s
2026-01-15 10:31:07.253 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#399(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.253 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 516, name: 'OutputAudioRawFrame#399', metadata: {} at 2.61s
2026-01-15 10:31:07.253 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 516, name: 'OutputAudioRawFrame#399', metadata: {} at 2.61s
2026-01-15 10:31:07.253 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 516, name: 'OutputAudioRawFrame#399', metadata: {} at 2.61s
2026-01-15 10:31:07.287 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 144, name: 'OutputAudioRawFrame#68', metadata: {} at 1.73s
2026-01-15 10:31:07.287 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 144, name: 'OutputAudioRawFrame#68', metadata: {} at 1.73s
2026-01-15 10:31:07.291 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 518, name: 'OutputAudioRawFrame#400', metadata: {} at 2.65s
2026-01-15 10:31:07.291 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 518, name: 'OutputAudioRawFrame#400', metadata: {} at 2.65s
2026-01-15 10:31:07.292 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#400(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.292 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 518, name: 'OutputAudioRawFrame#400', metadata: {} at 2.65s
2026-01-15 10:31:07.294 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 518, name: 'OutputAudioRawFrame#400', metadata: {} at 2.65s
2026-01-15 10:31:07.295 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 518, name: 'OutputAudioRawFrame#400', metadata: {} at 2.65s
2026-01-15 10:31:07.295 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#400(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.295 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 518, name: 'OutputAudioRawFrame#400', metadata: {} at 2.65s
2026-01-15 10:31:07.295 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 518, name: 'OutputAudioRawFrame#400', metadata: {} at 2.65s
2026-01-15 10:31:07.296 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 518, name: 'OutputAudioRawFrame#400', metadata: {} at 2.65s
2026-01-15 10:31:07.327 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 146, name: 'OutputAudioRawFrame#70', metadata: {} at 1.77s
2026-01-15 10:31:07.327 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 146, name: 'OutputAudioRawFrame#70', metadata: {} at 1.77s
2026-01-15 10:31:07.329 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 520, name: 'OutputAudioRawFrame#401', metadata: {} at 2.68s
2026-01-15 10:31:07.329 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 520, name: 'OutputAudioRawFrame#401', metadata: {} at 2.68s
2026-01-15 10:31:07.329 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#401(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.329 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 520, name: 'OutputAudioRawFrame#401', metadata: {} at 2.68s
2026-01-15 10:31:07.330 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 520, name: 'OutputAudioRawFrame#401', metadata: {} at 2.68s
2026-01-15 10:31:07.330 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 520, name: 'OutputAudioRawFrame#401', metadata: {} at 2.68s
2026-01-15 10:31:07.330 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#401(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.330 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 520, name: 'OutputAudioRawFrame#401', metadata: {} at 2.68s
2026-01-15 10:31:07.330 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 520, name: 'OutputAudioRawFrame#401', metadata: {} at 2.68s
2026-01-15 10:31:07.330 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 520, name: 'OutputAudioRawFrame#401', metadata: {} at 2.68s
2026-01-15 10:31:07.367 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 147, name: 'OutputAudioRawFrame#71', metadata: {} at 1.81s
2026-01-15 10:31:07.367 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 147, name: 'OutputAudioRawFrame#71', metadata: {} at 1.81s
2026-01-15 10:31:07.368 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 522, name: 'OutputAudioRawFrame#402', metadata: {} at 2.72s
2026-01-15 10:31:07.368 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 522, name: 'OutputAudioRawFrame#402', metadata: {} at 2.72s
2026-01-15 10:31:07.368 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#402(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.369 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 522, name: 'OutputAudioRawFrame#402', metadata: {} at 2.72s
2026-01-15 10:31:07.369 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 522, name: 'OutputAudioRawFrame#402', metadata: {} at 2.72s
2026-01-15 10:31:07.369 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 522, name: 'OutputAudioRawFrame#402', metadata: {} at 2.72s
2026-01-15 10:31:07.369 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#402(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.369 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 522, name: 'OutputAudioRawFrame#402', metadata: {} at 2.72s
2026-01-15 10:31:07.370 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 522, name: 'OutputAudioRawFrame#402', metadata: {} at 2.72s
2026-01-15 10:31:07.370 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 522, name: 'OutputAudioRawFrame#402', metadata: {} at 2.72s
2026-01-15 10:31:07.407 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 149, name: 'OutputAudioRawFrame#73', metadata: {} at 1.85s
2026-01-15 10:31:07.407 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 149, name: 'OutputAudioRawFrame#73', metadata: {} at 1.85s
2026-01-15 10:31:07.411 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 524, name: 'OutputAudioRawFrame#403', metadata: {} at 2.76s
2026-01-15 10:31:07.411 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 524, name: 'OutputAudioRawFrame#403', metadata: {} at 2.77s
2026-01-15 10:31:07.411 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#403(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.411 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 524, name: 'OutputAudioRawFrame#403', metadata: {} at 2.77s
2026-01-15 10:31:07.412 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 524, name: 'OutputAudioRawFrame#403', metadata: {} at 2.77s
2026-01-15 10:31:07.412 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 524, name: 'OutputAudioRawFrame#403', metadata: {} at 2.77s
2026-01-15 10:31:07.412 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#403(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.412 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 524, name: 'OutputAudioRawFrame#403', metadata: {} at 2.77s
2026-01-15 10:31:07.412 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 524, name: 'OutputAudioRawFrame#403', metadata: {} at 2.77s
2026-01-15 10:31:07.412 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 524, name: 'OutputAudioRawFrame#403', metadata: {} at 2.77s
2026-01-15 10:31:07.447 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 150, name: 'OutputAudioRawFrame#74', metadata: {} at 1.89s
2026-01-15 10:31:07.447 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 150, name: 'OutputAudioRawFrame#74', metadata: {} at 1.89s
2026-01-15 10:31:07.449 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 526, name: 'OutputAudioRawFrame#404', metadata: {} at 2.80s
2026-01-15 10:31:07.450 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 526, name: 'OutputAudioRawFrame#404', metadata: {} at 2.80s
2026-01-15 10:31:07.450 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#404(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.450 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 526, name: 'OutputAudioRawFrame#404', metadata: {} at 2.80s
2026-01-15 10:31:07.451 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 526, name: 'OutputAudioRawFrame#404', metadata: {} at 2.81s
2026-01-15 10:31:07.451 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 526, name: 'OutputAudioRawFrame#404', metadata: {} at 2.81s
2026-01-15 10:31:07.451 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#404(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.452 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 526, name: 'OutputAudioRawFrame#404', metadata: {} at 2.81s
2026-01-15 10:31:07.452 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 526, name: 'OutputAudioRawFrame#404', metadata: {} at 2.81s
2026-01-15 10:31:07.452 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 526, name: 'OutputAudioRawFrame#404', metadata: {} at 2.81s
2026-01-15 10:31:07.486 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 152, name: 'OutputAudioRawFrame#76', metadata: {} at 1.93s
2026-01-15 10:31:07.486 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 152, name: 'OutputAudioRawFrame#76', metadata: {} at 1.93s
2026-01-15 10:31:07.489 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 528, name: 'OutputAudioRawFrame#405', metadata: {} at 2.84s
2026-01-15 10:31:07.490 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 528, name: 'OutputAudioRawFrame#405', metadata: {} at 2.84s
2026-01-15 10:31:07.490 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#405(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.490 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 528, name: 'OutputAudioRawFrame#405', metadata: {} at 2.84s
2026-01-15 10:31:07.491 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 528, name: 'OutputAudioRawFrame#405', metadata: {} at 2.85s
2026-01-15 10:31:07.491 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 528, name: 'OutputAudioRawFrame#405', metadata: {} at 2.85s
2026-01-15 10:31:07.491 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#405(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.492 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 528, name: 'OutputAudioRawFrame#405', metadata: {} at 2.85s
2026-01-15 10:31:07.492 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 528, name: 'OutputAudioRawFrame#405', metadata: {} at 2.85s
2026-01-15 10:31:07.492 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 528, name: 'OutputAudioRawFrame#405', metadata: {} at 2.85s
2026-01-15 10:31:07.527 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 153, name: 'OutputAudioRawFrame#77', metadata: {} at 1.97s
2026-01-15 10:31:07.527 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 153, name: 'OutputAudioRawFrame#77', metadata: {} at 1.97s
2026-01-15 10:31:07.529 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 530, name: 'OutputAudioRawFrame#406', metadata: {} at 2.88s
2026-01-15 10:31:07.529 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 530, name: 'OutputAudioRawFrame#406', metadata: {} at 2.88s
2026-01-15 10:31:07.529 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#406(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.529 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 530, name: 'OutputAudioRawFrame#406', metadata: {} at 2.88s
2026-01-15 10:31:07.530 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 530, name: 'OutputAudioRawFrame#406', metadata: {} at 2.88s
2026-01-15 10:31:07.530 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 530, name: 'OutputAudioRawFrame#406', metadata: {} at 2.88s
2026-01-15 10:31:07.530 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#406(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.530 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 530, name: 'OutputAudioRawFrame#406', metadata: {} at 2.88s
2026-01-15 10:31:07.531 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 530, name: 'OutputAudioRawFrame#406', metadata: {} at 2.88s
2026-01-15 10:31:07.531 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 530, name: 'OutputAudioRawFrame#406', metadata: {} at 2.88s
2026-01-15 10:31:07.567 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 154, name: 'OutputAudioRawFrame#78', metadata: {} at 2.01s
2026-01-15 10:31:07.567 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 154, name: 'OutputAudioRawFrame#78', metadata: {} at 2.01s
2026-01-15 10:31:07.570 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 532, name: 'OutputAudioRawFrame#407', metadata: {} at 2.92s
2026-01-15 10:31:07.570 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 532, name: 'OutputAudioRawFrame#407', metadata: {} at 2.92s
2026-01-15 10:31:07.570 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#407(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.570 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 532, name: 'OutputAudioRawFrame#407', metadata: {} at 2.92s
2026-01-15 10:31:07.571 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 532, name: 'OutputAudioRawFrame#407', metadata: {} at 2.93s
2026-01-15 10:31:07.571 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 532, name: 'OutputAudioRawFrame#407', metadata: {} at 2.93s
2026-01-15 10:31:07.571 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#407(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.571 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 532, name: 'OutputAudioRawFrame#407', metadata: {} at 2.93s
2026-01-15 10:31:07.571 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 532, name: 'OutputAudioRawFrame#407', metadata: {} at 2.93s
2026-01-15 10:31:07.571 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 532, name: 'OutputAudioRawFrame#407', metadata: {} at 2.93s
2026-01-15 10:31:07.607 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 156, name: 'OutputAudioRawFrame#80', metadata: {} at 2.05s
2026-01-15 10:31:07.607 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 156, name: 'OutputAudioRawFrame#80', metadata: {} at 2.05s
2026-01-15 10:31:07.610 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 534, name: 'OutputAudioRawFrame#408', metadata: {} at 2.96s
2026-01-15 10:31:07.610 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 534, name: 'OutputAudioRawFrame#408', metadata: {} at 2.96s
2026-01-15 10:31:07.610 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#408(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.610 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 534, name: 'OutputAudioRawFrame#408', metadata: {} at 2.96s
2026-01-15 10:31:07.611 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 534, name: 'OutputAudioRawFrame#408', metadata: {} at 2.96s
2026-01-15 10:31:07.611 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 534, name: 'OutputAudioRawFrame#408', metadata: {} at 2.97s
2026-01-15 10:31:07.611 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#408(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.611 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 534, name: 'OutputAudioRawFrame#408', metadata: {} at 2.97s
2026-01-15 10:31:07.611 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 534, name: 'OutputAudioRawFrame#408', metadata: {} at 2.97s
2026-01-15 10:31:07.611 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 534, name: 'OutputAudioRawFrame#408', metadata: {} at 2.97s
2026-01-15 10:31:07.646 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 157, name: 'OutputAudioRawFrame#81', metadata: {} at 2.09s
2026-01-15 10:31:07.646 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 157, name: 'OutputAudioRawFrame#81', metadata: {} at 2.09s
2026-01-15 10:31:07.648 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 536, name: 'OutputAudioRawFrame#409', metadata: {} at 3.00s
2026-01-15 10:31:07.648 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 536, name: 'OutputAudioRawFrame#409', metadata: {} at 3.00s
2026-01-15 10:31:07.648 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#409(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.649 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 536, name: 'OutputAudioRawFrame#409', metadata: {} at 3.00s
2026-01-15 10:31:07.649 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 536, name: 'OutputAudioRawFrame#409', metadata: {} at 3.00s
2026-01-15 10:31:07.649 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 536, name: 'OutputAudioRawFrame#409', metadata: {} at 3.00s
2026-01-15 10:31:07.649 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#409(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.649 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 536, name: 'OutputAudioRawFrame#409', metadata: {} at 3.00s
2026-01-15 10:31:07.650 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 536, name: 'OutputAudioRawFrame#409', metadata: {} at 3.00s
2026-01-15 10:31:07.650 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 536, name: 'OutputAudioRawFrame#409', metadata: {} at 3.00s
2026-01-15 10:31:07.687 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 159, name: 'OutputAudioRawFrame#83', metadata: {} at 2.13s
2026-01-15 10:31:07.687 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 159, name: 'OutputAudioRawFrame#83', metadata: {} at 2.13s
2026-01-15 10:31:07.691 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 538, name: 'OutputAudioRawFrame#410', metadata: {} at 3.04s
2026-01-15 10:31:07.691 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 538, name: 'OutputAudioRawFrame#410', metadata: {} at 3.05s
2026-01-15 10:31:07.691 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#410(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.691 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 538, name: 'OutputAudioRawFrame#410', metadata: {} at 3.05s
2026-01-15 10:31:07.693 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 538, name: 'OutputAudioRawFrame#410', metadata: {} at 3.05s
2026-01-15 10:31:07.693 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 538, name: 'OutputAudioRawFrame#410', metadata: {} at 3.05s
2026-01-15 10:31:07.693 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#410(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.693 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 538, name: 'OutputAudioRawFrame#410', metadata: {} at 3.05s
2026-01-15 10:31:07.693 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 538, name: 'OutputAudioRawFrame#410', metadata: {} at 3.05s
2026-01-15 10:31:07.693 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 538, name: 'OutputAudioRawFrame#410', metadata: {} at 3.05s
2026-01-15 10:31:07.727 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 160, name: 'OutputAudioRawFrame#84', metadata: {} at 2.17s
2026-01-15 10:31:07.727 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 160, name: 'OutputAudioRawFrame#84', metadata: {} at 2.17s
2026-01-15 10:31:07.731 | DEBUG    | [BOT-SYS] | User started speaking
2026-01-15 10:31:07.732 | DEBUG    | [BOT-SYS] | PipelineTask#0: received interruption task frame InterruptionTaskFrame#0
2026-01-15 10:31:07.732 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: VADUserStartedSpeakingFrame id: 542, name: 'VADUserStartedSpeakingFrame#0', metadata: {} at 3.09s
2026-01-15 10:31:07.732 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserStartedSpeakingFrame id: 543, name: 'UserStartedSpeakingFrame#0', metadata: {}, emulated: False at 3.09s
2026-01-15 10:31:07.733 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserStartedSpeakingFrame id: 544, name: 'UserStartedSpeakingFrame#1', metadata: {}, emulated: False at 3.09s
2026-01-15 10:31:07.733 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserStartedSpeakingFrame id: 544, name: 'UserStartedSpeakingFrame#1', metadata: {}, emulated: False at 3.09s
2026-01-15 10:31:07.733 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: InterruptionTaskFrame id: 545, name: 'InterruptionTaskFrame#0', metadata: {} at 3.09s
2026-01-15 10:31:07.733 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: InterruptionTaskFrame id: 545, name: 'InterruptionTaskFrame#0', metadata: {} at 3.09s
2026-01-15 10:31:07.733 | DEBUG    | [BOT-SYS] | PipelineTask#0::Source â†’ Pipeline#0: InterruptionFrame id: 546, name: 'InterruptionFrame#0', metadata: {} at 3.09s
2026-01-15 10:31:07.733 | DEBUG    | [BOT-SYS] | Pipeline#0::Source â†’ WebsocketServerInputTransport#0: InterruptionFrame id: 546, name: 'InterruptionFrame#0', metadata: {} at 3.09s
2026-01-15 10:31:07.733 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InterruptionFrame id: 546, name: 'InterruptionFrame#0', metadata: {} at 3.09s
2026-01-15 10:31:07.733 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 547, name: 'UserSpeakingFrame#0', metadata: {} at 3.09s
2026-01-15 10:31:07.733 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 548, name: 'UserSpeakingFrame#1', metadata: {} at 3.09s
2026-01-15 10:31:07.733 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 548, name: 'UserSpeakingFrame#1', metadata: {} at 3.09s
2026-01-15 10:31:07.733 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 540, name: 'OutputAudioRawFrame#411', metadata: {} at 3.09s
2026-01-15 10:31:07.733 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 549, name: 'OutputTransportMessageUrgentFrame#1', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'} at 3.09s
2026-01-15 10:31:07.734 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#1(message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'})
2026-01-15 10:31:07.734 | INFO     | [BOT-SYS] | input bot frame: VADUserStartedSpeakingFrame#0
2026-01-15 10:31:07.734 | INFO     | [BOT-SYS] | input bot frame: UserStartedSpeakingFrame#0
2026-01-15 10:31:07.734 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: VADUserStartedSpeakingFrame id: 542, name: 'VADUserStartedSpeakingFrame#0', metadata: {} at 3.09s
2026-01-15 10:31:07.734 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserStartedSpeakingFrame id: 543, name: 'UserStartedSpeakingFrame#0', metadata: {}, emulated: False at 3.09s
2026-01-15 10:31:07.734 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 549, name: 'OutputTransportMessageUrgentFrame#1', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'} at 3.09s
2026-01-15 10:31:07.734 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: VADUserStartedSpeakingFrame id: 542, name: 'VADUserStartedSpeakingFrame#0', metadata: {} at 3.09s
2026-01-15 10:31:07.734 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: UserStartedSpeakingFrame id: 543, name: 'UserStartedSpeakingFrame#0', metadata: {}, emulated: False at 3.09s
2026-01-15 10:31:07.734 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 549, name: 'OutputTransportMessageUrgentFrame#1', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'} at 3.09s
2026-01-15 10:31:07.734 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: VADUserStartedSpeakingFrame id: 542, name: 'VADUserStartedSpeakingFrame#0', metadata: {} at 3.09s
2026-01-15 10:31:07.734 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: UserStartedSpeakingFrame id: 543, name: 'UserStartedSpeakingFrame#0', metadata: {}, emulated: False at 3.09s
2026-01-15 10:31:07.735 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 549, name: 'OutputTransportMessageUrgentFrame#1', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'} at 3.09s
2026-01-15 10:31:07.735 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: VADUserStartedSpeakingFrame id: 542, name: 'VADUserStartedSpeakingFrame#0', metadata: {} at 3.09s
2026-01-15 10:31:07.735 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: UserStartedSpeakingFrame id: 543, name: 'UserStartedSpeakingFrame#0', metadata: {}, emulated: False at 3.09s
2026-01-15 10:31:07.735 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InterruptionFrame id: 546, name: 'InterruptionFrame#0', metadata: {} at 3.09s
2026-01-15 10:31:07.735 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 547, name: 'UserSpeakingFrame#0', metadata: {} at 3.09s
2026-01-15 10:31:07.735 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 540, name: 'OutputAudioRawFrame#411', metadata: {} at 3.09s
2026-01-15 10:31:07.735 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#1(message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'})
2026-01-15 10:31:07.735 | INFO     | [BOT-SYS] | output bot frame: VADUserStartedSpeakingFrame#0
2026-01-15 10:31:07.735 | INFO     | [BOT-SYS] | output bot frame: UserStartedSpeakingFrame#0
2026-01-15 10:31:07.735 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 549, name: 'OutputTransportMessageUrgentFrame#1', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'} at 3.09s
2026-01-15 10:31:07.735 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: VADUserStartedSpeakingFrame id: 542, name: 'VADUserStartedSpeakingFrame#0', metadata: {} at 3.09s
2026-01-15 10:31:07.735 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: UserStartedSpeakingFrame id: 543, name: 'UserStartedSpeakingFrame#0', metadata: {}, emulated: False at 3.09s
2026-01-15 10:31:07.736 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: VADUserStartedSpeakingFrame id: 542, name: 'VADUserStartedSpeakingFrame#0', metadata: {} at 3.09s
2026-01-15 10:31:07.736 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: VADUserStartedSpeakingFrame id: 542, name: 'VADUserStartedSpeakingFrame#0', metadata: {} at 3.09s
2026-01-15 10:31:07.736 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: UserStartedSpeakingFrame id: 543, name: 'UserStartedSpeakingFrame#0', metadata: {}, emulated: False at 3.09s
2026-01-15 10:31:07.736 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: UserStartedSpeakingFrame id: 543, name: 'UserStartedSpeakingFrame#0', metadata: {}, emulated: False at 3.09s
2026-01-15 10:31:07.736 | INFO     | [BOT-SYS] | input bot frame: InterruptionFrame#0
2026-01-15 10:31:07.736 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#0
2026-01-15 10:31:07.736 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#411(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.736 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#0(message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'})
2026-01-15 10:31:07.736 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InterruptionFrame id: 546, name: 'InterruptionFrame#0', metadata: {} at 3.09s
2026-01-15 10:31:07.736 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 550, name: 'RTVIServerMessageFrame#0', metadata: {}, data: {'type': 'user-speaking'} at 3.09s
2026-01-15 10:31:07.736 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 540, name: 'OutputAudioRawFrame#411', metadata: {} at 3.09s
2026-01-15 10:31:07.736 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 552, name: 'OutputTransportMessageUrgentFrame#2', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.09s
2026-01-15 10:31:07.737 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 551, name: 'InputTransportMessageFrame#0', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'} at 2.18s
2026-01-15 10:31:07.737 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#0(message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'})
2026-01-15 10:31:07.737 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#0(message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'})
2026-01-15 10:31:07.737 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:07.737 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:07.737 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#2(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:07.737 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#0(data: {'type': 'user-speaking'})
2026-01-15 10:31:07.737 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 550, name: 'RTVIServerMessageFrame#0', metadata: {}, data: {'type': 'user-speaking'} at 3.09s
2026-01-15 10:31:07.737 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 552, name: 'OutputTransportMessageUrgentFrame#2', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.09s
2026-01-15 10:31:07.737 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 550, name: 'RTVIServerMessageFrame#0', metadata: {}, data: {'type': 'user-speaking'} at 3.09s
2026-01-15 10:31:07.737 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 551, name: 'InputTransportMessageFrame#0', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'} at 2.18s
2026-01-15 10:31:07.737 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 551, name: 'InputTransportMessageFrame#0', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'} at 2.18s
2026-01-15 10:31:07.737 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 551, name: 'InputTransportMessageFrame#0', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'} at 2.18s
2026-01-15 10:31:07.737 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 551, name: 'InputTransportMessageFrame#0', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'} at 2.18s
2026-01-15 10:31:07.737 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 551, name: 'InputTransportMessageFrame#0', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'} at 2.18s
2026-01-15 10:31:07.737 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 551, name: 'InputTransportMessageFrame#0', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'} at 2.18s
2026-01-15 10:31:07.738 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InterruptionFrame id: 546, name: 'InterruptionFrame#0', metadata: {} at 3.09s
2026-01-15 10:31:07.738 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 550, name: 'RTVIServerMessageFrame#0', metadata: {}, data: {'type': 'user-speaking'} at 3.09s
2026-01-15 10:31:07.739 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 540, name: 'OutputAudioRawFrame#411', metadata: {} at 3.09s
2026-01-15 10:31:07.739 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 552, name: 'OutputTransportMessageUrgentFrame#2', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.09s
2026-01-15 10:31:07.739 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 550, name: 'RTVIServerMessageFrame#0', metadata: {}, data: {'type': 'user-speaking'} at 3.09s
2026-01-15 10:31:07.739 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InterruptionFrame id: 546, name: 'InterruptionFrame#0', metadata: {} at 3.09s
2026-01-15 10:31:07.739 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 550, name: 'RTVIServerMessageFrame#0', metadata: {}, data: {'type': 'user-speaking'} at 3.09s
2026-01-15 10:31:07.739 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 540, name: 'OutputAudioRawFrame#411', metadata: {} at 3.09s
2026-01-15 10:31:07.739 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 552, name: 'OutputTransportMessageUrgentFrame#2', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.09s
2026-01-15 10:31:07.739 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 550, name: 'RTVIServerMessageFrame#0', metadata: {}, data: {'type': 'user-speaking'} at 3.09s
2026-01-15 10:31:07.739 | INFO     | [BOT-SYS] | output bot frame: InterruptionFrame#0
2026-01-15 10:31:07.739 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#0(data: {'type': 'user-speaking'})
2026-01-15 10:31:07.739 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#411(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.739 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#2(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:07.740 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#0(data: {'type': 'user-speaking'})
2026-01-15 10:31:07.740 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InterruptionFrame id: 546, name: 'InterruptionFrame#0', metadata: {} at 3.09s
2026-01-15 10:31:07.740 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 550, name: 'RTVIServerMessageFrame#0', metadata: {}, data: {'type': 'user-speaking'} at 3.09s
2026-01-15 10:31:07.740 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 540, name: 'OutputAudioRawFrame#411', metadata: {} at 3.09s
2026-01-15 10:31:07.740 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 552, name: 'OutputTransportMessageUrgentFrame#2', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.09s
2026-01-15 10:31:07.740 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 550, name: 'RTVIServerMessageFrame#0', metadata: {}, data: {'type': 'user-speaking'} at 3.09s
2026-01-15 10:31:07.740 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InterruptionFrame id: 546, name: 'InterruptionFrame#0', metadata: {} at 3.09s
2026-01-15 10:31:07.740 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InterruptionFrame id: 546, name: 'InterruptionFrame#0', metadata: {} at 3.09s
2026-01-15 10:31:07.740 | WARNING  | [BOT-SYS] | Frame type <class 'pipecat.frames.frames.InterruptionFrame'> is not serializable
2026-01-15 10:31:07.741 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 550, name: 'RTVIServerMessageFrame#0', metadata: {}, data: {'type': 'user-speaking'} at 3.09s
2026-01-15 10:31:07.741 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 550, name: 'RTVIServerMessageFrame#0', metadata: {}, data: {'type': 'user-speaking'} at 3.09s
2026-01-15 10:31:07.741 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 540, name: 'OutputAudioRawFrame#411', metadata: {} at 3.09s
2026-01-15 10:31:07.741 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 540, name: 'OutputAudioRawFrame#411', metadata: {} at 3.09s
2026-01-15 10:31:07.741 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 550, name: 'RTVIServerMessageFrame#0', metadata: {}, data: {'type': 'user-speaking'} at 3.10s
2026-01-15 10:31:07.741 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 550, name: 'RTVIServerMessageFrame#0', metadata: {}, data: {'type': 'user-speaking'} at 3.10s
2026-01-15 10:31:07.741 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#1(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:07.741 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 553, name: 'InputTransportMessageFrame#1', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.19s
2026-01-15 10:31:07.741 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#1(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:07.741 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#1(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:07.741 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:07.742 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:07.742 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 553, name: 'InputTransportMessageFrame#1', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.19s
2026-01-15 10:31:07.742 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 553, name: 'InputTransportMessageFrame#1', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.19s
2026-01-15 10:31:07.742 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 553, name: 'InputTransportMessageFrame#1', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.19s
2026-01-15 10:31:07.742 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 553, name: 'InputTransportMessageFrame#1', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.19s
2026-01-15 10:31:07.742 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 553, name: 'InputTransportMessageFrame#1', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.19s
2026-01-15 10:31:07.742 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 553, name: 'InputTransportMessageFrame#1', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.19s
2026-01-15 10:31:07.767 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 162, name: 'OutputAudioRawFrame#86', metadata: {} at 2.21s
2026-01-15 10:31:07.767 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 162, name: 'OutputAudioRawFrame#86', metadata: {} at 2.21s
2026-01-15 10:31:07.768 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 556, name: 'UserSpeakingFrame#2', metadata: {} at 3.12s
2026-01-15 10:31:07.768 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 557, name: 'UserSpeakingFrame#3', metadata: {} at 3.12s
2026-01-15 10:31:07.768 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 557, name: 'UserSpeakingFrame#3', metadata: {} at 3.12s
2026-01-15 10:31:07.768 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 554, name: 'OutputAudioRawFrame#412', metadata: {} at 3.12s
2026-01-15 10:31:07.769 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 556, name: 'UserSpeakingFrame#2', metadata: {} at 3.12s
2026-01-15 10:31:07.769 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 554, name: 'OutputAudioRawFrame#412', metadata: {} at 3.12s
2026-01-15 10:31:07.769 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#2
2026-01-15 10:31:07.769 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#412(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.769 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 558, name: 'RTVIServerMessageFrame#1', metadata: {}, data: {'type': 'user-speaking'} at 3.12s
2026-01-15 10:31:07.769 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 554, name: 'OutputAudioRawFrame#412', metadata: {} at 3.12s
2026-01-15 10:31:07.769 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 559, name: 'OutputTransportMessageUrgentFrame#3', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.12s
2026-01-15 10:31:07.770 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#3(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:07.770 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#1(data: {'type': 'user-speaking'})
2026-01-15 10:31:07.770 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 558, name: 'RTVIServerMessageFrame#1', metadata: {}, data: {'type': 'user-speaking'} at 3.12s
2026-01-15 10:31:07.770 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 558, name: 'RTVIServerMessageFrame#1', metadata: {}, data: {'type': 'user-speaking'} at 3.12s
2026-01-15 10:31:07.770 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 554, name: 'OutputAudioRawFrame#412', metadata: {} at 3.12s
2026-01-15 10:31:07.770 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 559, name: 'OutputTransportMessageUrgentFrame#3', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.12s
2026-01-15 10:31:07.770 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 558, name: 'RTVIServerMessageFrame#1', metadata: {}, data: {'type': 'user-speaking'} at 3.12s
2026-01-15 10:31:07.770 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 558, name: 'RTVIServerMessageFrame#1', metadata: {}, data: {'type': 'user-speaking'} at 3.12s
2026-01-15 10:31:07.770 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 554, name: 'OutputAudioRawFrame#412', metadata: {} at 3.12s
2026-01-15 10:31:07.770 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 559, name: 'OutputTransportMessageUrgentFrame#3', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.12s
2026-01-15 10:31:07.770 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 558, name: 'RTVIServerMessageFrame#1', metadata: {}, data: {'type': 'user-speaking'} at 3.12s
2026-01-15 10:31:07.770 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#1(data: {'type': 'user-speaking'})
2026-01-15 10:31:07.770 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#412(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.770 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 558, name: 'RTVIServerMessageFrame#1', metadata: {}, data: {'type': 'user-speaking'} at 3.12s
2026-01-15 10:31:07.770 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 554, name: 'OutputAudioRawFrame#412', metadata: {} at 3.12s
2026-01-15 10:31:07.770 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 559, name: 'OutputTransportMessageUrgentFrame#3', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.12s
2026-01-15 10:31:07.770 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 558, name: 'RTVIServerMessageFrame#1', metadata: {}, data: {'type': 'user-speaking'} at 3.12s
2026-01-15 10:31:07.771 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#3(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:07.771 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#1(data: {'type': 'user-speaking'})
2026-01-15 10:31:07.771 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 558, name: 'RTVIServerMessageFrame#1', metadata: {}, data: {'type': 'user-speaking'} at 3.12s
2026-01-15 10:31:07.771 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 558, name: 'RTVIServerMessageFrame#1', metadata: {}, data: {'type': 'user-speaking'} at 3.12s
2026-01-15 10:31:07.771 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 554, name: 'OutputAudioRawFrame#412', metadata: {} at 3.12s
2026-01-15 10:31:07.771 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 554, name: 'OutputAudioRawFrame#412', metadata: {} at 3.12s
2026-01-15 10:31:07.771 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 559, name: 'OutputTransportMessageUrgentFrame#3', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.12s
2026-01-15 10:31:07.771 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 558, name: 'RTVIServerMessageFrame#1', metadata: {}, data: {'type': 'user-speaking'} at 3.13s
2026-01-15 10:31:07.771 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 558, name: 'RTVIServerMessageFrame#1', metadata: {}, data: {'type': 'user-speaking'} at 3.13s
2026-01-15 10:31:07.771 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 558, name: 'RTVIServerMessageFrame#1', metadata: {}, data: {'type': 'user-speaking'} at 3.13s
2026-01-15 10:31:07.771 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#2(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:07.771 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 560, name: 'InputTransportMessageFrame#2', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.22s
2026-01-15 10:31:07.771 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#2(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:07.771 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#2(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:07.772 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:07.772 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:07.772 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 560, name: 'InputTransportMessageFrame#2', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.22s
2026-01-15 10:31:07.772 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 560, name: 'InputTransportMessageFrame#2', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.22s
2026-01-15 10:31:07.772 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 560, name: 'InputTransportMessageFrame#2', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.22s
2026-01-15 10:31:07.772 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 560, name: 'InputTransportMessageFrame#2', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.22s
2026-01-15 10:31:07.772 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 560, name: 'InputTransportMessageFrame#2', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.22s
2026-01-15 10:31:07.772 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 560, name: 'InputTransportMessageFrame#2', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.22s
2026-01-15 10:31:07.807 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 164, name: 'OutputAudioRawFrame#88', metadata: {} at 2.25s
2026-01-15 10:31:07.807 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 164, name: 'OutputAudioRawFrame#88', metadata: {} at 2.25s
2026-01-15 10:31:07.808 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 563, name: 'UserSpeakingFrame#4', metadata: {} at 3.16s
2026-01-15 10:31:07.808 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 564, name: 'UserSpeakingFrame#5', metadata: {} at 3.16s
2026-01-15 10:31:07.808 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 564, name: 'UserSpeakingFrame#5', metadata: {} at 3.16s
2026-01-15 10:31:07.808 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 561, name: 'OutputAudioRawFrame#413', metadata: {} at 3.16s
2026-01-15 10:31:07.808 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 563, name: 'UserSpeakingFrame#4', metadata: {} at 3.16s
2026-01-15 10:31:07.809 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 561, name: 'OutputAudioRawFrame#413', metadata: {} at 3.16s
2026-01-15 10:31:07.809 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#4
2026-01-15 10:31:07.809 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#413(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.809 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 565, name: 'RTVIServerMessageFrame#2', metadata: {}, data: {'type': 'user-speaking'} at 3.16s
2026-01-15 10:31:07.809 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 561, name: 'OutputAudioRawFrame#413', metadata: {} at 3.16s
2026-01-15 10:31:07.809 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 566, name: 'OutputTransportMessageUrgentFrame#4', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.16s
2026-01-15 10:31:07.809 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#4(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:07.809 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#2(data: {'type': 'user-speaking'})
2026-01-15 10:31:07.810 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 565, name: 'RTVIServerMessageFrame#2', metadata: {}, data: {'type': 'user-speaking'} at 3.16s
2026-01-15 10:31:07.810 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 565, name: 'RTVIServerMessageFrame#2', metadata: {}, data: {'type': 'user-speaking'} at 3.16s
2026-01-15 10:31:07.810 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 561, name: 'OutputAudioRawFrame#413', metadata: {} at 3.16s
2026-01-15 10:31:07.810 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 566, name: 'OutputTransportMessageUrgentFrame#4', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.16s
2026-01-15 10:31:07.810 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 565, name: 'RTVIServerMessageFrame#2', metadata: {}, data: {'type': 'user-speaking'} at 3.16s
2026-01-15 10:31:07.810 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 565, name: 'RTVIServerMessageFrame#2', metadata: {}, data: {'type': 'user-speaking'} at 3.16s
2026-01-15 10:31:07.810 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 561, name: 'OutputAudioRawFrame#413', metadata: {} at 3.16s
2026-01-15 10:31:07.810 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 566, name: 'OutputTransportMessageUrgentFrame#4', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.16s
2026-01-15 10:31:07.810 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 565, name: 'RTVIServerMessageFrame#2', metadata: {}, data: {'type': 'user-speaking'} at 3.16s
2026-01-15 10:31:07.810 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#2(data: {'type': 'user-speaking'})
2026-01-15 10:31:07.810 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#413(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.810 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 565, name: 'RTVIServerMessageFrame#2', metadata: {}, data: {'type': 'user-speaking'} at 3.16s
2026-01-15 10:31:07.810 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 561, name: 'OutputAudioRawFrame#413', metadata: {} at 3.16s
2026-01-15 10:31:07.810 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 566, name: 'OutputTransportMessageUrgentFrame#4', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.16s
2026-01-15 10:31:07.810 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 565, name: 'RTVIServerMessageFrame#2', metadata: {}, data: {'type': 'user-speaking'} at 3.16s
2026-01-15 10:31:07.810 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#4(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:07.810 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#2(data: {'type': 'user-speaking'})
2026-01-15 10:31:07.811 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 565, name: 'RTVIServerMessageFrame#2', metadata: {}, data: {'type': 'user-speaking'} at 3.16s
2026-01-15 10:31:07.811 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 565, name: 'RTVIServerMessageFrame#2', metadata: {}, data: {'type': 'user-speaking'} at 3.16s
2026-01-15 10:31:07.811 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 561, name: 'OutputAudioRawFrame#413', metadata: {} at 3.16s
2026-01-15 10:31:07.811 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 561, name: 'OutputAudioRawFrame#413', metadata: {} at 3.16s
2026-01-15 10:31:07.811 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 566, name: 'OutputTransportMessageUrgentFrame#4', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.16s
2026-01-15 10:31:07.811 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 565, name: 'RTVIServerMessageFrame#2', metadata: {}, data: {'type': 'user-speaking'} at 3.16s
2026-01-15 10:31:07.811 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 565, name: 'RTVIServerMessageFrame#2', metadata: {}, data: {'type': 'user-speaking'} at 3.17s
2026-01-15 10:31:07.811 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 565, name: 'RTVIServerMessageFrame#2', metadata: {}, data: {'type': 'user-speaking'} at 3.17s
2026-01-15 10:31:07.811 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#3(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:07.811 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 567, name: 'InputTransportMessageFrame#3', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.25s
2026-01-15 10:31:07.811 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#3(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:07.811 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#3(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:07.811 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:07.811 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:07.811 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 567, name: 'InputTransportMessageFrame#3', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.26s
2026-01-15 10:31:07.811 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 567, name: 'InputTransportMessageFrame#3', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.26s
2026-01-15 10:31:07.811 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 567, name: 'InputTransportMessageFrame#3', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.26s
2026-01-15 10:31:07.811 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 567, name: 'InputTransportMessageFrame#3', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.26s
2026-01-15 10:31:07.812 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 567, name: 'InputTransportMessageFrame#3', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.26s
2026-01-15 10:31:07.812 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 567, name: 'InputTransportMessageFrame#3', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.26s
2026-01-15 10:31:07.847 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 165, name: 'OutputAudioRawFrame#89', metadata: {} at 2.29s
2026-01-15 10:31:07.847 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 165, name: 'OutputAudioRawFrame#89', metadata: {} at 2.29s
2026-01-15 10:31:07.848 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 570, name: 'UserSpeakingFrame#6', metadata: {} at 3.20s
2026-01-15 10:31:07.848 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 571, name: 'UserSpeakingFrame#7', metadata: {} at 3.20s
2026-01-15 10:31:07.848 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 571, name: 'UserSpeakingFrame#7', metadata: {} at 3.20s
2026-01-15 10:31:07.848 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 568, name: 'OutputAudioRawFrame#414', metadata: {} at 3.20s
2026-01-15 10:31:07.848 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 570, name: 'UserSpeakingFrame#6', metadata: {} at 3.20s
2026-01-15 10:31:07.848 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 568, name: 'OutputAudioRawFrame#414', metadata: {} at 3.20s
2026-01-15 10:31:07.848 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#6
2026-01-15 10:31:07.848 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#414(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.848 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 572, name: 'RTVIServerMessageFrame#3', metadata: {}, data: {'type': 'user-speaking'} at 3.20s
2026-01-15 10:31:07.848 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 568, name: 'OutputAudioRawFrame#414', metadata: {} at 3.20s
2026-01-15 10:31:07.848 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 573, name: 'OutputTransportMessageUrgentFrame#5', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.20s
2026-01-15 10:31:07.849 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#5(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:07.849 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#3(data: {'type': 'user-speaking'})
2026-01-15 10:31:07.849 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 572, name: 'RTVIServerMessageFrame#3', metadata: {}, data: {'type': 'user-speaking'} at 3.20s
2026-01-15 10:31:07.849 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 572, name: 'RTVIServerMessageFrame#3', metadata: {}, data: {'type': 'user-speaking'} at 3.20s
2026-01-15 10:31:07.849 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 568, name: 'OutputAudioRawFrame#414', metadata: {} at 3.20s
2026-01-15 10:31:07.849 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 573, name: 'OutputTransportMessageUrgentFrame#5', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.20s
2026-01-15 10:31:07.849 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 572, name: 'RTVIServerMessageFrame#3', metadata: {}, data: {'type': 'user-speaking'} at 3.20s
2026-01-15 10:31:07.849 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 572, name: 'RTVIServerMessageFrame#3', metadata: {}, data: {'type': 'user-speaking'} at 3.20s
2026-01-15 10:31:07.849 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 568, name: 'OutputAudioRawFrame#414', metadata: {} at 3.20s
2026-01-15 10:31:07.849 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 573, name: 'OutputTransportMessageUrgentFrame#5', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.20s
2026-01-15 10:31:07.849 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 572, name: 'RTVIServerMessageFrame#3', metadata: {}, data: {'type': 'user-speaking'} at 3.20s
2026-01-15 10:31:07.849 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#3(data: {'type': 'user-speaking'})
2026-01-15 10:31:07.849 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#414(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.849 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 572, name: 'RTVIServerMessageFrame#3', metadata: {}, data: {'type': 'user-speaking'} at 3.20s
2026-01-15 10:31:07.849 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 568, name: 'OutputAudioRawFrame#414', metadata: {} at 3.20s
2026-01-15 10:31:07.849 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 573, name: 'OutputTransportMessageUrgentFrame#5', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.20s
2026-01-15 10:31:07.849 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 572, name: 'RTVIServerMessageFrame#3', metadata: {}, data: {'type': 'user-speaking'} at 3.20s
2026-01-15 10:31:07.849 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#5(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:07.849 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#3(data: {'type': 'user-speaking'})
2026-01-15 10:31:07.849 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 572, name: 'RTVIServerMessageFrame#3', metadata: {}, data: {'type': 'user-speaking'} at 3.20s
2026-01-15 10:31:07.849 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 572, name: 'RTVIServerMessageFrame#3', metadata: {}, data: {'type': 'user-speaking'} at 3.20s
2026-01-15 10:31:07.849 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 568, name: 'OutputAudioRawFrame#414', metadata: {} at 3.20s
2026-01-15 10:31:07.849 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 568, name: 'OutputAudioRawFrame#414', metadata: {} at 3.20s
2026-01-15 10:31:07.849 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 573, name: 'OutputTransportMessageUrgentFrame#5', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.20s
2026-01-15 10:31:07.849 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 572, name: 'RTVIServerMessageFrame#3', metadata: {}, data: {'type': 'user-speaking'} at 3.20s
2026-01-15 10:31:07.850 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 572, name: 'RTVIServerMessageFrame#3', metadata: {}, data: {'type': 'user-speaking'} at 3.20s
2026-01-15 10:31:07.850 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 572, name: 'RTVIServerMessageFrame#3', metadata: {}, data: {'type': 'user-speaking'} at 3.20s
2026-01-15 10:31:07.850 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#4(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:07.850 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 574, name: 'InputTransportMessageFrame#4', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.29s
2026-01-15 10:31:07.850 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#4(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:07.850 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#4(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:07.850 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:07.850 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:07.850 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 574, name: 'InputTransportMessageFrame#4', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.29s
2026-01-15 10:31:07.850 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 574, name: 'InputTransportMessageFrame#4', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.29s
2026-01-15 10:31:07.850 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 574, name: 'InputTransportMessageFrame#4', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.29s
2026-01-15 10:31:07.850 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 574, name: 'InputTransportMessageFrame#4', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.29s
2026-01-15 10:31:07.850 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 574, name: 'InputTransportMessageFrame#4', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.29s
2026-01-15 10:31:07.850 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 574, name: 'InputTransportMessageFrame#4', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.29s
2026-01-15 10:31:07.856 | DEBUG    | [BOT-SYS] | Received response: type='events' data=EventsData(event_type=None, timestamp=None, signal_type='START_SPEECH', occured_at=1768453267.8921714)
2026-01-15 10:31:07.856 | DEBUG    | [BOT-SYS] | VAD Signal: START_SPEECH, Occurred at: 1768453267.8921714
2026-01-15 10:31:07.856 | DEBUG    | [BOT-SYS] | User started speaking
2026-01-15 10:31:07.887 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 167, name: 'OutputAudioRawFrame#91', metadata: {} at 2.33s
2026-01-15 10:31:07.887 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 167, name: 'OutputAudioRawFrame#91', metadata: {} at 2.33s
2026-01-15 10:31:07.888 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 577, name: 'UserSpeakingFrame#8', metadata: {} at 3.24s
2026-01-15 10:31:07.888 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 578, name: 'UserSpeakingFrame#9', metadata: {} at 3.24s
2026-01-15 10:31:07.888 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 578, name: 'UserSpeakingFrame#9', metadata: {} at 3.24s
2026-01-15 10:31:07.888 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 575, name: 'OutputAudioRawFrame#415', metadata: {} at 3.24s
2026-01-15 10:31:07.888 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 577, name: 'UserSpeakingFrame#8', metadata: {} at 3.24s
2026-01-15 10:31:07.889 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 575, name: 'OutputAudioRawFrame#415', metadata: {} at 3.24s
2026-01-15 10:31:07.889 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#8
2026-01-15 10:31:07.889 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#415(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.889 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 579, name: 'RTVIServerMessageFrame#4', metadata: {}, data: {'type': 'user-speaking'} at 3.24s
2026-01-15 10:31:07.889 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 575, name: 'OutputAudioRawFrame#415', metadata: {} at 3.24s
2026-01-15 10:31:07.889 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 580, name: 'OutputTransportMessageUrgentFrame#6', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.24s
2026-01-15 10:31:07.889 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#6(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:07.889 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#4(data: {'type': 'user-speaking'})
2026-01-15 10:31:07.889 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 579, name: 'RTVIServerMessageFrame#4', metadata: {}, data: {'type': 'user-speaking'} at 3.24s
2026-01-15 10:31:07.889 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 579, name: 'RTVIServerMessageFrame#4', metadata: {}, data: {'type': 'user-speaking'} at 3.24s
2026-01-15 10:31:07.889 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 575, name: 'OutputAudioRawFrame#415', metadata: {} at 3.24s
2026-01-15 10:31:07.889 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 580, name: 'OutputTransportMessageUrgentFrame#6', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.24s
2026-01-15 10:31:07.889 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 579, name: 'RTVIServerMessageFrame#4', metadata: {}, data: {'type': 'user-speaking'} at 3.24s
2026-01-15 10:31:07.890 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 579, name: 'RTVIServerMessageFrame#4', metadata: {}, data: {'type': 'user-speaking'} at 3.24s
2026-01-15 10:31:07.890 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 575, name: 'OutputAudioRawFrame#415', metadata: {} at 3.24s
2026-01-15 10:31:07.890 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 580, name: 'OutputTransportMessageUrgentFrame#6', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.24s
2026-01-15 10:31:07.890 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 579, name: 'RTVIServerMessageFrame#4', metadata: {}, data: {'type': 'user-speaking'} at 3.24s
2026-01-15 10:31:07.890 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#4(data: {'type': 'user-speaking'})
2026-01-15 10:31:07.890 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#415(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.890 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 579, name: 'RTVIServerMessageFrame#4', metadata: {}, data: {'type': 'user-speaking'} at 3.24s
2026-01-15 10:31:07.890 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 575, name: 'OutputAudioRawFrame#415', metadata: {} at 3.24s
2026-01-15 10:31:07.890 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 580, name: 'OutputTransportMessageUrgentFrame#6', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.24s
2026-01-15 10:31:07.890 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 579, name: 'RTVIServerMessageFrame#4', metadata: {}, data: {'type': 'user-speaking'} at 3.24s
2026-01-15 10:31:07.890 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#6(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:07.890 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#4(data: {'type': 'user-speaking'})
2026-01-15 10:31:07.890 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 579, name: 'RTVIServerMessageFrame#4', metadata: {}, data: {'type': 'user-speaking'} at 3.24s
2026-01-15 10:31:07.890 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 579, name: 'RTVIServerMessageFrame#4', metadata: {}, data: {'type': 'user-speaking'} at 3.24s
2026-01-15 10:31:07.890 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 575, name: 'OutputAudioRawFrame#415', metadata: {} at 3.24s
2026-01-15 10:31:07.890 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 575, name: 'OutputAudioRawFrame#415', metadata: {} at 3.24s
2026-01-15 10:31:07.890 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 580, name: 'OutputTransportMessageUrgentFrame#6', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.24s
2026-01-15 10:31:07.890 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 579, name: 'RTVIServerMessageFrame#4', metadata: {}, data: {'type': 'user-speaking'} at 3.24s
2026-01-15 10:31:07.890 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 579, name: 'RTVIServerMessageFrame#4', metadata: {}, data: {'type': 'user-speaking'} at 3.24s
2026-01-15 10:31:07.890 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 579, name: 'RTVIServerMessageFrame#4', metadata: {}, data: {'type': 'user-speaking'} at 3.24s
2026-01-15 10:31:07.891 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#5(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:07.891 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 581, name: 'InputTransportMessageFrame#5', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.33s
2026-01-15 10:31:07.891 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#5(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:07.891 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#5(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:07.891 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:07.891 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:07.891 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 581, name: 'InputTransportMessageFrame#5', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.33s
2026-01-15 10:31:07.891 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 581, name: 'InputTransportMessageFrame#5', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.33s
2026-01-15 10:31:07.891 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 581, name: 'InputTransportMessageFrame#5', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.33s
2026-01-15 10:31:07.891 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 581, name: 'InputTransportMessageFrame#5', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.33s
2026-01-15 10:31:07.891 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 581, name: 'InputTransportMessageFrame#5', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.33s
2026-01-15 10:31:07.891 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 581, name: 'InputTransportMessageFrame#5', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.33s
2026-01-15 10:31:07.927 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 168, name: 'OutputAudioRawFrame#92', metadata: {} at 2.37s
2026-01-15 10:31:07.927 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 168, name: 'OutputAudioRawFrame#92', metadata: {} at 2.37s
2026-01-15 10:31:07.928 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: VADUserStoppedSpeakingFrame id: 584, name: 'VADUserStoppedSpeakingFrame#0', metadata: {} at 3.28s
2026-01-15 10:31:07.928 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: VADUserStoppedSpeakingFrame id: 584, name: 'VADUserStoppedSpeakingFrame#0', metadata: {} at 3.28s
2026-01-15 10:31:07.928 | INFO     | [BOT-SYS] | input bot frame: VADUserStoppedSpeakingFrame#0
2026-01-15 10:31:07.928 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: VADUserStoppedSpeakingFrame id: 584, name: 'VADUserStoppedSpeakingFrame#0', metadata: {} at 3.28s
2026-01-15 10:31:07.928 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: VADUserStoppedSpeakingFrame id: 584, name: 'VADUserStoppedSpeakingFrame#0', metadata: {} at 3.28s
2026-01-15 10:31:07.929 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: VADUserStoppedSpeakingFrame id: 584, name: 'VADUserStoppedSpeakingFrame#0', metadata: {} at 3.28s
2026-01-15 10:31:07.929 | INFO     | [BOT-SYS] | output bot frame: VADUserStoppedSpeakingFrame#0
2026-01-15 10:31:07.929 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: VADUserStoppedSpeakingFrame id: 584, name: 'VADUserStoppedSpeakingFrame#0', metadata: {} at 3.28s
2026-01-15 10:31:07.929 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: VADUserStoppedSpeakingFrame id: 584, name: 'VADUserStoppedSpeakingFrame#0', metadata: {} at 3.28s
2026-01-15 10:31:07.929 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: VADUserStoppedSpeakingFrame id: 584, name: 'VADUserStoppedSpeakingFrame#0', metadata: {} at 3.28s
2026-01-15 10:31:07.967 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 170, name: 'OutputAudioRawFrame#94', metadata: {} at 2.41s
2026-01-15 10:31:07.967 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 170, name: 'OutputAudioRawFrame#94', metadata: {} at 2.41s
2026-01-15 10:31:07.980 | DEBUG    | [BOT-SYS] | End of Turn result: EndOfTurnState.COMPLETE
2026-01-15 10:31:07.980 | DEBUG    | [BOT-SYS] | User stopped speaking
2026-01-15 10:31:07.980 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: MetricsFrame id: 587, name: 'MetricsFrame#1', metadata: {}, data: [SmartTurnMetricsData(processor='BaseSmartTurn', model=None, is_complete=True, probability=0.9772849082946777, inference_time_ms=0.0, server_total_time_ms=0.0, e2e_processing_time_ms=51.660875004017726)] at 3.33s
2026-01-15 10:31:07.980 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserStoppedSpeakingFrame id: 588, name: 'UserStoppedSpeakingFrame#0', metadata: {}, emulated: False at 3.33s
2026-01-15 10:31:07.980 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserStoppedSpeakingFrame id: 589, name: 'UserStoppedSpeakingFrame#1', metadata: {}, emulated: False at 3.33s
2026-01-15 10:31:07.980 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserStoppedSpeakingFrame id: 589, name: 'UserStoppedSpeakingFrame#1', metadata: {}, emulated: False at 3.33s
2026-01-15 10:31:07.980 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 582, name: 'OutputAudioRawFrame#416', metadata: {} at 3.33s
2026-01-15 10:31:07.980 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 590, name: 'OutputTransportMessageUrgentFrame#7', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 3.33s
2026-01-15 10:31:07.980 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 591, name: 'OutputTransportMessageUrgentFrame#8', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'} at 3.33s
2026-01-15 10:31:07.980 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#7(message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}})
2026-01-15 10:31:07.980 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#8(message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'})
2026-01-15 10:31:07.980 | INFO     | [BOT-SYS] | input bot frame: MetricsFrame#1
2026-01-15 10:31:07.980 | INFO     | [BOT-SYS] | input bot frame: UserStoppedSpeakingFrame#0
2026-01-15 10:31:07.980 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#416(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.980 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: MetricsFrame id: 587, name: 'MetricsFrame#1', metadata: {}, data: [SmartTurnMetricsData(processor='BaseSmartTurn', model=None, is_complete=True, probability=0.9772849082946777, inference_time_ms=0.0, server_total_time_ms=0.0, e2e_processing_time_ms=51.660875004017726)] at 3.33s
2026-01-15 10:31:07.980 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserStoppedSpeakingFrame id: 588, name: 'UserStoppedSpeakingFrame#0', metadata: {}, emulated: False at 3.33s
2026-01-15 10:31:07.980 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 582, name: 'OutputAudioRawFrame#416', metadata: {} at 3.33s
2026-01-15 10:31:07.980 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 590, name: 'OutputTransportMessageUrgentFrame#7', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 3.33s
2026-01-15 10:31:07.980 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 591, name: 'OutputTransportMessageUrgentFrame#8', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'} at 3.33s
2026-01-15 10:31:07.980 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: MetricsFrame id: 587, name: 'MetricsFrame#1', metadata: {}, data: [SmartTurnMetricsData(processor='BaseSmartTurn', model=None, is_complete=True, probability=0.9772849082946777, inference_time_ms=0.0, server_total_time_ms=0.0, e2e_processing_time_ms=51.660875004017726)] at 3.33s
2026-01-15 10:31:07.980 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: UserStoppedSpeakingFrame id: 588, name: 'UserStoppedSpeakingFrame#0', metadata: {}, emulated: False at 3.33s
2026-01-15 10:31:07.980 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 582, name: 'OutputAudioRawFrame#416', metadata: {} at 3.33s
2026-01-15 10:31:07.981 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 590, name: 'OutputTransportMessageUrgentFrame#7', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 3.33s
2026-01-15 10:31:07.981 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 591, name: 'OutputTransportMessageUrgentFrame#8', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'} at 3.33s
2026-01-15 10:31:07.981 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: MetricsFrame id: 587, name: 'MetricsFrame#1', metadata: {}, data: [SmartTurnMetricsData(processor='BaseSmartTurn', model=None, is_complete=True, probability=0.9772849082946777, inference_time_ms=0.0, server_total_time_ms=0.0, e2e_processing_time_ms=51.660875004017726)] at 3.33s
2026-01-15 10:31:07.981 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: UserStoppedSpeakingFrame id: 588, name: 'UserStoppedSpeakingFrame#0', metadata: {}, emulated: False at 3.33s
2026-01-15 10:31:07.981 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 582, name: 'OutputAudioRawFrame#416', metadata: {} at 3.34s
2026-01-15 10:31:07.981 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 590, name: 'OutputTransportMessageUrgentFrame#7', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 3.34s
2026-01-15 10:31:07.981 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 591, name: 'OutputTransportMessageUrgentFrame#8', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'} at 3.34s
2026-01-15 10:31:07.981 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: MetricsFrame id: 587, name: 'MetricsFrame#1', metadata: {}, data: [SmartTurnMetricsData(processor='BaseSmartTurn', model=None, is_complete=True, probability=0.9772849082946777, inference_time_ms=0.0, server_total_time_ms=0.0, e2e_processing_time_ms=51.660875004017726)] at 3.34s
2026-01-15 10:31:07.981 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: UserStoppedSpeakingFrame id: 588, name: 'UserStoppedSpeakingFrame#0', metadata: {}, emulated: False at 3.34s
2026-01-15 10:31:07.981 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 582, name: 'OutputAudioRawFrame#416', metadata: {} at 3.34s
2026-01-15 10:31:07.981 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#7(message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}})
2026-01-15 10:31:07.981 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#8(message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'})
2026-01-15 10:31:07.981 | INFO     | [BOT-SYS] | output bot frame: MetricsFrame#1
2026-01-15 10:31:07.981 | INFO     | [BOT-SYS] | output bot frame: UserStoppedSpeakingFrame#0
2026-01-15 10:31:07.981 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#416(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.981 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 590, name: 'OutputTransportMessageUrgentFrame#7', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 3.34s
2026-01-15 10:31:07.981 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 591, name: 'OutputTransportMessageUrgentFrame#8', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'} at 3.34s
2026-01-15 10:31:07.981 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: MetricsFrame id: 587, name: 'MetricsFrame#1', metadata: {}, data: [SmartTurnMetricsData(processor='BaseSmartTurn', model=None, is_complete=True, probability=0.9772849082946777, inference_time_ms=0.0, server_total_time_ms=0.0, e2e_processing_time_ms=51.660875004017726)] at 3.34s
2026-01-15 10:31:07.981 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: UserStoppedSpeakingFrame id: 588, name: 'UserStoppedSpeakingFrame#0', metadata: {}, emulated: False at 3.34s
2026-01-15 10:31:07.981 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 582, name: 'OutputAudioRawFrame#416', metadata: {} at 3.34s
2026-01-15 10:31:07.982 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: MetricsFrame id: 587, name: 'MetricsFrame#1', metadata: {}, data: [SmartTurnMetricsData(processor='BaseSmartTurn', model=None, is_complete=True, probability=0.9772849082946777, inference_time_ms=0.0, server_total_time_ms=0.0, e2e_processing_time_ms=51.660875004017726)] at 3.34s
2026-01-15 10:31:07.982 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: MetricsFrame id: 587, name: 'MetricsFrame#1', metadata: {}, data: [SmartTurnMetricsData(processor='BaseSmartTurn', model=None, is_complete=True, probability=0.9772849082946777, inference_time_ms=0.0, server_total_time_ms=0.0, e2e_processing_time_ms=51.660875004017726)] at 3.34s
2026-01-15 10:31:07.982 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: UserStoppedSpeakingFrame id: 588, name: 'UserStoppedSpeakingFrame#0', metadata: {}, emulated: False at 3.34s
2026-01-15 10:31:07.982 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: UserStoppedSpeakingFrame id: 588, name: 'UserStoppedSpeakingFrame#0', metadata: {}, emulated: False at 3.34s
2026-01-15 10:31:07.982 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 582, name: 'OutputAudioRawFrame#416', metadata: {} at 3.34s
2026-01-15 10:31:07.982 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 582, name: 'OutputAudioRawFrame#416', metadata: {} at 3.34s
2026-01-15 10:31:07.982 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 585, name: 'OutputAudioRawFrame#417', metadata: {} at 3.34s
2026-01-15 10:31:07.982 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 585, name: 'OutputAudioRawFrame#417', metadata: {} at 3.34s
2026-01-15 10:31:07.982 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#417(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.982 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#6(message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}})
2026-01-15 10:31:07.982 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#7(message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'})
2026-01-15 10:31:07.982 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 585, name: 'OutputAudioRawFrame#417', metadata: {} at 3.34s
2026-01-15 10:31:07.982 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 592, name: 'InputTransportMessageFrame#6', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 2.43s
2026-01-15 10:31:07.982 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 593, name: 'InputTransportMessageFrame#7', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'} at 2.43s
2026-01-15 10:31:07.982 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#6(message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}})
2026-01-15 10:31:07.982 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#6(message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}})
2026-01-15 10:31:07.982 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:07.982 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:07.982 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#7(message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'})
2026-01-15 10:31:07.982 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#7(message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'})
2026-01-15 10:31:07.982 | INFO     | [EVAL-SYS] | is_bot_turn_over: True
2026-01-15 10:31:07.982 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:07.982 | INFO     | [EVAL-SYS] | Setting state to buffering and advancing to next audio file in 5 seconds
2026-01-15 10:31:07.982 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 585, name: 'OutputAudioRawFrame#417', metadata: {} at 3.34s
2026-01-15 10:31:07.982 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 592, name: 'InputTransportMessageFrame#6', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 2.43s
2026-01-15 10:31:07.982 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 592, name: 'InputTransportMessageFrame#6', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 2.43s
2026-01-15 10:31:07.982 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 592, name: 'InputTransportMessageFrame#6', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 2.43s
2026-01-15 10:31:07.983 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 592, name: 'InputTransportMessageFrame#6', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 2.43s
2026-01-15 10:31:07.983 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 593, name: 'InputTransportMessageFrame#7', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'} at 2.43s
2026-01-15 10:31:07.983 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 593, name: 'InputTransportMessageFrame#7', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'} at 2.43s
2026-01-15 10:31:07.983 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 593, name: 'InputTransportMessageFrame#7', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'} at 2.43s
2026-01-15 10:31:07.983 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 593, name: 'InputTransportMessageFrame#7', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'} at 2.43s
2026-01-15 10:31:07.983 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 585, name: 'OutputAudioRawFrame#417', metadata: {} at 3.34s
2026-01-15 10:31:07.983 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#417(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:07.983 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 592, name: 'InputTransportMessageFrame#6', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 2.43s
2026-01-15 10:31:07.983 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 592, name: 'InputTransportMessageFrame#6', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 2.43s
2026-01-15 10:31:07.983 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 593, name: 'InputTransportMessageFrame#7', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'} at 2.43s
2026-01-15 10:31:07.983 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 593, name: 'InputTransportMessageFrame#7', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'} at 2.43s
2026-01-15 10:31:07.983 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 585, name: 'OutputAudioRawFrame#417', metadata: {} at 3.34s
2026-01-15 10:31:07.983 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 585, name: 'OutputAudioRawFrame#417', metadata: {} at 3.34s
2026-01-15 10:31:07.983 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 585, name: 'OutputAudioRawFrame#417', metadata: {} at 3.34s
2026-01-15 10:31:08.006 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 171, name: 'OutputAudioRawFrame#95', metadata: {} at 2.45s
2026-01-15 10:31:08.006 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 171, name: 'OutputAudioRawFrame#95', metadata: {} at 2.45s
2026-01-15 10:31:08.007 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 594, name: 'OutputAudioRawFrame#418', metadata: {} at 3.36s
2026-01-15 10:31:08.007 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 594, name: 'OutputAudioRawFrame#418', metadata: {} at 3.36s
2026-01-15 10:31:08.007 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#418(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.007 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 594, name: 'OutputAudioRawFrame#418', metadata: {} at 3.36s
2026-01-15 10:31:08.007 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 594, name: 'OutputAudioRawFrame#418', metadata: {} at 3.36s
2026-01-15 10:31:08.008 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 594, name: 'OutputAudioRawFrame#418', metadata: {} at 3.36s
2026-01-15 10:31:08.008 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#418(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.008 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 594, name: 'OutputAudioRawFrame#418', metadata: {} at 3.36s
2026-01-15 10:31:08.008 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 594, name: 'OutputAudioRawFrame#418', metadata: {} at 3.36s
2026-01-15 10:31:08.008 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 594, name: 'OutputAudioRawFrame#418', metadata: {} at 3.36s
2026-01-15 10:31:08.047 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 172, name: 'OutputAudioRawFrame#96', metadata: {} at 2.49s
2026-01-15 10:31:08.047 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 172, name: 'OutputAudioRawFrame#96', metadata: {} at 2.49s
2026-01-15 10:31:08.048 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 596, name: 'OutputAudioRawFrame#419', metadata: {} at 3.40s
2026-01-15 10:31:08.048 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 596, name: 'OutputAudioRawFrame#419', metadata: {} at 3.40s
2026-01-15 10:31:08.048 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#419(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.048 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 596, name: 'OutputAudioRawFrame#419', metadata: {} at 3.40s
2026-01-15 10:31:08.048 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 596, name: 'OutputAudioRawFrame#419', metadata: {} at 3.40s
2026-01-15 10:31:08.048 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 596, name: 'OutputAudioRawFrame#419', metadata: {} at 3.40s
2026-01-15 10:31:08.048 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#419(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.048 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 596, name: 'OutputAudioRawFrame#419', metadata: {} at 3.40s
2026-01-15 10:31:08.048 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 596, name: 'OutputAudioRawFrame#419', metadata: {} at 3.40s
2026-01-15 10:31:08.048 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 596, name: 'OutputAudioRawFrame#419', metadata: {} at 3.40s
2026-01-15 10:31:08.087 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 175, name: 'OutputAudioRawFrame#99', metadata: {} at 2.53s
2026-01-15 10:31:08.087 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 175, name: 'OutputAudioRawFrame#99', metadata: {} at 2.53s
2026-01-15 10:31:08.087 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 598, name: 'OutputAudioRawFrame#420', metadata: {} at 3.44s
2026-01-15 10:31:08.088 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 598, name: 'OutputAudioRawFrame#420', metadata: {} at 3.44s
2026-01-15 10:31:08.088 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#420(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.088 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 598, name: 'OutputAudioRawFrame#420', metadata: {} at 3.44s
2026-01-15 10:31:08.088 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 598, name: 'OutputAudioRawFrame#420', metadata: {} at 3.44s
2026-01-15 10:31:08.088 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 598, name: 'OutputAudioRawFrame#420', metadata: {} at 3.44s
2026-01-15 10:31:08.088 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#420(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.088 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 598, name: 'OutputAudioRawFrame#420', metadata: {} at 3.44s
2026-01-15 10:31:08.088 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 598, name: 'OutputAudioRawFrame#420', metadata: {} at 3.44s
2026-01-15 10:31:08.088 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 598, name: 'OutputAudioRawFrame#420', metadata: {} at 3.44s
2026-01-15 10:31:08.127 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 176, name: 'OutputAudioRawFrame#100', metadata: {} at 2.57s
2026-01-15 10:31:08.127 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 176, name: 'OutputAudioRawFrame#100', metadata: {} at 2.57s
2026-01-15 10:31:08.128 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 600, name: 'OutputAudioRawFrame#421', metadata: {} at 3.48s
2026-01-15 10:31:08.128 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 600, name: 'OutputAudioRawFrame#421', metadata: {} at 3.48s
2026-01-15 10:31:08.128 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#421(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.128 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 600, name: 'OutputAudioRawFrame#421', metadata: {} at 3.48s
2026-01-15 10:31:08.128 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 600, name: 'OutputAudioRawFrame#421', metadata: {} at 3.48s
2026-01-15 10:31:08.128 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 600, name: 'OutputAudioRawFrame#421', metadata: {} at 3.48s
2026-01-15 10:31:08.128 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#421(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.129 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 600, name: 'OutputAudioRawFrame#421', metadata: {} at 3.48s
2026-01-15 10:31:08.129 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 600, name: 'OutputAudioRawFrame#421', metadata: {} at 3.48s
2026-01-15 10:31:08.129 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 600, name: 'OutputAudioRawFrame#421', metadata: {} at 3.48s
2026-01-15 10:31:08.167 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 179, name: 'OutputAudioRawFrame#102', metadata: {} at 2.61s
2026-01-15 10:31:08.167 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 179, name: 'OutputAudioRawFrame#102', metadata: {} at 2.61s
2026-01-15 10:31:08.168 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 602, name: 'OutputAudioRawFrame#422', metadata: {} at 3.52s
2026-01-15 10:31:08.168 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 602, name: 'OutputAudioRawFrame#422', metadata: {} at 3.52s
2026-01-15 10:31:08.168 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#422(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.168 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 602, name: 'OutputAudioRawFrame#422', metadata: {} at 3.52s
2026-01-15 10:31:08.169 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 602, name: 'OutputAudioRawFrame#422', metadata: {} at 3.52s
2026-01-15 10:31:08.169 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 602, name: 'OutputAudioRawFrame#422', metadata: {} at 3.52s
2026-01-15 10:31:08.169 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#422(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.169 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 602, name: 'OutputAudioRawFrame#422', metadata: {} at 3.52s
2026-01-15 10:31:08.169 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 602, name: 'OutputAudioRawFrame#422', metadata: {} at 3.52s
2026-01-15 10:31:08.169 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 602, name: 'OutputAudioRawFrame#422', metadata: {} at 3.52s
2026-01-15 10:31:08.207 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 180, name: 'OutputAudioRawFrame#103', metadata: {} at 2.65s
2026-01-15 10:31:08.207 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 180, name: 'OutputAudioRawFrame#103', metadata: {} at 2.65s
2026-01-15 10:31:08.209 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 604, name: 'OutputAudioRawFrame#423', metadata: {} at 3.56s
2026-01-15 10:31:08.209 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 604, name: 'OutputAudioRawFrame#423', metadata: {} at 3.56s
2026-01-15 10:31:08.209 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#423(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.209 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 604, name: 'OutputAudioRawFrame#423', metadata: {} at 3.56s
2026-01-15 10:31:08.210 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 604, name: 'OutputAudioRawFrame#423', metadata: {} at 3.56s
2026-01-15 10:31:08.210 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 604, name: 'OutputAudioRawFrame#423', metadata: {} at 3.56s
2026-01-15 10:31:08.210 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#423(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.210 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 604, name: 'OutputAudioRawFrame#423', metadata: {} at 3.56s
2026-01-15 10:31:08.210 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 604, name: 'OutputAudioRawFrame#423', metadata: {} at 3.56s
2026-01-15 10:31:08.210 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 604, name: 'OutputAudioRawFrame#423', metadata: {} at 3.56s
2026-01-15 10:31:08.247 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 182, name: 'OutputAudioRawFrame#105', metadata: {} at 2.69s
2026-01-15 10:31:08.247 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 182, name: 'OutputAudioRawFrame#105', metadata: {} at 2.69s
2026-01-15 10:31:08.248 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 606, name: 'OutputAudioRawFrame#424', metadata: {} at 3.60s
2026-01-15 10:31:08.248 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 606, name: 'OutputAudioRawFrame#424', metadata: {} at 3.60s
2026-01-15 10:31:08.249 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#424(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.249 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 606, name: 'OutputAudioRawFrame#424', metadata: {} at 3.60s
2026-01-15 10:31:08.249 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 606, name: 'OutputAudioRawFrame#424', metadata: {} at 3.60s
2026-01-15 10:31:08.249 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 606, name: 'OutputAudioRawFrame#424', metadata: {} at 3.60s
2026-01-15 10:31:08.249 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#424(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.249 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 606, name: 'OutputAudioRawFrame#424', metadata: {} at 3.60s
2026-01-15 10:31:08.250 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 606, name: 'OutputAudioRawFrame#424', metadata: {} at 3.60s
2026-01-15 10:31:08.250 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 606, name: 'OutputAudioRawFrame#424', metadata: {} at 3.60s
2026-01-15 10:31:08.287 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 184, name: 'OutputAudioRawFrame#107', metadata: {} at 2.73s
2026-01-15 10:31:08.287 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 184, name: 'OutputAudioRawFrame#107', metadata: {} at 2.73s
2026-01-15 10:31:08.289 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 608, name: 'OutputAudioRawFrame#425', metadata: {} at 3.64s
2026-01-15 10:31:08.289 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 608, name: 'OutputAudioRawFrame#425', metadata: {} at 3.64s
2026-01-15 10:31:08.289 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#425(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.290 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 608, name: 'OutputAudioRawFrame#425', metadata: {} at 3.64s
2026-01-15 10:31:08.290 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 608, name: 'OutputAudioRawFrame#425', metadata: {} at 3.64s
2026-01-15 10:31:08.291 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 608, name: 'OutputAudioRawFrame#425', metadata: {} at 3.64s
2026-01-15 10:31:08.291 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#425(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.291 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 608, name: 'OutputAudioRawFrame#425', metadata: {} at 3.65s
2026-01-15 10:31:08.291 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 608, name: 'OutputAudioRawFrame#425', metadata: {} at 3.65s
2026-01-15 10:31:08.291 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 608, name: 'OutputAudioRawFrame#425', metadata: {} at 3.65s
2026-01-15 10:31:08.327 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 185, name: 'OutputAudioRawFrame#108', metadata: {} at 2.77s
2026-01-15 10:31:08.327 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 185, name: 'OutputAudioRawFrame#108', metadata: {} at 2.77s
2026-01-15 10:31:08.330 | DEBUG    | [BOT-SYS] | User started speaking
2026-01-15 10:31:08.331 | DEBUG    | [BOT-SYS] | PipelineTask#0: received interruption task frame InterruptionTaskFrame#1
2026-01-15 10:31:08.331 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: VADUserStartedSpeakingFrame id: 612, name: 'VADUserStartedSpeakingFrame#1', metadata: {} at 3.68s
2026-01-15 10:31:08.331 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserStartedSpeakingFrame id: 613, name: 'UserStartedSpeakingFrame#2', metadata: {}, emulated: False at 3.68s
2026-01-15 10:31:08.331 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserStartedSpeakingFrame id: 614, name: 'UserStartedSpeakingFrame#3', metadata: {}, emulated: False at 3.68s
2026-01-15 10:31:08.331 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserStartedSpeakingFrame id: 614, name: 'UserStartedSpeakingFrame#3', metadata: {}, emulated: False at 3.68s
2026-01-15 10:31:08.331 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: InterruptionTaskFrame id: 615, name: 'InterruptionTaskFrame#1', metadata: {} at 3.68s
2026-01-15 10:31:08.331 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: InterruptionTaskFrame id: 615, name: 'InterruptionTaskFrame#1', metadata: {} at 3.68s
2026-01-15 10:31:08.331 | DEBUG    | [BOT-SYS] | PipelineTask#0::Source â†’ Pipeline#0: InterruptionFrame id: 616, name: 'InterruptionFrame#1', metadata: {} at 3.69s
2026-01-15 10:31:08.331 | DEBUG    | [BOT-SYS] | Pipeline#0::Source â†’ WebsocketServerInputTransport#0: InterruptionFrame id: 616, name: 'InterruptionFrame#1', metadata: {} at 3.69s
2026-01-15 10:31:08.331 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InterruptionFrame id: 616, name: 'InterruptionFrame#1', metadata: {} at 3.69s
2026-01-15 10:31:08.331 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 617, name: 'UserSpeakingFrame#10', metadata: {} at 3.69s
2026-01-15 10:31:08.331 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 618, name: 'UserSpeakingFrame#11', metadata: {} at 3.69s
2026-01-15 10:31:08.332 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 618, name: 'UserSpeakingFrame#11', metadata: {} at 3.69s
2026-01-15 10:31:08.332 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 610, name: 'OutputAudioRawFrame#426', metadata: {} at 3.69s
2026-01-15 10:31:08.332 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 619, name: 'OutputTransportMessageUrgentFrame#9', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'} at 3.69s
2026-01-15 10:31:08.332 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#9(message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'})
2026-01-15 10:31:08.332 | INFO     | [BOT-SYS] | input bot frame: VADUserStartedSpeakingFrame#1
2026-01-15 10:31:08.332 | INFO     | [BOT-SYS] | input bot frame: UserStartedSpeakingFrame#2
2026-01-15 10:31:08.332 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: VADUserStartedSpeakingFrame id: 612, name: 'VADUserStartedSpeakingFrame#1', metadata: {} at 3.69s
2026-01-15 10:31:08.332 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserStartedSpeakingFrame id: 613, name: 'UserStartedSpeakingFrame#2', metadata: {}, emulated: False at 3.69s
2026-01-15 10:31:08.332 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 619, name: 'OutputTransportMessageUrgentFrame#9', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'} at 3.69s
2026-01-15 10:31:08.332 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: VADUserStartedSpeakingFrame id: 612, name: 'VADUserStartedSpeakingFrame#1', metadata: {} at 3.69s
2026-01-15 10:31:08.332 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: UserStartedSpeakingFrame id: 613, name: 'UserStartedSpeakingFrame#2', metadata: {}, emulated: False at 3.69s
2026-01-15 10:31:08.332 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 619, name: 'OutputTransportMessageUrgentFrame#9', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'} at 3.69s
2026-01-15 10:31:08.332 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: VADUserStartedSpeakingFrame id: 612, name: 'VADUserStartedSpeakingFrame#1', metadata: {} at 3.69s
2026-01-15 10:31:08.333 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: UserStartedSpeakingFrame id: 613, name: 'UserStartedSpeakingFrame#2', metadata: {}, emulated: False at 3.69s
2026-01-15 10:31:08.333 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 619, name: 'OutputTransportMessageUrgentFrame#9', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'} at 3.69s
2026-01-15 10:31:08.333 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: VADUserStartedSpeakingFrame id: 612, name: 'VADUserStartedSpeakingFrame#1', metadata: {} at 3.69s
2026-01-15 10:31:08.333 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: UserStartedSpeakingFrame id: 613, name: 'UserStartedSpeakingFrame#2', metadata: {}, emulated: False at 3.69s
2026-01-15 10:31:08.333 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InterruptionFrame id: 616, name: 'InterruptionFrame#1', metadata: {} at 3.69s
2026-01-15 10:31:08.333 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 617, name: 'UserSpeakingFrame#10', metadata: {} at 3.69s
2026-01-15 10:31:08.333 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 610, name: 'OutputAudioRawFrame#426', metadata: {} at 3.69s
2026-01-15 10:31:08.333 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#9(message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'})
2026-01-15 10:31:08.333 | INFO     | [BOT-SYS] | output bot frame: VADUserStartedSpeakingFrame#1
2026-01-15 10:31:08.333 | INFO     | [BOT-SYS] | output bot frame: UserStartedSpeakingFrame#2
2026-01-15 10:31:08.333 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 619, name: 'OutputTransportMessageUrgentFrame#9', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'} at 3.69s
2026-01-15 10:31:08.333 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: VADUserStartedSpeakingFrame id: 612, name: 'VADUserStartedSpeakingFrame#1', metadata: {} at 3.69s
2026-01-15 10:31:08.333 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: UserStartedSpeakingFrame id: 613, name: 'UserStartedSpeakingFrame#2', metadata: {}, emulated: False at 3.69s
2026-01-15 10:31:08.334 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: VADUserStartedSpeakingFrame id: 612, name: 'VADUserStartedSpeakingFrame#1', metadata: {} at 3.69s
2026-01-15 10:31:08.334 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: VADUserStartedSpeakingFrame id: 612, name: 'VADUserStartedSpeakingFrame#1', metadata: {} at 3.69s
2026-01-15 10:31:08.334 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: UserStartedSpeakingFrame id: 613, name: 'UserStartedSpeakingFrame#2', metadata: {}, emulated: False at 3.69s
2026-01-15 10:31:08.334 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: UserStartedSpeakingFrame id: 613, name: 'UserStartedSpeakingFrame#2', metadata: {}, emulated: False at 3.69s
2026-01-15 10:31:08.334 | INFO     | [BOT-SYS] | input bot frame: InterruptionFrame#1
2026-01-15 10:31:08.334 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#10
2026-01-15 10:31:08.334 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#426(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.334 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#8(message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'})
2026-01-15 10:31:08.334 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InterruptionFrame id: 616, name: 'InterruptionFrame#1', metadata: {} at 3.69s
2026-01-15 10:31:08.334 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 620, name: 'RTVIServerMessageFrame#5', metadata: {}, data: {'type': 'user-speaking'} at 3.69s
2026-01-15 10:31:08.334 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 610, name: 'OutputAudioRawFrame#426', metadata: {} at 3.69s
2026-01-15 10:31:08.334 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 622, name: 'OutputTransportMessageUrgentFrame#10', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.69s
2026-01-15 10:31:08.335 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 621, name: 'InputTransportMessageFrame#8', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'} at 2.78s
2026-01-15 10:31:08.335 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#8(message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'})
2026-01-15 10:31:08.335 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#8(message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'})
2026-01-15 10:31:08.335 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:08.335 | INFO     | [EVAL-SYS] | User started speaking during buffering, cancelling pending advance
2026-01-15 10:31:08.335 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:08.335 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#10(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.335 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#5(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.335 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 620, name: 'RTVIServerMessageFrame#5', metadata: {}, data: {'type': 'user-speaking'} at 3.69s
2026-01-15 10:31:08.335 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 622, name: 'OutputTransportMessageUrgentFrame#10', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.69s
2026-01-15 10:31:08.335 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 620, name: 'RTVIServerMessageFrame#5', metadata: {}, data: {'type': 'user-speaking'} at 3.69s
2026-01-15 10:31:08.335 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 621, name: 'InputTransportMessageFrame#8', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'} at 2.78s
2026-01-15 10:31:08.335 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 621, name: 'InputTransportMessageFrame#8', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'} at 2.78s
2026-01-15 10:31:08.336 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 621, name: 'InputTransportMessageFrame#8', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'} at 2.78s
2026-01-15 10:31:08.336 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 621, name: 'InputTransportMessageFrame#8', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'} at 2.78s
2026-01-15 10:31:08.336 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 621, name: 'InputTransportMessageFrame#8', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'} at 2.78s
2026-01-15 10:31:08.336 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 621, name: 'InputTransportMessageFrame#8', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-started-speaking'} at 2.78s
2026-01-15 10:31:08.336 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 TTFB: 0.4800558090209961
2026-01-15 10:31:08.336 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 processing time: 0.48012304306030273
2026-01-15 10:31:08.337 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: MetricsFrame id: 623, name: 'MetricsFrame#2', metadata: {}, data: [TTFBMetricsData(processor='SarvamSTTService#0', model='saarika:v2.5', value=0.4800558090209961)] at 3.69s
2026-01-15 10:31:08.337 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: MetricsFrame id: 624, name: 'MetricsFrame#3', metadata: {}, data: [ProcessingMetricsData(processor='SarvamSTTService#0', model='saarika:v2.5', value=0.48012304306030273)] at 3.69s
2026-01-15 10:31:08.337 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InterruptionFrame id: 616, name: 'InterruptionFrame#1', metadata: {} at 3.69s
2026-01-15 10:31:08.337 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 620, name: 'RTVIServerMessageFrame#5', metadata: {}, data: {'type': 'user-speaking'} at 3.69s
2026-01-15 10:31:08.337 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 610, name: 'OutputAudioRawFrame#426', metadata: {} at 3.69s
2026-01-15 10:31:08.337 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 622, name: 'OutputTransportMessageUrgentFrame#10', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.69s
2026-01-15 10:31:08.337 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 620, name: 'RTVIServerMessageFrame#5', metadata: {}, data: {'type': 'user-speaking'} at 3.69s
2026-01-15 10:31:08.337 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 625, name: 'OutputTransportMessageUrgentFrame#11', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'ttfb': [{'processor': 'SarvamSTTService#0', 'model': 'saarika:v2.5', 'value': 0.4800558090209961}]}} at 3.69s
2026-01-15 10:31:08.337 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 626, name: 'OutputTransportMessageUrgentFrame#12', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'processing': [{'processor': 'SarvamSTTService#0', 'model': 'saarika:v2.5', 'value': 0.48012304306030273}]}} at 3.69s
2026-01-15 10:31:08.337 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#11(message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'ttfb': [{'processor': 'SarvamSTTService#0', 'model': 'saarika:v2.5', 'value': 0.4800558090209961}]}})
2026-01-15 10:31:08.337 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#12(message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'processing': [{'processor': 'SarvamSTTService#0', 'model': 'saarika:v2.5', 'value': 0.48012304306030273}]}})
2026-01-15 10:31:08.337 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: MetricsFrame id: 623, name: 'MetricsFrame#2', metadata: {}, data: [TTFBMetricsData(processor='SarvamSTTService#0', model='saarika:v2.5', value=0.4800558090209961)] at 3.69s
2026-01-15 10:31:08.337 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: MetricsFrame id: 624, name: 'MetricsFrame#3', metadata: {}, data: [ProcessingMetricsData(processor='SarvamSTTService#0', model='saarika:v2.5', value=0.48012304306030273)] at 3.69s
2026-01-15 10:31:08.337 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 625, name: 'OutputTransportMessageUrgentFrame#11', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'ttfb': [{'processor': 'SarvamSTTService#0', 'model': 'saarika:v2.5', 'value': 0.4800558090209961}]}} at 3.69s
2026-01-15 10:31:08.337 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 626, name: 'OutputTransportMessageUrgentFrame#12', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'processing': [{'processor': 'SarvamSTTService#0', 'model': 'saarika:v2.5', 'value': 0.48012304306030273}]}} at 3.69s
2026-01-15 10:31:08.338 | INFO     | [BOT-SYS] | output bot frame: MetricsFrame#2
2026-01-15 10:31:08.338 | INFO     | [BOT-SYS] | output bot frame: MetricsFrame#3
2026-01-15 10:31:08.338 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: MetricsFrame id: 623, name: 'MetricsFrame#2', metadata: {}, data: [TTFBMetricsData(processor='SarvamSTTService#0', model='saarika:v2.5', value=0.4800558090209961)] at 3.69s
2026-01-15 10:31:08.338 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: MetricsFrame id: 624, name: 'MetricsFrame#3', metadata: {}, data: [ProcessingMetricsData(processor='SarvamSTTService#0', model='saarika:v2.5', value=0.48012304306030273)] at 3.69s
2026-01-15 10:31:08.338 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 625, name: 'OutputTransportMessageUrgentFrame#11', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'ttfb': [{'processor': 'SarvamSTTService#0', 'model': 'saarika:v2.5', 'value': 0.4800558090209961}]}} at 3.69s
2026-01-15 10:31:08.338 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 626, name: 'OutputTransportMessageUrgentFrame#12', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'processing': [{'processor': 'SarvamSTTService#0', 'model': 'saarika:v2.5', 'value': 0.48012304306030273}]}} at 3.69s
2026-01-15 10:31:08.338 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: MetricsFrame id: 623, name: 'MetricsFrame#2', metadata: {}, data: [TTFBMetricsData(processor='SarvamSTTService#0', model='saarika:v2.5', value=0.4800558090209961)] at 3.69s
2026-01-15 10:31:08.338 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: MetricsFrame id: 623, name: 'MetricsFrame#2', metadata: {}, data: [TTFBMetricsData(processor='SarvamSTTService#0', model='saarika:v2.5', value=0.4800558090209961)] at 3.69s
2026-01-15 10:31:08.338 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: MetricsFrame id: 624, name: 'MetricsFrame#3', metadata: {}, data: [ProcessingMetricsData(processor='SarvamSTTService#0', model='saarika:v2.5', value=0.48012304306030273)] at 3.69s
2026-01-15 10:31:08.338 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: MetricsFrame id: 624, name: 'MetricsFrame#3', metadata: {}, data: [ProcessingMetricsData(processor='SarvamSTTService#0', model='saarika:v2.5', value=0.48012304306030273)] at 3.69s
2026-01-15 10:31:08.338 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InterruptionFrame id: 616, name: 'InterruptionFrame#1', metadata: {} at 3.69s
2026-01-15 10:31:08.338 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 620, name: 'RTVIServerMessageFrame#5', metadata: {}, data: {'type': 'user-speaking'} at 3.69s
2026-01-15 10:31:08.339 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 610, name: 'OutputAudioRawFrame#426', metadata: {} at 3.69s
2026-01-15 10:31:08.339 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 622, name: 'OutputTransportMessageUrgentFrame#10', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.69s
2026-01-15 10:31:08.339 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 620, name: 'RTVIServerMessageFrame#5', metadata: {}, data: {'type': 'user-speaking'} at 3.69s
2026-01-15 10:31:08.339 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 625, name: 'OutputTransportMessageUrgentFrame#11', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'ttfb': [{'processor': 'SarvamSTTService#0', 'model': 'saarika:v2.5', 'value': 0.4800558090209961}]}} at 3.69s
2026-01-15 10:31:08.339 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 626, name: 'OutputTransportMessageUrgentFrame#12', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'processing': [{'processor': 'SarvamSTTService#0', 'model': 'saarika:v2.5', 'value': 0.48012304306030273}]}} at 3.69s
2026-01-15 10:31:08.339 | INFO     | [BOT-SYS] | output bot frame: InterruptionFrame#1
2026-01-15 10:31:08.339 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#5(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.339 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#426(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.339 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#10(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.339 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#5(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.339 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#11(message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'ttfb': [{'processor': 'SarvamSTTService#0', 'model': 'saarika:v2.5', 'value': 0.4800558090209961}]}})
2026-01-15 10:31:08.339 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#12(message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'processing': [{'processor': 'SarvamSTTService#0', 'model': 'saarika:v2.5', 'value': 0.48012304306030273}]}})
2026-01-15 10:31:08.339 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InterruptionFrame id: 616, name: 'InterruptionFrame#1', metadata: {} at 3.69s
2026-01-15 10:31:08.339 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 620, name: 'RTVIServerMessageFrame#5', metadata: {}, data: {'type': 'user-speaking'} at 3.69s
2026-01-15 10:31:08.339 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 610, name: 'OutputAudioRawFrame#426', metadata: {} at 3.69s
2026-01-15 10:31:08.339 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 622, name: 'OutputTransportMessageUrgentFrame#10', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.69s
2026-01-15 10:31:08.339 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 620, name: 'RTVIServerMessageFrame#5', metadata: {}, data: {'type': 'user-speaking'} at 3.69s
2026-01-15 10:31:08.339 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 625, name: 'OutputTransportMessageUrgentFrame#11', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'ttfb': [{'processor': 'SarvamSTTService#0', 'model': 'saarika:v2.5', 'value': 0.4800558090209961}]}} at 3.69s
2026-01-15 10:31:08.339 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 626, name: 'OutputTransportMessageUrgentFrame#12', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'processing': [{'processor': 'SarvamSTTService#0', 'model': 'saarika:v2.5', 'value': 0.48012304306030273}]}} at 3.69s
2026-01-15 10:31:08.340 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InterruptionFrame id: 616, name: 'InterruptionFrame#1', metadata: {} at 3.69s
2026-01-15 10:31:08.340 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InterruptionFrame id: 616, name: 'InterruptionFrame#1', metadata: {} at 3.69s
2026-01-15 10:31:08.340 | WARNING  | [BOT-SYS] | Frame type <class 'pipecat.frames.frames.InterruptionFrame'> is not serializable
2026-01-15 10:31:08.340 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 620, name: 'RTVIServerMessageFrame#5', metadata: {}, data: {'type': 'user-speaking'} at 3.69s
2026-01-15 10:31:08.340 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 620, name: 'RTVIServerMessageFrame#5', metadata: {}, data: {'type': 'user-speaking'} at 3.69s
2026-01-15 10:31:08.340 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 610, name: 'OutputAudioRawFrame#426', metadata: {} at 3.69s
2026-01-15 10:31:08.340 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 610, name: 'OutputAudioRawFrame#426', metadata: {} at 3.69s
2026-01-15 10:31:08.340 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 620, name: 'RTVIServerMessageFrame#5', metadata: {}, data: {'type': 'user-speaking'} at 3.69s
2026-01-15 10:31:08.340 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 620, name: 'RTVIServerMessageFrame#5', metadata: {}, data: {'type': 'user-speaking'} at 3.69s
2026-01-15 10:31:08.341 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#9(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.341 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#10(message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'ttfb': [{'processor': 'SarvamSTTService#0', 'model': 'saarika:v2.5', 'value': 0.4800558090209961}]}})
2026-01-15 10:31:08.341 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#11(message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'processing': [{'processor': 'SarvamSTTService#0', 'model': 'saarika:v2.5', 'value': 0.48012304306030273}]}})
2026-01-15 10:31:08.341 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 627, name: 'InputTransportMessageFrame#9', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.78s
2026-01-15 10:31:08.341 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 628, name: 'InputTransportMessageFrame#10', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'ttfb': [{'processor': 'SarvamSTTService#0', 'model': 'saarika:v2.5', 'value': 0.4800558090209961}]}} at 2.78s
2026-01-15 10:31:08.341 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 629, name: 'InputTransportMessageFrame#11', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'processing': [{'processor': 'SarvamSTTService#0', 'model': 'saarika:v2.5', 'value': 0.48012304306030273}]}} at 2.78s
2026-01-15 10:31:08.341 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#9(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.341 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#9(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.341 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:08.341 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:08.341 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#10(message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'ttfb': [{'processor': 'SarvamSTTService#0', 'model': 'saarika:v2.5', 'value': 0.4800558090209961}]}})
2026-01-15 10:31:08.341 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#10(message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'ttfb': [{'processor': 'SarvamSTTService#0', 'model': 'saarika:v2.5', 'value': 0.4800558090209961}]}})
2026-01-15 10:31:08.341 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:08.341 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:08.341 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#11(message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'processing': [{'processor': 'SarvamSTTService#0', 'model': 'saarika:v2.5', 'value': 0.48012304306030273}]}})
2026-01-15 10:31:08.341 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#11(message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'processing': [{'processor': 'SarvamSTTService#0', 'model': 'saarika:v2.5', 'value': 0.48012304306030273}]}})
2026-01-15 10:31:08.341 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:08.341 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:08.341 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 627, name: 'InputTransportMessageFrame#9', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.78s
2026-01-15 10:31:08.341 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 627, name: 'InputTransportMessageFrame#9', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.78s
2026-01-15 10:31:08.341 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 627, name: 'InputTransportMessageFrame#9', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.78s
2026-01-15 10:31:08.341 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 627, name: 'InputTransportMessageFrame#9', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.78s
2026-01-15 10:31:08.341 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 628, name: 'InputTransportMessageFrame#10', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'ttfb': [{'processor': 'SarvamSTTService#0', 'model': 'saarika:v2.5', 'value': 0.4800558090209961}]}} at 2.78s
2026-01-15 10:31:08.342 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 628, name: 'InputTransportMessageFrame#10', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'ttfb': [{'processor': 'SarvamSTTService#0', 'model': 'saarika:v2.5', 'value': 0.4800558090209961}]}} at 2.78s
2026-01-15 10:31:08.342 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 628, name: 'InputTransportMessageFrame#10', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'ttfb': [{'processor': 'SarvamSTTService#0', 'model': 'saarika:v2.5', 'value': 0.4800558090209961}]}} at 2.78s
2026-01-15 10:31:08.342 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 628, name: 'InputTransportMessageFrame#10', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'ttfb': [{'processor': 'SarvamSTTService#0', 'model': 'saarika:v2.5', 'value': 0.4800558090209961}]}} at 2.79s
2026-01-15 10:31:08.342 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 629, name: 'InputTransportMessageFrame#11', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'processing': [{'processor': 'SarvamSTTService#0', 'model': 'saarika:v2.5', 'value': 0.48012304306030273}]}} at 2.79s
2026-01-15 10:31:08.342 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 629, name: 'InputTransportMessageFrame#11', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'processing': [{'processor': 'SarvamSTTService#0', 'model': 'saarika:v2.5', 'value': 0.48012304306030273}]}} at 2.79s
2026-01-15 10:31:08.342 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 629, name: 'InputTransportMessageFrame#11', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'processing': [{'processor': 'SarvamSTTService#0', 'model': 'saarika:v2.5', 'value': 0.48012304306030273}]}} at 2.79s
2026-01-15 10:31:08.342 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 629, name: 'InputTransportMessageFrame#11', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'processing': [{'processor': 'SarvamSTTService#0', 'model': 'saarika:v2.5', 'value': 0.48012304306030273}]}} at 2.79s
2026-01-15 10:31:08.342 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 627, name: 'InputTransportMessageFrame#9', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.79s
2026-01-15 10:31:08.342 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 627, name: 'InputTransportMessageFrame#9', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.79s
2026-01-15 10:31:08.342 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 628, name: 'InputTransportMessageFrame#10', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'ttfb': [{'processor': 'SarvamSTTService#0', 'model': 'saarika:v2.5', 'value': 0.4800558090209961}]}} at 2.79s
2026-01-15 10:31:08.342 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 628, name: 'InputTransportMessageFrame#10', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'ttfb': [{'processor': 'SarvamSTTService#0', 'model': 'saarika:v2.5', 'value': 0.4800558090209961}]}} at 2.79s
2026-01-15 10:31:08.342 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 629, name: 'InputTransportMessageFrame#11', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'processing': [{'processor': 'SarvamSTTService#0', 'model': 'saarika:v2.5', 'value': 0.48012304306030273}]}} at 2.79s
2026-01-15 10:31:08.342 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 629, name: 'InputTransportMessageFrame#11', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'processing': [{'processor': 'SarvamSTTService#0', 'model': 'saarika:v2.5', 'value': 0.48012304306030273}]}} at 2.79s
2026-01-15 10:31:08.367 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 187, name: 'OutputAudioRawFrame#110', metadata: {} at 2.81s
2026-01-15 10:31:08.367 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 187, name: 'OutputAudioRawFrame#110', metadata: {} at 2.81s
2026-01-15 10:31:08.369 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 632, name: 'UserSpeakingFrame#12', metadata: {} at 3.72s
2026-01-15 10:31:08.369 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 633, name: 'UserSpeakingFrame#13', metadata: {} at 3.72s
2026-01-15 10:31:08.369 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 633, name: 'UserSpeakingFrame#13', metadata: {} at 3.72s
2026-01-15 10:31:08.369 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 630, name: 'OutputAudioRawFrame#427', metadata: {} at 3.72s
2026-01-15 10:31:08.369 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 632, name: 'UserSpeakingFrame#12', metadata: {} at 3.72s
2026-01-15 10:31:08.369 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 630, name: 'OutputAudioRawFrame#427', metadata: {} at 3.72s
2026-01-15 10:31:08.369 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#12
2026-01-15 10:31:08.369 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#427(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.370 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 634, name: 'RTVIServerMessageFrame#6', metadata: {}, data: {'type': 'user-speaking'} at 3.72s
2026-01-15 10:31:08.370 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 630, name: 'OutputAudioRawFrame#427', metadata: {} at 3.72s
2026-01-15 10:31:08.370 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 635, name: 'OutputTransportMessageUrgentFrame#13', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.72s
2026-01-15 10:31:08.370 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#13(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.370 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#6(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.370 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 634, name: 'RTVIServerMessageFrame#6', metadata: {}, data: {'type': 'user-speaking'} at 3.72s
2026-01-15 10:31:08.371 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 634, name: 'RTVIServerMessageFrame#6', metadata: {}, data: {'type': 'user-speaking'} at 3.72s
2026-01-15 10:31:08.371 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 630, name: 'OutputAudioRawFrame#427', metadata: {} at 3.72s
2026-01-15 10:31:08.371 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 635, name: 'OutputTransportMessageUrgentFrame#13', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.72s
2026-01-15 10:31:08.371 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 634, name: 'RTVIServerMessageFrame#6', metadata: {}, data: {'type': 'user-speaking'} at 3.72s
2026-01-15 10:31:08.371 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 634, name: 'RTVIServerMessageFrame#6', metadata: {}, data: {'type': 'user-speaking'} at 3.73s
2026-01-15 10:31:08.371 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 630, name: 'OutputAudioRawFrame#427', metadata: {} at 3.73s
2026-01-15 10:31:08.371 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 635, name: 'OutputTransportMessageUrgentFrame#13', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.73s
2026-01-15 10:31:08.371 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 634, name: 'RTVIServerMessageFrame#6', metadata: {}, data: {'type': 'user-speaking'} at 3.73s
2026-01-15 10:31:08.371 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#6(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.371 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#427(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.371 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 634, name: 'RTVIServerMessageFrame#6', metadata: {}, data: {'type': 'user-speaking'} at 3.73s
2026-01-15 10:31:08.371 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 630, name: 'OutputAudioRawFrame#427', metadata: {} at 3.73s
2026-01-15 10:31:08.371 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 635, name: 'OutputTransportMessageUrgentFrame#13', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.73s
2026-01-15 10:31:08.371 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 634, name: 'RTVIServerMessageFrame#6', metadata: {}, data: {'type': 'user-speaking'} at 3.73s
2026-01-15 10:31:08.371 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#13(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.371 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#6(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.371 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 634, name: 'RTVIServerMessageFrame#6', metadata: {}, data: {'type': 'user-speaking'} at 3.73s
2026-01-15 10:31:08.371 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 634, name: 'RTVIServerMessageFrame#6', metadata: {}, data: {'type': 'user-speaking'} at 3.73s
2026-01-15 10:31:08.371 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 630, name: 'OutputAudioRawFrame#427', metadata: {} at 3.73s
2026-01-15 10:31:08.372 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 630, name: 'OutputAudioRawFrame#427', metadata: {} at 3.73s
2026-01-15 10:31:08.372 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 635, name: 'OutputTransportMessageUrgentFrame#13', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.73s
2026-01-15 10:31:08.372 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 634, name: 'RTVIServerMessageFrame#6', metadata: {}, data: {'type': 'user-speaking'} at 3.73s
2026-01-15 10:31:08.372 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 634, name: 'RTVIServerMessageFrame#6', metadata: {}, data: {'type': 'user-speaking'} at 3.73s
2026-01-15 10:31:08.372 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 634, name: 'RTVIServerMessageFrame#6', metadata: {}, data: {'type': 'user-speaking'} at 3.73s
2026-01-15 10:31:08.372 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#12(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.372 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 636, name: 'InputTransportMessageFrame#12', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.82s
2026-01-15 10:31:08.372 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#12(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.372 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#12(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.372 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:08.372 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:08.372 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 636, name: 'InputTransportMessageFrame#12', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.82s
2026-01-15 10:31:08.372 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 636, name: 'InputTransportMessageFrame#12', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.82s
2026-01-15 10:31:08.372 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 636, name: 'InputTransportMessageFrame#12', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.82s
2026-01-15 10:31:08.372 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 636, name: 'InputTransportMessageFrame#12', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.82s
2026-01-15 10:31:08.373 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 636, name: 'InputTransportMessageFrame#12', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.82s
2026-01-15 10:31:08.373 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 636, name: 'InputTransportMessageFrame#12', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.82s
2026-01-15 10:31:08.407 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 188, name: 'OutputAudioRawFrame#111', metadata: {} at 2.85s
2026-01-15 10:31:08.407 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 188, name: 'OutputAudioRawFrame#111', metadata: {} at 2.85s
2026-01-15 10:31:08.410 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 639, name: 'UserSpeakingFrame#14', metadata: {} at 3.76s
2026-01-15 10:31:08.410 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 640, name: 'UserSpeakingFrame#15', metadata: {} at 3.76s
2026-01-15 10:31:08.410 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 640, name: 'UserSpeakingFrame#15', metadata: {} at 3.76s
2026-01-15 10:31:08.411 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 637, name: 'OutputAudioRawFrame#428', metadata: {} at 3.76s
2026-01-15 10:31:08.411 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 639, name: 'UserSpeakingFrame#14', metadata: {} at 3.77s
2026-01-15 10:31:08.411 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 637, name: 'OutputAudioRawFrame#428', metadata: {} at 3.77s
2026-01-15 10:31:08.411 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#14
2026-01-15 10:31:08.411 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#428(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.411 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 641, name: 'RTVIServerMessageFrame#7', metadata: {}, data: {'type': 'user-speaking'} at 3.77s
2026-01-15 10:31:08.411 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 637, name: 'OutputAudioRawFrame#428', metadata: {} at 3.77s
2026-01-15 10:31:08.411 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 642, name: 'OutputTransportMessageUrgentFrame#14', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.77s
2026-01-15 10:31:08.412 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#14(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.412 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#7(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.412 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 641, name: 'RTVIServerMessageFrame#7', metadata: {}, data: {'type': 'user-speaking'} at 3.77s
2026-01-15 10:31:08.412 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 641, name: 'RTVIServerMessageFrame#7', metadata: {}, data: {'type': 'user-speaking'} at 3.77s
2026-01-15 10:31:08.412 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 637, name: 'OutputAudioRawFrame#428', metadata: {} at 3.77s
2026-01-15 10:31:08.412 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 642, name: 'OutputTransportMessageUrgentFrame#14', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.77s
2026-01-15 10:31:08.412 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 641, name: 'RTVIServerMessageFrame#7', metadata: {}, data: {'type': 'user-speaking'} at 3.77s
2026-01-15 10:31:08.413 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 641, name: 'RTVIServerMessageFrame#7', metadata: {}, data: {'type': 'user-speaking'} at 3.77s
2026-01-15 10:31:08.413 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 637, name: 'OutputAudioRawFrame#428', metadata: {} at 3.77s
2026-01-15 10:31:08.413 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 642, name: 'OutputTransportMessageUrgentFrame#14', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.77s
2026-01-15 10:31:08.413 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 641, name: 'RTVIServerMessageFrame#7', metadata: {}, data: {'type': 'user-speaking'} at 3.77s
2026-01-15 10:31:08.413 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#7(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.413 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#428(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.413 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 641, name: 'RTVIServerMessageFrame#7', metadata: {}, data: {'type': 'user-speaking'} at 3.77s
2026-01-15 10:31:08.413 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 637, name: 'OutputAudioRawFrame#428', metadata: {} at 3.77s
2026-01-15 10:31:08.413 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 642, name: 'OutputTransportMessageUrgentFrame#14', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.77s
2026-01-15 10:31:08.413 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 641, name: 'RTVIServerMessageFrame#7', metadata: {}, data: {'type': 'user-speaking'} at 3.77s
2026-01-15 10:31:08.413 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#14(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.413 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#7(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.413 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 641, name: 'RTVIServerMessageFrame#7', metadata: {}, data: {'type': 'user-speaking'} at 3.77s
2026-01-15 10:31:08.413 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 641, name: 'RTVIServerMessageFrame#7', metadata: {}, data: {'type': 'user-speaking'} at 3.77s
2026-01-15 10:31:08.414 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 637, name: 'OutputAudioRawFrame#428', metadata: {} at 3.77s
2026-01-15 10:31:08.414 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 637, name: 'OutputAudioRawFrame#428', metadata: {} at 3.77s
2026-01-15 10:31:08.414 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 642, name: 'OutputTransportMessageUrgentFrame#14', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.77s
2026-01-15 10:31:08.414 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 641, name: 'RTVIServerMessageFrame#7', metadata: {}, data: {'type': 'user-speaking'} at 3.77s
2026-01-15 10:31:08.414 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 641, name: 'RTVIServerMessageFrame#7', metadata: {}, data: {'type': 'user-speaking'} at 3.77s
2026-01-15 10:31:08.414 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 641, name: 'RTVIServerMessageFrame#7', metadata: {}, data: {'type': 'user-speaking'} at 3.77s
2026-01-15 10:31:08.414 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#13(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.414 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 643, name: 'InputTransportMessageFrame#13', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.86s
2026-01-15 10:31:08.414 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#13(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.414 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#13(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.414 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:08.414 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:08.414 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 643, name: 'InputTransportMessageFrame#13', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.86s
2026-01-15 10:31:08.414 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 643, name: 'InputTransportMessageFrame#13', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.86s
2026-01-15 10:31:08.415 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 643, name: 'InputTransportMessageFrame#13', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.86s
2026-01-15 10:31:08.415 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 643, name: 'InputTransportMessageFrame#13', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.86s
2026-01-15 10:31:08.415 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 643, name: 'InputTransportMessageFrame#13', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.86s
2026-01-15 10:31:08.415 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 643, name: 'InputTransportMessageFrame#13', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.86s
2026-01-15 10:31:08.447 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 190, name: 'OutputAudioRawFrame#113', metadata: {} at 2.89s
2026-01-15 10:31:08.447 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 190, name: 'OutputAudioRawFrame#113', metadata: {} at 2.89s
2026-01-15 10:31:08.450 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 646, name: 'UserSpeakingFrame#16', metadata: {} at 3.80s
2026-01-15 10:31:08.450 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 647, name: 'UserSpeakingFrame#17', metadata: {} at 3.80s
2026-01-15 10:31:08.451 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 647, name: 'UserSpeakingFrame#17', metadata: {} at 3.80s
2026-01-15 10:31:08.451 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 644, name: 'OutputAudioRawFrame#429', metadata: {} at 3.80s
2026-01-15 10:31:08.451 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 646, name: 'UserSpeakingFrame#16', metadata: {} at 3.81s
2026-01-15 10:31:08.451 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 644, name: 'OutputAudioRawFrame#429', metadata: {} at 3.81s
2026-01-15 10:31:08.451 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#16
2026-01-15 10:31:08.451 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#429(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.452 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 648, name: 'RTVIServerMessageFrame#8', metadata: {}, data: {'type': 'user-speaking'} at 3.81s
2026-01-15 10:31:08.452 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 644, name: 'OutputAudioRawFrame#429', metadata: {} at 3.81s
2026-01-15 10:31:08.452 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 649, name: 'OutputTransportMessageUrgentFrame#15', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.81s
2026-01-15 10:31:08.453 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#15(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.453 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#8(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.454 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 648, name: 'RTVIServerMessageFrame#8', metadata: {}, data: {'type': 'user-speaking'} at 3.81s
2026-01-15 10:31:08.454 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 648, name: 'RTVIServerMessageFrame#8', metadata: {}, data: {'type': 'user-speaking'} at 3.81s
2026-01-15 10:31:08.454 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 644, name: 'OutputAudioRawFrame#429', metadata: {} at 3.81s
2026-01-15 10:31:08.454 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 649, name: 'OutputTransportMessageUrgentFrame#15', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.81s
2026-01-15 10:31:08.454 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 648, name: 'RTVIServerMessageFrame#8', metadata: {}, data: {'type': 'user-speaking'} at 3.81s
2026-01-15 10:31:08.454 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 648, name: 'RTVIServerMessageFrame#8', metadata: {}, data: {'type': 'user-speaking'} at 3.81s
2026-01-15 10:31:08.454 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 644, name: 'OutputAudioRawFrame#429', metadata: {} at 3.81s
2026-01-15 10:31:08.454 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 649, name: 'OutputTransportMessageUrgentFrame#15', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.81s
2026-01-15 10:31:08.454 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 648, name: 'RTVIServerMessageFrame#8', metadata: {}, data: {'type': 'user-speaking'} at 3.81s
2026-01-15 10:31:08.454 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#8(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.455 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#429(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.455 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 648, name: 'RTVIServerMessageFrame#8', metadata: {}, data: {'type': 'user-speaking'} at 3.81s
2026-01-15 10:31:08.455 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 644, name: 'OutputAudioRawFrame#429', metadata: {} at 3.81s
2026-01-15 10:31:08.455 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 649, name: 'OutputTransportMessageUrgentFrame#15', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.81s
2026-01-15 10:31:08.455 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 648, name: 'RTVIServerMessageFrame#8', metadata: {}, data: {'type': 'user-speaking'} at 3.81s
2026-01-15 10:31:08.455 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#15(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.455 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#8(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.455 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 648, name: 'RTVIServerMessageFrame#8', metadata: {}, data: {'type': 'user-speaking'} at 3.81s
2026-01-15 10:31:08.455 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 648, name: 'RTVIServerMessageFrame#8', metadata: {}, data: {'type': 'user-speaking'} at 3.81s
2026-01-15 10:31:08.455 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 644, name: 'OutputAudioRawFrame#429', metadata: {} at 3.81s
2026-01-15 10:31:08.455 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 644, name: 'OutputAudioRawFrame#429', metadata: {} at 3.81s
2026-01-15 10:31:08.455 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 649, name: 'OutputTransportMessageUrgentFrame#15', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.81s
2026-01-15 10:31:08.456 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 648, name: 'RTVIServerMessageFrame#8', metadata: {}, data: {'type': 'user-speaking'} at 3.81s
2026-01-15 10:31:08.456 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 648, name: 'RTVIServerMessageFrame#8', metadata: {}, data: {'type': 'user-speaking'} at 3.81s
2026-01-15 10:31:08.456 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 648, name: 'RTVIServerMessageFrame#8', metadata: {}, data: {'type': 'user-speaking'} at 3.81s
2026-01-15 10:31:08.456 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#14(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.456 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 650, name: 'InputTransportMessageFrame#14', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.90s
2026-01-15 10:31:08.456 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#14(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.456 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#14(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.456 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:08.456 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:08.456 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 650, name: 'InputTransportMessageFrame#14', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.90s
2026-01-15 10:31:08.456 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 650, name: 'InputTransportMessageFrame#14', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.90s
2026-01-15 10:31:08.456 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 650, name: 'InputTransportMessageFrame#14', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.90s
2026-01-15 10:31:08.456 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 650, name: 'InputTransportMessageFrame#14', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.90s
2026-01-15 10:31:08.457 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 650, name: 'InputTransportMessageFrame#14', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.90s
2026-01-15 10:31:08.457 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 650, name: 'InputTransportMessageFrame#14', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.90s
2026-01-15 10:31:08.486 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 191, name: 'OutputAudioRawFrame#114', metadata: {} at 2.93s
2026-01-15 10:31:08.486 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 191, name: 'OutputAudioRawFrame#114', metadata: {} at 2.93s
2026-01-15 10:31:08.488 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 653, name: 'UserSpeakingFrame#18', metadata: {} at 3.84s
2026-01-15 10:31:08.488 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 654, name: 'UserSpeakingFrame#19', metadata: {} at 3.84s
2026-01-15 10:31:08.488 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 654, name: 'UserSpeakingFrame#19', metadata: {} at 3.84s
2026-01-15 10:31:08.488 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 651, name: 'OutputAudioRawFrame#430', metadata: {} at 3.84s
2026-01-15 10:31:08.489 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 653, name: 'UserSpeakingFrame#18', metadata: {} at 3.84s
2026-01-15 10:31:08.489 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 651, name: 'OutputAudioRawFrame#430', metadata: {} at 3.84s
2026-01-15 10:31:08.489 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#18
2026-01-15 10:31:08.489 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#430(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.489 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 655, name: 'RTVIServerMessageFrame#9', metadata: {}, data: {'type': 'user-speaking'} at 3.84s
2026-01-15 10:31:08.489 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 651, name: 'OutputAudioRawFrame#430', metadata: {} at 3.84s
2026-01-15 10:31:08.489 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 656, name: 'OutputTransportMessageUrgentFrame#16', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.84s
2026-01-15 10:31:08.490 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#16(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.490 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#9(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.490 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 655, name: 'RTVIServerMessageFrame#9', metadata: {}, data: {'type': 'user-speaking'} at 3.84s
2026-01-15 10:31:08.490 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 655, name: 'RTVIServerMessageFrame#9', metadata: {}, data: {'type': 'user-speaking'} at 3.84s
2026-01-15 10:31:08.490 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 651, name: 'OutputAudioRawFrame#430', metadata: {} at 3.84s
2026-01-15 10:31:08.490 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 656, name: 'OutputTransportMessageUrgentFrame#16', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.84s
2026-01-15 10:31:08.490 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 655, name: 'RTVIServerMessageFrame#9', metadata: {}, data: {'type': 'user-speaking'} at 3.84s
2026-01-15 10:31:08.490 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 655, name: 'RTVIServerMessageFrame#9', metadata: {}, data: {'type': 'user-speaking'} at 3.84s
2026-01-15 10:31:08.490 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 651, name: 'OutputAudioRawFrame#430', metadata: {} at 3.84s
2026-01-15 10:31:08.490 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 656, name: 'OutputTransportMessageUrgentFrame#16', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.84s
2026-01-15 10:31:08.490 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 655, name: 'RTVIServerMessageFrame#9', metadata: {}, data: {'type': 'user-speaking'} at 3.84s
2026-01-15 10:31:08.490 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#9(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.490 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#430(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.490 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 655, name: 'RTVIServerMessageFrame#9', metadata: {}, data: {'type': 'user-speaking'} at 3.84s
2026-01-15 10:31:08.490 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 651, name: 'OutputAudioRawFrame#430', metadata: {} at 3.84s
2026-01-15 10:31:08.490 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 656, name: 'OutputTransportMessageUrgentFrame#16', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.84s
2026-01-15 10:31:08.490 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 655, name: 'RTVIServerMessageFrame#9', metadata: {}, data: {'type': 'user-speaking'} at 3.84s
2026-01-15 10:31:08.491 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#16(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.491 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#9(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.491 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 655, name: 'RTVIServerMessageFrame#9', metadata: {}, data: {'type': 'user-speaking'} at 3.84s
2026-01-15 10:31:08.491 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 655, name: 'RTVIServerMessageFrame#9', metadata: {}, data: {'type': 'user-speaking'} at 3.84s
2026-01-15 10:31:08.491 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 651, name: 'OutputAudioRawFrame#430', metadata: {} at 3.84s
2026-01-15 10:31:08.491 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 651, name: 'OutputAudioRawFrame#430', metadata: {} at 3.84s
2026-01-15 10:31:08.491 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 656, name: 'OutputTransportMessageUrgentFrame#16', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.84s
2026-01-15 10:31:08.491 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 655, name: 'RTVIServerMessageFrame#9', metadata: {}, data: {'type': 'user-speaking'} at 3.85s
2026-01-15 10:31:08.491 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 655, name: 'RTVIServerMessageFrame#9', metadata: {}, data: {'type': 'user-speaking'} at 3.85s
2026-01-15 10:31:08.491 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 655, name: 'RTVIServerMessageFrame#9', metadata: {}, data: {'type': 'user-speaking'} at 3.85s
2026-01-15 10:31:08.491 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#15(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.492 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 657, name: 'InputTransportMessageFrame#15', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.94s
2026-01-15 10:31:08.492 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#15(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.492 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#15(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.492 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:08.492 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:08.492 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 657, name: 'InputTransportMessageFrame#15', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.94s
2026-01-15 10:31:08.492 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 657, name: 'InputTransportMessageFrame#15', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.94s
2026-01-15 10:31:08.492 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 657, name: 'InputTransportMessageFrame#15', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.94s
2026-01-15 10:31:08.492 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 657, name: 'InputTransportMessageFrame#15', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.94s
2026-01-15 10:31:08.492 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 657, name: 'InputTransportMessageFrame#15', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.94s
2026-01-15 10:31:08.492 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 657, name: 'InputTransportMessageFrame#15', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.94s
2026-01-15 10:31:08.527 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 192, name: 'OutputAudioRawFrame#115', metadata: {} at 2.97s
2026-01-15 10:31:08.527 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 192, name: 'OutputAudioRawFrame#115', metadata: {} at 2.97s
2026-01-15 10:31:08.529 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 660, name: 'UserSpeakingFrame#20', metadata: {} at 3.88s
2026-01-15 10:31:08.529 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 661, name: 'UserSpeakingFrame#21', metadata: {} at 3.88s
2026-01-15 10:31:08.529 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 661, name: 'UserSpeakingFrame#21', metadata: {} at 3.88s
2026-01-15 10:31:08.529 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 658, name: 'OutputAudioRawFrame#431', metadata: {} at 3.88s
2026-01-15 10:31:08.529 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 660, name: 'UserSpeakingFrame#20', metadata: {} at 3.88s
2026-01-15 10:31:08.529 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 658, name: 'OutputAudioRawFrame#431', metadata: {} at 3.88s
2026-01-15 10:31:08.529 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#20
2026-01-15 10:31:08.529 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#431(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.529 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 662, name: 'RTVIServerMessageFrame#10', metadata: {}, data: {'type': 'user-speaking'} at 3.88s
2026-01-15 10:31:08.529 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 658, name: 'OutputAudioRawFrame#431', metadata: {} at 3.88s
2026-01-15 10:31:08.529 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 663, name: 'OutputTransportMessageUrgentFrame#17', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.88s
2026-01-15 10:31:08.530 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#17(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.530 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#10(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.530 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 662, name: 'RTVIServerMessageFrame#10', metadata: {}, data: {'type': 'user-speaking'} at 3.88s
2026-01-15 10:31:08.530 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 662, name: 'RTVIServerMessageFrame#10', metadata: {}, data: {'type': 'user-speaking'} at 3.88s
2026-01-15 10:31:08.530 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 658, name: 'OutputAudioRawFrame#431', metadata: {} at 3.88s
2026-01-15 10:31:08.530 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 663, name: 'OutputTransportMessageUrgentFrame#17', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.88s
2026-01-15 10:31:08.530 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 662, name: 'RTVIServerMessageFrame#10', metadata: {}, data: {'type': 'user-speaking'} at 3.88s
2026-01-15 10:31:08.530 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 662, name: 'RTVIServerMessageFrame#10', metadata: {}, data: {'type': 'user-speaking'} at 3.88s
2026-01-15 10:31:08.530 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 658, name: 'OutputAudioRawFrame#431', metadata: {} at 3.88s
2026-01-15 10:31:08.530 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 663, name: 'OutputTransportMessageUrgentFrame#17', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.88s
2026-01-15 10:31:08.531 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 662, name: 'RTVIServerMessageFrame#10', metadata: {}, data: {'type': 'user-speaking'} at 3.88s
2026-01-15 10:31:08.531 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#10(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.531 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#431(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.531 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 662, name: 'RTVIServerMessageFrame#10', metadata: {}, data: {'type': 'user-speaking'} at 3.88s
2026-01-15 10:31:08.531 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 658, name: 'OutputAudioRawFrame#431', metadata: {} at 3.89s
2026-01-15 10:31:08.531 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 663, name: 'OutputTransportMessageUrgentFrame#17', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.89s
2026-01-15 10:31:08.531 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 662, name: 'RTVIServerMessageFrame#10', metadata: {}, data: {'type': 'user-speaking'} at 3.89s
2026-01-15 10:31:08.531 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#17(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.531 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#10(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.531 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 662, name: 'RTVIServerMessageFrame#10', metadata: {}, data: {'type': 'user-speaking'} at 3.89s
2026-01-15 10:31:08.531 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 662, name: 'RTVIServerMessageFrame#10', metadata: {}, data: {'type': 'user-speaking'} at 3.89s
2026-01-15 10:31:08.531 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 658, name: 'OutputAudioRawFrame#431', metadata: {} at 3.89s
2026-01-15 10:31:08.531 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 658, name: 'OutputAudioRawFrame#431', metadata: {} at 3.89s
2026-01-15 10:31:08.531 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 663, name: 'OutputTransportMessageUrgentFrame#17', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.89s
2026-01-15 10:31:08.531 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 662, name: 'RTVIServerMessageFrame#10', metadata: {}, data: {'type': 'user-speaking'} at 3.89s
2026-01-15 10:31:08.531 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 662, name: 'RTVIServerMessageFrame#10', metadata: {}, data: {'type': 'user-speaking'} at 3.89s
2026-01-15 10:31:08.531 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 662, name: 'RTVIServerMessageFrame#10', metadata: {}, data: {'type': 'user-speaking'} at 3.89s
2026-01-15 10:31:08.532 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#16(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.532 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 664, name: 'InputTransportMessageFrame#16', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.98s
2026-01-15 10:31:08.532 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#16(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.532 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#16(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.532 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:08.532 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:08.532 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 664, name: 'InputTransportMessageFrame#16', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.98s
2026-01-15 10:31:08.532 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 664, name: 'InputTransportMessageFrame#16', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.98s
2026-01-15 10:31:08.532 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 664, name: 'InputTransportMessageFrame#16', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.98s
2026-01-15 10:31:08.532 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 664, name: 'InputTransportMessageFrame#16', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.98s
2026-01-15 10:31:08.532 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 664, name: 'InputTransportMessageFrame#16', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.98s
2026-01-15 10:31:08.532 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 664, name: 'InputTransportMessageFrame#16', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 2.98s
2026-01-15 10:31:08.567 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 194, name: 'OutputAudioRawFrame#117', metadata: {} at 3.01s
2026-01-15 10:31:08.567 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 194, name: 'OutputAudioRawFrame#117', metadata: {} at 3.01s
2026-01-15 10:31:08.568 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 667, name: 'UserSpeakingFrame#22', metadata: {} at 3.92s
2026-01-15 10:31:08.568 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 668, name: 'UserSpeakingFrame#23', metadata: {} at 3.92s
2026-01-15 10:31:08.568 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 668, name: 'UserSpeakingFrame#23', metadata: {} at 3.92s
2026-01-15 10:31:08.568 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 665, name: 'OutputAudioRawFrame#432', metadata: {} at 3.92s
2026-01-15 10:31:08.568 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 667, name: 'UserSpeakingFrame#22', metadata: {} at 3.92s
2026-01-15 10:31:08.568 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 665, name: 'OutputAudioRawFrame#432', metadata: {} at 3.92s
2026-01-15 10:31:08.568 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#22
2026-01-15 10:31:08.568 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#432(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.568 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 669, name: 'RTVIServerMessageFrame#11', metadata: {}, data: {'type': 'user-speaking'} at 3.92s
2026-01-15 10:31:08.568 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 665, name: 'OutputAudioRawFrame#432', metadata: {} at 3.92s
2026-01-15 10:31:08.569 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 670, name: 'OutputTransportMessageUrgentFrame#18', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.92s
2026-01-15 10:31:08.569 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#18(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.569 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#11(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.569 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 669, name: 'RTVIServerMessageFrame#11', metadata: {}, data: {'type': 'user-speaking'} at 3.92s
2026-01-15 10:31:08.569 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 669, name: 'RTVIServerMessageFrame#11', metadata: {}, data: {'type': 'user-speaking'} at 3.92s
2026-01-15 10:31:08.569 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 665, name: 'OutputAudioRawFrame#432', metadata: {} at 3.92s
2026-01-15 10:31:08.569 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 670, name: 'OutputTransportMessageUrgentFrame#18', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.92s
2026-01-15 10:31:08.569 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 669, name: 'RTVIServerMessageFrame#11', metadata: {}, data: {'type': 'user-speaking'} at 3.92s
2026-01-15 10:31:08.569 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 669, name: 'RTVIServerMessageFrame#11', metadata: {}, data: {'type': 'user-speaking'} at 3.92s
2026-01-15 10:31:08.570 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 665, name: 'OutputAudioRawFrame#432', metadata: {} at 3.92s
2026-01-15 10:31:08.570 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 670, name: 'OutputTransportMessageUrgentFrame#18', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.92s
2026-01-15 10:31:08.570 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 669, name: 'RTVIServerMessageFrame#11', metadata: {}, data: {'type': 'user-speaking'} at 3.92s
2026-01-15 10:31:08.570 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#11(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.570 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#432(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.570 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 669, name: 'RTVIServerMessageFrame#11', metadata: {}, data: {'type': 'user-speaking'} at 3.92s
2026-01-15 10:31:08.570 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 665, name: 'OutputAudioRawFrame#432', metadata: {} at 3.92s
2026-01-15 10:31:08.570 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 670, name: 'OutputTransportMessageUrgentFrame#18', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.92s
2026-01-15 10:31:08.570 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 669, name: 'RTVIServerMessageFrame#11', metadata: {}, data: {'type': 'user-speaking'} at 3.92s
2026-01-15 10:31:08.570 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#18(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.570 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#11(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.570 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 669, name: 'RTVIServerMessageFrame#11', metadata: {}, data: {'type': 'user-speaking'} at 3.92s
2026-01-15 10:31:08.570 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 669, name: 'RTVIServerMessageFrame#11', metadata: {}, data: {'type': 'user-speaking'} at 3.92s
2026-01-15 10:31:08.570 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 665, name: 'OutputAudioRawFrame#432', metadata: {} at 3.92s
2026-01-15 10:31:08.570 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 665, name: 'OutputAudioRawFrame#432', metadata: {} at 3.92s
2026-01-15 10:31:08.570 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 670, name: 'OutputTransportMessageUrgentFrame#18', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.92s
2026-01-15 10:31:08.570 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 669, name: 'RTVIServerMessageFrame#11', metadata: {}, data: {'type': 'user-speaking'} at 3.92s
2026-01-15 10:31:08.570 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 669, name: 'RTVIServerMessageFrame#11', metadata: {}, data: {'type': 'user-speaking'} at 3.92s
2026-01-15 10:31:08.571 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 669, name: 'RTVIServerMessageFrame#11', metadata: {}, data: {'type': 'user-speaking'} at 3.92s
2026-01-15 10:31:08.571 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#17(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.571 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 671, name: 'InputTransportMessageFrame#17', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.01s
2026-01-15 10:31:08.571 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#17(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.571 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#17(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.571 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:08.571 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:08.571 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 671, name: 'InputTransportMessageFrame#17', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.01s
2026-01-15 10:31:08.571 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 671, name: 'InputTransportMessageFrame#17', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.01s
2026-01-15 10:31:08.571 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 671, name: 'InputTransportMessageFrame#17', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.01s
2026-01-15 10:31:08.571 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 671, name: 'InputTransportMessageFrame#17', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.01s
2026-01-15 10:31:08.571 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 671, name: 'InputTransportMessageFrame#17', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.01s
2026-01-15 10:31:08.571 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 671, name: 'InputTransportMessageFrame#17', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.01s
2026-01-15 10:31:08.607 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 195, name: 'OutputAudioRawFrame#118', metadata: {} at 3.05s
2026-01-15 10:31:08.607 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 195, name: 'OutputAudioRawFrame#118', metadata: {} at 3.05s
2026-01-15 10:31:08.608 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 674, name: 'UserSpeakingFrame#24', metadata: {} at 3.96s
2026-01-15 10:31:08.608 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 675, name: 'UserSpeakingFrame#25', metadata: {} at 3.96s
2026-01-15 10:31:08.608 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 675, name: 'UserSpeakingFrame#25', metadata: {} at 3.96s
2026-01-15 10:31:08.608 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 672, name: 'OutputAudioRawFrame#433', metadata: {} at 3.96s
2026-01-15 10:31:08.608 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 674, name: 'UserSpeakingFrame#24', metadata: {} at 3.96s
2026-01-15 10:31:08.608 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 672, name: 'OutputAudioRawFrame#433', metadata: {} at 3.96s
2026-01-15 10:31:08.608 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#24
2026-01-15 10:31:08.609 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#433(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.609 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 676, name: 'RTVIServerMessageFrame#12', metadata: {}, data: {'type': 'user-speaking'} at 3.96s
2026-01-15 10:31:08.609 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 672, name: 'OutputAudioRawFrame#433', metadata: {} at 3.96s
2026-01-15 10:31:08.609 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 677, name: 'OutputTransportMessageUrgentFrame#19', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.96s
2026-01-15 10:31:08.609 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#19(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.610 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#12(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.610 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 676, name: 'RTVIServerMessageFrame#12', metadata: {}, data: {'type': 'user-speaking'} at 3.96s
2026-01-15 10:31:08.610 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 676, name: 'RTVIServerMessageFrame#12', metadata: {}, data: {'type': 'user-speaking'} at 3.96s
2026-01-15 10:31:08.610 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 672, name: 'OutputAudioRawFrame#433', metadata: {} at 3.96s
2026-01-15 10:31:08.610 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 677, name: 'OutputTransportMessageUrgentFrame#19', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.96s
2026-01-15 10:31:08.610 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 676, name: 'RTVIServerMessageFrame#12', metadata: {}, data: {'type': 'user-speaking'} at 3.96s
2026-01-15 10:31:08.610 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 676, name: 'RTVIServerMessageFrame#12', metadata: {}, data: {'type': 'user-speaking'} at 3.96s
2026-01-15 10:31:08.610 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 672, name: 'OutputAudioRawFrame#433', metadata: {} at 3.96s
2026-01-15 10:31:08.610 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 677, name: 'OutputTransportMessageUrgentFrame#19', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.96s
2026-01-15 10:31:08.610 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 676, name: 'RTVIServerMessageFrame#12', metadata: {}, data: {'type': 'user-speaking'} at 3.96s
2026-01-15 10:31:08.610 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#12(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.610 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#433(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.610 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 676, name: 'RTVIServerMessageFrame#12', metadata: {}, data: {'type': 'user-speaking'} at 3.96s
2026-01-15 10:31:08.611 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 672, name: 'OutputAudioRawFrame#433', metadata: {} at 3.96s
2026-01-15 10:31:08.611 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 677, name: 'OutputTransportMessageUrgentFrame#19', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.96s
2026-01-15 10:31:08.611 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 676, name: 'RTVIServerMessageFrame#12', metadata: {}, data: {'type': 'user-speaking'} at 3.96s
2026-01-15 10:31:08.611 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#19(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.611 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#12(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.611 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 676, name: 'RTVIServerMessageFrame#12', metadata: {}, data: {'type': 'user-speaking'} at 3.97s
2026-01-15 10:31:08.611 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 676, name: 'RTVIServerMessageFrame#12', metadata: {}, data: {'type': 'user-speaking'} at 3.97s
2026-01-15 10:31:08.611 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 672, name: 'OutputAudioRawFrame#433', metadata: {} at 3.97s
2026-01-15 10:31:08.611 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 672, name: 'OutputAudioRawFrame#433', metadata: {} at 3.97s
2026-01-15 10:31:08.611 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 677, name: 'OutputTransportMessageUrgentFrame#19', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.97s
2026-01-15 10:31:08.611 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 676, name: 'RTVIServerMessageFrame#12', metadata: {}, data: {'type': 'user-speaking'} at 3.97s
2026-01-15 10:31:08.611 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 676, name: 'RTVIServerMessageFrame#12', metadata: {}, data: {'type': 'user-speaking'} at 3.97s
2026-01-15 10:31:08.611 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 676, name: 'RTVIServerMessageFrame#12', metadata: {}, data: {'type': 'user-speaking'} at 3.97s
2026-01-15 10:31:08.612 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#18(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.612 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 678, name: 'InputTransportMessageFrame#18', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.06s
2026-01-15 10:31:08.612 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#18(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.612 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#18(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.612 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:08.612 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:08.612 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 678, name: 'InputTransportMessageFrame#18', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.06s
2026-01-15 10:31:08.612 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 678, name: 'InputTransportMessageFrame#18', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.06s
2026-01-15 10:31:08.612 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 678, name: 'InputTransportMessageFrame#18', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.06s
2026-01-15 10:31:08.612 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 678, name: 'InputTransportMessageFrame#18', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.06s
2026-01-15 10:31:08.612 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 678, name: 'InputTransportMessageFrame#18', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.06s
2026-01-15 10:31:08.612 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 678, name: 'InputTransportMessageFrame#18', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.06s
2026-01-15 10:31:08.647 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 197, name: 'OutputAudioRawFrame#120', metadata: {} at 3.09s
2026-01-15 10:31:08.647 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 197, name: 'OutputAudioRawFrame#120', metadata: {} at 3.09s
2026-01-15 10:31:08.649 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 681, name: 'UserSpeakingFrame#26', metadata: {} at 4.00s
2026-01-15 10:31:08.649 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 682, name: 'UserSpeakingFrame#27', metadata: {} at 4.00s
2026-01-15 10:31:08.649 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 682, name: 'UserSpeakingFrame#27', metadata: {} at 4.00s
2026-01-15 10:31:08.649 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 679, name: 'OutputAudioRawFrame#434', metadata: {} at 4.00s
2026-01-15 10:31:08.649 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 681, name: 'UserSpeakingFrame#26', metadata: {} at 4.00s
2026-01-15 10:31:08.649 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 679, name: 'OutputAudioRawFrame#434', metadata: {} at 4.00s
2026-01-15 10:31:08.649 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#26
2026-01-15 10:31:08.649 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#434(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.650 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 683, name: 'RTVIServerMessageFrame#13', metadata: {}, data: {'type': 'user-speaking'} at 4.00s
2026-01-15 10:31:08.650 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 679, name: 'OutputAudioRawFrame#434', metadata: {} at 4.00s
2026-01-15 10:31:08.650 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 684, name: 'OutputTransportMessageUrgentFrame#20', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.00s
2026-01-15 10:31:08.650 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#20(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.650 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#13(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.650 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 683, name: 'RTVIServerMessageFrame#13', metadata: {}, data: {'type': 'user-speaking'} at 4.00s
2026-01-15 10:31:08.650 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 683, name: 'RTVIServerMessageFrame#13', metadata: {}, data: {'type': 'user-speaking'} at 4.00s
2026-01-15 10:31:08.650 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 679, name: 'OutputAudioRawFrame#434', metadata: {} at 4.00s
2026-01-15 10:31:08.650 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 684, name: 'OutputTransportMessageUrgentFrame#20', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.00s
2026-01-15 10:31:08.651 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 683, name: 'RTVIServerMessageFrame#13', metadata: {}, data: {'type': 'user-speaking'} at 4.00s
2026-01-15 10:31:08.651 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 683, name: 'RTVIServerMessageFrame#13', metadata: {}, data: {'type': 'user-speaking'} at 4.00s
2026-01-15 10:31:08.651 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 679, name: 'OutputAudioRawFrame#434', metadata: {} at 4.00s
2026-01-15 10:31:08.651 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 684, name: 'OutputTransportMessageUrgentFrame#20', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.01s
2026-01-15 10:31:08.651 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 683, name: 'RTVIServerMessageFrame#13', metadata: {}, data: {'type': 'user-speaking'} at 4.01s
2026-01-15 10:31:08.651 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#13(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.651 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#434(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.651 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 683, name: 'RTVIServerMessageFrame#13', metadata: {}, data: {'type': 'user-speaking'} at 4.01s
2026-01-15 10:31:08.651 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 679, name: 'OutputAudioRawFrame#434', metadata: {} at 4.01s
2026-01-15 10:31:08.651 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 684, name: 'OutputTransportMessageUrgentFrame#20', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.01s
2026-01-15 10:31:08.651 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 683, name: 'RTVIServerMessageFrame#13', metadata: {}, data: {'type': 'user-speaking'} at 4.01s
2026-01-15 10:31:08.651 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#20(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.651 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#13(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.651 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 683, name: 'RTVIServerMessageFrame#13', metadata: {}, data: {'type': 'user-speaking'} at 4.01s
2026-01-15 10:31:08.651 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 683, name: 'RTVIServerMessageFrame#13', metadata: {}, data: {'type': 'user-speaking'} at 4.01s
2026-01-15 10:31:08.651 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 679, name: 'OutputAudioRawFrame#434', metadata: {} at 4.01s
2026-01-15 10:31:08.651 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 679, name: 'OutputAudioRawFrame#434', metadata: {} at 4.01s
2026-01-15 10:31:08.651 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 684, name: 'OutputTransportMessageUrgentFrame#20', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.01s
2026-01-15 10:31:08.651 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 683, name: 'RTVIServerMessageFrame#13', metadata: {}, data: {'type': 'user-speaking'} at 4.01s
2026-01-15 10:31:08.652 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 683, name: 'RTVIServerMessageFrame#13', metadata: {}, data: {'type': 'user-speaking'} at 4.01s
2026-01-15 10:31:08.652 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 683, name: 'RTVIServerMessageFrame#13', metadata: {}, data: {'type': 'user-speaking'} at 4.01s
2026-01-15 10:31:08.652 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#19(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.652 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 685, name: 'InputTransportMessageFrame#19', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.10s
2026-01-15 10:31:08.652 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#19(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.652 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#19(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.652 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:08.652 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:08.652 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 685, name: 'InputTransportMessageFrame#19', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.10s
2026-01-15 10:31:08.652 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 685, name: 'InputTransportMessageFrame#19', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.10s
2026-01-15 10:31:08.652 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 685, name: 'InputTransportMessageFrame#19', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.10s
2026-01-15 10:31:08.652 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 685, name: 'InputTransportMessageFrame#19', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.10s
2026-01-15 10:31:08.652 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 685, name: 'InputTransportMessageFrame#19', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.10s
2026-01-15 10:31:08.653 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 685, name: 'InputTransportMessageFrame#19', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.10s
2026-01-15 10:31:08.686 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 198, name: 'OutputAudioRawFrame#121', metadata: {} at 3.13s
2026-01-15 10:31:08.686 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 198, name: 'OutputAudioRawFrame#121', metadata: {} at 3.13s
2026-01-15 10:31:08.687 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 688, name: 'UserSpeakingFrame#28', metadata: {} at 4.04s
2026-01-15 10:31:08.687 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 689, name: 'UserSpeakingFrame#29', metadata: {} at 4.04s
2026-01-15 10:31:08.687 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 689, name: 'UserSpeakingFrame#29', metadata: {} at 4.04s
2026-01-15 10:31:08.687 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 686, name: 'OutputAudioRawFrame#435', metadata: {} at 4.04s
2026-01-15 10:31:08.687 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 688, name: 'UserSpeakingFrame#28', metadata: {} at 4.04s
2026-01-15 10:31:08.687 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 686, name: 'OutputAudioRawFrame#435', metadata: {} at 4.04s
2026-01-15 10:31:08.687 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#28
2026-01-15 10:31:08.687 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#435(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.688 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 690, name: 'RTVIServerMessageFrame#14', metadata: {}, data: {'type': 'user-speaking'} at 4.04s
2026-01-15 10:31:08.688 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 686, name: 'OutputAudioRawFrame#435', metadata: {} at 4.04s
2026-01-15 10:31:08.688 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 691, name: 'OutputTransportMessageUrgentFrame#21', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.04s
2026-01-15 10:31:08.688 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#21(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.688 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#14(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.688 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 690, name: 'RTVIServerMessageFrame#14', metadata: {}, data: {'type': 'user-speaking'} at 4.04s
2026-01-15 10:31:08.688 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 690, name: 'RTVIServerMessageFrame#14', metadata: {}, data: {'type': 'user-speaking'} at 4.04s
2026-01-15 10:31:08.688 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 686, name: 'OutputAudioRawFrame#435', metadata: {} at 4.04s
2026-01-15 10:31:08.688 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 691, name: 'OutputTransportMessageUrgentFrame#21', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.04s
2026-01-15 10:31:08.688 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 690, name: 'RTVIServerMessageFrame#14', metadata: {}, data: {'type': 'user-speaking'} at 4.04s
2026-01-15 10:31:08.688 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 690, name: 'RTVIServerMessageFrame#14', metadata: {}, data: {'type': 'user-speaking'} at 4.04s
2026-01-15 10:31:08.688 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 686, name: 'OutputAudioRawFrame#435', metadata: {} at 4.04s
2026-01-15 10:31:08.688 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 691, name: 'OutputTransportMessageUrgentFrame#21', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.04s
2026-01-15 10:31:08.688 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 690, name: 'RTVIServerMessageFrame#14', metadata: {}, data: {'type': 'user-speaking'} at 4.04s
2026-01-15 10:31:08.689 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#14(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.689 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#435(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.689 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 690, name: 'RTVIServerMessageFrame#14', metadata: {}, data: {'type': 'user-speaking'} at 4.04s
2026-01-15 10:31:08.689 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 686, name: 'OutputAudioRawFrame#435', metadata: {} at 4.04s
2026-01-15 10:31:08.689 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 691, name: 'OutputTransportMessageUrgentFrame#21', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.04s
2026-01-15 10:31:08.689 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 690, name: 'RTVIServerMessageFrame#14', metadata: {}, data: {'type': 'user-speaking'} at 4.04s
2026-01-15 10:31:08.689 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#21(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.689 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#14(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.689 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 690, name: 'RTVIServerMessageFrame#14', metadata: {}, data: {'type': 'user-speaking'} at 4.04s
2026-01-15 10:31:08.689 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 690, name: 'RTVIServerMessageFrame#14', metadata: {}, data: {'type': 'user-speaking'} at 4.04s
2026-01-15 10:31:08.689 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 686, name: 'OutputAudioRawFrame#435', metadata: {} at 4.04s
2026-01-15 10:31:08.689 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 686, name: 'OutputAudioRawFrame#435', metadata: {} at 4.04s
2026-01-15 10:31:08.689 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 691, name: 'OutputTransportMessageUrgentFrame#21', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.04s
2026-01-15 10:31:08.689 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 690, name: 'RTVIServerMessageFrame#14', metadata: {}, data: {'type': 'user-speaking'} at 4.04s
2026-01-15 10:31:08.689 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 690, name: 'RTVIServerMessageFrame#14', metadata: {}, data: {'type': 'user-speaking'} at 4.04s
2026-01-15 10:31:08.689 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 690, name: 'RTVIServerMessageFrame#14', metadata: {}, data: {'type': 'user-speaking'} at 4.04s
2026-01-15 10:31:08.689 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#20(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.689 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 692, name: 'InputTransportMessageFrame#20', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.13s
2026-01-15 10:31:08.689 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#20(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.689 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#20(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.689 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:08.689 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:08.690 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 692, name: 'InputTransportMessageFrame#20', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.13s
2026-01-15 10:31:08.690 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 692, name: 'InputTransportMessageFrame#20', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.13s
2026-01-15 10:31:08.690 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 692, name: 'InputTransportMessageFrame#20', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.13s
2026-01-15 10:31:08.690 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 692, name: 'InputTransportMessageFrame#20', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.13s
2026-01-15 10:31:08.690 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 692, name: 'InputTransportMessageFrame#20', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.13s
2026-01-15 10:31:08.690 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 692, name: 'InputTransportMessageFrame#20', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.13s
2026-01-15 10:31:08.727 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 200, name: 'OutputAudioRawFrame#123', metadata: {} at 3.17s
2026-01-15 10:31:08.727 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 200, name: 'OutputAudioRawFrame#123', metadata: {} at 3.17s
2026-01-15 10:31:08.728 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 695, name: 'UserSpeakingFrame#30', metadata: {} at 4.08s
2026-01-15 10:31:08.728 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 696, name: 'UserSpeakingFrame#31', metadata: {} at 4.08s
2026-01-15 10:31:08.728 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 696, name: 'UserSpeakingFrame#31', metadata: {} at 4.08s
2026-01-15 10:31:08.728 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 693, name: 'OutputAudioRawFrame#436', metadata: {} at 4.08s
2026-01-15 10:31:08.728 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 695, name: 'UserSpeakingFrame#30', metadata: {} at 4.08s
2026-01-15 10:31:08.728 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 693, name: 'OutputAudioRawFrame#436', metadata: {} at 4.08s
2026-01-15 10:31:08.728 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#30
2026-01-15 10:31:08.728 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#436(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.728 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 697, name: 'RTVIServerMessageFrame#15', metadata: {}, data: {'type': 'user-speaking'} at 4.08s
2026-01-15 10:31:08.728 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 693, name: 'OutputAudioRawFrame#436', metadata: {} at 4.08s
2026-01-15 10:31:08.728 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 698, name: 'OutputTransportMessageUrgentFrame#22', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.08s
2026-01-15 10:31:08.729 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#22(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.729 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#15(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.729 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 697, name: 'RTVIServerMessageFrame#15', metadata: {}, data: {'type': 'user-speaking'} at 4.08s
2026-01-15 10:31:08.729 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 697, name: 'RTVIServerMessageFrame#15', metadata: {}, data: {'type': 'user-speaking'} at 4.08s
2026-01-15 10:31:08.729 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 693, name: 'OutputAudioRawFrame#436', metadata: {} at 4.08s
2026-01-15 10:31:08.729 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 698, name: 'OutputTransportMessageUrgentFrame#22', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.08s
2026-01-15 10:31:08.729 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 697, name: 'RTVIServerMessageFrame#15', metadata: {}, data: {'type': 'user-speaking'} at 4.08s
2026-01-15 10:31:08.729 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 697, name: 'RTVIServerMessageFrame#15', metadata: {}, data: {'type': 'user-speaking'} at 4.08s
2026-01-15 10:31:08.729 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 693, name: 'OutputAudioRawFrame#436', metadata: {} at 4.08s
2026-01-15 10:31:08.729 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 698, name: 'OutputTransportMessageUrgentFrame#22', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.08s
2026-01-15 10:31:08.729 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 697, name: 'RTVIServerMessageFrame#15', metadata: {}, data: {'type': 'user-speaking'} at 4.08s
2026-01-15 10:31:08.729 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#15(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.729 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#436(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.729 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 697, name: 'RTVIServerMessageFrame#15', metadata: {}, data: {'type': 'user-speaking'} at 4.08s
2026-01-15 10:31:08.729 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 693, name: 'OutputAudioRawFrame#436', metadata: {} at 4.08s
2026-01-15 10:31:08.729 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 698, name: 'OutputTransportMessageUrgentFrame#22', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.08s
2026-01-15 10:31:08.730 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 697, name: 'RTVIServerMessageFrame#15', metadata: {}, data: {'type': 'user-speaking'} at 4.08s
2026-01-15 10:31:08.730 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#22(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.730 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#15(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.730 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 697, name: 'RTVIServerMessageFrame#15', metadata: {}, data: {'type': 'user-speaking'} at 4.08s
2026-01-15 10:31:08.730 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 697, name: 'RTVIServerMessageFrame#15', metadata: {}, data: {'type': 'user-speaking'} at 4.08s
2026-01-15 10:31:08.730 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 693, name: 'OutputAudioRawFrame#436', metadata: {} at 4.08s
2026-01-15 10:31:08.730 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 693, name: 'OutputAudioRawFrame#436', metadata: {} at 4.08s
2026-01-15 10:31:08.730 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 698, name: 'OutputTransportMessageUrgentFrame#22', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.08s
2026-01-15 10:31:08.730 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 697, name: 'RTVIServerMessageFrame#15', metadata: {}, data: {'type': 'user-speaking'} at 4.08s
2026-01-15 10:31:08.730 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 697, name: 'RTVIServerMessageFrame#15', metadata: {}, data: {'type': 'user-speaking'} at 4.08s
2026-01-15 10:31:08.730 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 697, name: 'RTVIServerMessageFrame#15', metadata: {}, data: {'type': 'user-speaking'} at 4.08s
2026-01-15 10:31:08.730 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#21(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.730 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 699, name: 'InputTransportMessageFrame#21', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.17s
2026-01-15 10:31:08.730 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#21(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.730 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#21(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.730 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:08.730 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:08.730 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 699, name: 'InputTransportMessageFrame#21', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.17s
2026-01-15 10:31:08.730 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 699, name: 'InputTransportMessageFrame#21', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.17s
2026-01-15 10:31:08.730 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 699, name: 'InputTransportMessageFrame#21', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.17s
2026-01-15 10:31:08.730 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 699, name: 'InputTransportMessageFrame#21', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.17s
2026-01-15 10:31:08.731 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 699, name: 'InputTransportMessageFrame#21', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.17s
2026-01-15 10:31:08.731 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 699, name: 'InputTransportMessageFrame#21', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.17s
2026-01-15 10:31:08.766 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 202, name: 'OutputAudioRawFrame#125', metadata: {} at 3.21s
2026-01-15 10:31:08.766 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 202, name: 'OutputAudioRawFrame#125', metadata: {} at 3.21s
2026-01-15 10:31:08.767 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 702, name: 'UserSpeakingFrame#32', metadata: {} at 4.12s
2026-01-15 10:31:08.767 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 703, name: 'UserSpeakingFrame#33', metadata: {} at 4.12s
2026-01-15 10:31:08.767 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 703, name: 'UserSpeakingFrame#33', metadata: {} at 4.12s
2026-01-15 10:31:08.767 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 700, name: 'OutputAudioRawFrame#437', metadata: {} at 4.12s
2026-01-15 10:31:08.767 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 702, name: 'UserSpeakingFrame#32', metadata: {} at 4.12s
2026-01-15 10:31:08.767 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 700, name: 'OutputAudioRawFrame#437', metadata: {} at 4.12s
2026-01-15 10:31:08.767 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#32
2026-01-15 10:31:08.767 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#437(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.768 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 704, name: 'RTVIServerMessageFrame#16', metadata: {}, data: {'type': 'user-speaking'} at 4.12s
2026-01-15 10:31:08.768 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 700, name: 'OutputAudioRawFrame#437', metadata: {} at 4.12s
2026-01-15 10:31:08.768 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 705, name: 'OutputTransportMessageUrgentFrame#23', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.12s
2026-01-15 10:31:08.768 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#23(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.768 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#16(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.768 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 704, name: 'RTVIServerMessageFrame#16', metadata: {}, data: {'type': 'user-speaking'} at 4.12s
2026-01-15 10:31:08.768 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 704, name: 'RTVIServerMessageFrame#16', metadata: {}, data: {'type': 'user-speaking'} at 4.12s
2026-01-15 10:31:08.768 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 700, name: 'OutputAudioRawFrame#437', metadata: {} at 4.12s
2026-01-15 10:31:08.768 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 705, name: 'OutputTransportMessageUrgentFrame#23', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.12s
2026-01-15 10:31:08.768 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 704, name: 'RTVIServerMessageFrame#16', metadata: {}, data: {'type': 'user-speaking'} at 4.12s
2026-01-15 10:31:08.769 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 704, name: 'RTVIServerMessageFrame#16', metadata: {}, data: {'type': 'user-speaking'} at 4.12s
2026-01-15 10:31:08.769 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 700, name: 'OutputAudioRawFrame#437', metadata: {} at 4.12s
2026-01-15 10:31:08.769 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 705, name: 'OutputTransportMessageUrgentFrame#23', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.12s
2026-01-15 10:31:08.769 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 704, name: 'RTVIServerMessageFrame#16', metadata: {}, data: {'type': 'user-speaking'} at 4.12s
2026-01-15 10:31:08.769 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#16(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.769 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#437(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.769 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 704, name: 'RTVIServerMessageFrame#16', metadata: {}, data: {'type': 'user-speaking'} at 4.12s
2026-01-15 10:31:08.769 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 700, name: 'OutputAudioRawFrame#437', metadata: {} at 4.12s
2026-01-15 10:31:08.769 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 705, name: 'OutputTransportMessageUrgentFrame#23', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.12s
2026-01-15 10:31:08.769 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 704, name: 'RTVIServerMessageFrame#16', metadata: {}, data: {'type': 'user-speaking'} at 4.12s
2026-01-15 10:31:08.769 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#23(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.769 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#16(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.769 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 704, name: 'RTVIServerMessageFrame#16', metadata: {}, data: {'type': 'user-speaking'} at 4.12s
2026-01-15 10:31:08.769 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 704, name: 'RTVIServerMessageFrame#16', metadata: {}, data: {'type': 'user-speaking'} at 4.12s
2026-01-15 10:31:08.769 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 700, name: 'OutputAudioRawFrame#437', metadata: {} at 4.12s
2026-01-15 10:31:08.769 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 700, name: 'OutputAudioRawFrame#437', metadata: {} at 4.12s
2026-01-15 10:31:08.769 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 705, name: 'OutputTransportMessageUrgentFrame#23', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.12s
2026-01-15 10:31:08.769 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 704, name: 'RTVIServerMessageFrame#16', metadata: {}, data: {'type': 'user-speaking'} at 4.12s
2026-01-15 10:31:08.770 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 704, name: 'RTVIServerMessageFrame#16', metadata: {}, data: {'type': 'user-speaking'} at 4.12s
2026-01-15 10:31:08.770 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 704, name: 'RTVIServerMessageFrame#16', metadata: {}, data: {'type': 'user-speaking'} at 4.12s
2026-01-15 10:31:08.770 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#22(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.770 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 706, name: 'InputTransportMessageFrame#22', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.21s
2026-01-15 10:31:08.770 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#22(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.770 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#22(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.770 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:08.770 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:08.770 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 706, name: 'InputTransportMessageFrame#22', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.21s
2026-01-15 10:31:08.770 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 706, name: 'InputTransportMessageFrame#22', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.21s
2026-01-15 10:31:08.770 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 706, name: 'InputTransportMessageFrame#22', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.21s
2026-01-15 10:31:08.770 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 706, name: 'InputTransportMessageFrame#22', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.21s
2026-01-15 10:31:08.770 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 706, name: 'InputTransportMessageFrame#22', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.21s
2026-01-15 10:31:08.770 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 706, name: 'InputTransportMessageFrame#22', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.21s
2026-01-15 10:31:08.807 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 203, name: 'OutputAudioRawFrame#126', metadata: {} at 3.25s
2026-01-15 10:31:08.807 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 203, name: 'OutputAudioRawFrame#126', metadata: {} at 3.25s
2026-01-15 10:31:08.808 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 709, name: 'UserSpeakingFrame#34', metadata: {} at 4.16s
2026-01-15 10:31:08.808 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 710, name: 'UserSpeakingFrame#35', metadata: {} at 4.16s
2026-01-15 10:31:08.808 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 710, name: 'UserSpeakingFrame#35', metadata: {} at 4.16s
2026-01-15 10:31:08.808 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 707, name: 'OutputAudioRawFrame#438', metadata: {} at 4.16s
2026-01-15 10:31:08.808 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 709, name: 'UserSpeakingFrame#34', metadata: {} at 4.16s
2026-01-15 10:31:08.809 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 707, name: 'OutputAudioRawFrame#438', metadata: {} at 4.16s
2026-01-15 10:31:08.809 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#34
2026-01-15 10:31:08.809 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#438(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.809 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 711, name: 'RTVIServerMessageFrame#17', metadata: {}, data: {'type': 'user-speaking'} at 4.16s
2026-01-15 10:31:08.809 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 707, name: 'OutputAudioRawFrame#438', metadata: {} at 4.16s
2026-01-15 10:31:08.809 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 712, name: 'OutputTransportMessageUrgentFrame#24', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.16s
2026-01-15 10:31:08.809 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#24(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.809 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#17(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.809 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 711, name: 'RTVIServerMessageFrame#17', metadata: {}, data: {'type': 'user-speaking'} at 4.16s
2026-01-15 10:31:08.810 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 711, name: 'RTVIServerMessageFrame#17', metadata: {}, data: {'type': 'user-speaking'} at 4.16s
2026-01-15 10:31:08.810 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 707, name: 'OutputAudioRawFrame#438', metadata: {} at 4.16s
2026-01-15 10:31:08.810 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 712, name: 'OutputTransportMessageUrgentFrame#24', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.16s
2026-01-15 10:31:08.810 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 711, name: 'RTVIServerMessageFrame#17', metadata: {}, data: {'type': 'user-speaking'} at 4.16s
2026-01-15 10:31:08.810 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 711, name: 'RTVIServerMessageFrame#17', metadata: {}, data: {'type': 'user-speaking'} at 4.16s
2026-01-15 10:31:08.810 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 707, name: 'OutputAudioRawFrame#438', metadata: {} at 4.16s
2026-01-15 10:31:08.810 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 712, name: 'OutputTransportMessageUrgentFrame#24', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.16s
2026-01-15 10:31:08.810 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 711, name: 'RTVIServerMessageFrame#17', metadata: {}, data: {'type': 'user-speaking'} at 4.16s
2026-01-15 10:31:08.810 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#17(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.810 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#438(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.810 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 711, name: 'RTVIServerMessageFrame#17', metadata: {}, data: {'type': 'user-speaking'} at 4.16s
2026-01-15 10:31:08.810 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 707, name: 'OutputAudioRawFrame#438', metadata: {} at 4.16s
2026-01-15 10:31:08.810 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 712, name: 'OutputTransportMessageUrgentFrame#24', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.16s
2026-01-15 10:31:08.810 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 711, name: 'RTVIServerMessageFrame#17', metadata: {}, data: {'type': 'user-speaking'} at 4.16s
2026-01-15 10:31:08.810 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#24(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.810 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#17(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.810 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 711, name: 'RTVIServerMessageFrame#17', metadata: {}, data: {'type': 'user-speaking'} at 4.16s
2026-01-15 10:31:08.810 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 711, name: 'RTVIServerMessageFrame#17', metadata: {}, data: {'type': 'user-speaking'} at 4.16s
2026-01-15 10:31:08.810 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 707, name: 'OutputAudioRawFrame#438', metadata: {} at 4.16s
2026-01-15 10:31:08.810 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 707, name: 'OutputAudioRawFrame#438', metadata: {} at 4.16s
2026-01-15 10:31:08.811 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 712, name: 'OutputTransportMessageUrgentFrame#24', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.16s
2026-01-15 10:31:08.811 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 711, name: 'RTVIServerMessageFrame#17', metadata: {}, data: {'type': 'user-speaking'} at 4.16s
2026-01-15 10:31:08.811 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 711, name: 'RTVIServerMessageFrame#17', metadata: {}, data: {'type': 'user-speaking'} at 4.17s
2026-01-15 10:31:08.811 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 711, name: 'RTVIServerMessageFrame#17', metadata: {}, data: {'type': 'user-speaking'} at 4.17s
2026-01-15 10:31:08.811 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#23(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.811 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 713, name: 'InputTransportMessageFrame#23', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.25s
2026-01-15 10:31:08.811 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#23(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.811 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#23(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.811 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:08.811 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:08.811 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 713, name: 'InputTransportMessageFrame#23', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.25s
2026-01-15 10:31:08.811 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 713, name: 'InputTransportMessageFrame#23', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.25s
2026-01-15 10:31:08.811 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 713, name: 'InputTransportMessageFrame#23', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.25s
2026-01-15 10:31:08.811 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 713, name: 'InputTransportMessageFrame#23', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.26s
2026-01-15 10:31:08.811 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 713, name: 'InputTransportMessageFrame#23', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.26s
2026-01-15 10:31:08.811 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 713, name: 'InputTransportMessageFrame#23', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.26s
2026-01-15 10:31:08.847 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 205, name: 'OutputAudioRawFrame#128', metadata: {} at 3.29s
2026-01-15 10:31:08.847 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 205, name: 'OutputAudioRawFrame#128', metadata: {} at 3.29s
2026-01-15 10:31:08.851 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 716, name: 'UserSpeakingFrame#36', metadata: {} at 4.21s
2026-01-15 10:31:08.852 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 717, name: 'UserSpeakingFrame#37', metadata: {} at 4.21s
2026-01-15 10:31:08.852 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 717, name: 'UserSpeakingFrame#37', metadata: {} at 4.21s
2026-01-15 10:31:08.852 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 714, name: 'OutputAudioRawFrame#439', metadata: {} at 4.21s
2026-01-15 10:31:08.852 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 716, name: 'UserSpeakingFrame#36', metadata: {} at 4.21s
2026-01-15 10:31:08.852 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 714, name: 'OutputAudioRawFrame#439', metadata: {} at 4.21s
2026-01-15 10:31:08.852 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#36
2026-01-15 10:31:08.852 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#439(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.852 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 718, name: 'RTVIServerMessageFrame#18', metadata: {}, data: {'type': 'user-speaking'} at 4.21s
2026-01-15 10:31:08.852 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 714, name: 'OutputAudioRawFrame#439', metadata: {} at 4.21s
2026-01-15 10:31:08.852 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 719, name: 'OutputTransportMessageUrgentFrame#25', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.21s
2026-01-15 10:31:08.853 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#25(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.853 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#18(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.853 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 718, name: 'RTVIServerMessageFrame#18', metadata: {}, data: {'type': 'user-speaking'} at 4.21s
2026-01-15 10:31:08.853 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 718, name: 'RTVIServerMessageFrame#18', metadata: {}, data: {'type': 'user-speaking'} at 4.21s
2026-01-15 10:31:08.853 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 714, name: 'OutputAudioRawFrame#439', metadata: {} at 4.21s
2026-01-15 10:31:08.853 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 719, name: 'OutputTransportMessageUrgentFrame#25', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.21s
2026-01-15 10:31:08.853 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 718, name: 'RTVIServerMessageFrame#18', metadata: {}, data: {'type': 'user-speaking'} at 4.21s
2026-01-15 10:31:08.854 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 718, name: 'RTVIServerMessageFrame#18', metadata: {}, data: {'type': 'user-speaking'} at 4.21s
2026-01-15 10:31:08.854 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 714, name: 'OutputAudioRawFrame#439', metadata: {} at 4.21s
2026-01-15 10:31:08.854 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 719, name: 'OutputTransportMessageUrgentFrame#25', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.21s
2026-01-15 10:31:08.854 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 718, name: 'RTVIServerMessageFrame#18', metadata: {}, data: {'type': 'user-speaking'} at 4.21s
2026-01-15 10:31:08.854 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#18(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.854 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#439(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.854 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 718, name: 'RTVIServerMessageFrame#18', metadata: {}, data: {'type': 'user-speaking'} at 4.21s
2026-01-15 10:31:08.854 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 714, name: 'OutputAudioRawFrame#439', metadata: {} at 4.21s
2026-01-15 10:31:08.854 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 719, name: 'OutputTransportMessageUrgentFrame#25', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.21s
2026-01-15 10:31:08.854 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 718, name: 'RTVIServerMessageFrame#18', metadata: {}, data: {'type': 'user-speaking'} at 4.21s
2026-01-15 10:31:08.854 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#25(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.854 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#18(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.854 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 718, name: 'RTVIServerMessageFrame#18', metadata: {}, data: {'type': 'user-speaking'} at 4.21s
2026-01-15 10:31:08.854 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 718, name: 'RTVIServerMessageFrame#18', metadata: {}, data: {'type': 'user-speaking'} at 4.21s
2026-01-15 10:31:08.854 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 714, name: 'OutputAudioRawFrame#439', metadata: {} at 4.21s
2026-01-15 10:31:08.854 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 714, name: 'OutputAudioRawFrame#439', metadata: {} at 4.21s
2026-01-15 10:31:08.854 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 719, name: 'OutputTransportMessageUrgentFrame#25', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.21s
2026-01-15 10:31:08.855 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 718, name: 'RTVIServerMessageFrame#18', metadata: {}, data: {'type': 'user-speaking'} at 4.21s
2026-01-15 10:31:08.855 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 718, name: 'RTVIServerMessageFrame#18', metadata: {}, data: {'type': 'user-speaking'} at 4.21s
2026-01-15 10:31:08.855 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 718, name: 'RTVIServerMessageFrame#18', metadata: {}, data: {'type': 'user-speaking'} at 4.21s
2026-01-15 10:31:08.855 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#24(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.855 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 720, name: 'InputTransportMessageFrame#24', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.30s
2026-01-15 10:31:08.855 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#24(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.855 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#24(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.855 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:08.855 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:08.855 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 720, name: 'InputTransportMessageFrame#24', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.30s
2026-01-15 10:31:08.855 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 720, name: 'InputTransportMessageFrame#24', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.30s
2026-01-15 10:31:08.855 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 720, name: 'InputTransportMessageFrame#24', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.30s
2026-01-15 10:31:08.855 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 720, name: 'InputTransportMessageFrame#24', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.30s
2026-01-15 10:31:08.856 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 720, name: 'InputTransportMessageFrame#24', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.30s
2026-01-15 10:31:08.856 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 720, name: 'InputTransportMessageFrame#24', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.30s
2026-01-15 10:31:08.887 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 206, name: 'OutputAudioRawFrame#129', metadata: {} at 3.33s
2026-01-15 10:31:08.887 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 206, name: 'OutputAudioRawFrame#129', metadata: {} at 3.33s
2026-01-15 10:31:08.890 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 723, name: 'UserSpeakingFrame#38', metadata: {} at 4.24s
2026-01-15 10:31:08.890 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 724, name: 'UserSpeakingFrame#39', metadata: {} at 4.24s
2026-01-15 10:31:08.890 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 724, name: 'UserSpeakingFrame#39', metadata: {} at 4.24s
2026-01-15 10:31:08.890 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 721, name: 'OutputAudioRawFrame#440', metadata: {} at 4.24s
2026-01-15 10:31:08.891 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 723, name: 'UserSpeakingFrame#38', metadata: {} at 4.24s
2026-01-15 10:31:08.891 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 721, name: 'OutputAudioRawFrame#440', metadata: {} at 4.24s
2026-01-15 10:31:08.891 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#38
2026-01-15 10:31:08.891 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#440(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.891 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 725, name: 'RTVIServerMessageFrame#19', metadata: {}, data: {'type': 'user-speaking'} at 4.25s
2026-01-15 10:31:08.891 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 721, name: 'OutputAudioRawFrame#440', metadata: {} at 4.25s
2026-01-15 10:31:08.891 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 726, name: 'OutputTransportMessageUrgentFrame#26', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.25s
2026-01-15 10:31:08.892 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#26(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.892 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#19(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.892 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 725, name: 'RTVIServerMessageFrame#19', metadata: {}, data: {'type': 'user-speaking'} at 4.25s
2026-01-15 10:31:08.892 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 725, name: 'RTVIServerMessageFrame#19', metadata: {}, data: {'type': 'user-speaking'} at 4.25s
2026-01-15 10:31:08.892 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 721, name: 'OutputAudioRawFrame#440', metadata: {} at 4.25s
2026-01-15 10:31:08.892 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 726, name: 'OutputTransportMessageUrgentFrame#26', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.25s
2026-01-15 10:31:08.892 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 725, name: 'RTVIServerMessageFrame#19', metadata: {}, data: {'type': 'user-speaking'} at 4.25s
2026-01-15 10:31:08.892 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 725, name: 'RTVIServerMessageFrame#19', metadata: {}, data: {'type': 'user-speaking'} at 4.25s
2026-01-15 10:31:08.893 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 721, name: 'OutputAudioRawFrame#440', metadata: {} at 4.25s
2026-01-15 10:31:08.893 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 726, name: 'OutputTransportMessageUrgentFrame#26', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.25s
2026-01-15 10:31:08.893 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 725, name: 'RTVIServerMessageFrame#19', metadata: {}, data: {'type': 'user-speaking'} at 4.25s
2026-01-15 10:31:08.893 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#19(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.893 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#440(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.893 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 725, name: 'RTVIServerMessageFrame#19', metadata: {}, data: {'type': 'user-speaking'} at 4.25s
2026-01-15 10:31:08.893 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 721, name: 'OutputAudioRawFrame#440', metadata: {} at 4.25s
2026-01-15 10:31:08.893 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 726, name: 'OutputTransportMessageUrgentFrame#26', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.25s
2026-01-15 10:31:08.893 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 725, name: 'RTVIServerMessageFrame#19', metadata: {}, data: {'type': 'user-speaking'} at 4.25s
2026-01-15 10:31:08.893 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#26(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.893 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#19(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.893 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 725, name: 'RTVIServerMessageFrame#19', metadata: {}, data: {'type': 'user-speaking'} at 4.25s
2026-01-15 10:31:08.893 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 725, name: 'RTVIServerMessageFrame#19', metadata: {}, data: {'type': 'user-speaking'} at 4.25s
2026-01-15 10:31:08.893 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 721, name: 'OutputAudioRawFrame#440', metadata: {} at 4.25s
2026-01-15 10:31:08.893 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 721, name: 'OutputAudioRawFrame#440', metadata: {} at 4.25s
2026-01-15 10:31:08.893 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 726, name: 'OutputTransportMessageUrgentFrame#26', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.25s
2026-01-15 10:31:08.893 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 725, name: 'RTVIServerMessageFrame#19', metadata: {}, data: {'type': 'user-speaking'} at 4.25s
2026-01-15 10:31:08.894 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 725, name: 'RTVIServerMessageFrame#19', metadata: {}, data: {'type': 'user-speaking'} at 4.25s
2026-01-15 10:31:08.894 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 725, name: 'RTVIServerMessageFrame#19', metadata: {}, data: {'type': 'user-speaking'} at 4.25s
2026-01-15 10:31:08.894 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#25(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.894 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 727, name: 'InputTransportMessageFrame#25', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.34s
2026-01-15 10:31:08.894 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#25(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.894 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#25(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.894 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:08.894 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:08.894 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 727, name: 'InputTransportMessageFrame#25', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.34s
2026-01-15 10:31:08.894 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 727, name: 'InputTransportMessageFrame#25', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.34s
2026-01-15 10:31:08.894 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 727, name: 'InputTransportMessageFrame#25', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.34s
2026-01-15 10:31:08.894 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 727, name: 'InputTransportMessageFrame#25', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.34s
2026-01-15 10:31:08.894 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 727, name: 'InputTransportMessageFrame#25', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.34s
2026-01-15 10:31:08.894 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 727, name: 'InputTransportMessageFrame#25', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.34s
2026-01-15 10:31:08.927 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 208, name: 'OutputAudioRawFrame#131', metadata: {} at 3.37s
2026-01-15 10:31:08.927 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 208, name: 'OutputAudioRawFrame#131', metadata: {} at 3.37s
2026-01-15 10:31:08.930 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 730, name: 'UserSpeakingFrame#40', metadata: {} at 4.28s
2026-01-15 10:31:08.930 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 731, name: 'UserSpeakingFrame#41', metadata: {} at 4.28s
2026-01-15 10:31:08.930 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 731, name: 'UserSpeakingFrame#41', metadata: {} at 4.28s
2026-01-15 10:31:08.930 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 728, name: 'OutputAudioRawFrame#441', metadata: {} at 4.28s
2026-01-15 10:31:08.931 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 730, name: 'UserSpeakingFrame#40', metadata: {} at 4.29s
2026-01-15 10:31:08.931 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 728, name: 'OutputAudioRawFrame#441', metadata: {} at 4.29s
2026-01-15 10:31:08.931 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#40
2026-01-15 10:31:08.931 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#441(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.931 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 732, name: 'RTVIServerMessageFrame#20', metadata: {}, data: {'type': 'user-speaking'} at 4.29s
2026-01-15 10:31:08.932 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 728, name: 'OutputAudioRawFrame#441', metadata: {} at 4.29s
2026-01-15 10:31:08.932 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 733, name: 'OutputTransportMessageUrgentFrame#27', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.29s
2026-01-15 10:31:08.933 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#27(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.933 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#20(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.933 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 732, name: 'RTVIServerMessageFrame#20', metadata: {}, data: {'type': 'user-speaking'} at 4.29s
2026-01-15 10:31:08.933 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 732, name: 'RTVIServerMessageFrame#20', metadata: {}, data: {'type': 'user-speaking'} at 4.29s
2026-01-15 10:31:08.933 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 728, name: 'OutputAudioRawFrame#441', metadata: {} at 4.29s
2026-01-15 10:31:08.934 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 733, name: 'OutputTransportMessageUrgentFrame#27', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.29s
2026-01-15 10:31:08.934 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 732, name: 'RTVIServerMessageFrame#20', metadata: {}, data: {'type': 'user-speaking'} at 4.29s
2026-01-15 10:31:08.934 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 732, name: 'RTVIServerMessageFrame#20', metadata: {}, data: {'type': 'user-speaking'} at 4.29s
2026-01-15 10:31:08.934 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 728, name: 'OutputAudioRawFrame#441', metadata: {} at 4.29s
2026-01-15 10:31:08.934 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 733, name: 'OutputTransportMessageUrgentFrame#27', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.29s
2026-01-15 10:31:08.934 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 732, name: 'RTVIServerMessageFrame#20', metadata: {}, data: {'type': 'user-speaking'} at 4.29s
2026-01-15 10:31:08.934 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#20(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.934 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#441(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:08.935 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 732, name: 'RTVIServerMessageFrame#20', metadata: {}, data: {'type': 'user-speaking'} at 4.29s
2026-01-15 10:31:08.935 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 728, name: 'OutputAudioRawFrame#441', metadata: {} at 4.29s
2026-01-15 10:31:08.935 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 733, name: 'OutputTransportMessageUrgentFrame#27', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.29s
2026-01-15 10:31:08.935 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 732, name: 'RTVIServerMessageFrame#20', metadata: {}, data: {'type': 'user-speaking'} at 4.29s
2026-01-15 10:31:08.935 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#27(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.935 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#20(data: {'type': 'user-speaking'})
2026-01-15 10:31:08.935 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 732, name: 'RTVIServerMessageFrame#20', metadata: {}, data: {'type': 'user-speaking'} at 4.29s
2026-01-15 10:31:08.936 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 732, name: 'RTVIServerMessageFrame#20', metadata: {}, data: {'type': 'user-speaking'} at 4.29s
2026-01-15 10:31:08.936 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 728, name: 'OutputAudioRawFrame#441', metadata: {} at 4.29s
2026-01-15 10:31:08.936 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 728, name: 'OutputAudioRawFrame#441', metadata: {} at 4.29s
2026-01-15 10:31:08.936 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 733, name: 'OutputTransportMessageUrgentFrame#27', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.29s
2026-01-15 10:31:08.936 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 732, name: 'RTVIServerMessageFrame#20', metadata: {}, data: {'type': 'user-speaking'} at 4.29s
2026-01-15 10:31:08.936 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 732, name: 'RTVIServerMessageFrame#20', metadata: {}, data: {'type': 'user-speaking'} at 4.29s
2026-01-15 10:31:08.936 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 732, name: 'RTVIServerMessageFrame#20', metadata: {}, data: {'type': 'user-speaking'} at 4.29s
2026-01-15 10:31:08.936 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#26(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.936 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 734, name: 'InputTransportMessageFrame#26', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.38s
2026-01-15 10:31:08.936 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#26(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.936 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#26(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:08.936 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:08.936 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:08.936 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 734, name: 'InputTransportMessageFrame#26', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.38s
2026-01-15 10:31:08.936 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 734, name: 'InputTransportMessageFrame#26', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.38s
2026-01-15 10:31:08.937 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 734, name: 'InputTransportMessageFrame#26', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.38s
2026-01-15 10:31:08.937 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 734, name: 'InputTransportMessageFrame#26', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.38s
2026-01-15 10:31:08.937 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 734, name: 'InputTransportMessageFrame#26', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.38s
2026-01-15 10:31:08.937 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 734, name: 'InputTransportMessageFrame#26', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.38s
2026-01-15 10:31:08.967 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 209, name: 'OutputAudioRawFrame#132', metadata: {} at 3.41s
2026-01-15 10:31:08.967 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 209, name: 'OutputAudioRawFrame#132', metadata: {} at 3.41s
2026-01-15 10:31:08.970 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: VADUserStoppedSpeakingFrame id: 737, name: 'VADUserStoppedSpeakingFrame#1', metadata: {} at 4.32s
2026-01-15 10:31:08.970 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: VADUserStoppedSpeakingFrame id: 737, name: 'VADUserStoppedSpeakingFrame#1', metadata: {} at 4.32s
2026-01-15 10:31:08.970 | INFO     | [BOT-SYS] | input bot frame: VADUserStoppedSpeakingFrame#1
2026-01-15 10:31:08.971 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: VADUserStoppedSpeakingFrame id: 737, name: 'VADUserStoppedSpeakingFrame#1', metadata: {} at 4.32s
2026-01-15 10:31:08.971 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: VADUserStoppedSpeakingFrame id: 737, name: 'VADUserStoppedSpeakingFrame#1', metadata: {} at 4.33s
2026-01-15 10:31:08.971 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: VADUserStoppedSpeakingFrame id: 737, name: 'VADUserStoppedSpeakingFrame#1', metadata: {} at 4.33s
2026-01-15 10:31:08.971 | INFO     | [BOT-SYS] | output bot frame: VADUserStoppedSpeakingFrame#1
2026-01-15 10:31:08.972 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: VADUserStoppedSpeakingFrame id: 737, name: 'VADUserStoppedSpeakingFrame#1', metadata: {} at 4.33s
2026-01-15 10:31:08.972 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: VADUserStoppedSpeakingFrame id: 737, name: 'VADUserStoppedSpeakingFrame#1', metadata: {} at 4.33s
2026-01-15 10:31:08.972 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: VADUserStoppedSpeakingFrame id: 737, name: 'VADUserStoppedSpeakingFrame#1', metadata: {} at 4.33s
2026-01-15 10:31:09.007 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 210, name: 'OutputAudioRawFrame#133', metadata: {} at 3.45s
2026-01-15 10:31:09.007 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 210, name: 'OutputAudioRawFrame#133', metadata: {} at 3.45s
2026-01-15 10:31:09.030 | DEBUG    | [BOT-SYS] | End of Turn result: EndOfTurnState.INCOMPLETE
2026-01-15 10:31:09.030 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: MetricsFrame id: 740, name: 'MetricsFrame#4', metadata: {}, data: [SmartTurnMetricsData(processor='BaseSmartTurn', model=None, is_complete=False, probability=0.012496739625930786, inference_time_ms=0.0, server_total_time_ms=0.0, e2e_processing_time_ms=60.05395800457336)] at 4.38s
2026-01-15 10:31:09.030 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 735, name: 'OutputAudioRawFrame#442', metadata: {} at 4.38s
2026-01-15 10:31:09.030 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 741, name: 'OutputTransportMessageUrgentFrame#28', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 4.38s
2026-01-15 10:31:09.030 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#28(message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}})
2026-01-15 10:31:09.030 | INFO     | [BOT-SYS] | input bot frame: MetricsFrame#4
2026-01-15 10:31:09.030 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#442(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.031 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: MetricsFrame id: 740, name: 'MetricsFrame#4', metadata: {}, data: [SmartTurnMetricsData(processor='BaseSmartTurn', model=None, is_complete=False, probability=0.012496739625930786, inference_time_ms=0.0, server_total_time_ms=0.0, e2e_processing_time_ms=60.05395800457336)] at 4.38s
2026-01-15 10:31:09.031 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 735, name: 'OutputAudioRawFrame#442', metadata: {} at 4.38s
2026-01-15 10:31:09.031 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 741, name: 'OutputTransportMessageUrgentFrame#28', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 4.38s
2026-01-15 10:31:09.031 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: MetricsFrame id: 740, name: 'MetricsFrame#4', metadata: {}, data: [SmartTurnMetricsData(processor='BaseSmartTurn', model=None, is_complete=False, probability=0.012496739625930786, inference_time_ms=0.0, server_total_time_ms=0.0, e2e_processing_time_ms=60.05395800457336)] at 4.38s
2026-01-15 10:31:09.031 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 735, name: 'OutputAudioRawFrame#442', metadata: {} at 4.38s
2026-01-15 10:31:09.031 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 741, name: 'OutputTransportMessageUrgentFrame#28', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 4.39s
2026-01-15 10:31:09.031 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: MetricsFrame id: 740, name: 'MetricsFrame#4', metadata: {}, data: [SmartTurnMetricsData(processor='BaseSmartTurn', model=None, is_complete=False, probability=0.012496739625930786, inference_time_ms=0.0, server_total_time_ms=0.0, e2e_processing_time_ms=60.05395800457336)] at 4.39s
2026-01-15 10:31:09.031 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 735, name: 'OutputAudioRawFrame#442', metadata: {} at 4.39s
2026-01-15 10:31:09.031 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 741, name: 'OutputTransportMessageUrgentFrame#28', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 4.39s
2026-01-15 10:31:09.031 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: MetricsFrame id: 740, name: 'MetricsFrame#4', metadata: {}, data: [SmartTurnMetricsData(processor='BaseSmartTurn', model=None, is_complete=False, probability=0.012496739625930786, inference_time_ms=0.0, server_total_time_ms=0.0, e2e_processing_time_ms=60.05395800457336)] at 4.39s
2026-01-15 10:31:09.031 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 735, name: 'OutputAudioRawFrame#442', metadata: {} at 4.39s
2026-01-15 10:31:09.031 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#28(message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}})
2026-01-15 10:31:09.031 | INFO     | [BOT-SYS] | output bot frame: MetricsFrame#4
2026-01-15 10:31:09.031 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#442(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.032 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 741, name: 'OutputTransportMessageUrgentFrame#28', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 4.39s
2026-01-15 10:31:09.032 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: MetricsFrame id: 740, name: 'MetricsFrame#4', metadata: {}, data: [SmartTurnMetricsData(processor='BaseSmartTurn', model=None, is_complete=False, probability=0.012496739625930786, inference_time_ms=0.0, server_total_time_ms=0.0, e2e_processing_time_ms=60.05395800457336)] at 4.39s
2026-01-15 10:31:09.032 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 735, name: 'OutputAudioRawFrame#442', metadata: {} at 4.39s
2026-01-15 10:31:09.032 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: MetricsFrame id: 740, name: 'MetricsFrame#4', metadata: {}, data: [SmartTurnMetricsData(processor='BaseSmartTurn', model=None, is_complete=False, probability=0.012496739625930786, inference_time_ms=0.0, server_total_time_ms=0.0, e2e_processing_time_ms=60.05395800457336)] at 4.39s
2026-01-15 10:31:09.032 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: MetricsFrame id: 740, name: 'MetricsFrame#4', metadata: {}, data: [SmartTurnMetricsData(processor='BaseSmartTurn', model=None, is_complete=False, probability=0.012496739625930786, inference_time_ms=0.0, server_total_time_ms=0.0, e2e_processing_time_ms=60.05395800457336)] at 4.39s
2026-01-15 10:31:09.032 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 735, name: 'OutputAudioRawFrame#442', metadata: {} at 4.39s
2026-01-15 10:31:09.032 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 735, name: 'OutputAudioRawFrame#442', metadata: {} at 4.39s
2026-01-15 10:31:09.032 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#27(message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}})
2026-01-15 10:31:09.032 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 742, name: 'InputTransportMessageFrame#27', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 3.48s
2026-01-15 10:31:09.032 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#27(message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}})
2026-01-15 10:31:09.032 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#27(message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}})
2026-01-15 10:31:09.032 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:09.032 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:09.032 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 738, name: 'OutputAudioRawFrame#443', metadata: {} at 4.39s
2026-01-15 10:31:09.032 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 742, name: 'InputTransportMessageFrame#27', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 3.48s
2026-01-15 10:31:09.032 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 742, name: 'InputTransportMessageFrame#27', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 3.48s
2026-01-15 10:31:09.032 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 742, name: 'InputTransportMessageFrame#27', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 3.48s
2026-01-15 10:31:09.032 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 742, name: 'InputTransportMessageFrame#27', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 3.48s
2026-01-15 10:31:09.033 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 738, name: 'OutputAudioRawFrame#443', metadata: {} at 4.39s
2026-01-15 10:31:09.033 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#443(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.033 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 742, name: 'InputTransportMessageFrame#27', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 3.48s
2026-01-15 10:31:09.033 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 742, name: 'InputTransportMessageFrame#27', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 3.48s
2026-01-15 10:31:09.033 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 738, name: 'OutputAudioRawFrame#443', metadata: {} at 4.39s
2026-01-15 10:31:09.033 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 738, name: 'OutputAudioRawFrame#443', metadata: {} at 4.39s
2026-01-15 10:31:09.033 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 738, name: 'OutputAudioRawFrame#443', metadata: {} at 4.39s
2026-01-15 10:31:09.033 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#443(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.033 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 738, name: 'OutputAudioRawFrame#443', metadata: {} at 4.39s
2026-01-15 10:31:09.033 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 738, name: 'OutputAudioRawFrame#443', metadata: {} at 4.39s
2026-01-15 10:31:09.033 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 738, name: 'OutputAudioRawFrame#443', metadata: {} at 4.39s
2026-01-15 10:31:09.046 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 212, name: 'OutputAudioRawFrame#135', metadata: {} at 3.49s
2026-01-15 10:31:09.046 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 212, name: 'OutputAudioRawFrame#135', metadata: {} at 3.49s
2026-01-15 10:31:09.047 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 743, name: 'OutputAudioRawFrame#444', metadata: {} at 4.40s
2026-01-15 10:31:09.047 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 743, name: 'OutputAudioRawFrame#444', metadata: {} at 4.40s
2026-01-15 10:31:09.047 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#444(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.047 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 743, name: 'OutputAudioRawFrame#444', metadata: {} at 4.40s
2026-01-15 10:31:09.047 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 743, name: 'OutputAudioRawFrame#444', metadata: {} at 4.40s
2026-01-15 10:31:09.047 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 743, name: 'OutputAudioRawFrame#444', metadata: {} at 4.40s
2026-01-15 10:31:09.047 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#444(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.047 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 743, name: 'OutputAudioRawFrame#444', metadata: {} at 4.40s
2026-01-15 10:31:09.047 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 743, name: 'OutputAudioRawFrame#444', metadata: {} at 4.40s
2026-01-15 10:31:09.047 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 743, name: 'OutputAudioRawFrame#444', metadata: {} at 4.40s
2026-01-15 10:31:09.087 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 213, name: 'OutputAudioRawFrame#136', metadata: {} at 3.53s
2026-01-15 10:31:09.087 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 213, name: 'OutputAudioRawFrame#136', metadata: {} at 3.53s
2026-01-15 10:31:09.088 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 745, name: 'OutputAudioRawFrame#445', metadata: {} at 4.44s
2026-01-15 10:31:09.088 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 745, name: 'OutputAudioRawFrame#445', metadata: {} at 4.44s
2026-01-15 10:31:09.088 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#445(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.088 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 745, name: 'OutputAudioRawFrame#445', metadata: {} at 4.44s
2026-01-15 10:31:09.088 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 745, name: 'OutputAudioRawFrame#445', metadata: {} at 4.44s
2026-01-15 10:31:09.088 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 745, name: 'OutputAudioRawFrame#445', metadata: {} at 4.44s
2026-01-15 10:31:09.088 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#445(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.088 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 745, name: 'OutputAudioRawFrame#445', metadata: {} at 4.44s
2026-01-15 10:31:09.089 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 745, name: 'OutputAudioRawFrame#445', metadata: {} at 4.44s
2026-01-15 10:31:09.089 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 745, name: 'OutputAudioRawFrame#445', metadata: {} at 4.44s
2026-01-15 10:31:09.127 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 215, name: 'OutputAudioRawFrame#138', metadata: {} at 3.57s
2026-01-15 10:31:09.127 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 215, name: 'OutputAudioRawFrame#138', metadata: {} at 3.57s
2026-01-15 10:31:09.128 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 747, name: 'OutputAudioRawFrame#446', metadata: {} at 4.48s
2026-01-15 10:31:09.128 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 747, name: 'OutputAudioRawFrame#446', metadata: {} at 4.48s
2026-01-15 10:31:09.128 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#446(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.128 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 747, name: 'OutputAudioRawFrame#446', metadata: {} at 4.48s
2026-01-15 10:31:09.128 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 747, name: 'OutputAudioRawFrame#446', metadata: {} at 4.48s
2026-01-15 10:31:09.128 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 747, name: 'OutputAudioRawFrame#446', metadata: {} at 4.48s
2026-01-15 10:31:09.128 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#446(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.128 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 747, name: 'OutputAudioRawFrame#446', metadata: {} at 4.48s
2026-01-15 10:31:09.128 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 747, name: 'OutputAudioRawFrame#446', metadata: {} at 4.48s
2026-01-15 10:31:09.128 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 747, name: 'OutputAudioRawFrame#446', metadata: {} at 4.48s
2026-01-15 10:31:09.167 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 216, name: 'OutputAudioRawFrame#139', metadata: {} at 3.61s
2026-01-15 10:31:09.167 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 216, name: 'OutputAudioRawFrame#139', metadata: {} at 3.61s
2026-01-15 10:31:09.168 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 749, name: 'OutputAudioRawFrame#447', metadata: {} at 4.52s
2026-01-15 10:31:09.168 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 749, name: 'OutputAudioRawFrame#447', metadata: {} at 4.52s
2026-01-15 10:31:09.168 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#447(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.168 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 749, name: 'OutputAudioRawFrame#447', metadata: {} at 4.52s
2026-01-15 10:31:09.169 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 749, name: 'OutputAudioRawFrame#447', metadata: {} at 4.52s
2026-01-15 10:31:09.169 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 749, name: 'OutputAudioRawFrame#447', metadata: {} at 4.52s
2026-01-15 10:31:09.169 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#447(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.169 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 749, name: 'OutputAudioRawFrame#447', metadata: {} at 4.52s
2026-01-15 10:31:09.169 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 749, name: 'OutputAudioRawFrame#447', metadata: {} at 4.52s
2026-01-15 10:31:09.169 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 749, name: 'OutputAudioRawFrame#447', metadata: {} at 4.52s
2026-01-15 10:31:09.207 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 218, name: 'OutputAudioRawFrame#141', metadata: {} at 3.65s
2026-01-15 10:31:09.207 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 218, name: 'OutputAudioRawFrame#141', metadata: {} at 3.65s
2026-01-15 10:31:09.208 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 751, name: 'OutputAudioRawFrame#448', metadata: {} at 4.56s
2026-01-15 10:31:09.208 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 751, name: 'OutputAudioRawFrame#448', metadata: {} at 4.56s
2026-01-15 10:31:09.208 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#448(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.208 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 751, name: 'OutputAudioRawFrame#448', metadata: {} at 4.56s
2026-01-15 10:31:09.209 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 751, name: 'OutputAudioRawFrame#448', metadata: {} at 4.56s
2026-01-15 10:31:09.209 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 751, name: 'OutputAudioRawFrame#448', metadata: {} at 4.56s
2026-01-15 10:31:09.209 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#448(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.209 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 751, name: 'OutputAudioRawFrame#448', metadata: {} at 4.56s
2026-01-15 10:31:09.209 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 751, name: 'OutputAudioRawFrame#448', metadata: {} at 4.56s
2026-01-15 10:31:09.209 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 751, name: 'OutputAudioRawFrame#448', metadata: {} at 4.56s
2026-01-15 10:31:09.247 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 220, name: 'OutputAudioRawFrame#143', metadata: {} at 3.69s
2026-01-15 10:31:09.247 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 220, name: 'OutputAudioRawFrame#143', metadata: {} at 3.69s
2026-01-15 10:31:09.248 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 753, name: 'OutputAudioRawFrame#449', metadata: {} at 4.60s
2026-01-15 10:31:09.248 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 753, name: 'OutputAudioRawFrame#449', metadata: {} at 4.60s
2026-01-15 10:31:09.248 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#449(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.248 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 753, name: 'OutputAudioRawFrame#449', metadata: {} at 4.60s
2026-01-15 10:31:09.249 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 753, name: 'OutputAudioRawFrame#449', metadata: {} at 4.60s
2026-01-15 10:31:09.249 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 753, name: 'OutputAudioRawFrame#449', metadata: {} at 4.60s
2026-01-15 10:31:09.249 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#449(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.249 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 753, name: 'OutputAudioRawFrame#449', metadata: {} at 4.60s
2026-01-15 10:31:09.249 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 753, name: 'OutputAudioRawFrame#449', metadata: {} at 4.60s
2026-01-15 10:31:09.249 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 753, name: 'OutputAudioRawFrame#449', metadata: {} at 4.60s
2026-01-15 10:31:09.287 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 221, name: 'OutputAudioRawFrame#144', metadata: {} at 3.73s
2026-01-15 10:31:09.287 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 221, name: 'OutputAudioRawFrame#144', metadata: {} at 3.73s
2026-01-15 10:31:09.290 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 755, name: 'OutputAudioRawFrame#450', metadata: {} at 4.64s
2026-01-15 10:31:09.290 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 755, name: 'OutputAudioRawFrame#450', metadata: {} at 4.64s
2026-01-15 10:31:09.290 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#450(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.290 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 755, name: 'OutputAudioRawFrame#450', metadata: {} at 4.64s
2026-01-15 10:31:09.291 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 755, name: 'OutputAudioRawFrame#450', metadata: {} at 4.65s
2026-01-15 10:31:09.291 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 755, name: 'OutputAudioRawFrame#450', metadata: {} at 4.65s
2026-01-15 10:31:09.291 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#450(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.291 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 755, name: 'OutputAudioRawFrame#450', metadata: {} at 4.65s
2026-01-15 10:31:09.291 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 755, name: 'OutputAudioRawFrame#450', metadata: {} at 4.65s
2026-01-15 10:31:09.291 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 755, name: 'OutputAudioRawFrame#450', metadata: {} at 4.65s
2026-01-15 10:31:09.327 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 223, name: 'OutputAudioRawFrame#146', metadata: {} at 3.77s
2026-01-15 10:31:09.327 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 223, name: 'OutputAudioRawFrame#146', metadata: {} at 3.77s
2026-01-15 10:31:09.331 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 757, name: 'OutputAudioRawFrame#451', metadata: {} at 4.69s
2026-01-15 10:31:09.331 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 757, name: 'OutputAudioRawFrame#451', metadata: {} at 4.69s
2026-01-15 10:31:09.331 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#451(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.331 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 757, name: 'OutputAudioRawFrame#451', metadata: {} at 4.69s
2026-01-15 10:31:09.332 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 757, name: 'OutputAudioRawFrame#451', metadata: {} at 4.69s
2026-01-15 10:31:09.332 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 757, name: 'OutputAudioRawFrame#451', metadata: {} at 4.69s
2026-01-15 10:31:09.332 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#451(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.332 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 757, name: 'OutputAudioRawFrame#451', metadata: {} at 4.69s
2026-01-15 10:31:09.333 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 757, name: 'OutputAudioRawFrame#451', metadata: {} at 4.69s
2026-01-15 10:31:09.333 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 757, name: 'OutputAudioRawFrame#451', metadata: {} at 4.69s
2026-01-15 10:31:09.367 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 224, name: 'OutputAudioRawFrame#147', metadata: {} at 3.81s
2026-01-15 10:31:09.367 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 224, name: 'OutputAudioRawFrame#147', metadata: {} at 3.81s
2026-01-15 10:31:09.370 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 759, name: 'OutputAudioRawFrame#452', metadata: {} at 4.72s
2026-01-15 10:31:09.370 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 759, name: 'OutputAudioRawFrame#452', metadata: {} at 4.72s
2026-01-15 10:31:09.370 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#452(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.370 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 759, name: 'OutputAudioRawFrame#452', metadata: {} at 4.72s
2026-01-15 10:31:09.371 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 759, name: 'OutputAudioRawFrame#452', metadata: {} at 4.73s
2026-01-15 10:31:09.371 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 759, name: 'OutputAudioRawFrame#452', metadata: {} at 4.73s
2026-01-15 10:31:09.371 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#452(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.372 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 759, name: 'OutputAudioRawFrame#452', metadata: {} at 4.73s
2026-01-15 10:31:09.372 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 759, name: 'OutputAudioRawFrame#452', metadata: {} at 4.73s
2026-01-15 10:31:09.372 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 759, name: 'OutputAudioRawFrame#452', metadata: {} at 4.73s
2026-01-15 10:31:09.407 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 226, name: 'OutputAudioRawFrame#149', metadata: {} at 3.85s
2026-01-15 10:31:09.407 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 226, name: 'OutputAudioRawFrame#149', metadata: {} at 3.85s
2026-01-15 10:31:09.409 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 761, name: 'OutputAudioRawFrame#453', metadata: {} at 4.76s
2026-01-15 10:31:09.409 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 761, name: 'OutputAudioRawFrame#453', metadata: {} at 4.76s
2026-01-15 10:31:09.409 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#453(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.409 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 761, name: 'OutputAudioRawFrame#453', metadata: {} at 4.76s
2026-01-15 10:31:09.409 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 761, name: 'OutputAudioRawFrame#453', metadata: {} at 4.76s
2026-01-15 10:31:09.410 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 761, name: 'OutputAudioRawFrame#453', metadata: {} at 4.76s
2026-01-15 10:31:09.410 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#453(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.410 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 761, name: 'OutputAudioRawFrame#453', metadata: {} at 4.76s
2026-01-15 10:31:09.410 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 761, name: 'OutputAudioRawFrame#453', metadata: {} at 4.76s
2026-01-15 10:31:09.410 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 761, name: 'OutputAudioRawFrame#453', metadata: {} at 4.76s
2026-01-15 10:31:09.447 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 227, name: 'OutputAudioRawFrame#150', metadata: {} at 3.89s
2026-01-15 10:31:09.447 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 227, name: 'OutputAudioRawFrame#150', metadata: {} at 3.89s
2026-01-15 10:31:09.449 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 763, name: 'OutputAudioRawFrame#454', metadata: {} at 4.80s
2026-01-15 10:31:09.450 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 763, name: 'OutputAudioRawFrame#454', metadata: {} at 4.80s
2026-01-15 10:31:09.450 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#454(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.450 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 763, name: 'OutputAudioRawFrame#454', metadata: {} at 4.80s
2026-01-15 10:31:09.450 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 763, name: 'OutputAudioRawFrame#454', metadata: {} at 4.80s
2026-01-15 10:31:09.451 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 763, name: 'OutputAudioRawFrame#454', metadata: {} at 4.80s
2026-01-15 10:31:09.451 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#454(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.451 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 763, name: 'OutputAudioRawFrame#454', metadata: {} at 4.81s
2026-01-15 10:31:09.451 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 763, name: 'OutputAudioRawFrame#454', metadata: {} at 4.81s
2026-01-15 10:31:09.451 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 763, name: 'OutputAudioRawFrame#454', metadata: {} at 4.81s
2026-01-15 10:31:09.487 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 228, name: 'OutputAudioRawFrame#151', metadata: {} at 3.93s
2026-01-15 10:31:09.487 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 228, name: 'OutputAudioRawFrame#151', metadata: {} at 3.93s
2026-01-15 10:31:09.488 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 765, name: 'OutputAudioRawFrame#455', metadata: {} at 4.84s
2026-01-15 10:31:09.488 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 765, name: 'OutputAudioRawFrame#455', metadata: {} at 4.84s
2026-01-15 10:31:09.488 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#455(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.488 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 765, name: 'OutputAudioRawFrame#455', metadata: {} at 4.84s
2026-01-15 10:31:09.489 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 765, name: 'OutputAudioRawFrame#455', metadata: {} at 4.84s
2026-01-15 10:31:09.489 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 765, name: 'OutputAudioRawFrame#455', metadata: {} at 4.84s
2026-01-15 10:31:09.489 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#455(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.489 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 765, name: 'OutputAudioRawFrame#455', metadata: {} at 4.84s
2026-01-15 10:31:09.489 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 765, name: 'OutputAudioRawFrame#455', metadata: {} at 4.84s
2026-01-15 10:31:09.489 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 765, name: 'OutputAudioRawFrame#455', metadata: {} at 4.84s
2026-01-15 10:31:09.526 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 230, name: 'OutputAudioRawFrame#153', metadata: {} at 3.97s
2026-01-15 10:31:09.526 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 230, name: 'OutputAudioRawFrame#153', metadata: {} at 3.97s
2026-01-15 10:31:09.528 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: VADUserStartedSpeakingFrame id: 769, name: 'VADUserStartedSpeakingFrame#2', metadata: {} at 4.88s
2026-01-15 10:31:09.528 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 770, name: 'UserSpeakingFrame#42', metadata: {} at 4.88s
2026-01-15 10:31:09.528 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 771, name: 'UserSpeakingFrame#43', metadata: {} at 4.88s
2026-01-15 10:31:09.528 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 771, name: 'UserSpeakingFrame#43', metadata: {} at 4.88s
2026-01-15 10:31:09.528 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 767, name: 'OutputAudioRawFrame#456', metadata: {} at 4.88s
2026-01-15 10:31:09.528 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: VADUserStartedSpeakingFrame id: 769, name: 'VADUserStartedSpeakingFrame#2', metadata: {} at 4.88s
2026-01-15 10:31:09.528 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 770, name: 'UserSpeakingFrame#42', metadata: {} at 4.88s
2026-01-15 10:31:09.528 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 767, name: 'OutputAudioRawFrame#456', metadata: {} at 4.88s
2026-01-15 10:31:09.528 | INFO     | [BOT-SYS] | input bot frame: VADUserStartedSpeakingFrame#2
2026-01-15 10:31:09.528 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#42
2026-01-15 10:31:09.528 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#456(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.528 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: VADUserStartedSpeakingFrame id: 769, name: 'VADUserStartedSpeakingFrame#2', metadata: {} at 4.88s
2026-01-15 10:31:09.528 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 772, name: 'RTVIServerMessageFrame#21', metadata: {}, data: {'type': 'user-speaking'} at 4.88s
2026-01-15 10:31:09.528 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 767, name: 'OutputAudioRawFrame#456', metadata: {} at 4.88s
2026-01-15 10:31:09.528 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 773, name: 'OutputTransportMessageUrgentFrame#29', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.88s
2026-01-15 10:31:09.529 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#29(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.529 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#21(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.529 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: VADUserStartedSpeakingFrame id: 769, name: 'VADUserStartedSpeakingFrame#2', metadata: {} at 4.88s
2026-01-15 10:31:09.529 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 772, name: 'RTVIServerMessageFrame#21', metadata: {}, data: {'type': 'user-speaking'} at 4.88s
2026-01-15 10:31:09.529 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 767, name: 'OutputAudioRawFrame#456', metadata: {} at 4.88s
2026-01-15 10:31:09.529 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 772, name: 'RTVIServerMessageFrame#21', metadata: {}, data: {'type': 'user-speaking'} at 4.88s
2026-01-15 10:31:09.529 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 773, name: 'OutputTransportMessageUrgentFrame#29', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.88s
2026-01-15 10:31:09.529 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 772, name: 'RTVIServerMessageFrame#21', metadata: {}, data: {'type': 'user-speaking'} at 4.88s
2026-01-15 10:31:09.529 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: VADUserStartedSpeakingFrame id: 769, name: 'VADUserStartedSpeakingFrame#2', metadata: {} at 4.88s
2026-01-15 10:31:09.529 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 772, name: 'RTVIServerMessageFrame#21', metadata: {}, data: {'type': 'user-speaking'} at 4.88s
2026-01-15 10:31:09.529 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 767, name: 'OutputAudioRawFrame#456', metadata: {} at 4.88s
2026-01-15 10:31:09.529 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 773, name: 'OutputTransportMessageUrgentFrame#29', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.88s
2026-01-15 10:31:09.529 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 772, name: 'RTVIServerMessageFrame#21', metadata: {}, data: {'type': 'user-speaking'} at 4.88s
2026-01-15 10:31:09.529 | INFO     | [BOT-SYS] | output bot frame: VADUserStartedSpeakingFrame#2
2026-01-15 10:31:09.529 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#21(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.529 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#456(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.529 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: VADUserStartedSpeakingFrame id: 769, name: 'VADUserStartedSpeakingFrame#2', metadata: {} at 4.88s
2026-01-15 10:31:09.529 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 772, name: 'RTVIServerMessageFrame#21', metadata: {}, data: {'type': 'user-speaking'} at 4.88s
2026-01-15 10:31:09.529 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 767, name: 'OutputAudioRawFrame#456', metadata: {} at 4.88s
2026-01-15 10:31:09.529 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 773, name: 'OutputTransportMessageUrgentFrame#29', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.88s
2026-01-15 10:31:09.529 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 772, name: 'RTVIServerMessageFrame#21', metadata: {}, data: {'type': 'user-speaking'} at 4.88s
2026-01-15 10:31:09.530 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#29(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.530 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#21(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.530 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: VADUserStartedSpeakingFrame id: 769, name: 'VADUserStartedSpeakingFrame#2', metadata: {} at 4.88s
2026-01-15 10:31:09.530 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: VADUserStartedSpeakingFrame id: 769, name: 'VADUserStartedSpeakingFrame#2', metadata: {} at 4.88s
2026-01-15 10:31:09.530 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 772, name: 'RTVIServerMessageFrame#21', metadata: {}, data: {'type': 'user-speaking'} at 4.88s
2026-01-15 10:31:09.530 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 772, name: 'RTVIServerMessageFrame#21', metadata: {}, data: {'type': 'user-speaking'} at 4.88s
2026-01-15 10:31:09.530 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 767, name: 'OutputAudioRawFrame#456', metadata: {} at 4.88s
2026-01-15 10:31:09.530 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 767, name: 'OutputAudioRawFrame#456', metadata: {} at 4.88s
2026-01-15 10:31:09.530 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 773, name: 'OutputTransportMessageUrgentFrame#29', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.88s
2026-01-15 10:31:09.530 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 772, name: 'RTVIServerMessageFrame#21', metadata: {}, data: {'type': 'user-speaking'} at 4.88s
2026-01-15 10:31:09.530 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 772, name: 'RTVIServerMessageFrame#21', metadata: {}, data: {'type': 'user-speaking'} at 4.88s
2026-01-15 10:31:09.530 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 772, name: 'RTVIServerMessageFrame#21', metadata: {}, data: {'type': 'user-speaking'} at 4.88s
2026-01-15 10:31:09.530 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#28(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.530 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 774, name: 'InputTransportMessageFrame#28', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.97s
2026-01-15 10:31:09.530 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#28(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.530 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#28(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.530 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:09.530 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:09.530 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 774, name: 'InputTransportMessageFrame#28', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.97s
2026-01-15 10:31:09.530 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 774, name: 'InputTransportMessageFrame#28', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.97s
2026-01-15 10:31:09.530 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 774, name: 'InputTransportMessageFrame#28', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.97s
2026-01-15 10:31:09.530 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 774, name: 'InputTransportMessageFrame#28', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.97s
2026-01-15 10:31:09.531 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 774, name: 'InputTransportMessageFrame#28', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.97s
2026-01-15 10:31:09.531 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 774, name: 'InputTransportMessageFrame#28', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 3.97s
2026-01-15 10:31:09.567 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 231, name: 'OutputAudioRawFrame#154', metadata: {} at 4.01s
2026-01-15 10:31:09.567 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 231, name: 'OutputAudioRawFrame#154', metadata: {} at 4.01s
2026-01-15 10:31:09.568 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 777, name: 'UserSpeakingFrame#44', metadata: {} at 4.92s
2026-01-15 10:31:09.568 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 778, name: 'UserSpeakingFrame#45', metadata: {} at 4.92s
2026-01-15 10:31:09.568 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 778, name: 'UserSpeakingFrame#45', metadata: {} at 4.92s
2026-01-15 10:31:09.568 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 775, name: 'OutputAudioRawFrame#457', metadata: {} at 4.92s
2026-01-15 10:31:09.568 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 777, name: 'UserSpeakingFrame#44', metadata: {} at 4.92s
2026-01-15 10:31:09.568 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 775, name: 'OutputAudioRawFrame#457', metadata: {} at 4.92s
2026-01-15 10:31:09.568 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#44
2026-01-15 10:31:09.568 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#457(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.568 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 779, name: 'RTVIServerMessageFrame#22', metadata: {}, data: {'type': 'user-speaking'} at 4.92s
2026-01-15 10:31:09.569 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 775, name: 'OutputAudioRawFrame#457', metadata: {} at 4.92s
2026-01-15 10:31:09.569 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 780, name: 'OutputTransportMessageUrgentFrame#30', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.92s
2026-01-15 10:31:09.569 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#30(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.569 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#22(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.569 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 779, name: 'RTVIServerMessageFrame#22', metadata: {}, data: {'type': 'user-speaking'} at 4.92s
2026-01-15 10:31:09.569 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 779, name: 'RTVIServerMessageFrame#22', metadata: {}, data: {'type': 'user-speaking'} at 4.92s
2026-01-15 10:31:09.569 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 775, name: 'OutputAudioRawFrame#457', metadata: {} at 4.92s
2026-01-15 10:31:09.569 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 780, name: 'OutputTransportMessageUrgentFrame#30', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.92s
2026-01-15 10:31:09.569 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 779, name: 'RTVIServerMessageFrame#22', metadata: {}, data: {'type': 'user-speaking'} at 4.92s
2026-01-15 10:31:09.569 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 779, name: 'RTVIServerMessageFrame#22', metadata: {}, data: {'type': 'user-speaking'} at 4.92s
2026-01-15 10:31:09.569 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 775, name: 'OutputAudioRawFrame#457', metadata: {} at 4.92s
2026-01-15 10:31:09.569 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 780, name: 'OutputTransportMessageUrgentFrame#30', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.92s
2026-01-15 10:31:09.569 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 779, name: 'RTVIServerMessageFrame#22', metadata: {}, data: {'type': 'user-speaking'} at 4.92s
2026-01-15 10:31:09.569 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#22(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.569 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#457(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.570 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 779, name: 'RTVIServerMessageFrame#22', metadata: {}, data: {'type': 'user-speaking'} at 4.92s
2026-01-15 10:31:09.570 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 775, name: 'OutputAudioRawFrame#457', metadata: {} at 4.92s
2026-01-15 10:31:09.570 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 780, name: 'OutputTransportMessageUrgentFrame#30', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.92s
2026-01-15 10:31:09.570 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 779, name: 'RTVIServerMessageFrame#22', metadata: {}, data: {'type': 'user-speaking'} at 4.92s
2026-01-15 10:31:09.570 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#30(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.570 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#22(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.570 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 779, name: 'RTVIServerMessageFrame#22', metadata: {}, data: {'type': 'user-speaking'} at 4.92s
2026-01-15 10:31:09.570 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 779, name: 'RTVIServerMessageFrame#22', metadata: {}, data: {'type': 'user-speaking'} at 4.92s
2026-01-15 10:31:09.570 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 775, name: 'OutputAudioRawFrame#457', metadata: {} at 4.92s
2026-01-15 10:31:09.570 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 775, name: 'OutputAudioRawFrame#457', metadata: {} at 4.92s
2026-01-15 10:31:09.570 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 780, name: 'OutputTransportMessageUrgentFrame#30', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.92s
2026-01-15 10:31:09.570 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 779, name: 'RTVIServerMessageFrame#22', metadata: {}, data: {'type': 'user-speaking'} at 4.92s
2026-01-15 10:31:09.570 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 779, name: 'RTVIServerMessageFrame#22', metadata: {}, data: {'type': 'user-speaking'} at 4.92s
2026-01-15 10:31:09.570 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 779, name: 'RTVIServerMessageFrame#22', metadata: {}, data: {'type': 'user-speaking'} at 4.92s
2026-01-15 10:31:09.570 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#29(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.570 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 781, name: 'InputTransportMessageFrame#29', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.01s
2026-01-15 10:31:09.570 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#29(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.570 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#29(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.570 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:09.570 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:09.570 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 781, name: 'InputTransportMessageFrame#29', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.01s
2026-01-15 10:31:09.571 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 781, name: 'InputTransportMessageFrame#29', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.01s
2026-01-15 10:31:09.571 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 781, name: 'InputTransportMessageFrame#29', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.01s
2026-01-15 10:31:09.571 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 781, name: 'InputTransportMessageFrame#29', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.01s
2026-01-15 10:31:09.571 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 781, name: 'InputTransportMessageFrame#29', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.01s
2026-01-15 10:31:09.571 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 781, name: 'InputTransportMessageFrame#29', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.01s
2026-01-15 10:31:09.607 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 233, name: 'OutputAudioRawFrame#156', metadata: {} at 4.05s
2026-01-15 10:31:09.607 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 233, name: 'OutputAudioRawFrame#156', metadata: {} at 4.05s
2026-01-15 10:31:09.608 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 784, name: 'UserSpeakingFrame#46', metadata: {} at 4.96s
2026-01-15 10:31:09.608 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 785, name: 'UserSpeakingFrame#47', metadata: {} at 4.96s
2026-01-15 10:31:09.608 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 785, name: 'UserSpeakingFrame#47', metadata: {} at 4.96s
2026-01-15 10:31:09.608 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 782, name: 'OutputAudioRawFrame#458', metadata: {} at 4.96s
2026-01-15 10:31:09.608 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 784, name: 'UserSpeakingFrame#46', metadata: {} at 4.96s
2026-01-15 10:31:09.608 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 782, name: 'OutputAudioRawFrame#458', metadata: {} at 4.96s
2026-01-15 10:31:09.608 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#46
2026-01-15 10:31:09.608 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#458(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.608 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 786, name: 'RTVIServerMessageFrame#23', metadata: {}, data: {'type': 'user-speaking'} at 4.96s
2026-01-15 10:31:09.608 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 782, name: 'OutputAudioRawFrame#458', metadata: {} at 4.96s
2026-01-15 10:31:09.608 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 787, name: 'OutputTransportMessageUrgentFrame#31', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.96s
2026-01-15 10:31:09.609 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#31(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.609 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#23(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.609 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 786, name: 'RTVIServerMessageFrame#23', metadata: {}, data: {'type': 'user-speaking'} at 4.96s
2026-01-15 10:31:09.609 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 786, name: 'RTVIServerMessageFrame#23', metadata: {}, data: {'type': 'user-speaking'} at 4.96s
2026-01-15 10:31:09.609 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 782, name: 'OutputAudioRawFrame#458', metadata: {} at 4.96s
2026-01-15 10:31:09.609 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 787, name: 'OutputTransportMessageUrgentFrame#31', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.96s
2026-01-15 10:31:09.609 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 786, name: 'RTVIServerMessageFrame#23', metadata: {}, data: {'type': 'user-speaking'} at 4.96s
2026-01-15 10:31:09.609 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 786, name: 'RTVIServerMessageFrame#23', metadata: {}, data: {'type': 'user-speaking'} at 4.96s
2026-01-15 10:31:09.609 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 782, name: 'OutputAudioRawFrame#458', metadata: {} at 4.96s
2026-01-15 10:31:09.609 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 787, name: 'OutputTransportMessageUrgentFrame#31', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.96s
2026-01-15 10:31:09.610 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 786, name: 'RTVIServerMessageFrame#23', metadata: {}, data: {'type': 'user-speaking'} at 4.96s
2026-01-15 10:31:09.610 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#23(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.610 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#458(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.610 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 786, name: 'RTVIServerMessageFrame#23', metadata: {}, data: {'type': 'user-speaking'} at 4.96s
2026-01-15 10:31:09.610 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 782, name: 'OutputAudioRawFrame#458', metadata: {} at 4.96s
2026-01-15 10:31:09.610 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 787, name: 'OutputTransportMessageUrgentFrame#31', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.96s
2026-01-15 10:31:09.610 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 786, name: 'RTVIServerMessageFrame#23', metadata: {}, data: {'type': 'user-speaking'} at 4.96s
2026-01-15 10:31:09.610 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#31(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.610 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#23(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.610 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 786, name: 'RTVIServerMessageFrame#23', metadata: {}, data: {'type': 'user-speaking'} at 4.96s
2026-01-15 10:31:09.610 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 786, name: 'RTVIServerMessageFrame#23', metadata: {}, data: {'type': 'user-speaking'} at 4.96s
2026-01-15 10:31:09.610 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 782, name: 'OutputAudioRawFrame#458', metadata: {} at 4.96s
2026-01-15 10:31:09.610 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 782, name: 'OutputAudioRawFrame#458', metadata: {} at 4.96s
2026-01-15 10:31:09.610 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 787, name: 'OutputTransportMessageUrgentFrame#31', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.96s
2026-01-15 10:31:09.610 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 786, name: 'RTVIServerMessageFrame#23', metadata: {}, data: {'type': 'user-speaking'} at 4.96s
2026-01-15 10:31:09.611 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 786, name: 'RTVIServerMessageFrame#23', metadata: {}, data: {'type': 'user-speaking'} at 4.96s
2026-01-15 10:31:09.611 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 786, name: 'RTVIServerMessageFrame#23', metadata: {}, data: {'type': 'user-speaking'} at 4.96s
2026-01-15 10:31:09.611 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#30(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.611 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 788, name: 'InputTransportMessageFrame#30', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.05s
2026-01-15 10:31:09.611 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#30(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.611 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#30(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.611 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:09.611 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:09.611 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 788, name: 'InputTransportMessageFrame#30', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.05s
2026-01-15 10:31:09.611 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 788, name: 'InputTransportMessageFrame#30', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.05s
2026-01-15 10:31:09.611 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 788, name: 'InputTransportMessageFrame#30', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.06s
2026-01-15 10:31:09.611 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 788, name: 'InputTransportMessageFrame#30', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.06s
2026-01-15 10:31:09.611 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 788, name: 'InputTransportMessageFrame#30', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.06s
2026-01-15 10:31:09.611 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 788, name: 'InputTransportMessageFrame#30', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.06s
2026-01-15 10:31:09.647 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 234, name: 'OutputAudioRawFrame#157', metadata: {} at 4.09s
2026-01-15 10:31:09.647 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 234, name: 'OutputAudioRawFrame#157', metadata: {} at 4.09s
2026-01-15 10:31:09.649 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 791, name: 'UserSpeakingFrame#48', metadata: {} at 5.00s
2026-01-15 10:31:09.649 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 792, name: 'UserSpeakingFrame#49', metadata: {} at 5.00s
2026-01-15 10:31:09.649 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 792, name: 'UserSpeakingFrame#49', metadata: {} at 5.00s
2026-01-15 10:31:09.649 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 789, name: 'OutputAudioRawFrame#459', metadata: {} at 5.00s
2026-01-15 10:31:09.649 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 791, name: 'UserSpeakingFrame#48', metadata: {} at 5.00s
2026-01-15 10:31:09.649 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 789, name: 'OutputAudioRawFrame#459', metadata: {} at 5.00s
2026-01-15 10:31:09.649 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#48
2026-01-15 10:31:09.649 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#459(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.649 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 793, name: 'RTVIServerMessageFrame#24', metadata: {}, data: {'type': 'user-speaking'} at 5.00s
2026-01-15 10:31:09.649 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 789, name: 'OutputAudioRawFrame#459', metadata: {} at 5.00s
2026-01-15 10:31:09.649 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 794, name: 'OutputTransportMessageUrgentFrame#32', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.00s
2026-01-15 10:31:09.650 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#32(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.650 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#24(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.650 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 793, name: 'RTVIServerMessageFrame#24', metadata: {}, data: {'type': 'user-speaking'} at 5.00s
2026-01-15 10:31:09.650 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 793, name: 'RTVIServerMessageFrame#24', metadata: {}, data: {'type': 'user-speaking'} at 5.00s
2026-01-15 10:31:09.650 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 789, name: 'OutputAudioRawFrame#459', metadata: {} at 5.00s
2026-01-15 10:31:09.650 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 794, name: 'OutputTransportMessageUrgentFrame#32', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.00s
2026-01-15 10:31:09.650 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 793, name: 'RTVIServerMessageFrame#24', metadata: {}, data: {'type': 'user-speaking'} at 5.00s
2026-01-15 10:31:09.650 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 793, name: 'RTVIServerMessageFrame#24', metadata: {}, data: {'type': 'user-speaking'} at 5.00s
2026-01-15 10:31:09.650 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 789, name: 'OutputAudioRawFrame#459', metadata: {} at 5.00s
2026-01-15 10:31:09.650 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 794, name: 'OutputTransportMessageUrgentFrame#32', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.00s
2026-01-15 10:31:09.650 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 793, name: 'RTVIServerMessageFrame#24', metadata: {}, data: {'type': 'user-speaking'} at 5.00s
2026-01-15 10:31:09.650 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#24(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.650 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#459(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.650 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 793, name: 'RTVIServerMessageFrame#24', metadata: {}, data: {'type': 'user-speaking'} at 5.00s
2026-01-15 10:31:09.650 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 789, name: 'OutputAudioRawFrame#459', metadata: {} at 5.00s
2026-01-15 10:31:09.651 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 794, name: 'OutputTransportMessageUrgentFrame#32', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.00s
2026-01-15 10:31:09.651 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 793, name: 'RTVIServerMessageFrame#24', metadata: {}, data: {'type': 'user-speaking'} at 5.00s
2026-01-15 10:31:09.651 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#32(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.651 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#24(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.651 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 793, name: 'RTVIServerMessageFrame#24', metadata: {}, data: {'type': 'user-speaking'} at 5.00s
2026-01-15 10:31:09.651 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 793, name: 'RTVIServerMessageFrame#24', metadata: {}, data: {'type': 'user-speaking'} at 5.01s
2026-01-15 10:31:09.651 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 789, name: 'OutputAudioRawFrame#459', metadata: {} at 5.01s
2026-01-15 10:31:09.651 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 789, name: 'OutputAudioRawFrame#459', metadata: {} at 5.01s
2026-01-15 10:31:09.651 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 794, name: 'OutputTransportMessageUrgentFrame#32', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.01s
2026-01-15 10:31:09.651 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 793, name: 'RTVIServerMessageFrame#24', metadata: {}, data: {'type': 'user-speaking'} at 5.01s
2026-01-15 10:31:09.651 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 793, name: 'RTVIServerMessageFrame#24', metadata: {}, data: {'type': 'user-speaking'} at 5.01s
2026-01-15 10:31:09.651 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 793, name: 'RTVIServerMessageFrame#24', metadata: {}, data: {'type': 'user-speaking'} at 5.01s
2026-01-15 10:31:09.651 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#31(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.651 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 795, name: 'InputTransportMessageFrame#31', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.10s
2026-01-15 10:31:09.651 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#31(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.651 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#31(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.651 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:09.651 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:09.651 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 795, name: 'InputTransportMessageFrame#31', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.10s
2026-01-15 10:31:09.652 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 795, name: 'InputTransportMessageFrame#31', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.10s
2026-01-15 10:31:09.652 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 795, name: 'InputTransportMessageFrame#31', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.10s
2026-01-15 10:31:09.652 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 795, name: 'InputTransportMessageFrame#31', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.10s
2026-01-15 10:31:09.652 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 795, name: 'InputTransportMessageFrame#31', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.10s
2026-01-15 10:31:09.652 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 795, name: 'InputTransportMessageFrame#31', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.10s
2026-01-15 10:31:09.687 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 236, name: 'OutputAudioRawFrame#159', metadata: {} at 4.13s
2026-01-15 10:31:09.687 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 236, name: 'OutputAudioRawFrame#159', metadata: {} at 4.13s
2026-01-15 10:31:09.688 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 798, name: 'UserSpeakingFrame#50', metadata: {} at 5.04s
2026-01-15 10:31:09.688 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 799, name: 'UserSpeakingFrame#51', metadata: {} at 5.04s
2026-01-15 10:31:09.688 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 799, name: 'UserSpeakingFrame#51', metadata: {} at 5.04s
2026-01-15 10:31:09.688 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 796, name: 'OutputAudioRawFrame#460', metadata: {} at 5.04s
2026-01-15 10:31:09.689 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 798, name: 'UserSpeakingFrame#50', metadata: {} at 5.04s
2026-01-15 10:31:09.689 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 796, name: 'OutputAudioRawFrame#460', metadata: {} at 5.04s
2026-01-15 10:31:09.689 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#50
2026-01-15 10:31:09.689 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#460(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.689 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 800, name: 'RTVIServerMessageFrame#25', metadata: {}, data: {'type': 'user-speaking'} at 5.04s
2026-01-15 10:31:09.689 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 796, name: 'OutputAudioRawFrame#460', metadata: {} at 5.04s
2026-01-15 10:31:09.689 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 801, name: 'OutputTransportMessageUrgentFrame#33', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.04s
2026-01-15 10:31:09.690 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#33(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.690 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#25(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.690 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 800, name: 'RTVIServerMessageFrame#25', metadata: {}, data: {'type': 'user-speaking'} at 5.04s
2026-01-15 10:31:09.690 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 800, name: 'RTVIServerMessageFrame#25', metadata: {}, data: {'type': 'user-speaking'} at 5.04s
2026-01-15 10:31:09.690 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 796, name: 'OutputAudioRawFrame#460', metadata: {} at 5.04s
2026-01-15 10:31:09.690 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 801, name: 'OutputTransportMessageUrgentFrame#33', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.04s
2026-01-15 10:31:09.690 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 800, name: 'RTVIServerMessageFrame#25', metadata: {}, data: {'type': 'user-speaking'} at 5.04s
2026-01-15 10:31:09.690 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 800, name: 'RTVIServerMessageFrame#25', metadata: {}, data: {'type': 'user-speaking'} at 5.04s
2026-01-15 10:31:09.690 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 796, name: 'OutputAudioRawFrame#460', metadata: {} at 5.04s
2026-01-15 10:31:09.690 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 801, name: 'OutputTransportMessageUrgentFrame#33', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.04s
2026-01-15 10:31:09.690 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 800, name: 'RTVIServerMessageFrame#25', metadata: {}, data: {'type': 'user-speaking'} at 5.04s
2026-01-15 10:31:09.690 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#25(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.690 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#460(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.690 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 800, name: 'RTVIServerMessageFrame#25', metadata: {}, data: {'type': 'user-speaking'} at 5.04s
2026-01-15 10:31:09.690 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 796, name: 'OutputAudioRawFrame#460', metadata: {} at 5.04s
2026-01-15 10:31:09.690 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 801, name: 'OutputTransportMessageUrgentFrame#33', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.04s
2026-01-15 10:31:09.690 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 800, name: 'RTVIServerMessageFrame#25', metadata: {}, data: {'type': 'user-speaking'} at 5.04s
2026-01-15 10:31:09.690 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#33(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.691 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#25(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.691 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 800, name: 'RTVIServerMessageFrame#25', metadata: {}, data: {'type': 'user-speaking'} at 5.04s
2026-01-15 10:31:09.691 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 800, name: 'RTVIServerMessageFrame#25', metadata: {}, data: {'type': 'user-speaking'} at 5.04s
2026-01-15 10:31:09.691 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 796, name: 'OutputAudioRawFrame#460', metadata: {} at 5.04s
2026-01-15 10:31:09.691 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 796, name: 'OutputAudioRawFrame#460', metadata: {} at 5.04s
2026-01-15 10:31:09.691 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 801, name: 'OutputTransportMessageUrgentFrame#33', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.04s
2026-01-15 10:31:09.691 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 800, name: 'RTVIServerMessageFrame#25', metadata: {}, data: {'type': 'user-speaking'} at 5.04s
2026-01-15 10:31:09.691 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 800, name: 'RTVIServerMessageFrame#25', metadata: {}, data: {'type': 'user-speaking'} at 5.05s
2026-01-15 10:31:09.691 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 800, name: 'RTVIServerMessageFrame#25', metadata: {}, data: {'type': 'user-speaking'} at 5.05s
2026-01-15 10:31:09.691 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#32(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.691 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 802, name: 'InputTransportMessageFrame#32', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.14s
2026-01-15 10:31:09.691 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#32(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.691 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#32(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.691 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:09.691 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:09.692 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 802, name: 'InputTransportMessageFrame#32', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.14s
2026-01-15 10:31:09.692 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 802, name: 'InputTransportMessageFrame#32', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.14s
2026-01-15 10:31:09.692 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 802, name: 'InputTransportMessageFrame#32', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.14s
2026-01-15 10:31:09.692 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 802, name: 'InputTransportMessageFrame#32', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.14s
2026-01-15 10:31:09.692 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 802, name: 'InputTransportMessageFrame#32', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.14s
2026-01-15 10:31:09.692 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 802, name: 'InputTransportMessageFrame#32', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.14s
2026-01-15 10:31:09.727 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 238, name: 'OutputAudioRawFrame#161', metadata: {} at 4.17s
2026-01-15 10:31:09.727 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 238, name: 'OutputAudioRawFrame#161', metadata: {} at 4.17s
2026-01-15 10:31:09.731 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 805, name: 'UserSpeakingFrame#52', metadata: {} at 5.08s
2026-01-15 10:31:09.731 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 806, name: 'UserSpeakingFrame#53', metadata: {} at 5.08s
2026-01-15 10:31:09.731 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 806, name: 'UserSpeakingFrame#53', metadata: {} at 5.08s
2026-01-15 10:31:09.731 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 803, name: 'OutputAudioRawFrame#461', metadata: {} at 5.08s
2026-01-15 10:31:09.731 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 805, name: 'UserSpeakingFrame#52', metadata: {} at 5.09s
2026-01-15 10:31:09.731 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 803, name: 'OutputAudioRawFrame#461', metadata: {} at 5.09s
2026-01-15 10:31:09.731 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#52
2026-01-15 10:31:09.731 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#461(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.732 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 807, name: 'RTVIServerMessageFrame#26', metadata: {}, data: {'type': 'user-speaking'} at 5.09s
2026-01-15 10:31:09.732 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 803, name: 'OutputAudioRawFrame#461', metadata: {} at 5.09s
2026-01-15 10:31:09.732 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 808, name: 'OutputTransportMessageUrgentFrame#34', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.09s
2026-01-15 10:31:09.733 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#34(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.733 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#26(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.733 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 807, name: 'RTVIServerMessageFrame#26', metadata: {}, data: {'type': 'user-speaking'} at 5.09s
2026-01-15 10:31:09.733 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 807, name: 'RTVIServerMessageFrame#26', metadata: {}, data: {'type': 'user-speaking'} at 5.09s
2026-01-15 10:31:09.733 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 803, name: 'OutputAudioRawFrame#461', metadata: {} at 5.09s
2026-01-15 10:31:09.733 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 808, name: 'OutputTransportMessageUrgentFrame#34', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.09s
2026-01-15 10:31:09.733 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 807, name: 'RTVIServerMessageFrame#26', metadata: {}, data: {'type': 'user-speaking'} at 5.09s
2026-01-15 10:31:09.733 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 807, name: 'RTVIServerMessageFrame#26', metadata: {}, data: {'type': 'user-speaking'} at 5.09s
2026-01-15 10:31:09.733 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 803, name: 'OutputAudioRawFrame#461', metadata: {} at 5.09s
2026-01-15 10:31:09.733 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 808, name: 'OutputTransportMessageUrgentFrame#34', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.09s
2026-01-15 10:31:09.734 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 807, name: 'RTVIServerMessageFrame#26', metadata: {}, data: {'type': 'user-speaking'} at 5.09s
2026-01-15 10:31:09.734 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#26(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.734 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#461(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.734 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 807, name: 'RTVIServerMessageFrame#26', metadata: {}, data: {'type': 'user-speaking'} at 5.09s
2026-01-15 10:31:09.734 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 803, name: 'OutputAudioRawFrame#461', metadata: {} at 5.09s
2026-01-15 10:31:09.734 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 808, name: 'OutputTransportMessageUrgentFrame#34', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.09s
2026-01-15 10:31:09.734 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 807, name: 'RTVIServerMessageFrame#26', metadata: {}, data: {'type': 'user-speaking'} at 5.09s
2026-01-15 10:31:09.734 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#34(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.734 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#26(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.734 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 807, name: 'RTVIServerMessageFrame#26', metadata: {}, data: {'type': 'user-speaking'} at 5.09s
2026-01-15 10:31:09.734 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 807, name: 'RTVIServerMessageFrame#26', metadata: {}, data: {'type': 'user-speaking'} at 5.09s
2026-01-15 10:31:09.734 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 803, name: 'OutputAudioRawFrame#461', metadata: {} at 5.09s
2026-01-15 10:31:09.734 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 803, name: 'OutputAudioRawFrame#461', metadata: {} at 5.09s
2026-01-15 10:31:09.734 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 808, name: 'OutputTransportMessageUrgentFrame#34', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.09s
2026-01-15 10:31:09.734 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 807, name: 'RTVIServerMessageFrame#26', metadata: {}, data: {'type': 'user-speaking'} at 5.09s
2026-01-15 10:31:09.735 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 807, name: 'RTVIServerMessageFrame#26', metadata: {}, data: {'type': 'user-speaking'} at 5.09s
2026-01-15 10:31:09.735 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 807, name: 'RTVIServerMessageFrame#26', metadata: {}, data: {'type': 'user-speaking'} at 5.09s
2026-01-15 10:31:09.735 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#33(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.735 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 809, name: 'InputTransportMessageFrame#33', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.18s
2026-01-15 10:31:09.735 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#33(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.735 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#33(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.735 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:09.735 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:09.735 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 809, name: 'InputTransportMessageFrame#33', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.18s
2026-01-15 10:31:09.735 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 809, name: 'InputTransportMessageFrame#33', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.18s
2026-01-15 10:31:09.735 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 809, name: 'InputTransportMessageFrame#33', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.18s
2026-01-15 10:31:09.735 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 809, name: 'InputTransportMessageFrame#33', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.18s
2026-01-15 10:31:09.736 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 809, name: 'InputTransportMessageFrame#33', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.18s
2026-01-15 10:31:09.736 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 809, name: 'InputTransportMessageFrame#33', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.18s
2026-01-15 10:31:09.767 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 239, name: 'OutputAudioRawFrame#162', metadata: {} at 4.21s
2026-01-15 10:31:09.767 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 239, name: 'OutputAudioRawFrame#162', metadata: {} at 4.21s
2026-01-15 10:31:09.769 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 812, name: 'UserSpeakingFrame#54', metadata: {} at 5.12s
2026-01-15 10:31:09.769 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 813, name: 'UserSpeakingFrame#55', metadata: {} at 5.12s
2026-01-15 10:31:09.769 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 813, name: 'UserSpeakingFrame#55', metadata: {} at 5.12s
2026-01-15 10:31:09.769 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 810, name: 'OutputAudioRawFrame#462', metadata: {} at 5.12s
2026-01-15 10:31:09.769 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 812, name: 'UserSpeakingFrame#54', metadata: {} at 5.12s
2026-01-15 10:31:09.769 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 810, name: 'OutputAudioRawFrame#462', metadata: {} at 5.12s
2026-01-15 10:31:09.769 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#54
2026-01-15 10:31:09.769 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#462(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.769 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 814, name: 'RTVIServerMessageFrame#27', metadata: {}, data: {'type': 'user-speaking'} at 5.12s
2026-01-15 10:31:09.769 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 810, name: 'OutputAudioRawFrame#462', metadata: {} at 5.12s
2026-01-15 10:31:09.769 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 815, name: 'OutputTransportMessageUrgentFrame#35', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.12s
2026-01-15 10:31:09.770 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#35(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.770 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#27(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.770 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 814, name: 'RTVIServerMessageFrame#27', metadata: {}, data: {'type': 'user-speaking'} at 5.12s
2026-01-15 10:31:09.770 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 814, name: 'RTVIServerMessageFrame#27', metadata: {}, data: {'type': 'user-speaking'} at 5.12s
2026-01-15 10:31:09.770 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 810, name: 'OutputAudioRawFrame#462', metadata: {} at 5.12s
2026-01-15 10:31:09.770 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 815, name: 'OutputTransportMessageUrgentFrame#35', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.12s
2026-01-15 10:31:09.770 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 814, name: 'RTVIServerMessageFrame#27', metadata: {}, data: {'type': 'user-speaking'} at 5.12s
2026-01-15 10:31:09.770 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 814, name: 'RTVIServerMessageFrame#27', metadata: {}, data: {'type': 'user-speaking'} at 5.12s
2026-01-15 10:31:09.770 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 810, name: 'OutputAudioRawFrame#462', metadata: {} at 5.12s
2026-01-15 10:31:09.770 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 815, name: 'OutputTransportMessageUrgentFrame#35', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.12s
2026-01-15 10:31:09.771 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 814, name: 'RTVIServerMessageFrame#27', metadata: {}, data: {'type': 'user-speaking'} at 5.12s
2026-01-15 10:31:09.771 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#27(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.771 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#462(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.771 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 814, name: 'RTVIServerMessageFrame#27', metadata: {}, data: {'type': 'user-speaking'} at 5.13s
2026-01-15 10:31:09.771 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 810, name: 'OutputAudioRawFrame#462', metadata: {} at 5.13s
2026-01-15 10:31:09.771 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 815, name: 'OutputTransportMessageUrgentFrame#35', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.13s
2026-01-15 10:31:09.771 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 814, name: 'RTVIServerMessageFrame#27', metadata: {}, data: {'type': 'user-speaking'} at 5.13s
2026-01-15 10:31:09.771 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#35(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.771 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#27(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.771 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 814, name: 'RTVIServerMessageFrame#27', metadata: {}, data: {'type': 'user-speaking'} at 5.13s
2026-01-15 10:31:09.771 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 814, name: 'RTVIServerMessageFrame#27', metadata: {}, data: {'type': 'user-speaking'} at 5.13s
2026-01-15 10:31:09.771 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 810, name: 'OutputAudioRawFrame#462', metadata: {} at 5.13s
2026-01-15 10:31:09.771 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 810, name: 'OutputAudioRawFrame#462', metadata: {} at 5.13s
2026-01-15 10:31:09.771 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 815, name: 'OutputTransportMessageUrgentFrame#35', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.13s
2026-01-15 10:31:09.771 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 814, name: 'RTVIServerMessageFrame#27', metadata: {}, data: {'type': 'user-speaking'} at 5.13s
2026-01-15 10:31:09.771 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 814, name: 'RTVIServerMessageFrame#27', metadata: {}, data: {'type': 'user-speaking'} at 5.13s
2026-01-15 10:31:09.771 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 814, name: 'RTVIServerMessageFrame#27', metadata: {}, data: {'type': 'user-speaking'} at 5.13s
2026-01-15 10:31:09.772 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#34(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.772 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 816, name: 'InputTransportMessageFrame#34', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.22s
2026-01-15 10:31:09.772 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#34(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.772 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#34(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.772 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:09.772 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:09.772 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 816, name: 'InputTransportMessageFrame#34', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.22s
2026-01-15 10:31:09.772 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 816, name: 'InputTransportMessageFrame#34', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.22s
2026-01-15 10:31:09.772 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 816, name: 'InputTransportMessageFrame#34', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.22s
2026-01-15 10:31:09.772 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 816, name: 'InputTransportMessageFrame#34', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.22s
2026-01-15 10:31:09.772 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 816, name: 'InputTransportMessageFrame#34', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.22s
2026-01-15 10:31:09.772 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 816, name: 'InputTransportMessageFrame#34', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.22s
2026-01-15 10:31:09.807 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 241, name: 'OutputAudioRawFrame#164', metadata: {} at 4.25s
2026-01-15 10:31:09.807 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 241, name: 'OutputAudioRawFrame#164', metadata: {} at 4.25s
2026-01-15 10:31:09.809 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 819, name: 'UserSpeakingFrame#56', metadata: {} at 5.16s
2026-01-15 10:31:09.809 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 820, name: 'UserSpeakingFrame#57', metadata: {} at 5.16s
2026-01-15 10:31:09.809 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 820, name: 'UserSpeakingFrame#57', metadata: {} at 5.16s
2026-01-15 10:31:09.809 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 817, name: 'OutputAudioRawFrame#463', metadata: {} at 5.16s
2026-01-15 10:31:09.809 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 819, name: 'UserSpeakingFrame#56', metadata: {} at 5.16s
2026-01-15 10:31:09.809 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 817, name: 'OutputAudioRawFrame#463', metadata: {} at 5.16s
2026-01-15 10:31:09.809 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#56
2026-01-15 10:31:09.809 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#463(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.810 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 821, name: 'RTVIServerMessageFrame#28', metadata: {}, data: {'type': 'user-speaking'} at 5.16s
2026-01-15 10:31:09.810 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 817, name: 'OutputAudioRawFrame#463', metadata: {} at 5.16s
2026-01-15 10:31:09.810 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 822, name: 'OutputTransportMessageUrgentFrame#36', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.16s
2026-01-15 10:31:09.810 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#36(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.810 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#28(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.810 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 821, name: 'RTVIServerMessageFrame#28', metadata: {}, data: {'type': 'user-speaking'} at 5.16s
2026-01-15 10:31:09.810 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 821, name: 'RTVIServerMessageFrame#28', metadata: {}, data: {'type': 'user-speaking'} at 5.16s
2026-01-15 10:31:09.811 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 817, name: 'OutputAudioRawFrame#463', metadata: {} at 5.16s
2026-01-15 10:31:09.811 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 822, name: 'OutputTransportMessageUrgentFrame#36', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.16s
2026-01-15 10:31:09.811 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 821, name: 'RTVIServerMessageFrame#28', metadata: {}, data: {'type': 'user-speaking'} at 5.16s
2026-01-15 10:31:09.811 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 821, name: 'RTVIServerMessageFrame#28', metadata: {}, data: {'type': 'user-speaking'} at 5.17s
2026-01-15 10:31:09.811 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 817, name: 'OutputAudioRawFrame#463', metadata: {} at 5.17s
2026-01-15 10:31:09.811 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 822, name: 'OutputTransportMessageUrgentFrame#36', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.17s
2026-01-15 10:31:09.811 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 821, name: 'RTVIServerMessageFrame#28', metadata: {}, data: {'type': 'user-speaking'} at 5.17s
2026-01-15 10:31:09.811 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#28(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.811 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#463(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.811 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 821, name: 'RTVIServerMessageFrame#28', metadata: {}, data: {'type': 'user-speaking'} at 5.17s
2026-01-15 10:31:09.811 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 817, name: 'OutputAudioRawFrame#463', metadata: {} at 5.17s
2026-01-15 10:31:09.811 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 822, name: 'OutputTransportMessageUrgentFrame#36', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.17s
2026-01-15 10:31:09.811 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 821, name: 'RTVIServerMessageFrame#28', metadata: {}, data: {'type': 'user-speaking'} at 5.17s
2026-01-15 10:31:09.811 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#36(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.811 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#28(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.811 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 821, name: 'RTVIServerMessageFrame#28', metadata: {}, data: {'type': 'user-speaking'} at 5.17s
2026-01-15 10:31:09.811 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 821, name: 'RTVIServerMessageFrame#28', metadata: {}, data: {'type': 'user-speaking'} at 5.17s
2026-01-15 10:31:09.811 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 817, name: 'OutputAudioRawFrame#463', metadata: {} at 5.17s
2026-01-15 10:31:09.811 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 817, name: 'OutputAudioRawFrame#463', metadata: {} at 5.17s
2026-01-15 10:31:09.811 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 822, name: 'OutputTransportMessageUrgentFrame#36', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.17s
2026-01-15 10:31:09.812 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 821, name: 'RTVIServerMessageFrame#28', metadata: {}, data: {'type': 'user-speaking'} at 5.17s
2026-01-15 10:31:09.812 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 821, name: 'RTVIServerMessageFrame#28', metadata: {}, data: {'type': 'user-speaking'} at 5.17s
2026-01-15 10:31:09.812 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 821, name: 'RTVIServerMessageFrame#28', metadata: {}, data: {'type': 'user-speaking'} at 5.17s
2026-01-15 10:31:09.812 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#35(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.812 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 823, name: 'InputTransportMessageFrame#35', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.26s
2026-01-15 10:31:09.812 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#35(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.812 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#35(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.812 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:09.812 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:09.812 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 823, name: 'InputTransportMessageFrame#35', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.26s
2026-01-15 10:31:09.812 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 823, name: 'InputTransportMessageFrame#35', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.26s
2026-01-15 10:31:09.812 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 823, name: 'InputTransportMessageFrame#35', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.26s
2026-01-15 10:31:09.812 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 823, name: 'InputTransportMessageFrame#35', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.26s
2026-01-15 10:31:09.813 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 823, name: 'InputTransportMessageFrame#35', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.26s
2026-01-15 10:31:09.813 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 823, name: 'InputTransportMessageFrame#35', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.26s
2026-01-15 10:31:09.847 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 242, name: 'OutputAudioRawFrame#165', metadata: {} at 4.29s
2026-01-15 10:31:09.847 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 242, name: 'OutputAudioRawFrame#165', metadata: {} at 4.29s
2026-01-15 10:31:09.848 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 826, name: 'UserSpeakingFrame#58', metadata: {} at 5.20s
2026-01-15 10:31:09.849 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 827, name: 'UserSpeakingFrame#59', metadata: {} at 5.20s
2026-01-15 10:31:09.849 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 827, name: 'UserSpeakingFrame#59', metadata: {} at 5.20s
2026-01-15 10:31:09.849 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 824, name: 'OutputAudioRawFrame#464', metadata: {} at 5.20s
2026-01-15 10:31:09.849 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 826, name: 'UserSpeakingFrame#58', metadata: {} at 5.20s
2026-01-15 10:31:09.849 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 824, name: 'OutputAudioRawFrame#464', metadata: {} at 5.20s
2026-01-15 10:31:09.849 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#58
2026-01-15 10:31:09.849 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#464(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.849 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 828, name: 'RTVIServerMessageFrame#29', metadata: {}, data: {'type': 'user-speaking'} at 5.20s
2026-01-15 10:31:09.849 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 824, name: 'OutputAudioRawFrame#464', metadata: {} at 5.20s
2026-01-15 10:31:09.849 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 829, name: 'OutputTransportMessageUrgentFrame#37', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.20s
2026-01-15 10:31:09.850 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#37(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.850 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#29(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.850 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 828, name: 'RTVIServerMessageFrame#29', metadata: {}, data: {'type': 'user-speaking'} at 5.20s
2026-01-15 10:31:09.850 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 828, name: 'RTVIServerMessageFrame#29', metadata: {}, data: {'type': 'user-speaking'} at 5.20s
2026-01-15 10:31:09.850 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 824, name: 'OutputAudioRawFrame#464', metadata: {} at 5.20s
2026-01-15 10:31:09.850 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 829, name: 'OutputTransportMessageUrgentFrame#37', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.20s
2026-01-15 10:31:09.850 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 828, name: 'RTVIServerMessageFrame#29', metadata: {}, data: {'type': 'user-speaking'} at 5.20s
2026-01-15 10:31:09.850 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 828, name: 'RTVIServerMessageFrame#29', metadata: {}, data: {'type': 'user-speaking'} at 5.20s
2026-01-15 10:31:09.850 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 824, name: 'OutputAudioRawFrame#464', metadata: {} at 5.20s
2026-01-15 10:31:09.850 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 829, name: 'OutputTransportMessageUrgentFrame#37', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.20s
2026-01-15 10:31:09.850 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 828, name: 'RTVIServerMessageFrame#29', metadata: {}, data: {'type': 'user-speaking'} at 5.20s
2026-01-15 10:31:09.850 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#29(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.851 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#464(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.851 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 828, name: 'RTVIServerMessageFrame#29', metadata: {}, data: {'type': 'user-speaking'} at 5.20s
2026-01-15 10:31:09.851 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 824, name: 'OutputAudioRawFrame#464', metadata: {} at 5.20s
2026-01-15 10:31:09.851 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 829, name: 'OutputTransportMessageUrgentFrame#37', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.20s
2026-01-15 10:31:09.851 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 828, name: 'RTVIServerMessageFrame#29', metadata: {}, data: {'type': 'user-speaking'} at 5.20s
2026-01-15 10:31:09.851 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#37(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.851 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#29(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.851 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 828, name: 'RTVIServerMessageFrame#29', metadata: {}, data: {'type': 'user-speaking'} at 5.21s
2026-01-15 10:31:09.851 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 828, name: 'RTVIServerMessageFrame#29', metadata: {}, data: {'type': 'user-speaking'} at 5.21s
2026-01-15 10:31:09.851 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 824, name: 'OutputAudioRawFrame#464', metadata: {} at 5.21s
2026-01-15 10:31:09.851 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 824, name: 'OutputAudioRawFrame#464', metadata: {} at 5.21s
2026-01-15 10:31:09.851 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 829, name: 'OutputTransportMessageUrgentFrame#37', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.21s
2026-01-15 10:31:09.851 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 828, name: 'RTVIServerMessageFrame#29', metadata: {}, data: {'type': 'user-speaking'} at 5.21s
2026-01-15 10:31:09.851 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 828, name: 'RTVIServerMessageFrame#29', metadata: {}, data: {'type': 'user-speaking'} at 5.21s
2026-01-15 10:31:09.852 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 828, name: 'RTVIServerMessageFrame#29', metadata: {}, data: {'type': 'user-speaking'} at 5.21s
2026-01-15 10:31:09.852 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#36(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.852 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 830, name: 'InputTransportMessageFrame#36', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.30s
2026-01-15 10:31:09.852 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#36(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.852 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#36(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.852 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:09.852 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:09.852 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 830, name: 'InputTransportMessageFrame#36', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.30s
2026-01-15 10:31:09.852 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 830, name: 'InputTransportMessageFrame#36', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.30s
2026-01-15 10:31:09.852 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 830, name: 'InputTransportMessageFrame#36', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.30s
2026-01-15 10:31:09.852 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 830, name: 'InputTransportMessageFrame#36', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.30s
2026-01-15 10:31:09.852 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 830, name: 'InputTransportMessageFrame#36', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.30s
2026-01-15 10:31:09.852 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 830, name: 'InputTransportMessageFrame#36', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.30s
2026-01-15 10:31:09.886 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 244, name: 'OutputAudioRawFrame#167', metadata: {} at 4.33s
2026-01-15 10:31:09.886 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 244, name: 'OutputAudioRawFrame#167', metadata: {} at 4.33s
2026-01-15 10:31:09.887 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 833, name: 'UserSpeakingFrame#60', metadata: {} at 5.24s
2026-01-15 10:31:09.888 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 834, name: 'UserSpeakingFrame#61', metadata: {} at 5.24s
2026-01-15 10:31:09.888 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 834, name: 'UserSpeakingFrame#61', metadata: {} at 5.24s
2026-01-15 10:31:09.888 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 831, name: 'OutputAudioRawFrame#465', metadata: {} at 5.24s
2026-01-15 10:31:09.888 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 833, name: 'UserSpeakingFrame#60', metadata: {} at 5.24s
2026-01-15 10:31:09.888 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 831, name: 'OutputAudioRawFrame#465', metadata: {} at 5.24s
2026-01-15 10:31:09.888 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#60
2026-01-15 10:31:09.888 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#465(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.888 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 835, name: 'RTVIServerMessageFrame#30', metadata: {}, data: {'type': 'user-speaking'} at 5.24s
2026-01-15 10:31:09.888 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 831, name: 'OutputAudioRawFrame#465', metadata: {} at 5.24s
2026-01-15 10:31:09.888 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 836, name: 'OutputTransportMessageUrgentFrame#38', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.24s
2026-01-15 10:31:09.889 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#38(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.889 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#30(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.889 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 835, name: 'RTVIServerMessageFrame#30', metadata: {}, data: {'type': 'user-speaking'} at 5.24s
2026-01-15 10:31:09.889 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 835, name: 'RTVIServerMessageFrame#30', metadata: {}, data: {'type': 'user-speaking'} at 5.24s
2026-01-15 10:31:09.889 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 831, name: 'OutputAudioRawFrame#465', metadata: {} at 5.24s
2026-01-15 10:31:09.889 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 836, name: 'OutputTransportMessageUrgentFrame#38', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.24s
2026-01-15 10:31:09.889 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 835, name: 'RTVIServerMessageFrame#30', metadata: {}, data: {'type': 'user-speaking'} at 5.24s
2026-01-15 10:31:09.889 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 835, name: 'RTVIServerMessageFrame#30', metadata: {}, data: {'type': 'user-speaking'} at 5.24s
2026-01-15 10:31:09.889 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 831, name: 'OutputAudioRawFrame#465', metadata: {} at 5.24s
2026-01-15 10:31:09.889 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 836, name: 'OutputTransportMessageUrgentFrame#38', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.24s
2026-01-15 10:31:09.889 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 835, name: 'RTVIServerMessageFrame#30', metadata: {}, data: {'type': 'user-speaking'} at 5.24s
2026-01-15 10:31:09.890 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#30(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.890 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#465(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.890 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 835, name: 'RTVIServerMessageFrame#30', metadata: {}, data: {'type': 'user-speaking'} at 5.24s
2026-01-15 10:31:09.890 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 831, name: 'OutputAudioRawFrame#465', metadata: {} at 5.24s
2026-01-15 10:31:09.890 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 836, name: 'OutputTransportMessageUrgentFrame#38', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.24s
2026-01-15 10:31:09.890 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 835, name: 'RTVIServerMessageFrame#30', metadata: {}, data: {'type': 'user-speaking'} at 5.24s
2026-01-15 10:31:09.890 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#38(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.890 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#30(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.890 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 835, name: 'RTVIServerMessageFrame#30', metadata: {}, data: {'type': 'user-speaking'} at 5.24s
2026-01-15 10:31:09.890 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 835, name: 'RTVIServerMessageFrame#30', metadata: {}, data: {'type': 'user-speaking'} at 5.24s
2026-01-15 10:31:09.890 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 831, name: 'OutputAudioRawFrame#465', metadata: {} at 5.24s
2026-01-15 10:31:09.890 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 831, name: 'OutputAudioRawFrame#465', metadata: {} at 5.24s
2026-01-15 10:31:09.890 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 836, name: 'OutputTransportMessageUrgentFrame#38', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.24s
2026-01-15 10:31:09.890 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 835, name: 'RTVIServerMessageFrame#30', metadata: {}, data: {'type': 'user-speaking'} at 5.24s
2026-01-15 10:31:09.890 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 835, name: 'RTVIServerMessageFrame#30', metadata: {}, data: {'type': 'user-speaking'} at 5.24s
2026-01-15 10:31:09.890 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 835, name: 'RTVIServerMessageFrame#30', metadata: {}, data: {'type': 'user-speaking'} at 5.24s
2026-01-15 10:31:09.891 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#37(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.891 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 837, name: 'InputTransportMessageFrame#37', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.33s
2026-01-15 10:31:09.891 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#37(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.891 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#37(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.891 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:09.891 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:09.891 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 837, name: 'InputTransportMessageFrame#37', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.33s
2026-01-15 10:31:09.891 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 837, name: 'InputTransportMessageFrame#37', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.33s
2026-01-15 10:31:09.891 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 837, name: 'InputTransportMessageFrame#37', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.33s
2026-01-15 10:31:09.891 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 837, name: 'InputTransportMessageFrame#37', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.33s
2026-01-15 10:31:09.891 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 837, name: 'InputTransportMessageFrame#37', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.33s
2026-01-15 10:31:09.891 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 837, name: 'InputTransportMessageFrame#37', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.33s
2026-01-15 10:31:09.927 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 245, name: 'OutputAudioRawFrame#168', metadata: {} at 4.37s
2026-01-15 10:31:09.927 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 245, name: 'OutputAudioRawFrame#168', metadata: {} at 4.37s
2026-01-15 10:31:09.929 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 840, name: 'UserSpeakingFrame#62', metadata: {} at 5.28s
2026-01-15 10:31:09.929 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 841, name: 'UserSpeakingFrame#63', metadata: {} at 5.28s
2026-01-15 10:31:09.929 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 841, name: 'UserSpeakingFrame#63', metadata: {} at 5.28s
2026-01-15 10:31:09.929 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 838, name: 'OutputAudioRawFrame#466', metadata: {} at 5.28s
2026-01-15 10:31:09.929 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 840, name: 'UserSpeakingFrame#62', metadata: {} at 5.28s
2026-01-15 10:31:09.929 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 838, name: 'OutputAudioRawFrame#466', metadata: {} at 5.28s
2026-01-15 10:31:09.929 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#62
2026-01-15 10:31:09.929 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#466(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.929 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 842, name: 'RTVIServerMessageFrame#31', metadata: {}, data: {'type': 'user-speaking'} at 5.28s
2026-01-15 10:31:09.929 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 838, name: 'OutputAudioRawFrame#466', metadata: {} at 5.28s
2026-01-15 10:31:09.929 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 843, name: 'OutputTransportMessageUrgentFrame#39', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.28s
2026-01-15 10:31:09.930 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#39(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.930 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#31(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.930 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 842, name: 'RTVIServerMessageFrame#31', metadata: {}, data: {'type': 'user-speaking'} at 5.28s
2026-01-15 10:31:09.930 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 842, name: 'RTVIServerMessageFrame#31', metadata: {}, data: {'type': 'user-speaking'} at 5.28s
2026-01-15 10:31:09.930 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 838, name: 'OutputAudioRawFrame#466', metadata: {} at 5.28s
2026-01-15 10:31:09.930 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 843, name: 'OutputTransportMessageUrgentFrame#39', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.28s
2026-01-15 10:31:09.930 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 842, name: 'RTVIServerMessageFrame#31', metadata: {}, data: {'type': 'user-speaking'} at 5.28s
2026-01-15 10:31:09.930 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 842, name: 'RTVIServerMessageFrame#31', metadata: {}, data: {'type': 'user-speaking'} at 5.28s
2026-01-15 10:31:09.930 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 838, name: 'OutputAudioRawFrame#466', metadata: {} at 5.28s
2026-01-15 10:31:09.930 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 843, name: 'OutputTransportMessageUrgentFrame#39', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.28s
2026-01-15 10:31:09.930 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 842, name: 'RTVIServerMessageFrame#31', metadata: {}, data: {'type': 'user-speaking'} at 5.28s
2026-01-15 10:31:09.930 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#31(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.931 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#466(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.931 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 842, name: 'RTVIServerMessageFrame#31', metadata: {}, data: {'type': 'user-speaking'} at 5.28s
2026-01-15 10:31:09.931 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 838, name: 'OutputAudioRawFrame#466', metadata: {} at 5.28s
2026-01-15 10:31:09.931 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 843, name: 'OutputTransportMessageUrgentFrame#39', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.28s
2026-01-15 10:31:09.931 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 842, name: 'RTVIServerMessageFrame#31', metadata: {}, data: {'type': 'user-speaking'} at 5.28s
2026-01-15 10:31:09.931 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#39(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.931 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#31(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.931 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 842, name: 'RTVIServerMessageFrame#31', metadata: {}, data: {'type': 'user-speaking'} at 5.29s
2026-01-15 10:31:09.931 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 842, name: 'RTVIServerMessageFrame#31', metadata: {}, data: {'type': 'user-speaking'} at 5.29s
2026-01-15 10:31:09.931 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 838, name: 'OutputAudioRawFrame#466', metadata: {} at 5.29s
2026-01-15 10:31:09.931 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 838, name: 'OutputAudioRawFrame#466', metadata: {} at 5.29s
2026-01-15 10:31:09.931 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 843, name: 'OutputTransportMessageUrgentFrame#39', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.29s
2026-01-15 10:31:09.931 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 842, name: 'RTVIServerMessageFrame#31', metadata: {}, data: {'type': 'user-speaking'} at 5.29s
2026-01-15 10:31:09.931 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 842, name: 'RTVIServerMessageFrame#31', metadata: {}, data: {'type': 'user-speaking'} at 5.29s
2026-01-15 10:31:09.931 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 842, name: 'RTVIServerMessageFrame#31', metadata: {}, data: {'type': 'user-speaking'} at 5.29s
2026-01-15 10:31:09.931 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#38(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.932 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 844, name: 'InputTransportMessageFrame#38', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.38s
2026-01-15 10:31:09.932 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#38(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.932 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#38(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.932 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:09.932 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:09.932 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 844, name: 'InputTransportMessageFrame#38', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.38s
2026-01-15 10:31:09.932 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 844, name: 'InputTransportMessageFrame#38', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.38s
2026-01-15 10:31:09.932 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 844, name: 'InputTransportMessageFrame#38', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.38s
2026-01-15 10:31:09.932 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 844, name: 'InputTransportMessageFrame#38', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.38s
2026-01-15 10:31:09.932 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 844, name: 'InputTransportMessageFrame#38', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.38s
2026-01-15 10:31:09.932 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 844, name: 'InputTransportMessageFrame#38', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.38s
2026-01-15 10:31:09.967 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 246, name: 'OutputAudioRawFrame#169', metadata: {} at 4.41s
2026-01-15 10:31:09.967 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 246, name: 'OutputAudioRawFrame#169', metadata: {} at 4.41s
2026-01-15 10:31:09.969 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 847, name: 'UserSpeakingFrame#64', metadata: {} at 5.32s
2026-01-15 10:31:09.969 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 848, name: 'UserSpeakingFrame#65', metadata: {} at 5.32s
2026-01-15 10:31:09.969 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 848, name: 'UserSpeakingFrame#65', metadata: {} at 5.32s
2026-01-15 10:31:09.969 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 845, name: 'OutputAudioRawFrame#467', metadata: {} at 5.32s
2026-01-15 10:31:09.969 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 847, name: 'UserSpeakingFrame#64', metadata: {} at 5.32s
2026-01-15 10:31:09.969 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 845, name: 'OutputAudioRawFrame#467', metadata: {} at 5.32s
2026-01-15 10:31:09.969 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#64
2026-01-15 10:31:09.969 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#467(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.969 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 849, name: 'RTVIServerMessageFrame#32', metadata: {}, data: {'type': 'user-speaking'} at 5.32s
2026-01-15 10:31:09.969 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 845, name: 'OutputAudioRawFrame#467', metadata: {} at 5.32s
2026-01-15 10:31:09.970 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 850, name: 'OutputTransportMessageUrgentFrame#40', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.32s
2026-01-15 10:31:09.970 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#40(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.970 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#32(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.970 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 849, name: 'RTVIServerMessageFrame#32', metadata: {}, data: {'type': 'user-speaking'} at 5.32s
2026-01-15 10:31:09.970 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 849, name: 'RTVIServerMessageFrame#32', metadata: {}, data: {'type': 'user-speaking'} at 5.32s
2026-01-15 10:31:09.970 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 845, name: 'OutputAudioRawFrame#467', metadata: {} at 5.32s
2026-01-15 10:31:09.970 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 850, name: 'OutputTransportMessageUrgentFrame#40', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.32s
2026-01-15 10:31:09.970 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 849, name: 'RTVIServerMessageFrame#32', metadata: {}, data: {'type': 'user-speaking'} at 5.32s
2026-01-15 10:31:09.970 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 849, name: 'RTVIServerMessageFrame#32', metadata: {}, data: {'type': 'user-speaking'} at 5.32s
2026-01-15 10:31:09.970 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 845, name: 'OutputAudioRawFrame#467', metadata: {} at 5.32s
2026-01-15 10:31:09.970 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 850, name: 'OutputTransportMessageUrgentFrame#40', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.32s
2026-01-15 10:31:09.970 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 849, name: 'RTVIServerMessageFrame#32', metadata: {}, data: {'type': 'user-speaking'} at 5.32s
2026-01-15 10:31:09.970 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#32(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.971 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#467(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:09.971 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 849, name: 'RTVIServerMessageFrame#32', metadata: {}, data: {'type': 'user-speaking'} at 5.32s
2026-01-15 10:31:09.971 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 845, name: 'OutputAudioRawFrame#467', metadata: {} at 5.32s
2026-01-15 10:31:09.971 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 850, name: 'OutputTransportMessageUrgentFrame#40', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.32s
2026-01-15 10:31:09.971 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 849, name: 'RTVIServerMessageFrame#32', metadata: {}, data: {'type': 'user-speaking'} at 5.32s
2026-01-15 10:31:09.971 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#40(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.971 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#32(data: {'type': 'user-speaking'})
2026-01-15 10:31:09.971 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 849, name: 'RTVIServerMessageFrame#32', metadata: {}, data: {'type': 'user-speaking'} at 5.33s
2026-01-15 10:31:09.971 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 849, name: 'RTVIServerMessageFrame#32', metadata: {}, data: {'type': 'user-speaking'} at 5.33s
2026-01-15 10:31:09.971 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 845, name: 'OutputAudioRawFrame#467', metadata: {} at 5.33s
2026-01-15 10:31:09.971 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 845, name: 'OutputAudioRawFrame#467', metadata: {} at 5.33s
2026-01-15 10:31:09.971 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 850, name: 'OutputTransportMessageUrgentFrame#40', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.33s
2026-01-15 10:31:09.971 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 849, name: 'RTVIServerMessageFrame#32', metadata: {}, data: {'type': 'user-speaking'} at 5.33s
2026-01-15 10:31:09.971 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 849, name: 'RTVIServerMessageFrame#32', metadata: {}, data: {'type': 'user-speaking'} at 5.33s
2026-01-15 10:31:09.971 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 849, name: 'RTVIServerMessageFrame#32', metadata: {}, data: {'type': 'user-speaking'} at 5.33s
2026-01-15 10:31:09.971 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#39(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.971 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 851, name: 'InputTransportMessageFrame#39', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.42s
2026-01-15 10:31:09.971 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#39(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.971 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#39(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:09.971 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:09.971 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:09.971 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 851, name: 'InputTransportMessageFrame#39', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.42s
2026-01-15 10:31:09.972 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 851, name: 'InputTransportMessageFrame#39', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.42s
2026-01-15 10:31:09.972 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 851, name: 'InputTransportMessageFrame#39', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.42s
2026-01-15 10:31:09.972 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 851, name: 'InputTransportMessageFrame#39', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.42s
2026-01-15 10:31:09.972 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 851, name: 'InputTransportMessageFrame#39', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.42s
2026-01-15 10:31:09.972 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 851, name: 'InputTransportMessageFrame#39', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.42s
2026-01-15 10:31:10.006 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 248, name: 'OutputAudioRawFrame#171', metadata: {} at 4.45s
2026-01-15 10:31:10.006 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 248, name: 'OutputAudioRawFrame#171', metadata: {} at 4.45s
2026-01-15 10:31:10.007 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 854, name: 'UserSpeakingFrame#66', metadata: {} at 5.36s
2026-01-15 10:31:10.007 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 855, name: 'UserSpeakingFrame#67', metadata: {} at 5.36s
2026-01-15 10:31:10.007 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 855, name: 'UserSpeakingFrame#67', metadata: {} at 5.36s
2026-01-15 10:31:10.007 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 852, name: 'OutputAudioRawFrame#468', metadata: {} at 5.36s
2026-01-15 10:31:10.007 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 854, name: 'UserSpeakingFrame#66', metadata: {} at 5.36s
2026-01-15 10:31:10.007 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 852, name: 'OutputAudioRawFrame#468', metadata: {} at 5.36s
2026-01-15 10:31:10.007 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#66
2026-01-15 10:31:10.008 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#468(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.008 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 856, name: 'RTVIServerMessageFrame#33', metadata: {}, data: {'type': 'user-speaking'} at 5.36s
2026-01-15 10:31:10.008 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 852, name: 'OutputAudioRawFrame#468', metadata: {} at 5.36s
2026-01-15 10:31:10.008 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 857, name: 'OutputTransportMessageUrgentFrame#41', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.36s
2026-01-15 10:31:10.008 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#41(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.008 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#33(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.008 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 856, name: 'RTVIServerMessageFrame#33', metadata: {}, data: {'type': 'user-speaking'} at 5.36s
2026-01-15 10:31:10.008 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 856, name: 'RTVIServerMessageFrame#33', metadata: {}, data: {'type': 'user-speaking'} at 5.36s
2026-01-15 10:31:10.008 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 852, name: 'OutputAudioRawFrame#468', metadata: {} at 5.36s
2026-01-15 10:31:10.008 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 857, name: 'OutputTransportMessageUrgentFrame#41', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.36s
2026-01-15 10:31:10.008 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 856, name: 'RTVIServerMessageFrame#33', metadata: {}, data: {'type': 'user-speaking'} at 5.36s
2026-01-15 10:31:10.009 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 856, name: 'RTVIServerMessageFrame#33', metadata: {}, data: {'type': 'user-speaking'} at 5.36s
2026-01-15 10:31:10.009 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 852, name: 'OutputAudioRawFrame#468', metadata: {} at 5.36s
2026-01-15 10:31:10.009 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 857, name: 'OutputTransportMessageUrgentFrame#41', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.36s
2026-01-15 10:31:10.009 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 856, name: 'RTVIServerMessageFrame#33', metadata: {}, data: {'type': 'user-speaking'} at 5.36s
2026-01-15 10:31:10.009 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#33(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.009 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#468(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.009 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 856, name: 'RTVIServerMessageFrame#33', metadata: {}, data: {'type': 'user-speaking'} at 5.36s
2026-01-15 10:31:10.009 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 852, name: 'OutputAudioRawFrame#468', metadata: {} at 5.36s
2026-01-15 10:31:10.009 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 857, name: 'OutputTransportMessageUrgentFrame#41', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.36s
2026-01-15 10:31:10.009 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 856, name: 'RTVIServerMessageFrame#33', metadata: {}, data: {'type': 'user-speaking'} at 5.36s
2026-01-15 10:31:10.009 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#41(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.009 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#33(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.009 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 856, name: 'RTVIServerMessageFrame#33', metadata: {}, data: {'type': 'user-speaking'} at 5.36s
2026-01-15 10:31:10.009 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 856, name: 'RTVIServerMessageFrame#33', metadata: {}, data: {'type': 'user-speaking'} at 5.36s
2026-01-15 10:31:10.009 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 852, name: 'OutputAudioRawFrame#468', metadata: {} at 5.36s
2026-01-15 10:31:10.009 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 852, name: 'OutputAudioRawFrame#468', metadata: {} at 5.36s
2026-01-15 10:31:10.009 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 857, name: 'OutputTransportMessageUrgentFrame#41', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.36s
2026-01-15 10:31:10.009 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 856, name: 'RTVIServerMessageFrame#33', metadata: {}, data: {'type': 'user-speaking'} at 5.36s
2026-01-15 10:31:10.009 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 856, name: 'RTVIServerMessageFrame#33', metadata: {}, data: {'type': 'user-speaking'} at 5.36s
2026-01-15 10:31:10.009 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 856, name: 'RTVIServerMessageFrame#33', metadata: {}, data: {'type': 'user-speaking'} at 5.36s
2026-01-15 10:31:10.009 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#40(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.009 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 858, name: 'InputTransportMessageFrame#40', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.45s
2026-01-15 10:31:10.009 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#40(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.009 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#40(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.009 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:10.009 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:10.009 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 858, name: 'InputTransportMessageFrame#40', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.45s
2026-01-15 10:31:10.009 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 858, name: 'InputTransportMessageFrame#40', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.45s
2026-01-15 10:31:10.009 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 858, name: 'InputTransportMessageFrame#40', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.45s
2026-01-15 10:31:10.009 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 858, name: 'InputTransportMessageFrame#40', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.45s
2026-01-15 10:31:10.010 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 858, name: 'InputTransportMessageFrame#40', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.45s
2026-01-15 10:31:10.010 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 858, name: 'InputTransportMessageFrame#40', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.45s
2026-01-15 10:31:10.046 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 249, name: 'OutputAudioRawFrame#172', metadata: {} at 4.49s
2026-01-15 10:31:10.047 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 249, name: 'OutputAudioRawFrame#172', metadata: {} at 4.49s
2026-01-15 10:31:10.048 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 861, name: 'UserSpeakingFrame#68', metadata: {} at 5.40s
2026-01-15 10:31:10.048 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 862, name: 'UserSpeakingFrame#69', metadata: {} at 5.40s
2026-01-15 10:31:10.048 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 862, name: 'UserSpeakingFrame#69', metadata: {} at 5.40s
2026-01-15 10:31:10.048 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 859, name: 'OutputAudioRawFrame#469', metadata: {} at 5.40s
2026-01-15 10:31:10.048 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 861, name: 'UserSpeakingFrame#68', metadata: {} at 5.40s
2026-01-15 10:31:10.048 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 859, name: 'OutputAudioRawFrame#469', metadata: {} at 5.40s
2026-01-15 10:31:10.048 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#68
2026-01-15 10:31:10.048 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#469(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.048 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 863, name: 'RTVIServerMessageFrame#34', metadata: {}, data: {'type': 'user-speaking'} at 5.40s
2026-01-15 10:31:10.048 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 859, name: 'OutputAudioRawFrame#469', metadata: {} at 5.40s
2026-01-15 10:31:10.048 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 864, name: 'OutputTransportMessageUrgentFrame#42', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.40s
2026-01-15 10:31:10.048 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#42(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.048 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#34(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.048 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 863, name: 'RTVIServerMessageFrame#34', metadata: {}, data: {'type': 'user-speaking'} at 5.40s
2026-01-15 10:31:10.048 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 863, name: 'RTVIServerMessageFrame#34', metadata: {}, data: {'type': 'user-speaking'} at 5.40s
2026-01-15 10:31:10.048 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 859, name: 'OutputAudioRawFrame#469', metadata: {} at 5.40s
2026-01-15 10:31:10.048 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 864, name: 'OutputTransportMessageUrgentFrame#42', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.40s
2026-01-15 10:31:10.048 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 863, name: 'RTVIServerMessageFrame#34', metadata: {}, data: {'type': 'user-speaking'} at 5.40s
2026-01-15 10:31:10.048 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 863, name: 'RTVIServerMessageFrame#34', metadata: {}, data: {'type': 'user-speaking'} at 5.40s
2026-01-15 10:31:10.048 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 859, name: 'OutputAudioRawFrame#469', metadata: {} at 5.40s
2026-01-15 10:31:10.048 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 864, name: 'OutputTransportMessageUrgentFrame#42', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.40s
2026-01-15 10:31:10.048 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 863, name: 'RTVIServerMessageFrame#34', metadata: {}, data: {'type': 'user-speaking'} at 5.40s
2026-01-15 10:31:10.048 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#34(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.049 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#469(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.049 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 863, name: 'RTVIServerMessageFrame#34', metadata: {}, data: {'type': 'user-speaking'} at 5.40s
2026-01-15 10:31:10.049 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 859, name: 'OutputAudioRawFrame#469', metadata: {} at 5.40s
2026-01-15 10:31:10.049 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 864, name: 'OutputTransportMessageUrgentFrame#42', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.40s
2026-01-15 10:31:10.049 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 863, name: 'RTVIServerMessageFrame#34', metadata: {}, data: {'type': 'user-speaking'} at 5.40s
2026-01-15 10:31:10.049 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#42(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.049 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#34(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.049 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 863, name: 'RTVIServerMessageFrame#34', metadata: {}, data: {'type': 'user-speaking'} at 5.40s
2026-01-15 10:31:10.049 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 863, name: 'RTVIServerMessageFrame#34', metadata: {}, data: {'type': 'user-speaking'} at 5.40s
2026-01-15 10:31:10.049 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 859, name: 'OutputAudioRawFrame#469', metadata: {} at 5.40s
2026-01-15 10:31:10.049 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 859, name: 'OutputAudioRawFrame#469', metadata: {} at 5.40s
2026-01-15 10:31:10.049 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 864, name: 'OutputTransportMessageUrgentFrame#42', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.40s
2026-01-15 10:31:10.049 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 863, name: 'RTVIServerMessageFrame#34', metadata: {}, data: {'type': 'user-speaking'} at 5.40s
2026-01-15 10:31:10.049 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 863, name: 'RTVIServerMessageFrame#34', metadata: {}, data: {'type': 'user-speaking'} at 5.40s
2026-01-15 10:31:10.049 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 863, name: 'RTVIServerMessageFrame#34', metadata: {}, data: {'type': 'user-speaking'} at 5.40s
2026-01-15 10:31:10.049 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#41(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.049 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 865, name: 'InputTransportMessageFrame#41', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.49s
2026-01-15 10:31:10.049 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#41(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.049 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#41(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.049 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:10.049 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:10.049 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 865, name: 'InputTransportMessageFrame#41', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.49s
2026-01-15 10:31:10.049 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 865, name: 'InputTransportMessageFrame#41', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.49s
2026-01-15 10:31:10.049 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 865, name: 'InputTransportMessageFrame#41', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.49s
2026-01-15 10:31:10.049 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 865, name: 'InputTransportMessageFrame#41', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.49s
2026-01-15 10:31:10.049 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 865, name: 'InputTransportMessageFrame#41', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.49s
2026-01-15 10:31:10.049 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 865, name: 'InputTransportMessageFrame#41', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.49s
2026-01-15 10:31:10.086 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 251, name: 'OutputAudioRawFrame#174', metadata: {} at 4.53s
2026-01-15 10:31:10.087 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 251, name: 'OutputAudioRawFrame#174', metadata: {} at 4.53s
2026-01-15 10:31:10.087 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 868, name: 'UserSpeakingFrame#70', metadata: {} at 5.44s
2026-01-15 10:31:10.087 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 869, name: 'UserSpeakingFrame#71', metadata: {} at 5.44s
2026-01-15 10:31:10.088 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 869, name: 'UserSpeakingFrame#71', metadata: {} at 5.44s
2026-01-15 10:31:10.088 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 866, name: 'OutputAudioRawFrame#470', metadata: {} at 5.44s
2026-01-15 10:31:10.088 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 868, name: 'UserSpeakingFrame#70', metadata: {} at 5.44s
2026-01-15 10:31:10.088 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 866, name: 'OutputAudioRawFrame#470', metadata: {} at 5.44s
2026-01-15 10:31:10.088 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#70
2026-01-15 10:31:10.088 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#470(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.088 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 870, name: 'RTVIServerMessageFrame#35', metadata: {}, data: {'type': 'user-speaking'} at 5.44s
2026-01-15 10:31:10.088 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 866, name: 'OutputAudioRawFrame#470', metadata: {} at 5.44s
2026-01-15 10:31:10.088 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 871, name: 'OutputTransportMessageUrgentFrame#43', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.44s
2026-01-15 10:31:10.088 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#43(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.088 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#35(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.088 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 870, name: 'RTVIServerMessageFrame#35', metadata: {}, data: {'type': 'user-speaking'} at 5.44s
2026-01-15 10:31:10.088 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 870, name: 'RTVIServerMessageFrame#35', metadata: {}, data: {'type': 'user-speaking'} at 5.44s
2026-01-15 10:31:10.088 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 866, name: 'OutputAudioRawFrame#470', metadata: {} at 5.44s
2026-01-15 10:31:10.088 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 871, name: 'OutputTransportMessageUrgentFrame#43', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.44s
2026-01-15 10:31:10.088 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 870, name: 'RTVIServerMessageFrame#35', metadata: {}, data: {'type': 'user-speaking'} at 5.44s
2026-01-15 10:31:10.088 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 870, name: 'RTVIServerMessageFrame#35', metadata: {}, data: {'type': 'user-speaking'} at 5.44s
2026-01-15 10:31:10.088 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 866, name: 'OutputAudioRawFrame#470', metadata: {} at 5.44s
2026-01-15 10:31:10.088 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 871, name: 'OutputTransportMessageUrgentFrame#43', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.44s
2026-01-15 10:31:10.088 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 870, name: 'RTVIServerMessageFrame#35', metadata: {}, data: {'type': 'user-speaking'} at 5.44s
2026-01-15 10:31:10.088 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#35(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.088 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#470(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.088 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 870, name: 'RTVIServerMessageFrame#35', metadata: {}, data: {'type': 'user-speaking'} at 5.44s
2026-01-15 10:31:10.089 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 866, name: 'OutputAudioRawFrame#470', metadata: {} at 5.44s
2026-01-15 10:31:10.089 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 871, name: 'OutputTransportMessageUrgentFrame#43', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.44s
2026-01-15 10:31:10.089 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 870, name: 'RTVIServerMessageFrame#35', metadata: {}, data: {'type': 'user-speaking'} at 5.44s
2026-01-15 10:31:10.089 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#43(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.089 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#35(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.089 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 870, name: 'RTVIServerMessageFrame#35', metadata: {}, data: {'type': 'user-speaking'} at 5.44s
2026-01-15 10:31:10.089 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 870, name: 'RTVIServerMessageFrame#35', metadata: {}, data: {'type': 'user-speaking'} at 5.44s
2026-01-15 10:31:10.089 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 866, name: 'OutputAudioRawFrame#470', metadata: {} at 5.44s
2026-01-15 10:31:10.089 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 866, name: 'OutputAudioRawFrame#470', metadata: {} at 5.44s
2026-01-15 10:31:10.089 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 871, name: 'OutputTransportMessageUrgentFrame#43', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.44s
2026-01-15 10:31:10.089 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 870, name: 'RTVIServerMessageFrame#35', metadata: {}, data: {'type': 'user-speaking'} at 5.44s
2026-01-15 10:31:10.089 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 870, name: 'RTVIServerMessageFrame#35', metadata: {}, data: {'type': 'user-speaking'} at 5.44s
2026-01-15 10:31:10.089 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 870, name: 'RTVIServerMessageFrame#35', metadata: {}, data: {'type': 'user-speaking'} at 5.44s
2026-01-15 10:31:10.089 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#42(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.089 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 872, name: 'InputTransportMessageFrame#42', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.53s
2026-01-15 10:31:10.089 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#42(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.089 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#42(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.089 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:10.089 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:10.089 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 872, name: 'InputTransportMessageFrame#42', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.53s
2026-01-15 10:31:10.089 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 872, name: 'InputTransportMessageFrame#42', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.53s
2026-01-15 10:31:10.089 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 872, name: 'InputTransportMessageFrame#42', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.53s
2026-01-15 10:31:10.089 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 872, name: 'InputTransportMessageFrame#42', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.53s
2026-01-15 10:31:10.089 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 872, name: 'InputTransportMessageFrame#42', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.53s
2026-01-15 10:31:10.089 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 872, name: 'InputTransportMessageFrame#42', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.53s
2026-01-15 10:31:10.127 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 252, name: 'OutputAudioRawFrame#175', metadata: {} at 4.57s
2026-01-15 10:31:10.127 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 252, name: 'OutputAudioRawFrame#175', metadata: {} at 4.57s
2026-01-15 10:31:10.128 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 875, name: 'UserSpeakingFrame#72', metadata: {} at 5.48s
2026-01-15 10:31:10.128 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 876, name: 'UserSpeakingFrame#73', metadata: {} at 5.48s
2026-01-15 10:31:10.128 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 876, name: 'UserSpeakingFrame#73', metadata: {} at 5.48s
2026-01-15 10:31:10.128 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 873, name: 'OutputAudioRawFrame#471', metadata: {} at 5.48s
2026-01-15 10:31:10.128 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 875, name: 'UserSpeakingFrame#72', metadata: {} at 5.48s
2026-01-15 10:31:10.128 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 873, name: 'OutputAudioRawFrame#471', metadata: {} at 5.48s
2026-01-15 10:31:10.128 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#72
2026-01-15 10:31:10.128 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#471(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.128 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 877, name: 'RTVIServerMessageFrame#36', metadata: {}, data: {'type': 'user-speaking'} at 5.48s
2026-01-15 10:31:10.128 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 873, name: 'OutputAudioRawFrame#471', metadata: {} at 5.48s
2026-01-15 10:31:10.128 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 878, name: 'OutputTransportMessageUrgentFrame#44', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.48s
2026-01-15 10:31:10.128 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#44(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.128 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#36(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.128 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 877, name: 'RTVIServerMessageFrame#36', metadata: {}, data: {'type': 'user-speaking'} at 5.48s
2026-01-15 10:31:10.129 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 877, name: 'RTVIServerMessageFrame#36', metadata: {}, data: {'type': 'user-speaking'} at 5.48s
2026-01-15 10:31:10.129 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 873, name: 'OutputAudioRawFrame#471', metadata: {} at 5.48s
2026-01-15 10:31:10.129 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 878, name: 'OutputTransportMessageUrgentFrame#44', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.48s
2026-01-15 10:31:10.129 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 877, name: 'RTVIServerMessageFrame#36', metadata: {}, data: {'type': 'user-speaking'} at 5.48s
2026-01-15 10:31:10.129 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 877, name: 'RTVIServerMessageFrame#36', metadata: {}, data: {'type': 'user-speaking'} at 5.48s
2026-01-15 10:31:10.129 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 873, name: 'OutputAudioRawFrame#471', metadata: {} at 5.48s
2026-01-15 10:31:10.129 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 878, name: 'OutputTransportMessageUrgentFrame#44', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.48s
2026-01-15 10:31:10.129 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 877, name: 'RTVIServerMessageFrame#36', metadata: {}, data: {'type': 'user-speaking'} at 5.48s
2026-01-15 10:31:10.129 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#36(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.129 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#471(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.129 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 877, name: 'RTVIServerMessageFrame#36', metadata: {}, data: {'type': 'user-speaking'} at 5.48s
2026-01-15 10:31:10.129 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 873, name: 'OutputAudioRawFrame#471', metadata: {} at 5.48s
2026-01-15 10:31:10.129 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 878, name: 'OutputTransportMessageUrgentFrame#44', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.48s
2026-01-15 10:31:10.129 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 877, name: 'RTVIServerMessageFrame#36', metadata: {}, data: {'type': 'user-speaking'} at 5.48s
2026-01-15 10:31:10.129 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#44(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.129 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#36(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.129 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 877, name: 'RTVIServerMessageFrame#36', metadata: {}, data: {'type': 'user-speaking'} at 5.48s
2026-01-15 10:31:10.129 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 877, name: 'RTVIServerMessageFrame#36', metadata: {}, data: {'type': 'user-speaking'} at 5.48s
2026-01-15 10:31:10.129 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 873, name: 'OutputAudioRawFrame#471', metadata: {} at 5.48s
2026-01-15 10:31:10.129 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 873, name: 'OutputAudioRawFrame#471', metadata: {} at 5.48s
2026-01-15 10:31:10.129 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 878, name: 'OutputTransportMessageUrgentFrame#44', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.48s
2026-01-15 10:31:10.129 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 877, name: 'RTVIServerMessageFrame#36', metadata: {}, data: {'type': 'user-speaking'} at 5.48s
2026-01-15 10:31:10.129 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 877, name: 'RTVIServerMessageFrame#36', metadata: {}, data: {'type': 'user-speaking'} at 5.48s
2026-01-15 10:31:10.129 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 877, name: 'RTVIServerMessageFrame#36', metadata: {}, data: {'type': 'user-speaking'} at 5.48s
2026-01-15 10:31:10.129 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#43(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.129 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 879, name: 'InputTransportMessageFrame#43', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.57s
2026-01-15 10:31:10.129 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#43(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.129 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#43(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.129 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:10.129 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:10.129 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 879, name: 'InputTransportMessageFrame#43', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.57s
2026-01-15 10:31:10.129 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 879, name: 'InputTransportMessageFrame#43', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.57s
2026-01-15 10:31:10.129 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 879, name: 'InputTransportMessageFrame#43', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.57s
2026-01-15 10:31:10.129 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 879, name: 'InputTransportMessageFrame#43', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.57s
2026-01-15 10:31:10.130 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 879, name: 'InputTransportMessageFrame#43', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.57s
2026-01-15 10:31:10.130 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 879, name: 'InputTransportMessageFrame#43', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.57s
2026-01-15 10:31:10.167 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 254, name: 'OutputAudioRawFrame#177', metadata: {} at 4.61s
2026-01-15 10:31:10.167 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 254, name: 'OutputAudioRawFrame#177', metadata: {} at 4.61s
2026-01-15 10:31:10.167 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 882, name: 'UserSpeakingFrame#74', metadata: {} at 5.52s
2026-01-15 10:31:10.168 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 883, name: 'UserSpeakingFrame#75', metadata: {} at 5.52s
2026-01-15 10:31:10.168 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 883, name: 'UserSpeakingFrame#75', metadata: {} at 5.52s
2026-01-15 10:31:10.168 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 880, name: 'OutputAudioRawFrame#472', metadata: {} at 5.52s
2026-01-15 10:31:10.168 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 882, name: 'UserSpeakingFrame#74', metadata: {} at 5.52s
2026-01-15 10:31:10.168 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 880, name: 'OutputAudioRawFrame#472', metadata: {} at 5.52s
2026-01-15 10:31:10.168 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#74
2026-01-15 10:31:10.168 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#472(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.168 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 884, name: 'RTVIServerMessageFrame#37', metadata: {}, data: {'type': 'user-speaking'} at 5.52s
2026-01-15 10:31:10.168 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 880, name: 'OutputAudioRawFrame#472', metadata: {} at 5.52s
2026-01-15 10:31:10.168 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 885, name: 'OutputTransportMessageUrgentFrame#45', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.52s
2026-01-15 10:31:10.168 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#45(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.168 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#37(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.168 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 884, name: 'RTVIServerMessageFrame#37', metadata: {}, data: {'type': 'user-speaking'} at 5.52s
2026-01-15 10:31:10.168 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 884, name: 'RTVIServerMessageFrame#37', metadata: {}, data: {'type': 'user-speaking'} at 5.52s
2026-01-15 10:31:10.168 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 880, name: 'OutputAudioRawFrame#472', metadata: {} at 5.52s
2026-01-15 10:31:10.168 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 885, name: 'OutputTransportMessageUrgentFrame#45', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.52s
2026-01-15 10:31:10.168 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 884, name: 'RTVIServerMessageFrame#37', metadata: {}, data: {'type': 'user-speaking'} at 5.52s
2026-01-15 10:31:10.168 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 884, name: 'RTVIServerMessageFrame#37', metadata: {}, data: {'type': 'user-speaking'} at 5.52s
2026-01-15 10:31:10.168 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 880, name: 'OutputAudioRawFrame#472', metadata: {} at 5.52s
2026-01-15 10:31:10.168 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 885, name: 'OutputTransportMessageUrgentFrame#45', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.52s
2026-01-15 10:31:10.168 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 884, name: 'RTVIServerMessageFrame#37', metadata: {}, data: {'type': 'user-speaking'} at 5.52s
2026-01-15 10:31:10.168 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#37(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.168 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#472(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.168 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 884, name: 'RTVIServerMessageFrame#37', metadata: {}, data: {'type': 'user-speaking'} at 5.52s
2026-01-15 10:31:10.168 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 880, name: 'OutputAudioRawFrame#472', metadata: {} at 5.52s
2026-01-15 10:31:10.168 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 885, name: 'OutputTransportMessageUrgentFrame#45', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.52s
2026-01-15 10:31:10.168 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 884, name: 'RTVIServerMessageFrame#37', metadata: {}, data: {'type': 'user-speaking'} at 5.52s
2026-01-15 10:31:10.168 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#45(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.169 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#37(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.169 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 884, name: 'RTVIServerMessageFrame#37', metadata: {}, data: {'type': 'user-speaking'} at 5.52s
2026-01-15 10:31:10.169 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 884, name: 'RTVIServerMessageFrame#37', metadata: {}, data: {'type': 'user-speaking'} at 5.52s
2026-01-15 10:31:10.169 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 880, name: 'OutputAudioRawFrame#472', metadata: {} at 5.52s
2026-01-15 10:31:10.169 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 880, name: 'OutputAudioRawFrame#472', metadata: {} at 5.52s
2026-01-15 10:31:10.169 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 885, name: 'OutputTransportMessageUrgentFrame#45', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.52s
2026-01-15 10:31:10.169 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 884, name: 'RTVIServerMessageFrame#37', metadata: {}, data: {'type': 'user-speaking'} at 5.52s
2026-01-15 10:31:10.169 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 884, name: 'RTVIServerMessageFrame#37', metadata: {}, data: {'type': 'user-speaking'} at 5.52s
2026-01-15 10:31:10.169 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 884, name: 'RTVIServerMessageFrame#37', metadata: {}, data: {'type': 'user-speaking'} at 5.52s
2026-01-15 10:31:10.169 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#44(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.169 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 886, name: 'InputTransportMessageFrame#44', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.61s
2026-01-15 10:31:10.169 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#44(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.169 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#44(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.169 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:10.169 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:10.169 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 886, name: 'InputTransportMessageFrame#44', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.61s
2026-01-15 10:31:10.169 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 886, name: 'InputTransportMessageFrame#44', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.61s
2026-01-15 10:31:10.169 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 886, name: 'InputTransportMessageFrame#44', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.61s
2026-01-15 10:31:10.169 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 886, name: 'InputTransportMessageFrame#44', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.61s
2026-01-15 10:31:10.169 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 886, name: 'InputTransportMessageFrame#44', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.61s
2026-01-15 10:31:10.169 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 886, name: 'InputTransportMessageFrame#44', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.61s
2026-01-15 10:31:10.206 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 256, name: 'OutputAudioRawFrame#179', metadata: {} at 4.65s
2026-01-15 10:31:10.206 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 256, name: 'OutputAudioRawFrame#179', metadata: {} at 4.65s
2026-01-15 10:31:10.207 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 889, name: 'UserSpeakingFrame#76', metadata: {} at 5.56s
2026-01-15 10:31:10.207 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 890, name: 'UserSpeakingFrame#77', metadata: {} at 5.56s
2026-01-15 10:31:10.207 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 890, name: 'UserSpeakingFrame#77', metadata: {} at 5.56s
2026-01-15 10:31:10.207 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 887, name: 'OutputAudioRawFrame#473', metadata: {} at 5.56s
2026-01-15 10:31:10.207 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 889, name: 'UserSpeakingFrame#76', metadata: {} at 5.56s
2026-01-15 10:31:10.207 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 887, name: 'OutputAudioRawFrame#473', metadata: {} at 5.56s
2026-01-15 10:31:10.207 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#76
2026-01-15 10:31:10.207 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#473(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.207 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 891, name: 'RTVIServerMessageFrame#38', metadata: {}, data: {'type': 'user-speaking'} at 5.56s
2026-01-15 10:31:10.207 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 887, name: 'OutputAudioRawFrame#473', metadata: {} at 5.56s
2026-01-15 10:31:10.207 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 892, name: 'OutputTransportMessageUrgentFrame#46', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.56s
2026-01-15 10:31:10.208 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#46(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.208 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#38(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.208 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 891, name: 'RTVIServerMessageFrame#38', metadata: {}, data: {'type': 'user-speaking'} at 5.56s
2026-01-15 10:31:10.208 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 891, name: 'RTVIServerMessageFrame#38', metadata: {}, data: {'type': 'user-speaking'} at 5.56s
2026-01-15 10:31:10.208 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 887, name: 'OutputAudioRawFrame#473', metadata: {} at 5.56s
2026-01-15 10:31:10.208 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 892, name: 'OutputTransportMessageUrgentFrame#46', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.56s
2026-01-15 10:31:10.208 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 891, name: 'RTVIServerMessageFrame#38', metadata: {}, data: {'type': 'user-speaking'} at 5.56s
2026-01-15 10:31:10.208 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 891, name: 'RTVIServerMessageFrame#38', metadata: {}, data: {'type': 'user-speaking'} at 5.56s
2026-01-15 10:31:10.208 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 887, name: 'OutputAudioRawFrame#473', metadata: {} at 5.56s
2026-01-15 10:31:10.208 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 892, name: 'OutputTransportMessageUrgentFrame#46', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.56s
2026-01-15 10:31:10.208 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 891, name: 'RTVIServerMessageFrame#38', metadata: {}, data: {'type': 'user-speaking'} at 5.56s
2026-01-15 10:31:10.208 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#38(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.208 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#473(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.208 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 891, name: 'RTVIServerMessageFrame#38', metadata: {}, data: {'type': 'user-speaking'} at 5.56s
2026-01-15 10:31:10.208 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 887, name: 'OutputAudioRawFrame#473', metadata: {} at 5.56s
2026-01-15 10:31:10.208 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 892, name: 'OutputTransportMessageUrgentFrame#46', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.56s
2026-01-15 10:31:10.208 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 891, name: 'RTVIServerMessageFrame#38', metadata: {}, data: {'type': 'user-speaking'} at 5.56s
2026-01-15 10:31:10.208 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#46(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.208 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#38(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.208 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 891, name: 'RTVIServerMessageFrame#38', metadata: {}, data: {'type': 'user-speaking'} at 5.56s
2026-01-15 10:31:10.208 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 891, name: 'RTVIServerMessageFrame#38', metadata: {}, data: {'type': 'user-speaking'} at 5.56s
2026-01-15 10:31:10.208 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 887, name: 'OutputAudioRawFrame#473', metadata: {} at 5.56s
2026-01-15 10:31:10.208 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 887, name: 'OutputAudioRawFrame#473', metadata: {} at 5.56s
2026-01-15 10:31:10.208 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 892, name: 'OutputTransportMessageUrgentFrame#46', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.56s
2026-01-15 10:31:10.208 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 891, name: 'RTVIServerMessageFrame#38', metadata: {}, data: {'type': 'user-speaking'} at 5.56s
2026-01-15 10:31:10.208 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 891, name: 'RTVIServerMessageFrame#38', metadata: {}, data: {'type': 'user-speaking'} at 5.56s
2026-01-15 10:31:10.208 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 891, name: 'RTVIServerMessageFrame#38', metadata: {}, data: {'type': 'user-speaking'} at 5.56s
2026-01-15 10:31:10.208 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#45(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.208 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 893, name: 'InputTransportMessageFrame#45', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.65s
2026-01-15 10:31:10.208 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#45(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.208 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#45(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.208 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:10.208 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:10.208 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 893, name: 'InputTransportMessageFrame#45', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.65s
2026-01-15 10:31:10.208 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 893, name: 'InputTransportMessageFrame#45', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.65s
2026-01-15 10:31:10.208 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 893, name: 'InputTransportMessageFrame#45', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.65s
2026-01-15 10:31:10.208 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 893, name: 'InputTransportMessageFrame#45', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.65s
2026-01-15 10:31:10.208 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 893, name: 'InputTransportMessageFrame#45', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.65s
2026-01-15 10:31:10.208 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 893, name: 'InputTransportMessageFrame#45', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.65s
2026-01-15 10:31:10.247 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 257, name: 'OutputAudioRawFrame#180', metadata: {} at 4.69s
2026-01-15 10:31:10.247 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 257, name: 'OutputAudioRawFrame#180', metadata: {} at 4.69s
2026-01-15 10:31:10.248 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 896, name: 'UserSpeakingFrame#78', metadata: {} at 5.60s
2026-01-15 10:31:10.248 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 897, name: 'UserSpeakingFrame#79', metadata: {} at 5.60s
2026-01-15 10:31:10.248 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 897, name: 'UserSpeakingFrame#79', metadata: {} at 5.60s
2026-01-15 10:31:10.248 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 894, name: 'OutputAudioRawFrame#474', metadata: {} at 5.60s
2026-01-15 10:31:10.248 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 896, name: 'UserSpeakingFrame#78', metadata: {} at 5.60s
2026-01-15 10:31:10.248 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 894, name: 'OutputAudioRawFrame#474', metadata: {} at 5.60s
2026-01-15 10:31:10.248 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#78
2026-01-15 10:31:10.248 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#474(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.248 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 898, name: 'RTVIServerMessageFrame#39', metadata: {}, data: {'type': 'user-speaking'} at 5.60s
2026-01-15 10:31:10.248 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 894, name: 'OutputAudioRawFrame#474', metadata: {} at 5.60s
2026-01-15 10:31:10.248 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 899, name: 'OutputTransportMessageUrgentFrame#47', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.60s
2026-01-15 10:31:10.249 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#47(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.249 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#39(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.249 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 898, name: 'RTVIServerMessageFrame#39', metadata: {}, data: {'type': 'user-speaking'} at 5.60s
2026-01-15 10:31:10.249 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 898, name: 'RTVIServerMessageFrame#39', metadata: {}, data: {'type': 'user-speaking'} at 5.60s
2026-01-15 10:31:10.249 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 894, name: 'OutputAudioRawFrame#474', metadata: {} at 5.60s
2026-01-15 10:31:10.249 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 899, name: 'OutputTransportMessageUrgentFrame#47', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.60s
2026-01-15 10:31:10.249 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 898, name: 'RTVIServerMessageFrame#39', metadata: {}, data: {'type': 'user-speaking'} at 5.60s
2026-01-15 10:31:10.249 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 898, name: 'RTVIServerMessageFrame#39', metadata: {}, data: {'type': 'user-speaking'} at 5.60s
2026-01-15 10:31:10.249 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 894, name: 'OutputAudioRawFrame#474', metadata: {} at 5.60s
2026-01-15 10:31:10.249 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 899, name: 'OutputTransportMessageUrgentFrame#47', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.60s
2026-01-15 10:31:10.249 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 898, name: 'RTVIServerMessageFrame#39', metadata: {}, data: {'type': 'user-speaking'} at 5.60s
2026-01-15 10:31:10.249 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#39(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.249 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#474(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.249 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 898, name: 'RTVIServerMessageFrame#39', metadata: {}, data: {'type': 'user-speaking'} at 5.60s
2026-01-15 10:31:10.249 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 894, name: 'OutputAudioRawFrame#474', metadata: {} at 5.60s
2026-01-15 10:31:10.249 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 899, name: 'OutputTransportMessageUrgentFrame#47', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.60s
2026-01-15 10:31:10.249 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 898, name: 'RTVIServerMessageFrame#39', metadata: {}, data: {'type': 'user-speaking'} at 5.60s
2026-01-15 10:31:10.249 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#47(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.249 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#39(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.249 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 898, name: 'RTVIServerMessageFrame#39', metadata: {}, data: {'type': 'user-speaking'} at 5.60s
2026-01-15 10:31:10.249 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 898, name: 'RTVIServerMessageFrame#39', metadata: {}, data: {'type': 'user-speaking'} at 5.60s
2026-01-15 10:31:10.249 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 894, name: 'OutputAudioRawFrame#474', metadata: {} at 5.60s
2026-01-15 10:31:10.249 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 894, name: 'OutputAudioRawFrame#474', metadata: {} at 5.60s
2026-01-15 10:31:10.249 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 899, name: 'OutputTransportMessageUrgentFrame#47', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.60s
2026-01-15 10:31:10.249 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 898, name: 'RTVIServerMessageFrame#39', metadata: {}, data: {'type': 'user-speaking'} at 5.60s
2026-01-15 10:31:10.249 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 898, name: 'RTVIServerMessageFrame#39', metadata: {}, data: {'type': 'user-speaking'} at 5.60s
2026-01-15 10:31:10.249 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 898, name: 'RTVIServerMessageFrame#39', metadata: {}, data: {'type': 'user-speaking'} at 5.60s
2026-01-15 10:31:10.249 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#46(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.249 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 900, name: 'InputTransportMessageFrame#46', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.69s
2026-01-15 10:31:10.249 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#46(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.250 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#46(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.250 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:10.250 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:10.250 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 900, name: 'InputTransportMessageFrame#46', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.69s
2026-01-15 10:31:10.250 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 900, name: 'InputTransportMessageFrame#46', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.69s
2026-01-15 10:31:10.250 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 900, name: 'InputTransportMessageFrame#46', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.69s
2026-01-15 10:31:10.250 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 900, name: 'InputTransportMessageFrame#46', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.69s
2026-01-15 10:31:10.250 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 900, name: 'InputTransportMessageFrame#46', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.69s
2026-01-15 10:31:10.250 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 900, name: 'InputTransportMessageFrame#46', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.69s
2026-01-15 10:31:10.287 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 259, name: 'OutputAudioRawFrame#182', metadata: {} at 4.73s
2026-01-15 10:31:10.287 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 259, name: 'OutputAudioRawFrame#182', metadata: {} at 4.73s
2026-01-15 10:31:10.288 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 903, name: 'UserSpeakingFrame#80', metadata: {} at 5.64s
2026-01-15 10:31:10.288 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 904, name: 'UserSpeakingFrame#81', metadata: {} at 5.64s
2026-01-15 10:31:10.288 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 904, name: 'UserSpeakingFrame#81', metadata: {} at 5.64s
2026-01-15 10:31:10.288 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 901, name: 'OutputAudioRawFrame#475', metadata: {} at 5.64s
2026-01-15 10:31:10.288 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 903, name: 'UserSpeakingFrame#80', metadata: {} at 5.64s
2026-01-15 10:31:10.288 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 901, name: 'OutputAudioRawFrame#475', metadata: {} at 5.64s
2026-01-15 10:31:10.288 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#80
2026-01-15 10:31:10.288 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#475(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.288 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 905, name: 'RTVIServerMessageFrame#40', metadata: {}, data: {'type': 'user-speaking'} at 5.64s
2026-01-15 10:31:10.288 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 901, name: 'OutputAudioRawFrame#475', metadata: {} at 5.64s
2026-01-15 10:31:10.288 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 906, name: 'OutputTransportMessageUrgentFrame#48', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.64s
2026-01-15 10:31:10.288 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#48(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.288 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#40(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.288 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 905, name: 'RTVIServerMessageFrame#40', metadata: {}, data: {'type': 'user-speaking'} at 5.64s
2026-01-15 10:31:10.288 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 905, name: 'RTVIServerMessageFrame#40', metadata: {}, data: {'type': 'user-speaking'} at 5.64s
2026-01-15 10:31:10.289 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 901, name: 'OutputAudioRawFrame#475', metadata: {} at 5.64s
2026-01-15 10:31:10.289 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 906, name: 'OutputTransportMessageUrgentFrame#48', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.64s
2026-01-15 10:31:10.289 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 905, name: 'RTVIServerMessageFrame#40', metadata: {}, data: {'type': 'user-speaking'} at 5.64s
2026-01-15 10:31:10.289 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 905, name: 'RTVIServerMessageFrame#40', metadata: {}, data: {'type': 'user-speaking'} at 5.64s
2026-01-15 10:31:10.289 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 901, name: 'OutputAudioRawFrame#475', metadata: {} at 5.64s
2026-01-15 10:31:10.289 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 906, name: 'OutputTransportMessageUrgentFrame#48', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.64s
2026-01-15 10:31:10.289 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 905, name: 'RTVIServerMessageFrame#40', metadata: {}, data: {'type': 'user-speaking'} at 5.64s
2026-01-15 10:31:10.289 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#40(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.289 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#475(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.289 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 905, name: 'RTVIServerMessageFrame#40', metadata: {}, data: {'type': 'user-speaking'} at 5.64s
2026-01-15 10:31:10.289 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 901, name: 'OutputAudioRawFrame#475', metadata: {} at 5.64s
2026-01-15 10:31:10.289 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 906, name: 'OutputTransportMessageUrgentFrame#48', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.64s
2026-01-15 10:31:10.289 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 905, name: 'RTVIServerMessageFrame#40', metadata: {}, data: {'type': 'user-speaking'} at 5.64s
2026-01-15 10:31:10.289 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#48(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.289 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#40(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.289 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 905, name: 'RTVIServerMessageFrame#40', metadata: {}, data: {'type': 'user-speaking'} at 5.64s
2026-01-15 10:31:10.289 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 905, name: 'RTVIServerMessageFrame#40', metadata: {}, data: {'type': 'user-speaking'} at 5.64s
2026-01-15 10:31:10.289 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 901, name: 'OutputAudioRawFrame#475', metadata: {} at 5.64s
2026-01-15 10:31:10.289 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 901, name: 'OutputAudioRawFrame#475', metadata: {} at 5.64s
2026-01-15 10:31:10.289 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 906, name: 'OutputTransportMessageUrgentFrame#48', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.64s
2026-01-15 10:31:10.289 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 905, name: 'RTVIServerMessageFrame#40', metadata: {}, data: {'type': 'user-speaking'} at 5.64s
2026-01-15 10:31:10.289 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 905, name: 'RTVIServerMessageFrame#40', metadata: {}, data: {'type': 'user-speaking'} at 5.64s
2026-01-15 10:31:10.289 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 905, name: 'RTVIServerMessageFrame#40', metadata: {}, data: {'type': 'user-speaking'} at 5.64s
2026-01-15 10:31:10.289 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#47(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.289 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 907, name: 'InputTransportMessageFrame#47', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.73s
2026-01-15 10:31:10.289 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#47(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.289 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#47(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.289 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:10.289 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:10.289 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 907, name: 'InputTransportMessageFrame#47', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.73s
2026-01-15 10:31:10.289 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 907, name: 'InputTransportMessageFrame#47', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.73s
2026-01-15 10:31:10.289 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 907, name: 'InputTransportMessageFrame#47', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.73s
2026-01-15 10:31:10.289 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 907, name: 'InputTransportMessageFrame#47', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.73s
2026-01-15 10:31:10.289 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 907, name: 'InputTransportMessageFrame#47', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.73s
2026-01-15 10:31:10.289 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 907, name: 'InputTransportMessageFrame#47', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.73s
2026-01-15 10:31:10.326 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 260, name: 'OutputAudioRawFrame#183', metadata: {} at 4.77s
2026-01-15 10:31:10.327 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 260, name: 'OutputAudioRawFrame#183', metadata: {} at 4.77s
2026-01-15 10:31:10.327 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 910, name: 'UserSpeakingFrame#82', metadata: {} at 5.68s
2026-01-15 10:31:10.327 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 911, name: 'UserSpeakingFrame#83', metadata: {} at 5.68s
2026-01-15 10:31:10.327 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 911, name: 'UserSpeakingFrame#83', metadata: {} at 5.68s
2026-01-15 10:31:10.327 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 908, name: 'OutputAudioRawFrame#476', metadata: {} at 5.68s
2026-01-15 10:31:10.327 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 910, name: 'UserSpeakingFrame#82', metadata: {} at 5.68s
2026-01-15 10:31:10.327 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 908, name: 'OutputAudioRawFrame#476', metadata: {} at 5.68s
2026-01-15 10:31:10.328 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#82
2026-01-15 10:31:10.328 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#476(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.328 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 912, name: 'RTVIServerMessageFrame#41', metadata: {}, data: {'type': 'user-speaking'} at 5.68s
2026-01-15 10:31:10.328 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 908, name: 'OutputAudioRawFrame#476', metadata: {} at 5.68s
2026-01-15 10:31:10.328 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 913, name: 'OutputTransportMessageUrgentFrame#49', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.68s
2026-01-15 10:31:10.328 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#49(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.328 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#41(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.328 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 912, name: 'RTVIServerMessageFrame#41', metadata: {}, data: {'type': 'user-speaking'} at 5.68s
2026-01-15 10:31:10.328 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 912, name: 'RTVIServerMessageFrame#41', metadata: {}, data: {'type': 'user-speaking'} at 5.68s
2026-01-15 10:31:10.328 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 908, name: 'OutputAudioRawFrame#476', metadata: {} at 5.68s
2026-01-15 10:31:10.328 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 913, name: 'OutputTransportMessageUrgentFrame#49', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.68s
2026-01-15 10:31:10.328 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 912, name: 'RTVIServerMessageFrame#41', metadata: {}, data: {'type': 'user-speaking'} at 5.68s
2026-01-15 10:31:10.328 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 912, name: 'RTVIServerMessageFrame#41', metadata: {}, data: {'type': 'user-speaking'} at 5.68s
2026-01-15 10:31:10.328 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 908, name: 'OutputAudioRawFrame#476', metadata: {} at 5.68s
2026-01-15 10:31:10.328 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 913, name: 'OutputTransportMessageUrgentFrame#49', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.68s
2026-01-15 10:31:10.328 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 912, name: 'RTVIServerMessageFrame#41', metadata: {}, data: {'type': 'user-speaking'} at 5.68s
2026-01-15 10:31:10.328 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#41(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.328 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#476(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.328 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 912, name: 'RTVIServerMessageFrame#41', metadata: {}, data: {'type': 'user-speaking'} at 5.68s
2026-01-15 10:31:10.328 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 908, name: 'OutputAudioRawFrame#476', metadata: {} at 5.68s
2026-01-15 10:31:10.328 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 913, name: 'OutputTransportMessageUrgentFrame#49', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.68s
2026-01-15 10:31:10.328 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 912, name: 'RTVIServerMessageFrame#41', metadata: {}, data: {'type': 'user-speaking'} at 5.68s
2026-01-15 10:31:10.328 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#49(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.328 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#41(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.328 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 912, name: 'RTVIServerMessageFrame#41', metadata: {}, data: {'type': 'user-speaking'} at 5.68s
2026-01-15 10:31:10.328 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 912, name: 'RTVIServerMessageFrame#41', metadata: {}, data: {'type': 'user-speaking'} at 5.68s
2026-01-15 10:31:10.329 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 908, name: 'OutputAudioRawFrame#476', metadata: {} at 5.68s
2026-01-15 10:31:10.329 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 908, name: 'OutputAudioRawFrame#476', metadata: {} at 5.68s
2026-01-15 10:31:10.329 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 913, name: 'OutputTransportMessageUrgentFrame#49', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.68s
2026-01-15 10:31:10.329 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 912, name: 'RTVIServerMessageFrame#41', metadata: {}, data: {'type': 'user-speaking'} at 5.68s
2026-01-15 10:31:10.329 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 912, name: 'RTVIServerMessageFrame#41', metadata: {}, data: {'type': 'user-speaking'} at 5.68s
2026-01-15 10:31:10.329 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 912, name: 'RTVIServerMessageFrame#41', metadata: {}, data: {'type': 'user-speaking'} at 5.68s
2026-01-15 10:31:10.329 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#48(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.329 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 914, name: 'InputTransportMessageFrame#48', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.77s
2026-01-15 10:31:10.329 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#48(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.329 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#48(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.329 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:10.329 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:10.329 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 914, name: 'InputTransportMessageFrame#48', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.77s
2026-01-15 10:31:10.329 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 914, name: 'InputTransportMessageFrame#48', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.77s
2026-01-15 10:31:10.329 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 914, name: 'InputTransportMessageFrame#48', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.77s
2026-01-15 10:31:10.329 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 914, name: 'InputTransportMessageFrame#48', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.77s
2026-01-15 10:31:10.329 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 914, name: 'InputTransportMessageFrame#48', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.77s
2026-01-15 10:31:10.329 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 914, name: 'InputTransportMessageFrame#48', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.77s
2026-01-15 10:31:10.367 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 262, name: 'OutputAudioRawFrame#185', metadata: {} at 4.81s
2026-01-15 10:31:10.367 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 262, name: 'OutputAudioRawFrame#185', metadata: {} at 4.81s
2026-01-15 10:31:10.367 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 917, name: 'UserSpeakingFrame#84', metadata: {} at 5.72s
2026-01-15 10:31:10.367 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 918, name: 'UserSpeakingFrame#85', metadata: {} at 5.72s
2026-01-15 10:31:10.368 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 918, name: 'UserSpeakingFrame#85', metadata: {} at 5.72s
2026-01-15 10:31:10.368 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 915, name: 'OutputAudioRawFrame#477', metadata: {} at 5.72s
2026-01-15 10:31:10.368 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 917, name: 'UserSpeakingFrame#84', metadata: {} at 5.72s
2026-01-15 10:31:10.368 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 915, name: 'OutputAudioRawFrame#477', metadata: {} at 5.72s
2026-01-15 10:31:10.368 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#84
2026-01-15 10:31:10.368 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#477(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.368 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 919, name: 'RTVIServerMessageFrame#42', metadata: {}, data: {'type': 'user-speaking'} at 5.72s
2026-01-15 10:31:10.368 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 915, name: 'OutputAudioRawFrame#477', metadata: {} at 5.72s
2026-01-15 10:31:10.368 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 920, name: 'OutputTransportMessageUrgentFrame#50', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.72s
2026-01-15 10:31:10.368 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#50(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.368 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#42(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.368 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 919, name: 'RTVIServerMessageFrame#42', metadata: {}, data: {'type': 'user-speaking'} at 5.72s
2026-01-15 10:31:10.368 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 919, name: 'RTVIServerMessageFrame#42', metadata: {}, data: {'type': 'user-speaking'} at 5.72s
2026-01-15 10:31:10.368 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 915, name: 'OutputAudioRawFrame#477', metadata: {} at 5.72s
2026-01-15 10:31:10.368 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 920, name: 'OutputTransportMessageUrgentFrame#50', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.72s
2026-01-15 10:31:10.368 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 919, name: 'RTVIServerMessageFrame#42', metadata: {}, data: {'type': 'user-speaking'} at 5.72s
2026-01-15 10:31:10.368 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 919, name: 'RTVIServerMessageFrame#42', metadata: {}, data: {'type': 'user-speaking'} at 5.72s
2026-01-15 10:31:10.368 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 915, name: 'OutputAudioRawFrame#477', metadata: {} at 5.72s
2026-01-15 10:31:10.368 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 920, name: 'OutputTransportMessageUrgentFrame#50', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.72s
2026-01-15 10:31:10.368 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 919, name: 'RTVIServerMessageFrame#42', metadata: {}, data: {'type': 'user-speaking'} at 5.72s
2026-01-15 10:31:10.368 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#42(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.368 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#477(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.369 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 919, name: 'RTVIServerMessageFrame#42', metadata: {}, data: {'type': 'user-speaking'} at 5.72s
2026-01-15 10:31:10.369 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 915, name: 'OutputAudioRawFrame#477', metadata: {} at 5.72s
2026-01-15 10:31:10.369 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 920, name: 'OutputTransportMessageUrgentFrame#50', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.72s
2026-01-15 10:31:10.369 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 919, name: 'RTVIServerMessageFrame#42', metadata: {}, data: {'type': 'user-speaking'} at 5.72s
2026-01-15 10:31:10.369 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#50(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.369 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#42(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.369 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 919, name: 'RTVIServerMessageFrame#42', metadata: {}, data: {'type': 'user-speaking'} at 5.72s
2026-01-15 10:31:10.369 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 919, name: 'RTVIServerMessageFrame#42', metadata: {}, data: {'type': 'user-speaking'} at 5.72s
2026-01-15 10:31:10.369 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 915, name: 'OutputAudioRawFrame#477', metadata: {} at 5.72s
2026-01-15 10:31:10.369 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 915, name: 'OutputAudioRawFrame#477', metadata: {} at 5.72s
2026-01-15 10:31:10.369 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 920, name: 'OutputTransportMessageUrgentFrame#50', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.72s
2026-01-15 10:31:10.369 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 919, name: 'RTVIServerMessageFrame#42', metadata: {}, data: {'type': 'user-speaking'} at 5.72s
2026-01-15 10:31:10.369 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 919, name: 'RTVIServerMessageFrame#42', metadata: {}, data: {'type': 'user-speaking'} at 5.72s
2026-01-15 10:31:10.369 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 919, name: 'RTVIServerMessageFrame#42', metadata: {}, data: {'type': 'user-speaking'} at 5.72s
2026-01-15 10:31:10.369 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#49(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.369 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 921, name: 'InputTransportMessageFrame#49', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.81s
2026-01-15 10:31:10.369 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#49(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.369 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#49(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.369 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:10.369 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:10.369 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 921, name: 'InputTransportMessageFrame#49', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.81s
2026-01-15 10:31:10.369 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 921, name: 'InputTransportMessageFrame#49', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.81s
2026-01-15 10:31:10.369 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 921, name: 'InputTransportMessageFrame#49', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.81s
2026-01-15 10:31:10.369 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 921, name: 'InputTransportMessageFrame#49', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.81s
2026-01-15 10:31:10.369 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 921, name: 'InputTransportMessageFrame#49', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.81s
2026-01-15 10:31:10.369 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 921, name: 'InputTransportMessageFrame#49', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.81s
2026-01-15 10:31:10.407 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 263, name: 'OutputAudioRawFrame#186', metadata: {} at 4.85s
2026-01-15 10:31:10.407 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 263, name: 'OutputAudioRawFrame#186', metadata: {} at 4.85s
2026-01-15 10:31:10.408 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 924, name: 'UserSpeakingFrame#86', metadata: {} at 5.76s
2026-01-15 10:31:10.408 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 925, name: 'UserSpeakingFrame#87', metadata: {} at 5.76s
2026-01-15 10:31:10.408 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 925, name: 'UserSpeakingFrame#87', metadata: {} at 5.76s
2026-01-15 10:31:10.408 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 922, name: 'OutputAudioRawFrame#478', metadata: {} at 5.76s
2026-01-15 10:31:10.408 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 924, name: 'UserSpeakingFrame#86', metadata: {} at 5.76s
2026-01-15 10:31:10.408 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 922, name: 'OutputAudioRawFrame#478', metadata: {} at 5.76s
2026-01-15 10:31:10.408 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#86
2026-01-15 10:31:10.408 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#478(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.408 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 926, name: 'RTVIServerMessageFrame#43', metadata: {}, data: {'type': 'user-speaking'} at 5.76s
2026-01-15 10:31:10.408 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 922, name: 'OutputAudioRawFrame#478', metadata: {} at 5.76s
2026-01-15 10:31:10.408 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 927, name: 'OutputTransportMessageUrgentFrame#51', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.76s
2026-01-15 10:31:10.408 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#51(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.408 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#43(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.408 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 926, name: 'RTVIServerMessageFrame#43', metadata: {}, data: {'type': 'user-speaking'} at 5.76s
2026-01-15 10:31:10.408 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 926, name: 'RTVIServerMessageFrame#43', metadata: {}, data: {'type': 'user-speaking'} at 5.76s
2026-01-15 10:31:10.408 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 922, name: 'OutputAudioRawFrame#478', metadata: {} at 5.76s
2026-01-15 10:31:10.408 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 927, name: 'OutputTransportMessageUrgentFrame#51', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.76s
2026-01-15 10:31:10.409 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 926, name: 'RTVIServerMessageFrame#43', metadata: {}, data: {'type': 'user-speaking'} at 5.76s
2026-01-15 10:31:10.409 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 926, name: 'RTVIServerMessageFrame#43', metadata: {}, data: {'type': 'user-speaking'} at 5.76s
2026-01-15 10:31:10.409 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 922, name: 'OutputAudioRawFrame#478', metadata: {} at 5.76s
2026-01-15 10:31:10.409 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 927, name: 'OutputTransportMessageUrgentFrame#51', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.76s
2026-01-15 10:31:10.409 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 926, name: 'RTVIServerMessageFrame#43', metadata: {}, data: {'type': 'user-speaking'} at 5.76s
2026-01-15 10:31:10.409 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#43(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.409 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#478(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.409 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 926, name: 'RTVIServerMessageFrame#43', metadata: {}, data: {'type': 'user-speaking'} at 5.76s
2026-01-15 10:31:10.409 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 922, name: 'OutputAudioRawFrame#478', metadata: {} at 5.76s
2026-01-15 10:31:10.409 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 927, name: 'OutputTransportMessageUrgentFrame#51', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.76s
2026-01-15 10:31:10.409 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 926, name: 'RTVIServerMessageFrame#43', metadata: {}, data: {'type': 'user-speaking'} at 5.76s
2026-01-15 10:31:10.409 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#51(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.409 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#43(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.409 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 926, name: 'RTVIServerMessageFrame#43', metadata: {}, data: {'type': 'user-speaking'} at 5.76s
2026-01-15 10:31:10.409 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 926, name: 'RTVIServerMessageFrame#43', metadata: {}, data: {'type': 'user-speaking'} at 5.76s
2026-01-15 10:31:10.409 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 922, name: 'OutputAudioRawFrame#478', metadata: {} at 5.76s
2026-01-15 10:31:10.409 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 922, name: 'OutputAudioRawFrame#478', metadata: {} at 5.76s
2026-01-15 10:31:10.409 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 927, name: 'OutputTransportMessageUrgentFrame#51', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.76s
2026-01-15 10:31:10.409 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 926, name: 'RTVIServerMessageFrame#43', metadata: {}, data: {'type': 'user-speaking'} at 5.76s
2026-01-15 10:31:10.409 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 926, name: 'RTVIServerMessageFrame#43', metadata: {}, data: {'type': 'user-speaking'} at 5.76s
2026-01-15 10:31:10.409 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 926, name: 'RTVIServerMessageFrame#43', metadata: {}, data: {'type': 'user-speaking'} at 5.76s
2026-01-15 10:31:10.409 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#50(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.409 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 928, name: 'InputTransportMessageFrame#50', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.85s
2026-01-15 10:31:10.410 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#50(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.410 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#50(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.410 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:10.410 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:10.410 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 928, name: 'InputTransportMessageFrame#50', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.85s
2026-01-15 10:31:10.410 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 928, name: 'InputTransportMessageFrame#50', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.85s
2026-01-15 10:31:10.410 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 928, name: 'InputTransportMessageFrame#50', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.85s
2026-01-15 10:31:10.410 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 928, name: 'InputTransportMessageFrame#50', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.85s
2026-01-15 10:31:10.410 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 928, name: 'InputTransportMessageFrame#50', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.85s
2026-01-15 10:31:10.410 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 928, name: 'InputTransportMessageFrame#50', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.85s
2026-01-15 10:31:10.446 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 264, name: 'OutputAudioRawFrame#187', metadata: {} at 4.89s
2026-01-15 10:31:10.446 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 264, name: 'OutputAudioRawFrame#187', metadata: {} at 4.89s
2026-01-15 10:31:10.447 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 931, name: 'UserSpeakingFrame#88', metadata: {} at 5.80s
2026-01-15 10:31:10.447 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 932, name: 'UserSpeakingFrame#89', metadata: {} at 5.80s
2026-01-15 10:31:10.447 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 932, name: 'UserSpeakingFrame#89', metadata: {} at 5.80s
2026-01-15 10:31:10.447 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 929, name: 'OutputAudioRawFrame#479', metadata: {} at 5.80s
2026-01-15 10:31:10.447 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 931, name: 'UserSpeakingFrame#88', metadata: {} at 5.80s
2026-01-15 10:31:10.447 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 929, name: 'OutputAudioRawFrame#479', metadata: {} at 5.80s
2026-01-15 10:31:10.447 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#88
2026-01-15 10:31:10.447 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#479(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.447 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 933, name: 'RTVIServerMessageFrame#44', metadata: {}, data: {'type': 'user-speaking'} at 5.80s
2026-01-15 10:31:10.447 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 929, name: 'OutputAudioRawFrame#479', metadata: {} at 5.80s
2026-01-15 10:31:10.447 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 934, name: 'OutputTransportMessageUrgentFrame#52', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.80s
2026-01-15 10:31:10.448 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#52(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.448 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#44(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.448 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 933, name: 'RTVIServerMessageFrame#44', metadata: {}, data: {'type': 'user-speaking'} at 5.80s
2026-01-15 10:31:10.448 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 933, name: 'RTVIServerMessageFrame#44', metadata: {}, data: {'type': 'user-speaking'} at 5.80s
2026-01-15 10:31:10.448 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 929, name: 'OutputAudioRawFrame#479', metadata: {} at 5.80s
2026-01-15 10:31:10.448 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 934, name: 'OutputTransportMessageUrgentFrame#52', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.80s
2026-01-15 10:31:10.448 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 933, name: 'RTVIServerMessageFrame#44', metadata: {}, data: {'type': 'user-speaking'} at 5.80s
2026-01-15 10:31:10.448 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 933, name: 'RTVIServerMessageFrame#44', metadata: {}, data: {'type': 'user-speaking'} at 5.80s
2026-01-15 10:31:10.448 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 929, name: 'OutputAudioRawFrame#479', metadata: {} at 5.80s
2026-01-15 10:31:10.448 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 934, name: 'OutputTransportMessageUrgentFrame#52', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.80s
2026-01-15 10:31:10.448 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 933, name: 'RTVIServerMessageFrame#44', metadata: {}, data: {'type': 'user-speaking'} at 5.80s
2026-01-15 10:31:10.448 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#44(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.448 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#479(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.448 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 933, name: 'RTVIServerMessageFrame#44', metadata: {}, data: {'type': 'user-speaking'} at 5.80s
2026-01-15 10:31:10.448 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 929, name: 'OutputAudioRawFrame#479', metadata: {} at 5.80s
2026-01-15 10:31:10.448 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 934, name: 'OutputTransportMessageUrgentFrame#52', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.80s
2026-01-15 10:31:10.448 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 933, name: 'RTVIServerMessageFrame#44', metadata: {}, data: {'type': 'user-speaking'} at 5.80s
2026-01-15 10:31:10.448 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#52(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.448 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#44(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.449 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 933, name: 'RTVIServerMessageFrame#44', metadata: {}, data: {'type': 'user-speaking'} at 5.80s
2026-01-15 10:31:10.449 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 933, name: 'RTVIServerMessageFrame#44', metadata: {}, data: {'type': 'user-speaking'} at 5.80s
2026-01-15 10:31:10.449 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 929, name: 'OutputAudioRawFrame#479', metadata: {} at 5.80s
2026-01-15 10:31:10.449 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 929, name: 'OutputAudioRawFrame#479', metadata: {} at 5.80s
2026-01-15 10:31:10.449 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 934, name: 'OutputTransportMessageUrgentFrame#52', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.80s
2026-01-15 10:31:10.449 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 933, name: 'RTVIServerMessageFrame#44', metadata: {}, data: {'type': 'user-speaking'} at 5.80s
2026-01-15 10:31:10.449 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 933, name: 'RTVIServerMessageFrame#44', metadata: {}, data: {'type': 'user-speaking'} at 5.80s
2026-01-15 10:31:10.449 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 933, name: 'RTVIServerMessageFrame#44', metadata: {}, data: {'type': 'user-speaking'} at 5.80s
2026-01-15 10:31:10.449 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#51(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.449 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 935, name: 'InputTransportMessageFrame#51', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.89s
2026-01-15 10:31:10.449 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#51(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.449 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#51(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.449 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:10.449 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:10.449 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 935, name: 'InputTransportMessageFrame#51', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.89s
2026-01-15 10:31:10.449 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 935, name: 'InputTransportMessageFrame#51', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.89s
2026-01-15 10:31:10.449 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 935, name: 'InputTransportMessageFrame#51', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.89s
2026-01-15 10:31:10.449 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 935, name: 'InputTransportMessageFrame#51', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.89s
2026-01-15 10:31:10.449 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 935, name: 'InputTransportMessageFrame#51', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.89s
2026-01-15 10:31:10.449 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 935, name: 'InputTransportMessageFrame#51', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.89s
2026-01-15 10:31:10.487 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 266, name: 'OutputAudioRawFrame#189', metadata: {} at 4.93s
2026-01-15 10:31:10.487 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 266, name: 'OutputAudioRawFrame#189', metadata: {} at 4.93s
2026-01-15 10:31:10.488 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 938, name: 'UserSpeakingFrame#90', metadata: {} at 5.84s
2026-01-15 10:31:10.488 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 939, name: 'UserSpeakingFrame#91', metadata: {} at 5.84s
2026-01-15 10:31:10.488 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 939, name: 'UserSpeakingFrame#91', metadata: {} at 5.84s
2026-01-15 10:31:10.488 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 936, name: 'OutputAudioRawFrame#480', metadata: {} at 5.84s
2026-01-15 10:31:10.488 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 938, name: 'UserSpeakingFrame#90', metadata: {} at 5.84s
2026-01-15 10:31:10.488 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 936, name: 'OutputAudioRawFrame#480', metadata: {} at 5.84s
2026-01-15 10:31:10.488 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#90
2026-01-15 10:31:10.488 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#480(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.488 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 940, name: 'RTVIServerMessageFrame#45', metadata: {}, data: {'type': 'user-speaking'} at 5.84s
2026-01-15 10:31:10.488 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 936, name: 'OutputAudioRawFrame#480', metadata: {} at 5.84s
2026-01-15 10:31:10.488 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 941, name: 'OutputTransportMessageUrgentFrame#53', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.84s
2026-01-15 10:31:10.489 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#53(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.489 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#45(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.489 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 940, name: 'RTVIServerMessageFrame#45', metadata: {}, data: {'type': 'user-speaking'} at 5.84s
2026-01-15 10:31:10.489 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 940, name: 'RTVIServerMessageFrame#45', metadata: {}, data: {'type': 'user-speaking'} at 5.84s
2026-01-15 10:31:10.489 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 936, name: 'OutputAudioRawFrame#480', metadata: {} at 5.84s
2026-01-15 10:31:10.489 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 941, name: 'OutputTransportMessageUrgentFrame#53', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.84s
2026-01-15 10:31:10.489 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 940, name: 'RTVIServerMessageFrame#45', metadata: {}, data: {'type': 'user-speaking'} at 5.84s
2026-01-15 10:31:10.489 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 940, name: 'RTVIServerMessageFrame#45', metadata: {}, data: {'type': 'user-speaking'} at 5.84s
2026-01-15 10:31:10.489 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 936, name: 'OutputAudioRawFrame#480', metadata: {} at 5.84s
2026-01-15 10:31:10.489 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 941, name: 'OutputTransportMessageUrgentFrame#53', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.84s
2026-01-15 10:31:10.489 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 940, name: 'RTVIServerMessageFrame#45', metadata: {}, data: {'type': 'user-speaking'} at 5.84s
2026-01-15 10:31:10.489 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#45(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.489 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#480(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.489 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 940, name: 'RTVIServerMessageFrame#45', metadata: {}, data: {'type': 'user-speaking'} at 5.84s
2026-01-15 10:31:10.489 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 936, name: 'OutputAudioRawFrame#480', metadata: {} at 5.84s
2026-01-15 10:31:10.489 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 941, name: 'OutputTransportMessageUrgentFrame#53', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.84s
2026-01-15 10:31:10.489 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 940, name: 'RTVIServerMessageFrame#45', metadata: {}, data: {'type': 'user-speaking'} at 5.84s
2026-01-15 10:31:10.490 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#53(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.490 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#45(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.490 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 940, name: 'RTVIServerMessageFrame#45', metadata: {}, data: {'type': 'user-speaking'} at 5.84s
2026-01-15 10:31:10.490 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 940, name: 'RTVIServerMessageFrame#45', metadata: {}, data: {'type': 'user-speaking'} at 5.84s
2026-01-15 10:31:10.490 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 936, name: 'OutputAudioRawFrame#480', metadata: {} at 5.84s
2026-01-15 10:31:10.490 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 936, name: 'OutputAudioRawFrame#480', metadata: {} at 5.84s
2026-01-15 10:31:10.490 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 941, name: 'OutputTransportMessageUrgentFrame#53', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.84s
2026-01-15 10:31:10.490 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 940, name: 'RTVIServerMessageFrame#45', metadata: {}, data: {'type': 'user-speaking'} at 5.84s
2026-01-15 10:31:10.490 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 940, name: 'RTVIServerMessageFrame#45', metadata: {}, data: {'type': 'user-speaking'} at 5.84s
2026-01-15 10:31:10.490 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 940, name: 'RTVIServerMessageFrame#45', metadata: {}, data: {'type': 'user-speaking'} at 5.84s
2026-01-15 10:31:10.490 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#52(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.490 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 942, name: 'InputTransportMessageFrame#52', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.93s
2026-01-15 10:31:10.490 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#52(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.490 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#52(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.490 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:10.490 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:10.490 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 942, name: 'InputTransportMessageFrame#52', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.93s
2026-01-15 10:31:10.490 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 942, name: 'InputTransportMessageFrame#52', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.93s
2026-01-15 10:31:10.490 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 942, name: 'InputTransportMessageFrame#52', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.93s
2026-01-15 10:31:10.490 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 942, name: 'InputTransportMessageFrame#52', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.93s
2026-01-15 10:31:10.491 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 942, name: 'InputTransportMessageFrame#52', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.93s
2026-01-15 10:31:10.491 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 942, name: 'InputTransportMessageFrame#52', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.93s
2026-01-15 10:31:10.527 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 267, name: 'OutputAudioRawFrame#190', metadata: {} at 4.97s
2026-01-15 10:31:10.527 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 267, name: 'OutputAudioRawFrame#190', metadata: {} at 4.97s
2026-01-15 10:31:10.528 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 945, name: 'UserSpeakingFrame#92', metadata: {} at 5.88s
2026-01-15 10:31:10.528 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 946, name: 'UserSpeakingFrame#93', metadata: {} at 5.88s
2026-01-15 10:31:10.528 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 946, name: 'UserSpeakingFrame#93', metadata: {} at 5.88s
2026-01-15 10:31:10.528 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 943, name: 'OutputAudioRawFrame#481', metadata: {} at 5.88s
2026-01-15 10:31:10.528 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 945, name: 'UserSpeakingFrame#92', metadata: {} at 5.88s
2026-01-15 10:31:10.528 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 943, name: 'OutputAudioRawFrame#481', metadata: {} at 5.88s
2026-01-15 10:31:10.528 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#92
2026-01-15 10:31:10.528 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#481(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.528 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 947, name: 'RTVIServerMessageFrame#46', metadata: {}, data: {'type': 'user-speaking'} at 5.88s
2026-01-15 10:31:10.528 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 943, name: 'OutputAudioRawFrame#481', metadata: {} at 5.88s
2026-01-15 10:31:10.528 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 948, name: 'OutputTransportMessageUrgentFrame#54', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.88s
2026-01-15 10:31:10.529 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#54(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.529 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#46(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.529 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 947, name: 'RTVIServerMessageFrame#46', metadata: {}, data: {'type': 'user-speaking'} at 5.88s
2026-01-15 10:31:10.529 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 947, name: 'RTVIServerMessageFrame#46', metadata: {}, data: {'type': 'user-speaking'} at 5.88s
2026-01-15 10:31:10.529 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 943, name: 'OutputAudioRawFrame#481', metadata: {} at 5.88s
2026-01-15 10:31:10.529 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 948, name: 'OutputTransportMessageUrgentFrame#54', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.88s
2026-01-15 10:31:10.529 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 947, name: 'RTVIServerMessageFrame#46', metadata: {}, data: {'type': 'user-speaking'} at 5.88s
2026-01-15 10:31:10.529 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 947, name: 'RTVIServerMessageFrame#46', metadata: {}, data: {'type': 'user-speaking'} at 5.88s
2026-01-15 10:31:10.529 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 943, name: 'OutputAudioRawFrame#481', metadata: {} at 5.88s
2026-01-15 10:31:10.529 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 948, name: 'OutputTransportMessageUrgentFrame#54', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.88s
2026-01-15 10:31:10.529 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 947, name: 'RTVIServerMessageFrame#46', metadata: {}, data: {'type': 'user-speaking'} at 5.88s
2026-01-15 10:31:10.530 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#46(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.530 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#481(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.530 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 947, name: 'RTVIServerMessageFrame#46', metadata: {}, data: {'type': 'user-speaking'} at 5.88s
2026-01-15 10:31:10.530 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 943, name: 'OutputAudioRawFrame#481', metadata: {} at 5.88s
2026-01-15 10:31:10.530 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 948, name: 'OutputTransportMessageUrgentFrame#54', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.88s
2026-01-15 10:31:10.530 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 947, name: 'RTVIServerMessageFrame#46', metadata: {}, data: {'type': 'user-speaking'} at 5.88s
2026-01-15 10:31:10.530 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#54(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.530 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#46(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.530 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 947, name: 'RTVIServerMessageFrame#46', metadata: {}, data: {'type': 'user-speaking'} at 5.88s
2026-01-15 10:31:10.530 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 947, name: 'RTVIServerMessageFrame#46', metadata: {}, data: {'type': 'user-speaking'} at 5.88s
2026-01-15 10:31:10.530 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 943, name: 'OutputAudioRawFrame#481', metadata: {} at 5.88s
2026-01-15 10:31:10.530 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 943, name: 'OutputAudioRawFrame#481', metadata: {} at 5.88s
2026-01-15 10:31:10.530 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 948, name: 'OutputTransportMessageUrgentFrame#54', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.88s
2026-01-15 10:31:10.530 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 947, name: 'RTVIServerMessageFrame#46', metadata: {}, data: {'type': 'user-speaking'} at 5.88s
2026-01-15 10:31:10.530 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 947, name: 'RTVIServerMessageFrame#46', metadata: {}, data: {'type': 'user-speaking'} at 5.88s
2026-01-15 10:31:10.530 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 947, name: 'RTVIServerMessageFrame#46', metadata: {}, data: {'type': 'user-speaking'} at 5.88s
2026-01-15 10:31:10.530 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#53(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.531 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 949, name: 'InputTransportMessageFrame#53', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.97s
2026-01-15 10:31:10.531 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#53(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.531 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#53(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.531 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:10.531 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:10.531 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 949, name: 'InputTransportMessageFrame#53', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.97s
2026-01-15 10:31:10.531 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 949, name: 'InputTransportMessageFrame#53', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.97s
2026-01-15 10:31:10.531 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 949, name: 'InputTransportMessageFrame#53', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.97s
2026-01-15 10:31:10.531 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 949, name: 'InputTransportMessageFrame#53', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.97s
2026-01-15 10:31:10.531 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 949, name: 'InputTransportMessageFrame#53', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.97s
2026-01-15 10:31:10.531 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 949, name: 'InputTransportMessageFrame#53', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 4.97s
2026-01-15 10:31:10.567 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 269, name: 'OutputAudioRawFrame#192', metadata: {} at 5.01s
2026-01-15 10:31:10.567 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 269, name: 'OutputAudioRawFrame#192', metadata: {} at 5.01s
2026-01-15 10:31:10.568 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 952, name: 'UserSpeakingFrame#94', metadata: {} at 5.92s
2026-01-15 10:31:10.568 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 953, name: 'UserSpeakingFrame#95', metadata: {} at 5.92s
2026-01-15 10:31:10.568 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 953, name: 'UserSpeakingFrame#95', metadata: {} at 5.92s
2026-01-15 10:31:10.568 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 950, name: 'OutputAudioRawFrame#482', metadata: {} at 5.92s
2026-01-15 10:31:10.568 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 952, name: 'UserSpeakingFrame#94', metadata: {} at 5.92s
2026-01-15 10:31:10.568 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 950, name: 'OutputAudioRawFrame#482', metadata: {} at 5.92s
2026-01-15 10:31:10.568 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#94
2026-01-15 10:31:10.569 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#482(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.569 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 954, name: 'RTVIServerMessageFrame#47', metadata: {}, data: {'type': 'user-speaking'} at 5.92s
2026-01-15 10:31:10.569 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 950, name: 'OutputAudioRawFrame#482', metadata: {} at 5.92s
2026-01-15 10:31:10.569 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 955, name: 'OutputTransportMessageUrgentFrame#55', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.92s
2026-01-15 10:31:10.569 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#55(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.569 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#47(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.570 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 954, name: 'RTVIServerMessageFrame#47', metadata: {}, data: {'type': 'user-speaking'} at 5.92s
2026-01-15 10:31:10.570 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 954, name: 'RTVIServerMessageFrame#47', metadata: {}, data: {'type': 'user-speaking'} at 5.92s
2026-01-15 10:31:10.570 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 950, name: 'OutputAudioRawFrame#482', metadata: {} at 5.92s
2026-01-15 10:31:10.570 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 955, name: 'OutputTransportMessageUrgentFrame#55', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.92s
2026-01-15 10:31:10.570 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 954, name: 'RTVIServerMessageFrame#47', metadata: {}, data: {'type': 'user-speaking'} at 5.92s
2026-01-15 10:31:10.570 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 954, name: 'RTVIServerMessageFrame#47', metadata: {}, data: {'type': 'user-speaking'} at 5.92s
2026-01-15 10:31:10.570 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 950, name: 'OutputAudioRawFrame#482', metadata: {} at 5.92s
2026-01-15 10:31:10.570 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 955, name: 'OutputTransportMessageUrgentFrame#55', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.92s
2026-01-15 10:31:10.570 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 954, name: 'RTVIServerMessageFrame#47', metadata: {}, data: {'type': 'user-speaking'} at 5.92s
2026-01-15 10:31:10.570 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#47(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.570 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#482(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.570 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 954, name: 'RTVIServerMessageFrame#47', metadata: {}, data: {'type': 'user-speaking'} at 5.92s
2026-01-15 10:31:10.570 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 950, name: 'OutputAudioRawFrame#482', metadata: {} at 5.92s
2026-01-15 10:31:10.570 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 955, name: 'OutputTransportMessageUrgentFrame#55', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.92s
2026-01-15 10:31:10.570 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 954, name: 'RTVIServerMessageFrame#47', metadata: {}, data: {'type': 'user-speaking'} at 5.92s
2026-01-15 10:31:10.570 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#55(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.570 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#47(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.571 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 954, name: 'RTVIServerMessageFrame#47', metadata: {}, data: {'type': 'user-speaking'} at 5.92s
2026-01-15 10:31:10.571 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 954, name: 'RTVIServerMessageFrame#47', metadata: {}, data: {'type': 'user-speaking'} at 5.92s
2026-01-15 10:31:10.571 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 950, name: 'OutputAudioRawFrame#482', metadata: {} at 5.92s
2026-01-15 10:31:10.571 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 950, name: 'OutputAudioRawFrame#482', metadata: {} at 5.92s
2026-01-15 10:31:10.571 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 955, name: 'OutputTransportMessageUrgentFrame#55', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.92s
2026-01-15 10:31:10.571 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 954, name: 'RTVIServerMessageFrame#47', metadata: {}, data: {'type': 'user-speaking'} at 5.92s
2026-01-15 10:31:10.571 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 954, name: 'RTVIServerMessageFrame#47', metadata: {}, data: {'type': 'user-speaking'} at 5.93s
2026-01-15 10:31:10.571 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 954, name: 'RTVIServerMessageFrame#47', metadata: {}, data: {'type': 'user-speaking'} at 5.93s
2026-01-15 10:31:10.571 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#54(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.571 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 956, name: 'InputTransportMessageFrame#54', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.02s
2026-01-15 10:31:10.571 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#54(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.571 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#54(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.571 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:10.571 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:10.572 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 956, name: 'InputTransportMessageFrame#54', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.02s
2026-01-15 10:31:10.572 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 956, name: 'InputTransportMessageFrame#54', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.02s
2026-01-15 10:31:10.572 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 956, name: 'InputTransportMessageFrame#54', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.02s
2026-01-15 10:31:10.572 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 956, name: 'InputTransportMessageFrame#54', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.02s
2026-01-15 10:31:10.572 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 956, name: 'InputTransportMessageFrame#54', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.02s
2026-01-15 10:31:10.572 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 956, name: 'InputTransportMessageFrame#54', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.02s
2026-01-15 10:31:10.607 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 270, name: 'OutputAudioRawFrame#193', metadata: {} at 5.05s
2026-01-15 10:31:10.607 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 270, name: 'OutputAudioRawFrame#193', metadata: {} at 5.05s
2026-01-15 10:31:10.609 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 959, name: 'UserSpeakingFrame#96', metadata: {} at 5.96s
2026-01-15 10:31:10.609 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 960, name: 'UserSpeakingFrame#97', metadata: {} at 5.96s
2026-01-15 10:31:10.609 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 960, name: 'UserSpeakingFrame#97', metadata: {} at 5.96s
2026-01-15 10:31:10.609 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 957, name: 'OutputAudioRawFrame#483', metadata: {} at 5.96s
2026-01-15 10:31:10.609 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 959, name: 'UserSpeakingFrame#96', metadata: {} at 5.96s
2026-01-15 10:31:10.609 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 957, name: 'OutputAudioRawFrame#483', metadata: {} at 5.96s
2026-01-15 10:31:10.609 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#96
2026-01-15 10:31:10.609 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#483(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.609 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 961, name: 'RTVIServerMessageFrame#48', metadata: {}, data: {'type': 'user-speaking'} at 5.96s
2026-01-15 10:31:10.609 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 957, name: 'OutputAudioRawFrame#483', metadata: {} at 5.96s
2026-01-15 10:31:10.609 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 962, name: 'OutputTransportMessageUrgentFrame#56', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.96s
2026-01-15 10:31:10.610 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#56(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.610 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#48(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.610 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 961, name: 'RTVIServerMessageFrame#48', metadata: {}, data: {'type': 'user-speaking'} at 5.96s
2026-01-15 10:31:10.610 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 961, name: 'RTVIServerMessageFrame#48', metadata: {}, data: {'type': 'user-speaking'} at 5.96s
2026-01-15 10:31:10.610 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 957, name: 'OutputAudioRawFrame#483', metadata: {} at 5.96s
2026-01-15 10:31:10.610 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 962, name: 'OutputTransportMessageUrgentFrame#56', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.96s
2026-01-15 10:31:10.610 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 961, name: 'RTVIServerMessageFrame#48', metadata: {}, data: {'type': 'user-speaking'} at 5.96s
2026-01-15 10:31:10.610 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 961, name: 'RTVIServerMessageFrame#48', metadata: {}, data: {'type': 'user-speaking'} at 5.96s
2026-01-15 10:31:10.610 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 957, name: 'OutputAudioRawFrame#483', metadata: {} at 5.96s
2026-01-15 10:31:10.610 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 962, name: 'OutputTransportMessageUrgentFrame#56', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.96s
2026-01-15 10:31:10.611 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 961, name: 'RTVIServerMessageFrame#48', metadata: {}, data: {'type': 'user-speaking'} at 5.96s
2026-01-15 10:31:10.611 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#48(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.611 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#483(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.611 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 961, name: 'RTVIServerMessageFrame#48', metadata: {}, data: {'type': 'user-speaking'} at 5.96s
2026-01-15 10:31:10.611 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 957, name: 'OutputAudioRawFrame#483', metadata: {} at 5.97s
2026-01-15 10:31:10.611 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 962, name: 'OutputTransportMessageUrgentFrame#56', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.97s
2026-01-15 10:31:10.611 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 961, name: 'RTVIServerMessageFrame#48', metadata: {}, data: {'type': 'user-speaking'} at 5.97s
2026-01-15 10:31:10.611 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#56(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.611 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#48(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.611 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 961, name: 'RTVIServerMessageFrame#48', metadata: {}, data: {'type': 'user-speaking'} at 5.97s
2026-01-15 10:31:10.611 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 961, name: 'RTVIServerMessageFrame#48', metadata: {}, data: {'type': 'user-speaking'} at 5.97s
2026-01-15 10:31:10.611 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 957, name: 'OutputAudioRawFrame#483', metadata: {} at 5.97s
2026-01-15 10:31:10.611 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 957, name: 'OutputAudioRawFrame#483', metadata: {} at 5.97s
2026-01-15 10:31:10.611 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 962, name: 'OutputTransportMessageUrgentFrame#56', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.97s
2026-01-15 10:31:10.611 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 961, name: 'RTVIServerMessageFrame#48', metadata: {}, data: {'type': 'user-speaking'} at 5.97s
2026-01-15 10:31:10.611 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 961, name: 'RTVIServerMessageFrame#48', metadata: {}, data: {'type': 'user-speaking'} at 5.97s
2026-01-15 10:31:10.611 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 961, name: 'RTVIServerMessageFrame#48', metadata: {}, data: {'type': 'user-speaking'} at 5.97s
2026-01-15 10:31:10.612 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#55(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.612 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 963, name: 'InputTransportMessageFrame#55', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.06s
2026-01-15 10:31:10.612 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#55(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.612 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#55(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.612 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:10.612 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:10.612 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 963, name: 'InputTransportMessageFrame#55', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.06s
2026-01-15 10:31:10.612 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 963, name: 'InputTransportMessageFrame#55', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.06s
2026-01-15 10:31:10.612 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 963, name: 'InputTransportMessageFrame#55', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.06s
2026-01-15 10:31:10.612 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 963, name: 'InputTransportMessageFrame#55', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.06s
2026-01-15 10:31:10.612 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 963, name: 'InputTransportMessageFrame#55', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.06s
2026-01-15 10:31:10.612 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 963, name: 'InputTransportMessageFrame#55', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.06s
2026-01-15 10:31:10.647 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 272, name: 'OutputAudioRawFrame#195', metadata: {} at 5.09s
2026-01-15 10:31:10.647 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 272, name: 'OutputAudioRawFrame#195', metadata: {} at 5.09s
2026-01-15 10:31:10.648 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 966, name: 'UserSpeakingFrame#98', metadata: {} at 6.00s
2026-01-15 10:31:10.648 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 967, name: 'UserSpeakingFrame#99', metadata: {} at 6.00s
2026-01-15 10:31:10.648 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 967, name: 'UserSpeakingFrame#99', metadata: {} at 6.00s
2026-01-15 10:31:10.648 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 964, name: 'OutputAudioRawFrame#484', metadata: {} at 6.00s
2026-01-15 10:31:10.649 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 966, name: 'UserSpeakingFrame#98', metadata: {} at 6.00s
2026-01-15 10:31:10.649 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 964, name: 'OutputAudioRawFrame#484', metadata: {} at 6.00s
2026-01-15 10:31:10.649 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#98
2026-01-15 10:31:10.649 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#484(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.649 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 968, name: 'RTVIServerMessageFrame#49', metadata: {}, data: {'type': 'user-speaking'} at 6.00s
2026-01-15 10:31:10.649 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 964, name: 'OutputAudioRawFrame#484', metadata: {} at 6.00s
2026-01-15 10:31:10.649 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 969, name: 'OutputTransportMessageUrgentFrame#57', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.00s
2026-01-15 10:31:10.650 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#57(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.650 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#49(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.650 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 968, name: 'RTVIServerMessageFrame#49', metadata: {}, data: {'type': 'user-speaking'} at 6.00s
2026-01-15 10:31:10.650 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 968, name: 'RTVIServerMessageFrame#49', metadata: {}, data: {'type': 'user-speaking'} at 6.00s
2026-01-15 10:31:10.650 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 964, name: 'OutputAudioRawFrame#484', metadata: {} at 6.00s
2026-01-15 10:31:10.650 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 969, name: 'OutputTransportMessageUrgentFrame#57', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.00s
2026-01-15 10:31:10.650 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 968, name: 'RTVIServerMessageFrame#49', metadata: {}, data: {'type': 'user-speaking'} at 6.00s
2026-01-15 10:31:10.650 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 968, name: 'RTVIServerMessageFrame#49', metadata: {}, data: {'type': 'user-speaking'} at 6.00s
2026-01-15 10:31:10.650 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 964, name: 'OutputAudioRawFrame#484', metadata: {} at 6.00s
2026-01-15 10:31:10.650 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 969, name: 'OutputTransportMessageUrgentFrame#57', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.00s
2026-01-15 10:31:10.650 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 968, name: 'RTVIServerMessageFrame#49', metadata: {}, data: {'type': 'user-speaking'} at 6.00s
2026-01-15 10:31:10.650 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#49(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.650 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#484(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.650 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 968, name: 'RTVIServerMessageFrame#49', metadata: {}, data: {'type': 'user-speaking'} at 6.00s
2026-01-15 10:31:10.650 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 964, name: 'OutputAudioRawFrame#484', metadata: {} at 6.00s
2026-01-15 10:31:10.650 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 969, name: 'OutputTransportMessageUrgentFrame#57', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.00s
2026-01-15 10:31:10.650 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 968, name: 'RTVIServerMessageFrame#49', metadata: {}, data: {'type': 'user-speaking'} at 6.00s
2026-01-15 10:31:10.651 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#57(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.651 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#49(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.651 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 968, name: 'RTVIServerMessageFrame#49', metadata: {}, data: {'type': 'user-speaking'} at 6.00s
2026-01-15 10:31:10.651 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 968, name: 'RTVIServerMessageFrame#49', metadata: {}, data: {'type': 'user-speaking'} at 6.00s
2026-01-15 10:31:10.651 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 964, name: 'OutputAudioRawFrame#484', metadata: {} at 6.00s
2026-01-15 10:31:10.651 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 964, name: 'OutputAudioRawFrame#484', metadata: {} at 6.00s
2026-01-15 10:31:10.651 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 969, name: 'OutputTransportMessageUrgentFrame#57', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.01s
2026-01-15 10:31:10.651 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 968, name: 'RTVIServerMessageFrame#49', metadata: {}, data: {'type': 'user-speaking'} at 6.01s
2026-01-15 10:31:10.651 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 968, name: 'RTVIServerMessageFrame#49', metadata: {}, data: {'type': 'user-speaking'} at 6.01s
2026-01-15 10:31:10.651 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 968, name: 'RTVIServerMessageFrame#49', metadata: {}, data: {'type': 'user-speaking'} at 6.01s
2026-01-15 10:31:10.651 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#56(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.651 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 970, name: 'InputTransportMessageFrame#56', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.10s
2026-01-15 10:31:10.651 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#56(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.651 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#56(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.651 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:10.651 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:10.652 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 970, name: 'InputTransportMessageFrame#56', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.10s
2026-01-15 10:31:10.652 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 970, name: 'InputTransportMessageFrame#56', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.10s
2026-01-15 10:31:10.652 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 970, name: 'InputTransportMessageFrame#56', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.10s
2026-01-15 10:31:10.652 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 970, name: 'InputTransportMessageFrame#56', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.10s
2026-01-15 10:31:10.652 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 970, name: 'InputTransportMessageFrame#56', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.10s
2026-01-15 10:31:10.652 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 970, name: 'InputTransportMessageFrame#56', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.10s
2026-01-15 10:31:10.687 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 274, name: 'OutputAudioRawFrame#197', metadata: {} at 5.13s
2026-01-15 10:31:10.687 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 274, name: 'OutputAudioRawFrame#197', metadata: {} at 5.13s
2026-01-15 10:31:10.690 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 973, name: 'UserSpeakingFrame#100', metadata: {} at 6.04s
2026-01-15 10:31:10.690 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 974, name: 'UserSpeakingFrame#101', metadata: {} at 6.04s
2026-01-15 10:31:10.690 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 974, name: 'UserSpeakingFrame#101', metadata: {} at 6.04s
2026-01-15 10:31:10.690 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 971, name: 'OutputAudioRawFrame#485', metadata: {} at 6.04s
2026-01-15 10:31:10.690 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 973, name: 'UserSpeakingFrame#100', metadata: {} at 6.04s
2026-01-15 10:31:10.690 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 971, name: 'OutputAudioRawFrame#485', metadata: {} at 6.04s
2026-01-15 10:31:10.690 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#100
2026-01-15 10:31:10.690 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#485(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.690 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 975, name: 'RTVIServerMessageFrame#50', metadata: {}, data: {'type': 'user-speaking'} at 6.04s
2026-01-15 10:31:10.690 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 971, name: 'OutputAudioRawFrame#485', metadata: {} at 6.04s
2026-01-15 10:31:10.690 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 976, name: 'OutputTransportMessageUrgentFrame#58', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.04s
2026-01-15 10:31:10.691 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#58(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.691 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#50(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.691 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 975, name: 'RTVIServerMessageFrame#50', metadata: {}, data: {'type': 'user-speaking'} at 6.04s
2026-01-15 10:31:10.691 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 975, name: 'RTVIServerMessageFrame#50', metadata: {}, data: {'type': 'user-speaking'} at 6.04s
2026-01-15 10:31:10.691 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 971, name: 'OutputAudioRawFrame#485', metadata: {} at 6.05s
2026-01-15 10:31:10.691 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 976, name: 'OutputTransportMessageUrgentFrame#58', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.05s
2026-01-15 10:31:10.691 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 975, name: 'RTVIServerMessageFrame#50', metadata: {}, data: {'type': 'user-speaking'} at 6.05s
2026-01-15 10:31:10.691 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 975, name: 'RTVIServerMessageFrame#50', metadata: {}, data: {'type': 'user-speaking'} at 6.05s
2026-01-15 10:31:10.691 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 971, name: 'OutputAudioRawFrame#485', metadata: {} at 6.05s
2026-01-15 10:31:10.692 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 976, name: 'OutputTransportMessageUrgentFrame#58', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.05s
2026-01-15 10:31:10.692 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 975, name: 'RTVIServerMessageFrame#50', metadata: {}, data: {'type': 'user-speaking'} at 6.05s
2026-01-15 10:31:10.692 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#50(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.692 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#485(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.692 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 975, name: 'RTVIServerMessageFrame#50', metadata: {}, data: {'type': 'user-speaking'} at 6.05s
2026-01-15 10:31:10.692 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 971, name: 'OutputAudioRawFrame#485', metadata: {} at 6.05s
2026-01-15 10:31:10.692 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 976, name: 'OutputTransportMessageUrgentFrame#58', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.05s
2026-01-15 10:31:10.692 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 975, name: 'RTVIServerMessageFrame#50', metadata: {}, data: {'type': 'user-speaking'} at 6.05s
2026-01-15 10:31:10.692 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#58(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.692 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#50(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.692 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 975, name: 'RTVIServerMessageFrame#50', metadata: {}, data: {'type': 'user-speaking'} at 6.05s
2026-01-15 10:31:10.692 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 975, name: 'RTVIServerMessageFrame#50', metadata: {}, data: {'type': 'user-speaking'} at 6.05s
2026-01-15 10:31:10.692 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 971, name: 'OutputAudioRawFrame#485', metadata: {} at 6.05s
2026-01-15 10:31:10.692 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 971, name: 'OutputAudioRawFrame#485', metadata: {} at 6.05s
2026-01-15 10:31:10.692 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 976, name: 'OutputTransportMessageUrgentFrame#58', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.05s
2026-01-15 10:31:10.692 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 975, name: 'RTVIServerMessageFrame#50', metadata: {}, data: {'type': 'user-speaking'} at 6.05s
2026-01-15 10:31:10.693 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 975, name: 'RTVIServerMessageFrame#50', metadata: {}, data: {'type': 'user-speaking'} at 6.05s
2026-01-15 10:31:10.693 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 975, name: 'RTVIServerMessageFrame#50', metadata: {}, data: {'type': 'user-speaking'} at 6.05s
2026-01-15 10:31:10.693 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#57(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.693 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 977, name: 'InputTransportMessageFrame#57', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.14s
2026-01-15 10:31:10.693 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#57(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.693 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#57(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.693 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:10.693 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:10.693 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 977, name: 'InputTransportMessageFrame#57', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.14s
2026-01-15 10:31:10.693 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 977, name: 'InputTransportMessageFrame#57', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.14s
2026-01-15 10:31:10.693 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 977, name: 'InputTransportMessageFrame#57', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.14s
2026-01-15 10:31:10.693 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 977, name: 'InputTransportMessageFrame#57', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.14s
2026-01-15 10:31:10.693 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 977, name: 'InputTransportMessageFrame#57', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.14s
2026-01-15 10:31:10.693 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 977, name: 'InputTransportMessageFrame#57', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.14s
2026-01-15 10:31:10.727 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 275, name: 'OutputAudioRawFrame#198', metadata: {} at 5.17s
2026-01-15 10:31:10.727 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 275, name: 'OutputAudioRawFrame#198', metadata: {} at 5.17s
2026-01-15 10:31:10.730 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 980, name: 'UserSpeakingFrame#102', metadata: {} at 6.08s
2026-01-15 10:31:10.731 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 981, name: 'UserSpeakingFrame#103', metadata: {} at 6.08s
2026-01-15 10:31:10.731 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 981, name: 'UserSpeakingFrame#103', metadata: {} at 6.08s
2026-01-15 10:31:10.731 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 978, name: 'OutputAudioRawFrame#486', metadata: {} at 6.08s
2026-01-15 10:31:10.732 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 980, name: 'UserSpeakingFrame#102', metadata: {} at 6.09s
2026-01-15 10:31:10.732 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 978, name: 'OutputAudioRawFrame#486', metadata: {} at 6.09s
2026-01-15 10:31:10.732 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#102
2026-01-15 10:31:10.732 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#486(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.733 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 982, name: 'RTVIServerMessageFrame#51', metadata: {}, data: {'type': 'user-speaking'} at 6.09s
2026-01-15 10:31:10.733 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 978, name: 'OutputAudioRawFrame#486', metadata: {} at 6.09s
2026-01-15 10:31:10.733 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 983, name: 'OutputTransportMessageUrgentFrame#59', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.09s
2026-01-15 10:31:10.734 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#59(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.734 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#51(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.734 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 982, name: 'RTVIServerMessageFrame#51', metadata: {}, data: {'type': 'user-speaking'} at 6.09s
2026-01-15 10:31:10.734 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 982, name: 'RTVIServerMessageFrame#51', metadata: {}, data: {'type': 'user-speaking'} at 6.09s
2026-01-15 10:31:10.734 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 978, name: 'OutputAudioRawFrame#486', metadata: {} at 6.09s
2026-01-15 10:31:10.734 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 983, name: 'OutputTransportMessageUrgentFrame#59', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.09s
2026-01-15 10:31:10.734 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 982, name: 'RTVIServerMessageFrame#51', metadata: {}, data: {'type': 'user-speaking'} at 6.09s
2026-01-15 10:31:10.734 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 982, name: 'RTVIServerMessageFrame#51', metadata: {}, data: {'type': 'user-speaking'} at 6.09s
2026-01-15 10:31:10.735 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 978, name: 'OutputAudioRawFrame#486', metadata: {} at 6.09s
2026-01-15 10:31:10.735 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 983, name: 'OutputTransportMessageUrgentFrame#59', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.09s
2026-01-15 10:31:10.735 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 982, name: 'RTVIServerMessageFrame#51', metadata: {}, data: {'type': 'user-speaking'} at 6.09s
2026-01-15 10:31:10.735 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#51(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.735 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#486(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.735 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 982, name: 'RTVIServerMessageFrame#51', metadata: {}, data: {'type': 'user-speaking'} at 6.09s
2026-01-15 10:31:10.735 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 978, name: 'OutputAudioRawFrame#486', metadata: {} at 6.09s
2026-01-15 10:31:10.735 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 983, name: 'OutputTransportMessageUrgentFrame#59', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.09s
2026-01-15 10:31:10.735 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 982, name: 'RTVIServerMessageFrame#51', metadata: {}, data: {'type': 'user-speaking'} at 6.09s
2026-01-15 10:31:10.735 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#59(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.735 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#51(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.735 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 982, name: 'RTVIServerMessageFrame#51', metadata: {}, data: {'type': 'user-speaking'} at 6.09s
2026-01-15 10:31:10.735 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 982, name: 'RTVIServerMessageFrame#51', metadata: {}, data: {'type': 'user-speaking'} at 6.09s
2026-01-15 10:31:10.735 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 978, name: 'OutputAudioRawFrame#486', metadata: {} at 6.09s
2026-01-15 10:31:10.735 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 978, name: 'OutputAudioRawFrame#486', metadata: {} at 6.09s
2026-01-15 10:31:10.735 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 983, name: 'OutputTransportMessageUrgentFrame#59', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.09s
2026-01-15 10:31:10.735 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 982, name: 'RTVIServerMessageFrame#51', metadata: {}, data: {'type': 'user-speaking'} at 6.09s
2026-01-15 10:31:10.736 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 982, name: 'RTVIServerMessageFrame#51', metadata: {}, data: {'type': 'user-speaking'} at 6.09s
2026-01-15 10:31:10.736 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 982, name: 'RTVIServerMessageFrame#51', metadata: {}, data: {'type': 'user-speaking'} at 6.09s
2026-01-15 10:31:10.736 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#58(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.736 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 984, name: 'InputTransportMessageFrame#58', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.18s
2026-01-15 10:31:10.736 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#58(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.736 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#58(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.736 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:10.736 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:10.736 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 984, name: 'InputTransportMessageFrame#58', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.18s
2026-01-15 10:31:10.736 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 984, name: 'InputTransportMessageFrame#58', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.18s
2026-01-15 10:31:10.736 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 984, name: 'InputTransportMessageFrame#58', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.18s
2026-01-15 10:31:10.736 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 984, name: 'InputTransportMessageFrame#58', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.18s
2026-01-15 10:31:10.737 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 984, name: 'InputTransportMessageFrame#58', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.18s
2026-01-15 10:31:10.737 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 984, name: 'InputTransportMessageFrame#58', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.18s
2026-01-15 10:31:10.767 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 279, name: 'OutputAudioRawFrame#201', metadata: {} at 5.21s
2026-01-15 10:31:10.767 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 279, name: 'OutputAudioRawFrame#201', metadata: {} at 5.21s
2026-01-15 10:31:10.769 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 987, name: 'UserSpeakingFrame#104', metadata: {} at 6.12s
2026-01-15 10:31:10.769 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 988, name: 'UserSpeakingFrame#105', metadata: {} at 6.12s
2026-01-15 10:31:10.769 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 988, name: 'UserSpeakingFrame#105', metadata: {} at 6.12s
2026-01-15 10:31:10.769 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 985, name: 'OutputAudioRawFrame#487', metadata: {} at 6.12s
2026-01-15 10:31:10.770 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 987, name: 'UserSpeakingFrame#104', metadata: {} at 6.12s
2026-01-15 10:31:10.770 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 985, name: 'OutputAudioRawFrame#487', metadata: {} at 6.12s
2026-01-15 10:31:10.770 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#104
2026-01-15 10:31:10.770 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#487(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.770 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 989, name: 'RTVIServerMessageFrame#52', metadata: {}, data: {'type': 'user-speaking'} at 6.12s
2026-01-15 10:31:10.770 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 985, name: 'OutputAudioRawFrame#487', metadata: {} at 6.12s
2026-01-15 10:31:10.770 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 990, name: 'OutputTransportMessageUrgentFrame#60', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.12s
2026-01-15 10:31:10.771 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#60(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.771 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#52(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.771 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 989, name: 'RTVIServerMessageFrame#52', metadata: {}, data: {'type': 'user-speaking'} at 6.12s
2026-01-15 10:31:10.771 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 989, name: 'RTVIServerMessageFrame#52', metadata: {}, data: {'type': 'user-speaking'} at 6.12s
2026-01-15 10:31:10.771 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 985, name: 'OutputAudioRawFrame#487', metadata: {} at 6.13s
2026-01-15 10:31:10.771 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 990, name: 'OutputTransportMessageUrgentFrame#60', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.13s
2026-01-15 10:31:10.771 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 989, name: 'RTVIServerMessageFrame#52', metadata: {}, data: {'type': 'user-speaking'} at 6.13s
2026-01-15 10:31:10.771 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 989, name: 'RTVIServerMessageFrame#52', metadata: {}, data: {'type': 'user-speaking'} at 6.13s
2026-01-15 10:31:10.771 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 985, name: 'OutputAudioRawFrame#487', metadata: {} at 6.13s
2026-01-15 10:31:10.771 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 990, name: 'OutputTransportMessageUrgentFrame#60', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.13s
2026-01-15 10:31:10.771 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 989, name: 'RTVIServerMessageFrame#52', metadata: {}, data: {'type': 'user-speaking'} at 6.13s
2026-01-15 10:31:10.771 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#52(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.771 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#487(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.771 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 989, name: 'RTVIServerMessageFrame#52', metadata: {}, data: {'type': 'user-speaking'} at 6.13s
2026-01-15 10:31:10.771 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 985, name: 'OutputAudioRawFrame#487', metadata: {} at 6.13s
2026-01-15 10:31:10.771 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 990, name: 'OutputTransportMessageUrgentFrame#60', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.13s
2026-01-15 10:31:10.771 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 989, name: 'RTVIServerMessageFrame#52', metadata: {}, data: {'type': 'user-speaking'} at 6.13s
2026-01-15 10:31:10.772 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#60(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.772 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#52(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.772 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 989, name: 'RTVIServerMessageFrame#52', metadata: {}, data: {'type': 'user-speaking'} at 6.13s
2026-01-15 10:31:10.772 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 989, name: 'RTVIServerMessageFrame#52', metadata: {}, data: {'type': 'user-speaking'} at 6.13s
2026-01-15 10:31:10.772 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 985, name: 'OutputAudioRawFrame#487', metadata: {} at 6.13s
2026-01-15 10:31:10.772 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 985, name: 'OutputAudioRawFrame#487', metadata: {} at 6.13s
2026-01-15 10:31:10.772 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 990, name: 'OutputTransportMessageUrgentFrame#60', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.13s
2026-01-15 10:31:10.772 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 989, name: 'RTVIServerMessageFrame#52', metadata: {}, data: {'type': 'user-speaking'} at 6.13s
2026-01-15 10:31:10.772 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 989, name: 'RTVIServerMessageFrame#52', metadata: {}, data: {'type': 'user-speaking'} at 6.13s
2026-01-15 10:31:10.772 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 989, name: 'RTVIServerMessageFrame#52', metadata: {}, data: {'type': 'user-speaking'} at 6.13s
2026-01-15 10:31:10.772 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#59(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.772 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 991, name: 'InputTransportMessageFrame#59', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.22s
2026-01-15 10:31:10.773 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#59(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.773 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#59(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.773 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:10.773 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:10.773 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 991, name: 'InputTransportMessageFrame#59', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.22s
2026-01-15 10:31:10.773 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 991, name: 'InputTransportMessageFrame#59', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.22s
2026-01-15 10:31:10.773 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 991, name: 'InputTransportMessageFrame#59', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.22s
2026-01-15 10:31:10.773 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 991, name: 'InputTransportMessageFrame#59', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.22s
2026-01-15 10:31:10.773 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 991, name: 'InputTransportMessageFrame#59', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.22s
2026-01-15 10:31:10.773 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 991, name: 'InputTransportMessageFrame#59', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.22s
2026-01-15 10:31:10.807 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 280, name: 'OutputAudioRawFrame#202', metadata: {} at 5.25s
2026-01-15 10:31:10.807 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 280, name: 'OutputAudioRawFrame#202', metadata: {} at 5.25s
2026-01-15 10:31:10.810 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 994, name: 'UserSpeakingFrame#106', metadata: {} at 6.16s
2026-01-15 10:31:10.810 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 995, name: 'UserSpeakingFrame#107', metadata: {} at 6.16s
2026-01-15 10:31:10.810 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 995, name: 'UserSpeakingFrame#107', metadata: {} at 6.16s
2026-01-15 10:31:10.810 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 992, name: 'OutputAudioRawFrame#488', metadata: {} at 6.16s
2026-01-15 10:31:10.810 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 994, name: 'UserSpeakingFrame#106', metadata: {} at 6.16s
2026-01-15 10:31:10.810 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 992, name: 'OutputAudioRawFrame#488', metadata: {} at 6.16s
2026-01-15 10:31:10.810 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#106
2026-01-15 10:31:10.810 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#488(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.810 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 996, name: 'RTVIServerMessageFrame#53', metadata: {}, data: {'type': 'user-speaking'} at 6.16s
2026-01-15 10:31:10.810 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 992, name: 'OutputAudioRawFrame#488', metadata: {} at 6.16s
2026-01-15 10:31:10.811 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 997, name: 'OutputTransportMessageUrgentFrame#61', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.16s
2026-01-15 10:31:10.811 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#61(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.811 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#53(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.811 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 996, name: 'RTVIServerMessageFrame#53', metadata: {}, data: {'type': 'user-speaking'} at 6.16s
2026-01-15 10:31:10.811 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 996, name: 'RTVIServerMessageFrame#53', metadata: {}, data: {'type': 'user-speaking'} at 6.17s
2026-01-15 10:31:10.812 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 992, name: 'OutputAudioRawFrame#488', metadata: {} at 6.17s
2026-01-15 10:31:10.812 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 997, name: 'OutputTransportMessageUrgentFrame#61', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.17s
2026-01-15 10:31:10.812 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 996, name: 'RTVIServerMessageFrame#53', metadata: {}, data: {'type': 'user-speaking'} at 6.17s
2026-01-15 10:31:10.812 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 996, name: 'RTVIServerMessageFrame#53', metadata: {}, data: {'type': 'user-speaking'} at 6.17s
2026-01-15 10:31:10.812 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 992, name: 'OutputAudioRawFrame#488', metadata: {} at 6.17s
2026-01-15 10:31:10.812 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 997, name: 'OutputTransportMessageUrgentFrame#61', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.17s
2026-01-15 10:31:10.812 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 996, name: 'RTVIServerMessageFrame#53', metadata: {}, data: {'type': 'user-speaking'} at 6.17s
2026-01-15 10:31:10.812 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#53(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.812 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#488(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.812 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 996, name: 'RTVIServerMessageFrame#53', metadata: {}, data: {'type': 'user-speaking'} at 6.17s
2026-01-15 10:31:10.812 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 992, name: 'OutputAudioRawFrame#488', metadata: {} at 6.17s
2026-01-15 10:31:10.812 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 997, name: 'OutputTransportMessageUrgentFrame#61', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.17s
2026-01-15 10:31:10.812 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 996, name: 'RTVIServerMessageFrame#53', metadata: {}, data: {'type': 'user-speaking'} at 6.17s
2026-01-15 10:31:10.812 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#61(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.812 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#53(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.812 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 996, name: 'RTVIServerMessageFrame#53', metadata: {}, data: {'type': 'user-speaking'} at 6.17s
2026-01-15 10:31:10.812 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 996, name: 'RTVIServerMessageFrame#53', metadata: {}, data: {'type': 'user-speaking'} at 6.17s
2026-01-15 10:31:10.813 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 992, name: 'OutputAudioRawFrame#488', metadata: {} at 6.17s
2026-01-15 10:31:10.813 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 992, name: 'OutputAudioRawFrame#488', metadata: {} at 6.17s
2026-01-15 10:31:10.813 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 997, name: 'OutputTransportMessageUrgentFrame#61', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.17s
2026-01-15 10:31:10.813 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 996, name: 'RTVIServerMessageFrame#53', metadata: {}, data: {'type': 'user-speaking'} at 6.17s
2026-01-15 10:31:10.813 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 996, name: 'RTVIServerMessageFrame#53', metadata: {}, data: {'type': 'user-speaking'} at 6.17s
2026-01-15 10:31:10.813 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 996, name: 'RTVIServerMessageFrame#53', metadata: {}, data: {'type': 'user-speaking'} at 6.17s
2026-01-15 10:31:10.813 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#60(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.813 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 998, name: 'InputTransportMessageFrame#60', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.26s
2026-01-15 10:31:10.813 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#60(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.813 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#60(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.813 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:10.813 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:10.813 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 998, name: 'InputTransportMessageFrame#60', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.26s
2026-01-15 10:31:10.813 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 998, name: 'InputTransportMessageFrame#60', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.26s
2026-01-15 10:31:10.813 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 998, name: 'InputTransportMessageFrame#60', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.26s
2026-01-15 10:31:10.813 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 998, name: 'InputTransportMessageFrame#60', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.26s
2026-01-15 10:31:10.814 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 998, name: 'InputTransportMessageFrame#60', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.26s
2026-01-15 10:31:10.814 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 998, name: 'InputTransportMessageFrame#60', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.26s
2026-01-15 10:31:10.847 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 282, name: 'OutputAudioRawFrame#204', metadata: {} at 5.29s
2026-01-15 10:31:10.847 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 282, name: 'OutputAudioRawFrame#204', metadata: {} at 5.29s
2026-01-15 10:31:10.850 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 1001, name: 'UserSpeakingFrame#108', metadata: {} at 6.20s
2026-01-15 10:31:10.850 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 1002, name: 'UserSpeakingFrame#109', metadata: {} at 6.20s
2026-01-15 10:31:10.850 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 1002, name: 'UserSpeakingFrame#109', metadata: {} at 6.20s
2026-01-15 10:31:10.850 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 999, name: 'OutputAudioRawFrame#489', metadata: {} at 6.20s
2026-01-15 10:31:10.850 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 1001, name: 'UserSpeakingFrame#108', metadata: {} at 6.20s
2026-01-15 10:31:10.850 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 999, name: 'OutputAudioRawFrame#489', metadata: {} at 6.20s
2026-01-15 10:31:10.850 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#108
2026-01-15 10:31:10.850 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#489(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.850 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1003, name: 'RTVIServerMessageFrame#54', metadata: {}, data: {'type': 'user-speaking'} at 6.20s
2026-01-15 10:31:10.850 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 999, name: 'OutputAudioRawFrame#489', metadata: {} at 6.20s
2026-01-15 10:31:10.850 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1004, name: 'OutputTransportMessageUrgentFrame#62', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.20s
2026-01-15 10:31:10.851 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#62(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.851 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#54(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.851 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 1003, name: 'RTVIServerMessageFrame#54', metadata: {}, data: {'type': 'user-speaking'} at 6.20s
2026-01-15 10:31:10.851 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1003, name: 'RTVIServerMessageFrame#54', metadata: {}, data: {'type': 'user-speaking'} at 6.20s
2026-01-15 10:31:10.851 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 999, name: 'OutputAudioRawFrame#489', metadata: {} at 6.21s
2026-01-15 10:31:10.851 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1004, name: 'OutputTransportMessageUrgentFrame#62', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.21s
2026-01-15 10:31:10.851 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1003, name: 'RTVIServerMessageFrame#54', metadata: {}, data: {'type': 'user-speaking'} at 6.21s
2026-01-15 10:31:10.851 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1003, name: 'RTVIServerMessageFrame#54', metadata: {}, data: {'type': 'user-speaking'} at 6.21s
2026-01-15 10:31:10.851 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 999, name: 'OutputAudioRawFrame#489', metadata: {} at 6.21s
2026-01-15 10:31:10.851 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1004, name: 'OutputTransportMessageUrgentFrame#62', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.21s
2026-01-15 10:31:10.851 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1003, name: 'RTVIServerMessageFrame#54', metadata: {}, data: {'type': 'user-speaking'} at 6.21s
2026-01-15 10:31:10.852 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#54(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.852 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#489(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.852 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1003, name: 'RTVIServerMessageFrame#54', metadata: {}, data: {'type': 'user-speaking'} at 6.21s
2026-01-15 10:31:10.852 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 999, name: 'OutputAudioRawFrame#489', metadata: {} at 6.21s
2026-01-15 10:31:10.852 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1004, name: 'OutputTransportMessageUrgentFrame#62', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.21s
2026-01-15 10:31:10.852 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1003, name: 'RTVIServerMessageFrame#54', metadata: {}, data: {'type': 'user-speaking'} at 6.21s
2026-01-15 10:31:10.852 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#62(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.852 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#54(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.852 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1003, name: 'RTVIServerMessageFrame#54', metadata: {}, data: {'type': 'user-speaking'} at 6.21s
2026-01-15 10:31:10.852 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1003, name: 'RTVIServerMessageFrame#54', metadata: {}, data: {'type': 'user-speaking'} at 6.21s
2026-01-15 10:31:10.852 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 999, name: 'OutputAudioRawFrame#489', metadata: {} at 6.21s
2026-01-15 10:31:10.852 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 999, name: 'OutputAudioRawFrame#489', metadata: {} at 6.21s
2026-01-15 10:31:10.852 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1004, name: 'OutputTransportMessageUrgentFrame#62', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.21s
2026-01-15 10:31:10.852 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1003, name: 'RTVIServerMessageFrame#54', metadata: {}, data: {'type': 'user-speaking'} at 6.21s
2026-01-15 10:31:10.853 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1003, name: 'RTVIServerMessageFrame#54', metadata: {}, data: {'type': 'user-speaking'} at 6.21s
2026-01-15 10:31:10.853 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1003, name: 'RTVIServerMessageFrame#54', metadata: {}, data: {'type': 'user-speaking'} at 6.21s
2026-01-15 10:31:10.853 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#61(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.853 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1005, name: 'InputTransportMessageFrame#61', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.30s
2026-01-15 10:31:10.853 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#61(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.853 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#61(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.853 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:10.853 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:10.853 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1005, name: 'InputTransportMessageFrame#61', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.30s
2026-01-15 10:31:10.853 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1005, name: 'InputTransportMessageFrame#61', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.30s
2026-01-15 10:31:10.853 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1005, name: 'InputTransportMessageFrame#61', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.30s
2026-01-15 10:31:10.853 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1005, name: 'InputTransportMessageFrame#61', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.30s
2026-01-15 10:31:10.853 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1005, name: 'InputTransportMessageFrame#61', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.30s
2026-01-15 10:31:10.853 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1005, name: 'InputTransportMessageFrame#61', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.30s
2026-01-15 10:31:10.887 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 283, name: 'OutputAudioRawFrame#205', metadata: {} at 5.33s
2026-01-15 10:31:10.887 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 283, name: 'OutputAudioRawFrame#205', metadata: {} at 5.33s
2026-01-15 10:31:10.890 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 1008, name: 'UserSpeakingFrame#110', metadata: {} at 6.24s
2026-01-15 10:31:10.890 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 1009, name: 'UserSpeakingFrame#111', metadata: {} at 6.24s
2026-01-15 10:31:10.890 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 1009, name: 'UserSpeakingFrame#111', metadata: {} at 6.24s
2026-01-15 10:31:10.890 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1006, name: 'OutputAudioRawFrame#490', metadata: {} at 6.24s
2026-01-15 10:31:10.890 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 1008, name: 'UserSpeakingFrame#110', metadata: {} at 6.24s
2026-01-15 10:31:10.890 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1006, name: 'OutputAudioRawFrame#490', metadata: {} at 6.24s
2026-01-15 10:31:10.891 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#110
2026-01-15 10:31:10.891 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#490(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.891 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1010, name: 'RTVIServerMessageFrame#55', metadata: {}, data: {'type': 'user-speaking'} at 6.25s
2026-01-15 10:31:10.891 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1006, name: 'OutputAudioRawFrame#490', metadata: {} at 6.25s
2026-01-15 10:31:10.891 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1011, name: 'OutputTransportMessageUrgentFrame#63', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.25s
2026-01-15 10:31:10.892 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#63(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.892 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#55(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.892 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 1010, name: 'RTVIServerMessageFrame#55', metadata: {}, data: {'type': 'user-speaking'} at 6.25s
2026-01-15 10:31:10.892 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1010, name: 'RTVIServerMessageFrame#55', metadata: {}, data: {'type': 'user-speaking'} at 6.25s
2026-01-15 10:31:10.893 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1006, name: 'OutputAudioRawFrame#490', metadata: {} at 6.25s
2026-01-15 10:31:10.893 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1011, name: 'OutputTransportMessageUrgentFrame#63', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.25s
2026-01-15 10:31:10.893 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1010, name: 'RTVIServerMessageFrame#55', metadata: {}, data: {'type': 'user-speaking'} at 6.25s
2026-01-15 10:31:10.893 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1010, name: 'RTVIServerMessageFrame#55', metadata: {}, data: {'type': 'user-speaking'} at 6.25s
2026-01-15 10:31:10.893 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1006, name: 'OutputAudioRawFrame#490', metadata: {} at 6.25s
2026-01-15 10:31:10.893 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1011, name: 'OutputTransportMessageUrgentFrame#63', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.25s
2026-01-15 10:31:10.893 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1010, name: 'RTVIServerMessageFrame#55', metadata: {}, data: {'type': 'user-speaking'} at 6.25s
2026-01-15 10:31:10.893 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#55(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.893 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#490(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.893 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1010, name: 'RTVIServerMessageFrame#55', metadata: {}, data: {'type': 'user-speaking'} at 6.25s
2026-01-15 10:31:10.893 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1006, name: 'OutputAudioRawFrame#490', metadata: {} at 6.25s
2026-01-15 10:31:10.893 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1011, name: 'OutputTransportMessageUrgentFrame#63', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.25s
2026-01-15 10:31:10.893 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1010, name: 'RTVIServerMessageFrame#55', metadata: {}, data: {'type': 'user-speaking'} at 6.25s
2026-01-15 10:31:10.894 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#63(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.894 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#55(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.894 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1010, name: 'RTVIServerMessageFrame#55', metadata: {}, data: {'type': 'user-speaking'} at 6.25s
2026-01-15 10:31:10.894 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1010, name: 'RTVIServerMessageFrame#55', metadata: {}, data: {'type': 'user-speaking'} at 6.25s
2026-01-15 10:31:10.894 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1006, name: 'OutputAudioRawFrame#490', metadata: {} at 6.25s
2026-01-15 10:31:10.894 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1006, name: 'OutputAudioRawFrame#490', metadata: {} at 6.25s
2026-01-15 10:31:10.894 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1011, name: 'OutputTransportMessageUrgentFrame#63', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.25s
2026-01-15 10:31:10.894 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1010, name: 'RTVIServerMessageFrame#55', metadata: {}, data: {'type': 'user-speaking'} at 6.25s
2026-01-15 10:31:10.894 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1010, name: 'RTVIServerMessageFrame#55', metadata: {}, data: {'type': 'user-speaking'} at 6.25s
2026-01-15 10:31:10.894 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1010, name: 'RTVIServerMessageFrame#55', metadata: {}, data: {'type': 'user-speaking'} at 6.25s
2026-01-15 10:31:10.895 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#62(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.895 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1012, name: 'InputTransportMessageFrame#62', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.34s
2026-01-15 10:31:10.895 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#62(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.895 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#62(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.895 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:10.895 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:10.895 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1012, name: 'InputTransportMessageFrame#62', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.34s
2026-01-15 10:31:10.895 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1012, name: 'InputTransportMessageFrame#62', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.34s
2026-01-15 10:31:10.895 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1012, name: 'InputTransportMessageFrame#62', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.34s
2026-01-15 10:31:10.895 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1012, name: 'InputTransportMessageFrame#62', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.34s
2026-01-15 10:31:10.895 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1012, name: 'InputTransportMessageFrame#62', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.34s
2026-01-15 10:31:10.895 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1012, name: 'InputTransportMessageFrame#62', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.34s
2026-01-15 10:31:10.927 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 284, name: 'OutputAudioRawFrame#206', metadata: {} at 5.37s
2026-01-15 10:31:10.927 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 284, name: 'OutputAudioRawFrame#206', metadata: {} at 5.37s
2026-01-15 10:31:10.931 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 1015, name: 'UserSpeakingFrame#112', metadata: {} at 6.29s
2026-01-15 10:31:10.932 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 1016, name: 'UserSpeakingFrame#113', metadata: {} at 6.29s
2026-01-15 10:31:10.932 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 1016, name: 'UserSpeakingFrame#113', metadata: {} at 6.29s
2026-01-15 10:31:10.932 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1013, name: 'OutputAudioRawFrame#491', metadata: {} at 6.29s
2026-01-15 10:31:10.932 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 1015, name: 'UserSpeakingFrame#112', metadata: {} at 6.29s
2026-01-15 10:31:10.932 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1013, name: 'OutputAudioRawFrame#491', metadata: {} at 6.29s
2026-01-15 10:31:10.932 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#112
2026-01-15 10:31:10.932 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#491(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.932 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1017, name: 'RTVIServerMessageFrame#56', metadata: {}, data: {'type': 'user-speaking'} at 6.29s
2026-01-15 10:31:10.932 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1013, name: 'OutputAudioRawFrame#491', metadata: {} at 6.29s
2026-01-15 10:31:10.932 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1018, name: 'OutputTransportMessageUrgentFrame#64', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.29s
2026-01-15 10:31:10.933 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#64(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.934 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#56(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.934 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 1017, name: 'RTVIServerMessageFrame#56', metadata: {}, data: {'type': 'user-speaking'} at 6.29s
2026-01-15 10:31:10.934 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1017, name: 'RTVIServerMessageFrame#56', metadata: {}, data: {'type': 'user-speaking'} at 6.29s
2026-01-15 10:31:10.934 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1013, name: 'OutputAudioRawFrame#491', metadata: {} at 6.29s
2026-01-15 10:31:10.934 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1018, name: 'OutputTransportMessageUrgentFrame#64', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.29s
2026-01-15 10:31:10.934 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1017, name: 'RTVIServerMessageFrame#56', metadata: {}, data: {'type': 'user-speaking'} at 6.29s
2026-01-15 10:31:10.934 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1017, name: 'RTVIServerMessageFrame#56', metadata: {}, data: {'type': 'user-speaking'} at 6.29s
2026-01-15 10:31:10.934 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1013, name: 'OutputAudioRawFrame#491', metadata: {} at 6.29s
2026-01-15 10:31:10.934 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1018, name: 'OutputTransportMessageUrgentFrame#64', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.29s
2026-01-15 10:31:10.934 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1017, name: 'RTVIServerMessageFrame#56', metadata: {}, data: {'type': 'user-speaking'} at 6.29s
2026-01-15 10:31:10.934 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#56(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.934 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#491(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.935 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1017, name: 'RTVIServerMessageFrame#56', metadata: {}, data: {'type': 'user-speaking'} at 6.29s
2026-01-15 10:31:10.935 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1013, name: 'OutputAudioRawFrame#491', metadata: {} at 6.29s
2026-01-15 10:31:10.935 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1018, name: 'OutputTransportMessageUrgentFrame#64', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.29s
2026-01-15 10:31:10.935 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1017, name: 'RTVIServerMessageFrame#56', metadata: {}, data: {'type': 'user-speaking'} at 6.29s
2026-01-15 10:31:10.935 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#64(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.935 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#56(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.935 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1017, name: 'RTVIServerMessageFrame#56', metadata: {}, data: {'type': 'user-speaking'} at 6.29s
2026-01-15 10:31:10.936 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1017, name: 'RTVIServerMessageFrame#56', metadata: {}, data: {'type': 'user-speaking'} at 6.29s
2026-01-15 10:31:10.936 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1013, name: 'OutputAudioRawFrame#491', metadata: {} at 6.29s
2026-01-15 10:31:10.936 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1013, name: 'OutputAudioRawFrame#491', metadata: {} at 6.29s
2026-01-15 10:31:10.936 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1018, name: 'OutputTransportMessageUrgentFrame#64', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.29s
2026-01-15 10:31:10.936 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1017, name: 'RTVIServerMessageFrame#56', metadata: {}, data: {'type': 'user-speaking'} at 6.29s
2026-01-15 10:31:10.936 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1017, name: 'RTVIServerMessageFrame#56', metadata: {}, data: {'type': 'user-speaking'} at 6.29s
2026-01-15 10:31:10.936 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1017, name: 'RTVIServerMessageFrame#56', metadata: {}, data: {'type': 'user-speaking'} at 6.29s
2026-01-15 10:31:10.937 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#63(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.937 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1019, name: 'InputTransportMessageFrame#63', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.38s
2026-01-15 10:31:10.937 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#63(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.937 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#63(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.937 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:10.937 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:10.937 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1019, name: 'InputTransportMessageFrame#63', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.38s
2026-01-15 10:31:10.937 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1019, name: 'InputTransportMessageFrame#63', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.38s
2026-01-15 10:31:10.937 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1019, name: 'InputTransportMessageFrame#63', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.38s
2026-01-15 10:31:10.937 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1019, name: 'InputTransportMessageFrame#63', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.38s
2026-01-15 10:31:10.937 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1019, name: 'InputTransportMessageFrame#63', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.38s
2026-01-15 10:31:10.937 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1019, name: 'InputTransportMessageFrame#63', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.38s
2026-01-15 10:31:10.967 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 286, name: 'OutputAudioRawFrame#208', metadata: {} at 5.41s
2026-01-15 10:31:10.967 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 286, name: 'OutputAudioRawFrame#208', metadata: {} at 5.41s
2026-01-15 10:31:10.969 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 1022, name: 'UserSpeakingFrame#114', metadata: {} at 6.32s
2026-01-15 10:31:10.969 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 1023, name: 'UserSpeakingFrame#115', metadata: {} at 6.32s
2026-01-15 10:31:10.969 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 1023, name: 'UserSpeakingFrame#115', metadata: {} at 6.32s
2026-01-15 10:31:10.969 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1020, name: 'OutputAudioRawFrame#492', metadata: {} at 6.32s
2026-01-15 10:31:10.969 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 1022, name: 'UserSpeakingFrame#114', metadata: {} at 6.32s
2026-01-15 10:31:10.969 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1020, name: 'OutputAudioRawFrame#492', metadata: {} at 6.32s
2026-01-15 10:31:10.969 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#114
2026-01-15 10:31:10.969 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#492(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.969 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1024, name: 'RTVIServerMessageFrame#57', metadata: {}, data: {'type': 'user-speaking'} at 6.32s
2026-01-15 10:31:10.969 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1020, name: 'OutputAudioRawFrame#492', metadata: {} at 6.32s
2026-01-15 10:31:10.969 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1025, name: 'OutputTransportMessageUrgentFrame#65', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.32s
2026-01-15 10:31:10.970 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#65(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.970 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#57(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.970 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 1024, name: 'RTVIServerMessageFrame#57', metadata: {}, data: {'type': 'user-speaking'} at 6.32s
2026-01-15 10:31:10.970 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1024, name: 'RTVIServerMessageFrame#57', metadata: {}, data: {'type': 'user-speaking'} at 6.32s
2026-01-15 10:31:10.970 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1020, name: 'OutputAudioRawFrame#492', metadata: {} at 6.32s
2026-01-15 10:31:10.970 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1025, name: 'OutputTransportMessageUrgentFrame#65', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.32s
2026-01-15 10:31:10.970 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1024, name: 'RTVIServerMessageFrame#57', metadata: {}, data: {'type': 'user-speaking'} at 6.32s
2026-01-15 10:31:10.970 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1024, name: 'RTVIServerMessageFrame#57', metadata: {}, data: {'type': 'user-speaking'} at 6.32s
2026-01-15 10:31:10.971 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1020, name: 'OutputAudioRawFrame#492', metadata: {} at 6.32s
2026-01-15 10:31:10.971 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1025, name: 'OutputTransportMessageUrgentFrame#65', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.32s
2026-01-15 10:31:10.971 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1024, name: 'RTVIServerMessageFrame#57', metadata: {}, data: {'type': 'user-speaking'} at 6.32s
2026-01-15 10:31:10.971 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#57(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.971 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#492(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:10.971 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1024, name: 'RTVIServerMessageFrame#57', metadata: {}, data: {'type': 'user-speaking'} at 6.33s
2026-01-15 10:31:10.971 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1020, name: 'OutputAudioRawFrame#492', metadata: {} at 6.33s
2026-01-15 10:31:10.971 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1025, name: 'OutputTransportMessageUrgentFrame#65', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.33s
2026-01-15 10:31:10.971 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1024, name: 'RTVIServerMessageFrame#57', metadata: {}, data: {'type': 'user-speaking'} at 6.33s
2026-01-15 10:31:10.971 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#65(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.971 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#57(data: {'type': 'user-speaking'})
2026-01-15 10:31:10.971 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1024, name: 'RTVIServerMessageFrame#57', metadata: {}, data: {'type': 'user-speaking'} at 6.33s
2026-01-15 10:31:10.971 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1024, name: 'RTVIServerMessageFrame#57', metadata: {}, data: {'type': 'user-speaking'} at 6.33s
2026-01-15 10:31:10.971 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1020, name: 'OutputAudioRawFrame#492', metadata: {} at 6.33s
2026-01-15 10:31:10.971 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1020, name: 'OutputAudioRawFrame#492', metadata: {} at 6.33s
2026-01-15 10:31:10.971 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1025, name: 'OutputTransportMessageUrgentFrame#65', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.33s
2026-01-15 10:31:10.971 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1024, name: 'RTVIServerMessageFrame#57', metadata: {}, data: {'type': 'user-speaking'} at 6.33s
2026-01-15 10:31:10.971 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1024, name: 'RTVIServerMessageFrame#57', metadata: {}, data: {'type': 'user-speaking'} at 6.33s
2026-01-15 10:31:10.971 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1024, name: 'RTVIServerMessageFrame#57', metadata: {}, data: {'type': 'user-speaking'} at 6.33s
2026-01-15 10:31:10.972 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#64(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.972 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1026, name: 'InputTransportMessageFrame#64', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.42s
2026-01-15 10:31:10.972 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#64(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.972 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#64(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:10.972 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:10.972 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:10.972 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1026, name: 'InputTransportMessageFrame#64', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.42s
2026-01-15 10:31:10.972 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1026, name: 'InputTransportMessageFrame#64', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.42s
2026-01-15 10:31:10.972 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1026, name: 'InputTransportMessageFrame#64', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.42s
2026-01-15 10:31:10.972 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1026, name: 'InputTransportMessageFrame#64', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.42s
2026-01-15 10:31:10.972 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1026, name: 'InputTransportMessageFrame#64', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.42s
2026-01-15 10:31:10.972 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1026, name: 'InputTransportMessageFrame#64', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.42s
2026-01-15 10:31:11.007 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 287, name: 'OutputAudioRawFrame#209', metadata: {} at 5.45s
2026-01-15 10:31:11.007 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 287, name: 'OutputAudioRawFrame#209', metadata: {} at 5.45s
2026-01-15 10:31:11.008 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 1029, name: 'UserSpeakingFrame#116', metadata: {} at 6.36s
2026-01-15 10:31:11.008 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 1030, name: 'UserSpeakingFrame#117', metadata: {} at 6.36s
2026-01-15 10:31:11.008 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 1030, name: 'UserSpeakingFrame#117', metadata: {} at 6.36s
2026-01-15 10:31:11.008 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1027, name: 'OutputAudioRawFrame#493', metadata: {} at 6.36s
2026-01-15 10:31:11.009 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 1029, name: 'UserSpeakingFrame#116', metadata: {} at 6.36s
2026-01-15 10:31:11.009 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1027, name: 'OutputAudioRawFrame#493', metadata: {} at 6.36s
2026-01-15 10:31:11.009 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#116
2026-01-15 10:31:11.009 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#493(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.009 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1031, name: 'RTVIServerMessageFrame#58', metadata: {}, data: {'type': 'user-speaking'} at 6.36s
2026-01-15 10:31:11.009 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1027, name: 'OutputAudioRawFrame#493', metadata: {} at 6.36s
2026-01-15 10:31:11.009 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1032, name: 'OutputTransportMessageUrgentFrame#66', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.36s
2026-01-15 10:31:11.009 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#66(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.009 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#58(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.009 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 1031, name: 'RTVIServerMessageFrame#58', metadata: {}, data: {'type': 'user-speaking'} at 6.36s
2026-01-15 10:31:11.009 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1031, name: 'RTVIServerMessageFrame#58', metadata: {}, data: {'type': 'user-speaking'} at 6.36s
2026-01-15 10:31:11.009 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1027, name: 'OutputAudioRawFrame#493', metadata: {} at 6.36s
2026-01-15 10:31:11.009 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1032, name: 'OutputTransportMessageUrgentFrame#66', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.36s
2026-01-15 10:31:11.010 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1031, name: 'RTVIServerMessageFrame#58', metadata: {}, data: {'type': 'user-speaking'} at 6.36s
2026-01-15 10:31:11.010 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1031, name: 'RTVIServerMessageFrame#58', metadata: {}, data: {'type': 'user-speaking'} at 6.36s
2026-01-15 10:31:11.010 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1027, name: 'OutputAudioRawFrame#493', metadata: {} at 6.36s
2026-01-15 10:31:11.010 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1032, name: 'OutputTransportMessageUrgentFrame#66', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.36s
2026-01-15 10:31:11.010 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1031, name: 'RTVIServerMessageFrame#58', metadata: {}, data: {'type': 'user-speaking'} at 6.36s
2026-01-15 10:31:11.010 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#58(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.010 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#493(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.010 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1031, name: 'RTVIServerMessageFrame#58', metadata: {}, data: {'type': 'user-speaking'} at 6.36s
2026-01-15 10:31:11.010 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1027, name: 'OutputAudioRawFrame#493', metadata: {} at 6.36s
2026-01-15 10:31:11.010 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1032, name: 'OutputTransportMessageUrgentFrame#66', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.36s
2026-01-15 10:31:11.010 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1031, name: 'RTVIServerMessageFrame#58', metadata: {}, data: {'type': 'user-speaking'} at 6.36s
2026-01-15 10:31:11.010 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#66(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.010 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#58(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.010 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1031, name: 'RTVIServerMessageFrame#58', metadata: {}, data: {'type': 'user-speaking'} at 6.36s
2026-01-15 10:31:11.010 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1031, name: 'RTVIServerMessageFrame#58', metadata: {}, data: {'type': 'user-speaking'} at 6.36s
2026-01-15 10:31:11.010 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1027, name: 'OutputAudioRawFrame#493', metadata: {} at 6.36s
2026-01-15 10:31:11.010 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1027, name: 'OutputAudioRawFrame#493', metadata: {} at 6.36s
2026-01-15 10:31:11.010 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1032, name: 'OutputTransportMessageUrgentFrame#66', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.36s
2026-01-15 10:31:11.010 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1031, name: 'RTVIServerMessageFrame#58', metadata: {}, data: {'type': 'user-speaking'} at 6.36s
2026-01-15 10:31:11.010 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1031, name: 'RTVIServerMessageFrame#58', metadata: {}, data: {'type': 'user-speaking'} at 6.36s
2026-01-15 10:31:11.010 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1031, name: 'RTVIServerMessageFrame#58', metadata: {}, data: {'type': 'user-speaking'} at 6.36s
2026-01-15 10:31:11.011 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#65(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.011 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1033, name: 'InputTransportMessageFrame#65', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.45s
2026-01-15 10:31:11.011 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#65(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.011 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#65(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.011 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:11.011 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:11.011 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1033, name: 'InputTransportMessageFrame#65', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.45s
2026-01-15 10:31:11.011 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1033, name: 'InputTransportMessageFrame#65', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.45s
2026-01-15 10:31:11.011 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1033, name: 'InputTransportMessageFrame#65', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.45s
2026-01-15 10:31:11.011 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1033, name: 'InputTransportMessageFrame#65', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.45s
2026-01-15 10:31:11.011 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1033, name: 'InputTransportMessageFrame#65', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.45s
2026-01-15 10:31:11.011 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1033, name: 'InputTransportMessageFrame#65', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.45s
2026-01-15 10:31:11.046 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 289, name: 'OutputAudioRawFrame#211', metadata: {} at 5.49s
2026-01-15 10:31:11.046 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 289, name: 'OutputAudioRawFrame#211', metadata: {} at 5.49s
2026-01-15 10:31:11.048 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 1036, name: 'UserSpeakingFrame#118', metadata: {} at 6.40s
2026-01-15 10:31:11.048 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 1037, name: 'UserSpeakingFrame#119', metadata: {} at 6.40s
2026-01-15 10:31:11.048 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 1037, name: 'UserSpeakingFrame#119', metadata: {} at 6.40s
2026-01-15 10:31:11.048 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1034, name: 'OutputAudioRawFrame#494', metadata: {} at 6.40s
2026-01-15 10:31:11.048 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 1036, name: 'UserSpeakingFrame#118', metadata: {} at 6.40s
2026-01-15 10:31:11.048 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1034, name: 'OutputAudioRawFrame#494', metadata: {} at 6.40s
2026-01-15 10:31:11.048 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#118
2026-01-15 10:31:11.048 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#494(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.048 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1038, name: 'RTVIServerMessageFrame#59', metadata: {}, data: {'type': 'user-speaking'} at 6.40s
2026-01-15 10:31:11.048 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1034, name: 'OutputAudioRawFrame#494', metadata: {} at 6.40s
2026-01-15 10:31:11.048 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1039, name: 'OutputTransportMessageUrgentFrame#67', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.40s
2026-01-15 10:31:11.049 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#67(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.049 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#59(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.049 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 1038, name: 'RTVIServerMessageFrame#59', metadata: {}, data: {'type': 'user-speaking'} at 6.40s
2026-01-15 10:31:11.049 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1038, name: 'RTVIServerMessageFrame#59', metadata: {}, data: {'type': 'user-speaking'} at 6.40s
2026-01-15 10:31:11.049 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1034, name: 'OutputAudioRawFrame#494', metadata: {} at 6.40s
2026-01-15 10:31:11.049 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1039, name: 'OutputTransportMessageUrgentFrame#67', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.40s
2026-01-15 10:31:11.049 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1038, name: 'RTVIServerMessageFrame#59', metadata: {}, data: {'type': 'user-speaking'} at 6.40s
2026-01-15 10:31:11.049 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1038, name: 'RTVIServerMessageFrame#59', metadata: {}, data: {'type': 'user-speaking'} at 6.40s
2026-01-15 10:31:11.049 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1034, name: 'OutputAudioRawFrame#494', metadata: {} at 6.40s
2026-01-15 10:31:11.050 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1039, name: 'OutputTransportMessageUrgentFrame#67', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.40s
2026-01-15 10:31:11.050 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1038, name: 'RTVIServerMessageFrame#59', metadata: {}, data: {'type': 'user-speaking'} at 6.40s
2026-01-15 10:31:11.050 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#59(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.050 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#494(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.050 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1038, name: 'RTVIServerMessageFrame#59', metadata: {}, data: {'type': 'user-speaking'} at 6.40s
2026-01-15 10:31:11.050 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1034, name: 'OutputAudioRawFrame#494', metadata: {} at 6.40s
2026-01-15 10:31:11.050 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1039, name: 'OutputTransportMessageUrgentFrame#67', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.40s
2026-01-15 10:31:11.050 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1038, name: 'RTVIServerMessageFrame#59', metadata: {}, data: {'type': 'user-speaking'} at 6.40s
2026-01-15 10:31:11.050 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#67(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.050 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#59(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.050 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1038, name: 'RTVIServerMessageFrame#59', metadata: {}, data: {'type': 'user-speaking'} at 6.40s
2026-01-15 10:31:11.050 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1038, name: 'RTVIServerMessageFrame#59', metadata: {}, data: {'type': 'user-speaking'} at 6.40s
2026-01-15 10:31:11.050 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1034, name: 'OutputAudioRawFrame#494', metadata: {} at 6.40s
2026-01-15 10:31:11.050 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1034, name: 'OutputAudioRawFrame#494', metadata: {} at 6.40s
2026-01-15 10:31:11.050 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1039, name: 'OutputTransportMessageUrgentFrame#67', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.40s
2026-01-15 10:31:11.050 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1038, name: 'RTVIServerMessageFrame#59', metadata: {}, data: {'type': 'user-speaking'} at 6.40s
2026-01-15 10:31:11.050 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1038, name: 'RTVIServerMessageFrame#59', metadata: {}, data: {'type': 'user-speaking'} at 6.40s
2026-01-15 10:31:11.050 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1038, name: 'RTVIServerMessageFrame#59', metadata: {}, data: {'type': 'user-speaking'} at 6.40s
2026-01-15 10:31:11.051 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#66(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.051 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1040, name: 'InputTransportMessageFrame#66', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.49s
2026-01-15 10:31:11.051 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#66(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.051 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#66(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.051 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:11.051 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:11.051 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1040, name: 'InputTransportMessageFrame#66', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.49s
2026-01-15 10:31:11.051 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1040, name: 'InputTransportMessageFrame#66', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.49s
2026-01-15 10:31:11.051 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1040, name: 'InputTransportMessageFrame#66', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.49s
2026-01-15 10:31:11.051 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1040, name: 'InputTransportMessageFrame#66', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.49s
2026-01-15 10:31:11.051 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1040, name: 'InputTransportMessageFrame#66', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.49s
2026-01-15 10:31:11.051 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1040, name: 'InputTransportMessageFrame#66', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.49s
2026-01-15 10:31:11.087 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 290, name: 'OutputAudioRawFrame#212', metadata: {} at 5.53s
2026-01-15 10:31:11.087 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 290, name: 'OutputAudioRawFrame#212', metadata: {} at 5.53s
2026-01-15 10:31:11.089 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 1043, name: 'UserSpeakingFrame#120', metadata: {} at 6.44s
2026-01-15 10:31:11.089 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 1044, name: 'UserSpeakingFrame#121', metadata: {} at 6.44s
2026-01-15 10:31:11.089 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 1044, name: 'UserSpeakingFrame#121', metadata: {} at 6.44s
2026-01-15 10:31:11.089 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1041, name: 'OutputAudioRawFrame#495', metadata: {} at 6.44s
2026-01-15 10:31:11.089 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 1043, name: 'UserSpeakingFrame#120', metadata: {} at 6.44s
2026-01-15 10:31:11.090 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1041, name: 'OutputAudioRawFrame#495', metadata: {} at 6.44s
2026-01-15 10:31:11.090 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#120
2026-01-15 10:31:11.090 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#495(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.090 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1045, name: 'RTVIServerMessageFrame#60', metadata: {}, data: {'type': 'user-speaking'} at 6.44s
2026-01-15 10:31:11.090 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1041, name: 'OutputAudioRawFrame#495', metadata: {} at 6.44s
2026-01-15 10:31:11.090 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1046, name: 'OutputTransportMessageUrgentFrame#68', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.44s
2026-01-15 10:31:11.090 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#68(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.091 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#60(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.091 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 1045, name: 'RTVIServerMessageFrame#60', metadata: {}, data: {'type': 'user-speaking'} at 6.44s
2026-01-15 10:31:11.091 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1045, name: 'RTVIServerMessageFrame#60', metadata: {}, data: {'type': 'user-speaking'} at 6.44s
2026-01-15 10:31:11.091 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1041, name: 'OutputAudioRawFrame#495', metadata: {} at 6.44s
2026-01-15 10:31:11.091 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1046, name: 'OutputTransportMessageUrgentFrame#68', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.44s
2026-01-15 10:31:11.091 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1045, name: 'RTVIServerMessageFrame#60', metadata: {}, data: {'type': 'user-speaking'} at 6.44s
2026-01-15 10:31:11.091 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1045, name: 'RTVIServerMessageFrame#60', metadata: {}, data: {'type': 'user-speaking'} at 6.45s
2026-01-15 10:31:11.091 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1041, name: 'OutputAudioRawFrame#495', metadata: {} at 6.45s
2026-01-15 10:31:11.091 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1046, name: 'OutputTransportMessageUrgentFrame#68', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.45s
2026-01-15 10:31:11.091 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1045, name: 'RTVIServerMessageFrame#60', metadata: {}, data: {'type': 'user-speaking'} at 6.45s
2026-01-15 10:31:11.091 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#60(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.091 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#495(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.091 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1045, name: 'RTVIServerMessageFrame#60', metadata: {}, data: {'type': 'user-speaking'} at 6.45s
2026-01-15 10:31:11.091 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1041, name: 'OutputAudioRawFrame#495', metadata: {} at 6.45s
2026-01-15 10:31:11.091 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1046, name: 'OutputTransportMessageUrgentFrame#68', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.45s
2026-01-15 10:31:11.091 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1045, name: 'RTVIServerMessageFrame#60', metadata: {}, data: {'type': 'user-speaking'} at 6.45s
2026-01-15 10:31:11.091 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#68(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.092 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#60(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.092 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1045, name: 'RTVIServerMessageFrame#60', metadata: {}, data: {'type': 'user-speaking'} at 6.45s
2026-01-15 10:31:11.092 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1045, name: 'RTVIServerMessageFrame#60', metadata: {}, data: {'type': 'user-speaking'} at 6.45s
2026-01-15 10:31:11.092 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1041, name: 'OutputAudioRawFrame#495', metadata: {} at 6.45s
2026-01-15 10:31:11.092 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1041, name: 'OutputAudioRawFrame#495', metadata: {} at 6.45s
2026-01-15 10:31:11.092 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1046, name: 'OutputTransportMessageUrgentFrame#68', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.45s
2026-01-15 10:31:11.092 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1045, name: 'RTVIServerMessageFrame#60', metadata: {}, data: {'type': 'user-speaking'} at 6.45s
2026-01-15 10:31:11.092 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1045, name: 'RTVIServerMessageFrame#60', metadata: {}, data: {'type': 'user-speaking'} at 6.45s
2026-01-15 10:31:11.092 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1045, name: 'RTVIServerMessageFrame#60', metadata: {}, data: {'type': 'user-speaking'} at 6.45s
2026-01-15 10:31:11.093 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#67(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.093 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1047, name: 'InputTransportMessageFrame#67', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.54s
2026-01-15 10:31:11.093 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#67(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.093 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#67(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.093 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:11.093 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:11.093 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1047, name: 'InputTransportMessageFrame#67', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.54s
2026-01-15 10:31:11.093 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1047, name: 'InputTransportMessageFrame#67', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.54s
2026-01-15 10:31:11.093 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1047, name: 'InputTransportMessageFrame#67', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.54s
2026-01-15 10:31:11.093 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1047, name: 'InputTransportMessageFrame#67', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.54s
2026-01-15 10:31:11.093 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1047, name: 'InputTransportMessageFrame#67', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.54s
2026-01-15 10:31:11.093 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1047, name: 'InputTransportMessageFrame#67', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.54s
2026-01-15 10:31:11.127 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 292, name: 'OutputAudioRawFrame#214', metadata: {} at 5.57s
2026-01-15 10:31:11.127 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 292, name: 'OutputAudioRawFrame#214', metadata: {} at 5.57s
2026-01-15 10:31:11.128 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 1050, name: 'UserSpeakingFrame#122', metadata: {} at 6.48s
2026-01-15 10:31:11.128 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 1051, name: 'UserSpeakingFrame#123', metadata: {} at 6.48s
2026-01-15 10:31:11.128 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 1051, name: 'UserSpeakingFrame#123', metadata: {} at 6.48s
2026-01-15 10:31:11.128 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1048, name: 'OutputAudioRawFrame#496', metadata: {} at 6.48s
2026-01-15 10:31:11.128 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 1050, name: 'UserSpeakingFrame#122', metadata: {} at 6.48s
2026-01-15 10:31:11.128 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1048, name: 'OutputAudioRawFrame#496', metadata: {} at 6.48s
2026-01-15 10:31:11.128 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#122
2026-01-15 10:31:11.128 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#496(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.128 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1052, name: 'RTVIServerMessageFrame#61', metadata: {}, data: {'type': 'user-speaking'} at 6.48s
2026-01-15 10:31:11.128 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1048, name: 'OutputAudioRawFrame#496', metadata: {} at 6.48s
2026-01-15 10:31:11.128 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1053, name: 'OutputTransportMessageUrgentFrame#69', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.48s
2026-01-15 10:31:11.129 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#69(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.129 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#61(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.129 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 1052, name: 'RTVIServerMessageFrame#61', metadata: {}, data: {'type': 'user-speaking'} at 6.48s
2026-01-15 10:31:11.129 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1052, name: 'RTVIServerMessageFrame#61', metadata: {}, data: {'type': 'user-speaking'} at 6.48s
2026-01-15 10:31:11.129 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1048, name: 'OutputAudioRawFrame#496', metadata: {} at 6.48s
2026-01-15 10:31:11.129 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1053, name: 'OutputTransportMessageUrgentFrame#69', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.48s
2026-01-15 10:31:11.129 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1052, name: 'RTVIServerMessageFrame#61', metadata: {}, data: {'type': 'user-speaking'} at 6.48s
2026-01-15 10:31:11.129 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1052, name: 'RTVIServerMessageFrame#61', metadata: {}, data: {'type': 'user-speaking'} at 6.48s
2026-01-15 10:31:11.129 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1048, name: 'OutputAudioRawFrame#496', metadata: {} at 6.48s
2026-01-15 10:31:11.129 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1053, name: 'OutputTransportMessageUrgentFrame#69', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.48s
2026-01-15 10:31:11.129 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1052, name: 'RTVIServerMessageFrame#61', metadata: {}, data: {'type': 'user-speaking'} at 6.48s
2026-01-15 10:31:11.129 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#61(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.129 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#496(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.129 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1052, name: 'RTVIServerMessageFrame#61', metadata: {}, data: {'type': 'user-speaking'} at 6.48s
2026-01-15 10:31:11.129 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1048, name: 'OutputAudioRawFrame#496', metadata: {} at 6.48s
2026-01-15 10:31:11.129 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1053, name: 'OutputTransportMessageUrgentFrame#69', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.48s
2026-01-15 10:31:11.129 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1052, name: 'RTVIServerMessageFrame#61', metadata: {}, data: {'type': 'user-speaking'} at 6.48s
2026-01-15 10:31:11.129 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#69(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.129 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#61(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.129 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1052, name: 'RTVIServerMessageFrame#61', metadata: {}, data: {'type': 'user-speaking'} at 6.48s
2026-01-15 10:31:11.129 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1052, name: 'RTVIServerMessageFrame#61', metadata: {}, data: {'type': 'user-speaking'} at 6.48s
2026-01-15 10:31:11.129 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1048, name: 'OutputAudioRawFrame#496', metadata: {} at 6.48s
2026-01-15 10:31:11.129 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1048, name: 'OutputAudioRawFrame#496', metadata: {} at 6.48s
2026-01-15 10:31:11.129 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1053, name: 'OutputTransportMessageUrgentFrame#69', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.48s
2026-01-15 10:31:11.129 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1052, name: 'RTVIServerMessageFrame#61', metadata: {}, data: {'type': 'user-speaking'} at 6.48s
2026-01-15 10:31:11.130 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1052, name: 'RTVIServerMessageFrame#61', metadata: {}, data: {'type': 'user-speaking'} at 6.48s
2026-01-15 10:31:11.130 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1052, name: 'RTVIServerMessageFrame#61', metadata: {}, data: {'type': 'user-speaking'} at 6.48s
2026-01-15 10:31:11.130 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#68(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.130 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1054, name: 'InputTransportMessageFrame#68', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.57s
2026-01-15 10:31:11.130 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#68(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.130 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#68(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.130 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:11.130 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:11.130 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1054, name: 'InputTransportMessageFrame#68', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.57s
2026-01-15 10:31:11.130 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1054, name: 'InputTransportMessageFrame#68', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.57s
2026-01-15 10:31:11.130 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1054, name: 'InputTransportMessageFrame#68', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.57s
2026-01-15 10:31:11.130 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1054, name: 'InputTransportMessageFrame#68', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.57s
2026-01-15 10:31:11.130 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1054, name: 'InputTransportMessageFrame#68', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.57s
2026-01-15 10:31:11.130 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1054, name: 'InputTransportMessageFrame#68', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.57s
2026-01-15 10:31:11.167 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 294, name: 'OutputAudioRawFrame#216', metadata: {} at 5.61s
2026-01-15 10:31:11.167 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 294, name: 'OutputAudioRawFrame#216', metadata: {} at 5.61s
2026-01-15 10:31:11.168 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 1057, name: 'UserSpeakingFrame#124', metadata: {} at 6.52s
2026-01-15 10:31:11.168 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 1058, name: 'UserSpeakingFrame#125', metadata: {} at 6.52s
2026-01-15 10:31:11.168 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 1058, name: 'UserSpeakingFrame#125', metadata: {} at 6.52s
2026-01-15 10:31:11.168 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1055, name: 'OutputAudioRawFrame#497', metadata: {} at 6.52s
2026-01-15 10:31:11.168 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 1057, name: 'UserSpeakingFrame#124', metadata: {} at 6.52s
2026-01-15 10:31:11.168 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1055, name: 'OutputAudioRawFrame#497', metadata: {} at 6.52s
2026-01-15 10:31:11.168 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#124
2026-01-15 10:31:11.168 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#497(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.168 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1059, name: 'RTVIServerMessageFrame#62', metadata: {}, data: {'type': 'user-speaking'} at 6.52s
2026-01-15 10:31:11.168 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1055, name: 'OutputAudioRawFrame#497', metadata: {} at 6.52s
2026-01-15 10:31:11.168 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1060, name: 'OutputTransportMessageUrgentFrame#70', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.52s
2026-01-15 10:31:11.169 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#70(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.169 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#62(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.169 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 1059, name: 'RTVIServerMessageFrame#62', metadata: {}, data: {'type': 'user-speaking'} at 6.52s
2026-01-15 10:31:11.169 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1059, name: 'RTVIServerMessageFrame#62', metadata: {}, data: {'type': 'user-speaking'} at 6.52s
2026-01-15 10:31:11.169 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1055, name: 'OutputAudioRawFrame#497', metadata: {} at 6.52s
2026-01-15 10:31:11.169 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1060, name: 'OutputTransportMessageUrgentFrame#70', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.52s
2026-01-15 10:31:11.169 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1059, name: 'RTVIServerMessageFrame#62', metadata: {}, data: {'type': 'user-speaking'} at 6.52s
2026-01-15 10:31:11.169 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1059, name: 'RTVIServerMessageFrame#62', metadata: {}, data: {'type': 'user-speaking'} at 6.52s
2026-01-15 10:31:11.169 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1055, name: 'OutputAudioRawFrame#497', metadata: {} at 6.52s
2026-01-15 10:31:11.169 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1060, name: 'OutputTransportMessageUrgentFrame#70', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.52s
2026-01-15 10:31:11.169 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1059, name: 'RTVIServerMessageFrame#62', metadata: {}, data: {'type': 'user-speaking'} at 6.52s
2026-01-15 10:31:11.169 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#62(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.169 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#497(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.169 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1059, name: 'RTVIServerMessageFrame#62', metadata: {}, data: {'type': 'user-speaking'} at 6.52s
2026-01-15 10:31:11.169 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1055, name: 'OutputAudioRawFrame#497', metadata: {} at 6.52s
2026-01-15 10:31:11.169 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1060, name: 'OutputTransportMessageUrgentFrame#70', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.52s
2026-01-15 10:31:11.169 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1059, name: 'RTVIServerMessageFrame#62', metadata: {}, data: {'type': 'user-speaking'} at 6.52s
2026-01-15 10:31:11.170 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#70(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.170 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#62(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.170 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1059, name: 'RTVIServerMessageFrame#62', metadata: {}, data: {'type': 'user-speaking'} at 6.52s
2026-01-15 10:31:11.170 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1059, name: 'RTVIServerMessageFrame#62', metadata: {}, data: {'type': 'user-speaking'} at 6.52s
2026-01-15 10:31:11.170 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1055, name: 'OutputAudioRawFrame#497', metadata: {} at 6.52s
2026-01-15 10:31:11.170 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1055, name: 'OutputAudioRawFrame#497', metadata: {} at 6.52s
2026-01-15 10:31:11.170 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1060, name: 'OutputTransportMessageUrgentFrame#70', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.52s
2026-01-15 10:31:11.170 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1059, name: 'RTVIServerMessageFrame#62', metadata: {}, data: {'type': 'user-speaking'} at 6.52s
2026-01-15 10:31:11.170 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1059, name: 'RTVIServerMessageFrame#62', metadata: {}, data: {'type': 'user-speaking'} at 6.52s
2026-01-15 10:31:11.170 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1059, name: 'RTVIServerMessageFrame#62', metadata: {}, data: {'type': 'user-speaking'} at 6.52s
2026-01-15 10:31:11.170 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#69(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.170 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1061, name: 'InputTransportMessageFrame#69', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.61s
2026-01-15 10:31:11.170 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#69(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.170 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#69(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.170 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:11.170 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:11.170 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1061, name: 'InputTransportMessageFrame#69', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.61s
2026-01-15 10:31:11.170 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1061, name: 'InputTransportMessageFrame#69', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.61s
2026-01-15 10:31:11.170 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1061, name: 'InputTransportMessageFrame#69', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.61s
2026-01-15 10:31:11.170 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1061, name: 'InputTransportMessageFrame#69', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.61s
2026-01-15 10:31:11.170 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1061, name: 'InputTransportMessageFrame#69', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.61s
2026-01-15 10:31:11.170 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1061, name: 'InputTransportMessageFrame#69', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.61s
2026-01-15 10:31:11.207 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 295, name: 'OutputAudioRawFrame#217', metadata: {} at 5.65s
2026-01-15 10:31:11.207 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 295, name: 'OutputAudioRawFrame#217', metadata: {} at 5.65s
2026-01-15 10:31:11.208 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 1064, name: 'UserSpeakingFrame#126', metadata: {} at 6.56s
2026-01-15 10:31:11.208 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 1065, name: 'UserSpeakingFrame#127', metadata: {} at 6.56s
2026-01-15 10:31:11.208 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 1065, name: 'UserSpeakingFrame#127', metadata: {} at 6.56s
2026-01-15 10:31:11.208 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1062, name: 'OutputAudioRawFrame#498', metadata: {} at 6.56s
2026-01-15 10:31:11.208 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 1064, name: 'UserSpeakingFrame#126', metadata: {} at 6.56s
2026-01-15 10:31:11.208 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1062, name: 'OutputAudioRawFrame#498', metadata: {} at 6.56s
2026-01-15 10:31:11.208 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#126
2026-01-15 10:31:11.208 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#498(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.208 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1066, name: 'RTVIServerMessageFrame#63', metadata: {}, data: {'type': 'user-speaking'} at 6.56s
2026-01-15 10:31:11.208 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1062, name: 'OutputAudioRawFrame#498', metadata: {} at 6.56s
2026-01-15 10:31:11.208 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1067, name: 'OutputTransportMessageUrgentFrame#71', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.56s
2026-01-15 10:31:11.209 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#71(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.209 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#63(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.209 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 1066, name: 'RTVIServerMessageFrame#63', metadata: {}, data: {'type': 'user-speaking'} at 6.56s
2026-01-15 10:31:11.209 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1066, name: 'RTVIServerMessageFrame#63', metadata: {}, data: {'type': 'user-speaking'} at 6.56s
2026-01-15 10:31:11.209 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1062, name: 'OutputAudioRawFrame#498', metadata: {} at 6.56s
2026-01-15 10:31:11.209 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1067, name: 'OutputTransportMessageUrgentFrame#71', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.56s
2026-01-15 10:31:11.209 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1066, name: 'RTVIServerMessageFrame#63', metadata: {}, data: {'type': 'user-speaking'} at 6.56s
2026-01-15 10:31:11.209 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1066, name: 'RTVIServerMessageFrame#63', metadata: {}, data: {'type': 'user-speaking'} at 6.56s
2026-01-15 10:31:11.209 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1062, name: 'OutputAudioRawFrame#498', metadata: {} at 6.56s
2026-01-15 10:31:11.209 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1067, name: 'OutputTransportMessageUrgentFrame#71', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.56s
2026-01-15 10:31:11.209 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1066, name: 'RTVIServerMessageFrame#63', metadata: {}, data: {'type': 'user-speaking'} at 6.56s
2026-01-15 10:31:11.209 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#63(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.209 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#498(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.209 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1066, name: 'RTVIServerMessageFrame#63', metadata: {}, data: {'type': 'user-speaking'} at 6.56s
2026-01-15 10:31:11.209 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1062, name: 'OutputAudioRawFrame#498', metadata: {} at 6.56s
2026-01-15 10:31:11.209 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1067, name: 'OutputTransportMessageUrgentFrame#71', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.56s
2026-01-15 10:31:11.209 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1066, name: 'RTVIServerMessageFrame#63', metadata: {}, data: {'type': 'user-speaking'} at 6.56s
2026-01-15 10:31:11.209 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#71(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.209 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#63(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.209 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1066, name: 'RTVIServerMessageFrame#63', metadata: {}, data: {'type': 'user-speaking'} at 6.56s
2026-01-15 10:31:11.209 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1066, name: 'RTVIServerMessageFrame#63', metadata: {}, data: {'type': 'user-speaking'} at 6.56s
2026-01-15 10:31:11.209 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1062, name: 'OutputAudioRawFrame#498', metadata: {} at 6.56s
2026-01-15 10:31:11.209 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1062, name: 'OutputAudioRawFrame#498', metadata: {} at 6.56s
2026-01-15 10:31:11.209 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1067, name: 'OutputTransportMessageUrgentFrame#71', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.56s
2026-01-15 10:31:11.209 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1066, name: 'RTVIServerMessageFrame#63', metadata: {}, data: {'type': 'user-speaking'} at 6.56s
2026-01-15 10:31:11.210 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1066, name: 'RTVIServerMessageFrame#63', metadata: {}, data: {'type': 'user-speaking'} at 6.56s
2026-01-15 10:31:11.210 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1066, name: 'RTVIServerMessageFrame#63', metadata: {}, data: {'type': 'user-speaking'} at 6.56s
2026-01-15 10:31:11.210 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#70(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.210 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1068, name: 'InputTransportMessageFrame#70', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.65s
2026-01-15 10:31:11.210 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#70(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.210 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#70(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.210 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:11.210 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:11.210 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1068, name: 'InputTransportMessageFrame#70', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.65s
2026-01-15 10:31:11.210 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1068, name: 'InputTransportMessageFrame#70', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.65s
2026-01-15 10:31:11.210 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1068, name: 'InputTransportMessageFrame#70', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.65s
2026-01-15 10:31:11.210 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1068, name: 'InputTransportMessageFrame#70', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.65s
2026-01-15 10:31:11.210 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1068, name: 'InputTransportMessageFrame#70', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.65s
2026-01-15 10:31:11.210 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1068, name: 'InputTransportMessageFrame#70', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.65s
2026-01-15 10:31:11.247 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 297, name: 'OutputAudioRawFrame#219', metadata: {} at 5.69s
2026-01-15 10:31:11.247 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 297, name: 'OutputAudioRawFrame#219', metadata: {} at 5.69s
2026-01-15 10:31:11.248 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 1071, name: 'UserSpeakingFrame#128', metadata: {} at 6.60s
2026-01-15 10:31:11.249 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 1072, name: 'UserSpeakingFrame#129', metadata: {} at 6.60s
2026-01-15 10:31:11.249 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 1072, name: 'UserSpeakingFrame#129', metadata: {} at 6.60s
2026-01-15 10:31:11.249 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1069, name: 'OutputAudioRawFrame#499', metadata: {} at 6.60s
2026-01-15 10:31:11.249 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 1071, name: 'UserSpeakingFrame#128', metadata: {} at 6.60s
2026-01-15 10:31:11.249 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1069, name: 'OutputAudioRawFrame#499', metadata: {} at 6.60s
2026-01-15 10:31:11.249 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#128
2026-01-15 10:31:11.249 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#499(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.249 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1073, name: 'RTVIServerMessageFrame#64', metadata: {}, data: {'type': 'user-speaking'} at 6.60s
2026-01-15 10:31:11.249 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1069, name: 'OutputAudioRawFrame#499', metadata: {} at 6.60s
2026-01-15 10:31:11.249 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1074, name: 'OutputTransportMessageUrgentFrame#72', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.60s
2026-01-15 10:31:11.250 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#72(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.250 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#64(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.250 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 1073, name: 'RTVIServerMessageFrame#64', metadata: {}, data: {'type': 'user-speaking'} at 6.60s
2026-01-15 10:31:11.250 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1073, name: 'RTVIServerMessageFrame#64', metadata: {}, data: {'type': 'user-speaking'} at 6.60s
2026-01-15 10:31:11.250 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1069, name: 'OutputAudioRawFrame#499', metadata: {} at 6.60s
2026-01-15 10:31:11.250 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1074, name: 'OutputTransportMessageUrgentFrame#72', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.60s
2026-01-15 10:31:11.250 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1073, name: 'RTVIServerMessageFrame#64', metadata: {}, data: {'type': 'user-speaking'} at 6.60s
2026-01-15 10:31:11.250 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1073, name: 'RTVIServerMessageFrame#64', metadata: {}, data: {'type': 'user-speaking'} at 6.60s
2026-01-15 10:31:11.250 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1069, name: 'OutputAudioRawFrame#499', metadata: {} at 6.60s
2026-01-15 10:31:11.250 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1074, name: 'OutputTransportMessageUrgentFrame#72', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.60s
2026-01-15 10:31:11.250 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1073, name: 'RTVIServerMessageFrame#64', metadata: {}, data: {'type': 'user-speaking'} at 6.60s
2026-01-15 10:31:11.250 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#64(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.250 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#499(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.251 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1073, name: 'RTVIServerMessageFrame#64', metadata: {}, data: {'type': 'user-speaking'} at 6.60s
2026-01-15 10:31:11.251 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1069, name: 'OutputAudioRawFrame#499', metadata: {} at 6.60s
2026-01-15 10:31:11.251 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1074, name: 'OutputTransportMessageUrgentFrame#72', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.60s
2026-01-15 10:31:11.251 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1073, name: 'RTVIServerMessageFrame#64', metadata: {}, data: {'type': 'user-speaking'} at 6.60s
2026-01-15 10:31:11.251 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#72(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.251 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#64(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.251 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1073, name: 'RTVIServerMessageFrame#64', metadata: {}, data: {'type': 'user-speaking'} at 6.61s
2026-01-15 10:31:11.251 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1073, name: 'RTVIServerMessageFrame#64', metadata: {}, data: {'type': 'user-speaking'} at 6.61s
2026-01-15 10:31:11.251 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1069, name: 'OutputAudioRawFrame#499', metadata: {} at 6.61s
2026-01-15 10:31:11.251 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1069, name: 'OutputAudioRawFrame#499', metadata: {} at 6.61s
2026-01-15 10:31:11.251 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1074, name: 'OutputTransportMessageUrgentFrame#72', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.61s
2026-01-15 10:31:11.251 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1073, name: 'RTVIServerMessageFrame#64', metadata: {}, data: {'type': 'user-speaking'} at 6.61s
2026-01-15 10:31:11.251 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1073, name: 'RTVIServerMessageFrame#64', metadata: {}, data: {'type': 'user-speaking'} at 6.61s
2026-01-15 10:31:11.251 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1073, name: 'RTVIServerMessageFrame#64', metadata: {}, data: {'type': 'user-speaking'} at 6.61s
2026-01-15 10:31:11.251 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#71(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.251 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1075, name: 'InputTransportMessageFrame#71', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.70s
2026-01-15 10:31:11.251 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#71(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.251 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#71(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.251 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:11.252 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:11.252 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1075, name: 'InputTransportMessageFrame#71', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.70s
2026-01-15 10:31:11.252 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1075, name: 'InputTransportMessageFrame#71', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.70s
2026-01-15 10:31:11.252 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1075, name: 'InputTransportMessageFrame#71', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.70s
2026-01-15 10:31:11.252 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1075, name: 'InputTransportMessageFrame#71', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.70s
2026-01-15 10:31:11.252 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1075, name: 'InputTransportMessageFrame#71', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.70s
2026-01-15 10:31:11.252 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1075, name: 'InputTransportMessageFrame#71', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.70s
2026-01-15 10:31:11.287 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 298, name: 'OutputAudioRawFrame#220', metadata: {} at 5.73s
2026-01-15 10:31:11.287 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 298, name: 'OutputAudioRawFrame#220', metadata: {} at 5.73s
2026-01-15 10:31:11.288 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 1078, name: 'UserSpeakingFrame#130', metadata: {} at 6.64s
2026-01-15 10:31:11.288 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 1079, name: 'UserSpeakingFrame#131', metadata: {} at 6.64s
2026-01-15 10:31:11.288 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 1079, name: 'UserSpeakingFrame#131', metadata: {} at 6.64s
2026-01-15 10:31:11.288 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1076, name: 'OutputAudioRawFrame#500', metadata: {} at 6.64s
2026-01-15 10:31:11.288 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 1078, name: 'UserSpeakingFrame#130', metadata: {} at 6.64s
2026-01-15 10:31:11.288 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1076, name: 'OutputAudioRawFrame#500', metadata: {} at 6.64s
2026-01-15 10:31:11.288 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#130
2026-01-15 10:31:11.288 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#500(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.288 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1080, name: 'RTVIServerMessageFrame#65', metadata: {}, data: {'type': 'user-speaking'} at 6.64s
2026-01-15 10:31:11.289 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1076, name: 'OutputAudioRawFrame#500', metadata: {} at 6.64s
2026-01-15 10:31:11.289 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1081, name: 'OutputTransportMessageUrgentFrame#73', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.64s
2026-01-15 10:31:11.289 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#73(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.289 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#65(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.289 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 1080, name: 'RTVIServerMessageFrame#65', metadata: {}, data: {'type': 'user-speaking'} at 6.64s
2026-01-15 10:31:11.289 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1080, name: 'RTVIServerMessageFrame#65', metadata: {}, data: {'type': 'user-speaking'} at 6.64s
2026-01-15 10:31:11.289 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1076, name: 'OutputAudioRawFrame#500', metadata: {} at 6.64s
2026-01-15 10:31:11.289 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1081, name: 'OutputTransportMessageUrgentFrame#73', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.64s
2026-01-15 10:31:11.289 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1080, name: 'RTVIServerMessageFrame#65', metadata: {}, data: {'type': 'user-speaking'} at 6.64s
2026-01-15 10:31:11.290 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1080, name: 'RTVIServerMessageFrame#65', metadata: {}, data: {'type': 'user-speaking'} at 6.64s
2026-01-15 10:31:11.290 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1076, name: 'OutputAudioRawFrame#500', metadata: {} at 6.64s
2026-01-15 10:31:11.290 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1081, name: 'OutputTransportMessageUrgentFrame#73', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.64s
2026-01-15 10:31:11.290 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1080, name: 'RTVIServerMessageFrame#65', metadata: {}, data: {'type': 'user-speaking'} at 6.64s
2026-01-15 10:31:11.290 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#65(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.290 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#500(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.290 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1080, name: 'RTVIServerMessageFrame#65', metadata: {}, data: {'type': 'user-speaking'} at 6.64s
2026-01-15 10:31:11.290 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1076, name: 'OutputAudioRawFrame#500', metadata: {} at 6.64s
2026-01-15 10:31:11.290 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1081, name: 'OutputTransportMessageUrgentFrame#73', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.64s
2026-01-15 10:31:11.290 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1080, name: 'RTVIServerMessageFrame#65', metadata: {}, data: {'type': 'user-speaking'} at 6.64s
2026-01-15 10:31:11.290 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#73(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.290 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#65(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.290 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1080, name: 'RTVIServerMessageFrame#65', metadata: {}, data: {'type': 'user-speaking'} at 6.64s
2026-01-15 10:31:11.290 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1080, name: 'RTVIServerMessageFrame#65', metadata: {}, data: {'type': 'user-speaking'} at 6.64s
2026-01-15 10:31:11.290 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1076, name: 'OutputAudioRawFrame#500', metadata: {} at 6.64s
2026-01-15 10:31:11.290 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1076, name: 'OutputAudioRawFrame#500', metadata: {} at 6.64s
2026-01-15 10:31:11.290 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1081, name: 'OutputTransportMessageUrgentFrame#73', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.64s
2026-01-15 10:31:11.290 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1080, name: 'RTVIServerMessageFrame#65', metadata: {}, data: {'type': 'user-speaking'} at 6.64s
2026-01-15 10:31:11.291 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1080, name: 'RTVIServerMessageFrame#65', metadata: {}, data: {'type': 'user-speaking'} at 6.64s
2026-01-15 10:31:11.291 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1080, name: 'RTVIServerMessageFrame#65', metadata: {}, data: {'type': 'user-speaking'} at 6.64s
2026-01-15 10:31:11.291 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#72(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.291 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1082, name: 'InputTransportMessageFrame#72', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.73s
2026-01-15 10:31:11.291 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#72(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.291 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#72(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.291 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:11.291 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:11.291 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1082, name: 'InputTransportMessageFrame#72', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.73s
2026-01-15 10:31:11.291 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1082, name: 'InputTransportMessageFrame#72', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.73s
2026-01-15 10:31:11.291 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1082, name: 'InputTransportMessageFrame#72', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.73s
2026-01-15 10:31:11.291 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1082, name: 'InputTransportMessageFrame#72', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.73s
2026-01-15 10:31:11.291 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1082, name: 'InputTransportMessageFrame#72', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.74s
2026-01-15 10:31:11.291 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1082, name: 'InputTransportMessageFrame#72', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.74s
2026-01-15 10:31:11.327 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 300, name: 'OutputAudioRawFrame#222', metadata: {} at 5.77s
2026-01-15 10:31:11.327 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 300, name: 'OutputAudioRawFrame#222', metadata: {} at 5.77s
2026-01-15 10:31:11.328 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 1085, name: 'UserSpeakingFrame#132', metadata: {} at 6.68s
2026-01-15 10:31:11.328 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 1086, name: 'UserSpeakingFrame#133', metadata: {} at 6.68s
2026-01-15 10:31:11.328 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 1086, name: 'UserSpeakingFrame#133', metadata: {} at 6.68s
2026-01-15 10:31:11.328 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1083, name: 'OutputAudioRawFrame#501', metadata: {} at 6.68s
2026-01-15 10:31:11.328 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 1085, name: 'UserSpeakingFrame#132', metadata: {} at 6.68s
2026-01-15 10:31:11.328 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1083, name: 'OutputAudioRawFrame#501', metadata: {} at 6.68s
2026-01-15 10:31:11.328 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#132
2026-01-15 10:31:11.328 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#501(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.329 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1087, name: 'RTVIServerMessageFrame#66', metadata: {}, data: {'type': 'user-speaking'} at 6.68s
2026-01-15 10:31:11.329 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1083, name: 'OutputAudioRawFrame#501', metadata: {} at 6.68s
2026-01-15 10:31:11.329 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1088, name: 'OutputTransportMessageUrgentFrame#74', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.68s
2026-01-15 10:31:11.329 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#74(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.329 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#66(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.329 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 1087, name: 'RTVIServerMessageFrame#66', metadata: {}, data: {'type': 'user-speaking'} at 6.68s
2026-01-15 10:31:11.329 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1087, name: 'RTVIServerMessageFrame#66', metadata: {}, data: {'type': 'user-speaking'} at 6.68s
2026-01-15 10:31:11.329 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1083, name: 'OutputAudioRawFrame#501', metadata: {} at 6.68s
2026-01-15 10:31:11.329 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1088, name: 'OutputTransportMessageUrgentFrame#74', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.68s
2026-01-15 10:31:11.329 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1087, name: 'RTVIServerMessageFrame#66', metadata: {}, data: {'type': 'user-speaking'} at 6.68s
2026-01-15 10:31:11.330 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1087, name: 'RTVIServerMessageFrame#66', metadata: {}, data: {'type': 'user-speaking'} at 6.68s
2026-01-15 10:31:11.330 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1083, name: 'OutputAudioRawFrame#501', metadata: {} at 6.68s
2026-01-15 10:31:11.330 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1088, name: 'OutputTransportMessageUrgentFrame#74', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.68s
2026-01-15 10:31:11.330 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1087, name: 'RTVIServerMessageFrame#66', metadata: {}, data: {'type': 'user-speaking'} at 6.68s
2026-01-15 10:31:11.330 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#66(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.330 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#501(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.330 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1087, name: 'RTVIServerMessageFrame#66', metadata: {}, data: {'type': 'user-speaking'} at 6.68s
2026-01-15 10:31:11.330 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1083, name: 'OutputAudioRawFrame#501', metadata: {} at 6.68s
2026-01-15 10:31:11.330 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1088, name: 'OutputTransportMessageUrgentFrame#74', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.68s
2026-01-15 10:31:11.330 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1087, name: 'RTVIServerMessageFrame#66', metadata: {}, data: {'type': 'user-speaking'} at 6.68s
2026-01-15 10:31:11.330 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#74(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.330 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#66(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.330 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1087, name: 'RTVIServerMessageFrame#66', metadata: {}, data: {'type': 'user-speaking'} at 6.68s
2026-01-15 10:31:11.330 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1087, name: 'RTVIServerMessageFrame#66', metadata: {}, data: {'type': 'user-speaking'} at 6.68s
2026-01-15 10:31:11.330 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1083, name: 'OutputAudioRawFrame#501', metadata: {} at 6.68s
2026-01-15 10:31:11.330 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1083, name: 'OutputAudioRawFrame#501', metadata: {} at 6.68s
2026-01-15 10:31:11.330 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1088, name: 'OutputTransportMessageUrgentFrame#74', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.68s
2026-01-15 10:31:11.331 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1087, name: 'RTVIServerMessageFrame#66', metadata: {}, data: {'type': 'user-speaking'} at 6.68s
2026-01-15 10:31:11.331 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1087, name: 'RTVIServerMessageFrame#66', metadata: {}, data: {'type': 'user-speaking'} at 6.69s
2026-01-15 10:31:11.331 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1087, name: 'RTVIServerMessageFrame#66', metadata: {}, data: {'type': 'user-speaking'} at 6.69s
2026-01-15 10:31:11.331 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#73(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.331 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1089, name: 'InputTransportMessageFrame#73', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.77s
2026-01-15 10:31:11.331 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#73(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.331 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#73(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.331 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:11.331 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:11.331 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1089, name: 'InputTransportMessageFrame#73', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.77s
2026-01-15 10:31:11.331 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1089, name: 'InputTransportMessageFrame#73', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.77s
2026-01-15 10:31:11.331 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1089, name: 'InputTransportMessageFrame#73', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.77s
2026-01-15 10:31:11.331 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1089, name: 'InputTransportMessageFrame#73', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.78s
2026-01-15 10:31:11.331 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1089, name: 'InputTransportMessageFrame#73', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.78s
2026-01-15 10:31:11.331 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1089, name: 'InputTransportMessageFrame#73', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.78s
2026-01-15 10:31:11.367 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 301, name: 'OutputAudioRawFrame#223', metadata: {} at 5.81s
2026-01-15 10:31:11.367 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 301, name: 'OutputAudioRawFrame#223', metadata: {} at 5.81s
2026-01-15 10:31:11.370 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 1092, name: 'UserSpeakingFrame#134', metadata: {} at 6.72s
2026-01-15 10:31:11.370 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 1093, name: 'UserSpeakingFrame#135', metadata: {} at 6.72s
2026-01-15 10:31:11.370 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 1093, name: 'UserSpeakingFrame#135', metadata: {} at 6.72s
2026-01-15 10:31:11.370 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1090, name: 'OutputAudioRawFrame#502', metadata: {} at 6.72s
2026-01-15 10:31:11.370 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 1092, name: 'UserSpeakingFrame#134', metadata: {} at 6.72s
2026-01-15 10:31:11.370 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1090, name: 'OutputAudioRawFrame#502', metadata: {} at 6.72s
2026-01-15 10:31:11.370 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#134
2026-01-15 10:31:11.370 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#502(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.370 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1094, name: 'RTVIServerMessageFrame#67', metadata: {}, data: {'type': 'user-speaking'} at 6.72s
2026-01-15 10:31:11.370 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1090, name: 'OutputAudioRawFrame#502', metadata: {} at 6.72s
2026-01-15 10:31:11.371 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1095, name: 'OutputTransportMessageUrgentFrame#75', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.72s
2026-01-15 10:31:11.371 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#75(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.371 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#67(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.371 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 1094, name: 'RTVIServerMessageFrame#67', metadata: {}, data: {'type': 'user-speaking'} at 6.73s
2026-01-15 10:31:11.371 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1094, name: 'RTVIServerMessageFrame#67', metadata: {}, data: {'type': 'user-speaking'} at 6.73s
2026-01-15 10:31:11.371 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1090, name: 'OutputAudioRawFrame#502', metadata: {} at 6.73s
2026-01-15 10:31:11.371 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1095, name: 'OutputTransportMessageUrgentFrame#75', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.73s
2026-01-15 10:31:11.372 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1094, name: 'RTVIServerMessageFrame#67', metadata: {}, data: {'type': 'user-speaking'} at 6.73s
2026-01-15 10:31:11.372 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1094, name: 'RTVIServerMessageFrame#67', metadata: {}, data: {'type': 'user-speaking'} at 6.73s
2026-01-15 10:31:11.372 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1090, name: 'OutputAudioRawFrame#502', metadata: {} at 6.73s
2026-01-15 10:31:11.372 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1095, name: 'OutputTransportMessageUrgentFrame#75', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.73s
2026-01-15 10:31:11.372 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1094, name: 'RTVIServerMessageFrame#67', metadata: {}, data: {'type': 'user-speaking'} at 6.73s
2026-01-15 10:31:11.372 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#67(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.372 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#502(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.372 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1094, name: 'RTVIServerMessageFrame#67', metadata: {}, data: {'type': 'user-speaking'} at 6.73s
2026-01-15 10:31:11.372 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1090, name: 'OutputAudioRawFrame#502', metadata: {} at 6.73s
2026-01-15 10:31:11.372 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1095, name: 'OutputTransportMessageUrgentFrame#75', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.73s
2026-01-15 10:31:11.372 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1094, name: 'RTVIServerMessageFrame#67', metadata: {}, data: {'type': 'user-speaking'} at 6.73s
2026-01-15 10:31:11.372 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#75(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.372 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#67(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.372 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1094, name: 'RTVIServerMessageFrame#67', metadata: {}, data: {'type': 'user-speaking'} at 6.73s
2026-01-15 10:31:11.372 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1094, name: 'RTVIServerMessageFrame#67', metadata: {}, data: {'type': 'user-speaking'} at 6.73s
2026-01-15 10:31:11.373 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1090, name: 'OutputAudioRawFrame#502', metadata: {} at 6.73s
2026-01-15 10:31:11.373 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1090, name: 'OutputAudioRawFrame#502', metadata: {} at 6.73s
2026-01-15 10:31:11.373 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1095, name: 'OutputTransportMessageUrgentFrame#75', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.73s
2026-01-15 10:31:11.373 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1094, name: 'RTVIServerMessageFrame#67', metadata: {}, data: {'type': 'user-speaking'} at 6.73s
2026-01-15 10:31:11.373 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1094, name: 'RTVIServerMessageFrame#67', metadata: {}, data: {'type': 'user-speaking'} at 6.73s
2026-01-15 10:31:11.373 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1094, name: 'RTVIServerMessageFrame#67', metadata: {}, data: {'type': 'user-speaking'} at 6.73s
2026-01-15 10:31:11.373 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#74(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.373 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1096, name: 'InputTransportMessageFrame#74', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.82s
2026-01-15 10:31:11.373 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#74(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.373 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#74(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.373 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:11.373 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:11.373 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1096, name: 'InputTransportMessageFrame#74', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.82s
2026-01-15 10:31:11.373 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1096, name: 'InputTransportMessageFrame#74', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.82s
2026-01-15 10:31:11.373 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1096, name: 'InputTransportMessageFrame#74', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.82s
2026-01-15 10:31:11.373 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1096, name: 'InputTransportMessageFrame#74', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.82s
2026-01-15 10:31:11.374 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1096, name: 'InputTransportMessageFrame#74', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.82s
2026-01-15 10:31:11.374 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1096, name: 'InputTransportMessageFrame#74', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.82s
2026-01-15 10:31:11.407 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 303, name: 'OutputAudioRawFrame#225', metadata: {} at 5.85s
2026-01-15 10:31:11.407 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 303, name: 'OutputAudioRawFrame#225', metadata: {} at 5.85s
2026-01-15 10:31:11.411 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 1099, name: 'UserSpeakingFrame#136', metadata: {} at 6.77s
2026-01-15 10:31:11.412 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 1100, name: 'UserSpeakingFrame#137', metadata: {} at 6.77s
2026-01-15 10:31:11.412 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 1100, name: 'UserSpeakingFrame#137', metadata: {} at 6.77s
2026-01-15 10:31:11.412 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1097, name: 'OutputAudioRawFrame#503', metadata: {} at 6.77s
2026-01-15 10:31:11.412 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 1099, name: 'UserSpeakingFrame#136', metadata: {} at 6.77s
2026-01-15 10:31:11.412 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1097, name: 'OutputAudioRawFrame#503', metadata: {} at 6.77s
2026-01-15 10:31:11.412 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#136
2026-01-15 10:31:11.412 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#503(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.412 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1101, name: 'RTVIServerMessageFrame#68', metadata: {}, data: {'type': 'user-speaking'} at 6.77s
2026-01-15 10:31:11.412 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1097, name: 'OutputAudioRawFrame#503', metadata: {} at 6.77s
2026-01-15 10:31:11.412 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1102, name: 'OutputTransportMessageUrgentFrame#76', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.77s
2026-01-15 10:31:11.413 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#76(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.413 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#68(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.413 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 1101, name: 'RTVIServerMessageFrame#68', metadata: {}, data: {'type': 'user-speaking'} at 6.77s
2026-01-15 10:31:11.413 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1101, name: 'RTVIServerMessageFrame#68', metadata: {}, data: {'type': 'user-speaking'} at 6.77s
2026-01-15 10:31:11.413 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1097, name: 'OutputAudioRawFrame#503', metadata: {} at 6.77s
2026-01-15 10:31:11.413 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1102, name: 'OutputTransportMessageUrgentFrame#76', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.77s
2026-01-15 10:31:11.413 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1101, name: 'RTVIServerMessageFrame#68', metadata: {}, data: {'type': 'user-speaking'} at 6.77s
2026-01-15 10:31:11.414 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1101, name: 'RTVIServerMessageFrame#68', metadata: {}, data: {'type': 'user-speaking'} at 6.77s
2026-01-15 10:31:11.414 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1097, name: 'OutputAudioRawFrame#503', metadata: {} at 6.77s
2026-01-15 10:31:11.414 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1102, name: 'OutputTransportMessageUrgentFrame#76', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.77s
2026-01-15 10:31:11.414 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1101, name: 'RTVIServerMessageFrame#68', metadata: {}, data: {'type': 'user-speaking'} at 6.77s
2026-01-15 10:31:11.414 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#68(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.414 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#503(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.414 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1101, name: 'RTVIServerMessageFrame#68', metadata: {}, data: {'type': 'user-speaking'} at 6.77s
2026-01-15 10:31:11.414 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1097, name: 'OutputAudioRawFrame#503', metadata: {} at 6.77s
2026-01-15 10:31:11.414 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1102, name: 'OutputTransportMessageUrgentFrame#76', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.77s
2026-01-15 10:31:11.414 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1101, name: 'RTVIServerMessageFrame#68', metadata: {}, data: {'type': 'user-speaking'} at 6.77s
2026-01-15 10:31:11.414 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#76(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.414 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#68(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.414 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1101, name: 'RTVIServerMessageFrame#68', metadata: {}, data: {'type': 'user-speaking'} at 6.77s
2026-01-15 10:31:11.414 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1101, name: 'RTVIServerMessageFrame#68', metadata: {}, data: {'type': 'user-speaking'} at 6.77s
2026-01-15 10:31:11.414 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1097, name: 'OutputAudioRawFrame#503', metadata: {} at 6.77s
2026-01-15 10:31:11.414 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1097, name: 'OutputAudioRawFrame#503', metadata: {} at 6.77s
2026-01-15 10:31:11.415 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1102, name: 'OutputTransportMessageUrgentFrame#76', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.77s
2026-01-15 10:31:11.415 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1101, name: 'RTVIServerMessageFrame#68', metadata: {}, data: {'type': 'user-speaking'} at 6.77s
2026-01-15 10:31:11.415 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1101, name: 'RTVIServerMessageFrame#68', metadata: {}, data: {'type': 'user-speaking'} at 6.77s
2026-01-15 10:31:11.415 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1101, name: 'RTVIServerMessageFrame#68', metadata: {}, data: {'type': 'user-speaking'} at 6.77s
2026-01-15 10:31:11.415 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#75(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.415 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1103, name: 'InputTransportMessageFrame#75', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.86s
2026-01-15 10:31:11.415 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#75(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.415 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#75(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.415 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:11.415 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:11.415 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1103, name: 'InputTransportMessageFrame#75', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.86s
2026-01-15 10:31:11.416 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1103, name: 'InputTransportMessageFrame#75', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.86s
2026-01-15 10:31:11.416 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1103, name: 'InputTransportMessageFrame#75', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.86s
2026-01-15 10:31:11.416 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1103, name: 'InputTransportMessageFrame#75', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.86s
2026-01-15 10:31:11.416 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1103, name: 'InputTransportMessageFrame#75', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.86s
2026-01-15 10:31:11.416 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1103, name: 'InputTransportMessageFrame#75', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.86s
2026-01-15 10:31:11.447 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 304, name: 'OutputAudioRawFrame#226', metadata: {} at 5.89s
2026-01-15 10:31:11.447 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 304, name: 'OutputAudioRawFrame#226', metadata: {} at 5.89s
2026-01-15 10:31:11.449 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 1106, name: 'UserSpeakingFrame#138', metadata: {} at 6.80s
2026-01-15 10:31:11.449 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 1107, name: 'UserSpeakingFrame#139', metadata: {} at 6.80s
2026-01-15 10:31:11.449 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 1107, name: 'UserSpeakingFrame#139', metadata: {} at 6.80s
2026-01-15 10:31:11.449 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1104, name: 'OutputAudioRawFrame#504', metadata: {} at 6.80s
2026-01-15 10:31:11.449 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 1106, name: 'UserSpeakingFrame#138', metadata: {} at 6.80s
2026-01-15 10:31:11.449 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1104, name: 'OutputAudioRawFrame#504', metadata: {} at 6.80s
2026-01-15 10:31:11.449 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#138
2026-01-15 10:31:11.449 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#504(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.450 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1108, name: 'RTVIServerMessageFrame#69', metadata: {}, data: {'type': 'user-speaking'} at 6.80s
2026-01-15 10:31:11.450 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1104, name: 'OutputAudioRawFrame#504', metadata: {} at 6.80s
2026-01-15 10:31:11.450 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1109, name: 'OutputTransportMessageUrgentFrame#77', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.80s
2026-01-15 10:31:11.450 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#77(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.450 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#69(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.451 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 1108, name: 'RTVIServerMessageFrame#69', metadata: {}, data: {'type': 'user-speaking'} at 6.80s
2026-01-15 10:31:11.451 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1108, name: 'RTVIServerMessageFrame#69', metadata: {}, data: {'type': 'user-speaking'} at 6.80s
2026-01-15 10:31:11.451 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1104, name: 'OutputAudioRawFrame#504', metadata: {} at 6.80s
2026-01-15 10:31:11.451 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1109, name: 'OutputTransportMessageUrgentFrame#77', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.80s
2026-01-15 10:31:11.451 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1108, name: 'RTVIServerMessageFrame#69', metadata: {}, data: {'type': 'user-speaking'} at 6.80s
2026-01-15 10:31:11.451 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1108, name: 'RTVIServerMessageFrame#69', metadata: {}, data: {'type': 'user-speaking'} at 6.81s
2026-01-15 10:31:11.451 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1104, name: 'OutputAudioRawFrame#504', metadata: {} at 6.81s
2026-01-15 10:31:11.451 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1109, name: 'OutputTransportMessageUrgentFrame#77', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.81s
2026-01-15 10:31:11.451 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1108, name: 'RTVIServerMessageFrame#69', metadata: {}, data: {'type': 'user-speaking'} at 6.81s
2026-01-15 10:31:11.451 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#69(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.451 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#504(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.451 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1108, name: 'RTVIServerMessageFrame#69', metadata: {}, data: {'type': 'user-speaking'} at 6.81s
2026-01-15 10:31:11.451 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1104, name: 'OutputAudioRawFrame#504', metadata: {} at 6.81s
2026-01-15 10:31:11.451 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1109, name: 'OutputTransportMessageUrgentFrame#77', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.81s
2026-01-15 10:31:11.451 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1108, name: 'RTVIServerMessageFrame#69', metadata: {}, data: {'type': 'user-speaking'} at 6.81s
2026-01-15 10:31:11.452 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#77(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.452 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#69(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.452 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1108, name: 'RTVIServerMessageFrame#69', metadata: {}, data: {'type': 'user-speaking'} at 6.81s
2026-01-15 10:31:11.452 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1108, name: 'RTVIServerMessageFrame#69', metadata: {}, data: {'type': 'user-speaking'} at 6.81s
2026-01-15 10:31:11.452 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1104, name: 'OutputAudioRawFrame#504', metadata: {} at 6.81s
2026-01-15 10:31:11.452 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1104, name: 'OutputAudioRawFrame#504', metadata: {} at 6.81s
2026-01-15 10:31:11.452 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1109, name: 'OutputTransportMessageUrgentFrame#77', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.81s
2026-01-15 10:31:11.452 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1108, name: 'RTVIServerMessageFrame#69', metadata: {}, data: {'type': 'user-speaking'} at 6.81s
2026-01-15 10:31:11.452 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1108, name: 'RTVIServerMessageFrame#69', metadata: {}, data: {'type': 'user-speaking'} at 6.81s
2026-01-15 10:31:11.452 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1108, name: 'RTVIServerMessageFrame#69', metadata: {}, data: {'type': 'user-speaking'} at 6.81s
2026-01-15 10:31:11.452 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#76(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.452 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1110, name: 'InputTransportMessageFrame#76', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.90s
2026-01-15 10:31:11.452 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#76(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.452 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#76(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.452 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:11.452 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:11.452 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1110, name: 'InputTransportMessageFrame#76', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.90s
2026-01-15 10:31:11.453 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1110, name: 'InputTransportMessageFrame#76', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.90s
2026-01-15 10:31:11.453 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1110, name: 'InputTransportMessageFrame#76', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.90s
2026-01-15 10:31:11.453 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1110, name: 'InputTransportMessageFrame#76', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.90s
2026-01-15 10:31:11.453 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1110, name: 'InputTransportMessageFrame#76', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.90s
2026-01-15 10:31:11.453 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1110, name: 'InputTransportMessageFrame#76', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.90s
2026-01-15 10:31:11.487 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 305, name: 'OutputAudioRawFrame#227', metadata: {} at 5.93s
2026-01-15 10:31:11.487 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 305, name: 'OutputAudioRawFrame#227', metadata: {} at 5.93s
2026-01-15 10:31:11.488 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 1113, name: 'UserSpeakingFrame#140', metadata: {} at 6.84s
2026-01-15 10:31:11.488 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 1114, name: 'UserSpeakingFrame#141', metadata: {} at 6.84s
2026-01-15 10:31:11.488 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 1114, name: 'UserSpeakingFrame#141', metadata: {} at 6.84s
2026-01-15 10:31:11.488 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1111, name: 'OutputAudioRawFrame#505', metadata: {} at 6.84s
2026-01-15 10:31:11.488 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 1113, name: 'UserSpeakingFrame#140', metadata: {} at 6.84s
2026-01-15 10:31:11.488 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1111, name: 'OutputAudioRawFrame#505', metadata: {} at 6.84s
2026-01-15 10:31:11.488 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#140
2026-01-15 10:31:11.488 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#505(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.488 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1115, name: 'RTVIServerMessageFrame#70', metadata: {}, data: {'type': 'user-speaking'} at 6.84s
2026-01-15 10:31:11.488 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1111, name: 'OutputAudioRawFrame#505', metadata: {} at 6.84s
2026-01-15 10:31:11.488 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1116, name: 'OutputTransportMessageUrgentFrame#78', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.84s
2026-01-15 10:31:11.488 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#78(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.488 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#70(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.488 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 1115, name: 'RTVIServerMessageFrame#70', metadata: {}, data: {'type': 'user-speaking'} at 6.84s
2026-01-15 10:31:11.488 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1115, name: 'RTVIServerMessageFrame#70', metadata: {}, data: {'type': 'user-speaking'} at 6.84s
2026-01-15 10:31:11.488 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1111, name: 'OutputAudioRawFrame#505', metadata: {} at 6.84s
2026-01-15 10:31:11.488 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1116, name: 'OutputTransportMessageUrgentFrame#78', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.84s
2026-01-15 10:31:11.488 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1115, name: 'RTVIServerMessageFrame#70', metadata: {}, data: {'type': 'user-speaking'} at 6.84s
2026-01-15 10:31:11.488 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1115, name: 'RTVIServerMessageFrame#70', metadata: {}, data: {'type': 'user-speaking'} at 6.84s
2026-01-15 10:31:11.488 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1111, name: 'OutputAudioRawFrame#505', metadata: {} at 6.84s
2026-01-15 10:31:11.488 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1116, name: 'OutputTransportMessageUrgentFrame#78', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.84s
2026-01-15 10:31:11.489 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1115, name: 'RTVIServerMessageFrame#70', metadata: {}, data: {'type': 'user-speaking'} at 6.84s
2026-01-15 10:31:11.489 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#70(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.489 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#505(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.489 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1115, name: 'RTVIServerMessageFrame#70', metadata: {}, data: {'type': 'user-speaking'} at 6.84s
2026-01-15 10:31:11.489 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1111, name: 'OutputAudioRawFrame#505', metadata: {} at 6.84s
2026-01-15 10:31:11.489 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1116, name: 'OutputTransportMessageUrgentFrame#78', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.84s
2026-01-15 10:31:11.489 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1115, name: 'RTVIServerMessageFrame#70', metadata: {}, data: {'type': 'user-speaking'} at 6.84s
2026-01-15 10:31:11.489 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#78(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.489 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#70(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.489 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1115, name: 'RTVIServerMessageFrame#70', metadata: {}, data: {'type': 'user-speaking'} at 6.84s
2026-01-15 10:31:11.489 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1115, name: 'RTVIServerMessageFrame#70', metadata: {}, data: {'type': 'user-speaking'} at 6.84s
2026-01-15 10:31:11.489 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1111, name: 'OutputAudioRawFrame#505', metadata: {} at 6.84s
2026-01-15 10:31:11.489 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1111, name: 'OutputAudioRawFrame#505', metadata: {} at 6.84s
2026-01-15 10:31:11.489 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1116, name: 'OutputTransportMessageUrgentFrame#78', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.84s
2026-01-15 10:31:11.489 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1115, name: 'RTVIServerMessageFrame#70', metadata: {}, data: {'type': 'user-speaking'} at 6.84s
2026-01-15 10:31:11.489 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1115, name: 'RTVIServerMessageFrame#70', metadata: {}, data: {'type': 'user-speaking'} at 6.84s
2026-01-15 10:31:11.489 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1115, name: 'RTVIServerMessageFrame#70', metadata: {}, data: {'type': 'user-speaking'} at 6.84s
2026-01-15 10:31:11.489 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#77(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.489 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1117, name: 'InputTransportMessageFrame#77', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.93s
2026-01-15 10:31:11.489 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#77(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.489 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#77(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.489 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:11.489 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:11.489 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1117, name: 'InputTransportMessageFrame#77', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.93s
2026-01-15 10:31:11.489 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1117, name: 'InputTransportMessageFrame#77', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.93s
2026-01-15 10:31:11.489 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1117, name: 'InputTransportMessageFrame#77', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.93s
2026-01-15 10:31:11.489 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1117, name: 'InputTransportMessageFrame#77', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.93s
2026-01-15 10:31:11.489 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1117, name: 'InputTransportMessageFrame#77', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.93s
2026-01-15 10:31:11.489 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1117, name: 'InputTransportMessageFrame#77', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.93s
2026-01-15 10:31:11.527 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 307, name: 'OutputAudioRawFrame#229', metadata: {} at 5.97s
2026-01-15 10:31:11.527 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 307, name: 'OutputAudioRawFrame#229', metadata: {} at 5.97s
2026-01-15 10:31:11.528 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 1120, name: 'UserSpeakingFrame#142', metadata: {} at 6.88s
2026-01-15 10:31:11.528 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 1121, name: 'UserSpeakingFrame#143', metadata: {} at 6.88s
2026-01-15 10:31:11.528 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 1121, name: 'UserSpeakingFrame#143', metadata: {} at 6.88s
2026-01-15 10:31:11.528 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1118, name: 'OutputAudioRawFrame#506', metadata: {} at 6.88s
2026-01-15 10:31:11.528 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 1120, name: 'UserSpeakingFrame#142', metadata: {} at 6.88s
2026-01-15 10:31:11.528 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1118, name: 'OutputAudioRawFrame#506', metadata: {} at 6.88s
2026-01-15 10:31:11.528 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#142
2026-01-15 10:31:11.528 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#506(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.528 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1122, name: 'RTVIServerMessageFrame#71', metadata: {}, data: {'type': 'user-speaking'} at 6.88s
2026-01-15 10:31:11.528 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1118, name: 'OutputAudioRawFrame#506', metadata: {} at 6.88s
2026-01-15 10:31:11.528 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1123, name: 'OutputTransportMessageUrgentFrame#79', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.88s
2026-01-15 10:31:11.529 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#79(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.529 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#71(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.529 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 1122, name: 'RTVIServerMessageFrame#71', metadata: {}, data: {'type': 'user-speaking'} at 6.88s
2026-01-15 10:31:11.529 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1122, name: 'RTVIServerMessageFrame#71', metadata: {}, data: {'type': 'user-speaking'} at 6.88s
2026-01-15 10:31:11.529 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1118, name: 'OutputAudioRawFrame#506', metadata: {} at 6.88s
2026-01-15 10:31:11.529 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1123, name: 'OutputTransportMessageUrgentFrame#79', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.88s
2026-01-15 10:31:11.529 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1122, name: 'RTVIServerMessageFrame#71', metadata: {}, data: {'type': 'user-speaking'} at 6.88s
2026-01-15 10:31:11.529 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1122, name: 'RTVIServerMessageFrame#71', metadata: {}, data: {'type': 'user-speaking'} at 6.88s
2026-01-15 10:31:11.530 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1118, name: 'OutputAudioRawFrame#506', metadata: {} at 6.88s
2026-01-15 10:31:11.530 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1123, name: 'OutputTransportMessageUrgentFrame#79', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.88s
2026-01-15 10:31:11.530 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1122, name: 'RTVIServerMessageFrame#71', metadata: {}, data: {'type': 'user-speaking'} at 6.88s
2026-01-15 10:31:11.530 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#71(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.530 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#506(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.530 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1122, name: 'RTVIServerMessageFrame#71', metadata: {}, data: {'type': 'user-speaking'} at 6.88s
2026-01-15 10:31:11.530 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1118, name: 'OutputAudioRawFrame#506', metadata: {} at 6.88s
2026-01-15 10:31:11.530 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1123, name: 'OutputTransportMessageUrgentFrame#79', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.88s
2026-01-15 10:31:11.530 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1122, name: 'RTVIServerMessageFrame#71', metadata: {}, data: {'type': 'user-speaking'} at 6.88s
2026-01-15 10:31:11.530 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#79(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.530 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#71(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.530 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1122, name: 'RTVIServerMessageFrame#71', metadata: {}, data: {'type': 'user-speaking'} at 6.88s
2026-01-15 10:31:11.530 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1122, name: 'RTVIServerMessageFrame#71', metadata: {}, data: {'type': 'user-speaking'} at 6.88s
2026-01-15 10:31:11.530 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1118, name: 'OutputAudioRawFrame#506', metadata: {} at 6.88s
2026-01-15 10:31:11.530 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1118, name: 'OutputAudioRawFrame#506', metadata: {} at 6.88s
2026-01-15 10:31:11.530 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1123, name: 'OutputTransportMessageUrgentFrame#79', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.88s
2026-01-15 10:31:11.530 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1122, name: 'RTVIServerMessageFrame#71', metadata: {}, data: {'type': 'user-speaking'} at 6.88s
2026-01-15 10:31:11.530 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1122, name: 'RTVIServerMessageFrame#71', metadata: {}, data: {'type': 'user-speaking'} at 6.88s
2026-01-15 10:31:11.530 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1122, name: 'RTVIServerMessageFrame#71', metadata: {}, data: {'type': 'user-speaking'} at 6.88s
2026-01-15 10:31:11.531 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#78(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.531 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1124, name: 'InputTransportMessageFrame#78', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.97s
2026-01-15 10:31:11.531 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#78(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.531 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#78(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.531 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:11.531 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:11.531 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1124, name: 'InputTransportMessageFrame#78', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.97s
2026-01-15 10:31:11.531 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1124, name: 'InputTransportMessageFrame#78', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.97s
2026-01-15 10:31:11.531 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1124, name: 'InputTransportMessageFrame#78', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.97s
2026-01-15 10:31:11.531 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1124, name: 'InputTransportMessageFrame#78', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.97s
2026-01-15 10:31:11.531 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1124, name: 'InputTransportMessageFrame#78', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.97s
2026-01-15 10:31:11.531 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1124, name: 'InputTransportMessageFrame#78', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 5.97s
2026-01-15 10:31:11.567 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 308, name: 'OutputAudioRawFrame#230', metadata: {} at 6.01s
2026-01-15 10:31:11.567 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 308, name: 'OutputAudioRawFrame#230', metadata: {} at 6.01s
2026-01-15 10:31:11.569 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 1127, name: 'UserSpeakingFrame#144', metadata: {} at 6.92s
2026-01-15 10:31:11.569 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 1128, name: 'UserSpeakingFrame#145', metadata: {} at 6.92s
2026-01-15 10:31:11.569 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 1128, name: 'UserSpeakingFrame#145', metadata: {} at 6.92s
2026-01-15 10:31:11.569 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1125, name: 'OutputAudioRawFrame#507', metadata: {} at 6.92s
2026-01-15 10:31:11.569 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 1127, name: 'UserSpeakingFrame#144', metadata: {} at 6.92s
2026-01-15 10:31:11.569 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1125, name: 'OutputAudioRawFrame#507', metadata: {} at 6.92s
2026-01-15 10:31:11.569 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#144
2026-01-15 10:31:11.569 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#507(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.569 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1129, name: 'RTVIServerMessageFrame#72', metadata: {}, data: {'type': 'user-speaking'} at 6.92s
2026-01-15 10:31:11.570 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1125, name: 'OutputAudioRawFrame#507', metadata: {} at 6.92s
2026-01-15 10:31:11.570 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1130, name: 'OutputTransportMessageUrgentFrame#80', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.92s
2026-01-15 10:31:11.570 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#80(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.570 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#72(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.570 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 1129, name: 'RTVIServerMessageFrame#72', metadata: {}, data: {'type': 'user-speaking'} at 6.92s
2026-01-15 10:31:11.570 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1129, name: 'RTVIServerMessageFrame#72', metadata: {}, data: {'type': 'user-speaking'} at 6.92s
2026-01-15 10:31:11.570 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1125, name: 'OutputAudioRawFrame#507', metadata: {} at 6.92s
2026-01-15 10:31:11.570 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1130, name: 'OutputTransportMessageUrgentFrame#80', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.92s
2026-01-15 10:31:11.570 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1129, name: 'RTVIServerMessageFrame#72', metadata: {}, data: {'type': 'user-speaking'} at 6.92s
2026-01-15 10:31:11.570 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1129, name: 'RTVIServerMessageFrame#72', metadata: {}, data: {'type': 'user-speaking'} at 6.92s
2026-01-15 10:31:11.571 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1125, name: 'OutputAudioRawFrame#507', metadata: {} at 6.92s
2026-01-15 10:31:11.571 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1130, name: 'OutputTransportMessageUrgentFrame#80', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.92s
2026-01-15 10:31:11.571 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1129, name: 'RTVIServerMessageFrame#72', metadata: {}, data: {'type': 'user-speaking'} at 6.92s
2026-01-15 10:31:11.571 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#72(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.571 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#507(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.571 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1129, name: 'RTVIServerMessageFrame#72', metadata: {}, data: {'type': 'user-speaking'} at 6.93s
2026-01-15 10:31:11.571 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1125, name: 'OutputAudioRawFrame#507', metadata: {} at 6.93s
2026-01-15 10:31:11.571 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1130, name: 'OutputTransportMessageUrgentFrame#80', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.93s
2026-01-15 10:31:11.571 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1129, name: 'RTVIServerMessageFrame#72', metadata: {}, data: {'type': 'user-speaking'} at 6.93s
2026-01-15 10:31:11.571 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#80(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.571 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#72(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.571 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1129, name: 'RTVIServerMessageFrame#72', metadata: {}, data: {'type': 'user-speaking'} at 6.93s
2026-01-15 10:31:11.571 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1129, name: 'RTVIServerMessageFrame#72', metadata: {}, data: {'type': 'user-speaking'} at 6.93s
2026-01-15 10:31:11.571 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1125, name: 'OutputAudioRawFrame#507', metadata: {} at 6.93s
2026-01-15 10:31:11.571 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1125, name: 'OutputAudioRawFrame#507', metadata: {} at 6.93s
2026-01-15 10:31:11.571 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1130, name: 'OutputTransportMessageUrgentFrame#80', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.93s
2026-01-15 10:31:11.571 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1129, name: 'RTVIServerMessageFrame#72', metadata: {}, data: {'type': 'user-speaking'} at 6.93s
2026-01-15 10:31:11.571 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1129, name: 'RTVIServerMessageFrame#72', metadata: {}, data: {'type': 'user-speaking'} at 6.93s
2026-01-15 10:31:11.571 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1129, name: 'RTVIServerMessageFrame#72', metadata: {}, data: {'type': 'user-speaking'} at 6.93s
2026-01-15 10:31:11.571 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#79(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.571 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1131, name: 'InputTransportMessageFrame#79', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.02s
2026-01-15 10:31:11.571 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#79(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.571 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#79(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.571 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:11.571 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:11.571 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1131, name: 'InputTransportMessageFrame#79', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.02s
2026-01-15 10:31:11.571 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1131, name: 'InputTransportMessageFrame#79', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.02s
2026-01-15 10:31:11.571 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1131, name: 'InputTransportMessageFrame#79', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.02s
2026-01-15 10:31:11.571 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1131, name: 'InputTransportMessageFrame#79', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.02s
2026-01-15 10:31:11.571 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1131, name: 'InputTransportMessageFrame#79', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.02s
2026-01-15 10:31:11.571 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1131, name: 'InputTransportMessageFrame#79', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.02s
2026-01-15 10:31:11.607 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 310, name: 'OutputAudioRawFrame#232', metadata: {} at 6.05s
2026-01-15 10:31:11.607 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 310, name: 'OutputAudioRawFrame#232', metadata: {} at 6.05s
2026-01-15 10:31:11.610 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 1134, name: 'UserSpeakingFrame#146', metadata: {} at 6.96s
2026-01-15 10:31:11.610 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 1135, name: 'UserSpeakingFrame#147', metadata: {} at 6.96s
2026-01-15 10:31:11.610 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 1135, name: 'UserSpeakingFrame#147', metadata: {} at 6.96s
2026-01-15 10:31:11.610 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1132, name: 'OutputAudioRawFrame#508', metadata: {} at 6.96s
2026-01-15 10:31:11.610 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 1134, name: 'UserSpeakingFrame#146', metadata: {} at 6.96s
2026-01-15 10:31:11.610 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1132, name: 'OutputAudioRawFrame#508', metadata: {} at 6.96s
2026-01-15 10:31:11.610 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#146
2026-01-15 10:31:11.610 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#508(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.611 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1136, name: 'RTVIServerMessageFrame#73', metadata: {}, data: {'type': 'user-speaking'} at 6.96s
2026-01-15 10:31:11.611 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1132, name: 'OutputAudioRawFrame#508', metadata: {} at 6.96s
2026-01-15 10:31:11.611 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1137, name: 'OutputTransportMessageUrgentFrame#81', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.97s
2026-01-15 10:31:11.612 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#81(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.612 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#73(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.612 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 1136, name: 'RTVIServerMessageFrame#73', metadata: {}, data: {'type': 'user-speaking'} at 6.97s
2026-01-15 10:31:11.612 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1136, name: 'RTVIServerMessageFrame#73', metadata: {}, data: {'type': 'user-speaking'} at 6.97s
2026-01-15 10:31:11.613 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1132, name: 'OutputAudioRawFrame#508', metadata: {} at 6.97s
2026-01-15 10:31:11.613 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1137, name: 'OutputTransportMessageUrgentFrame#81', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.97s
2026-01-15 10:31:11.613 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1136, name: 'RTVIServerMessageFrame#73', metadata: {}, data: {'type': 'user-speaking'} at 6.97s
2026-01-15 10:31:11.613 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1136, name: 'RTVIServerMessageFrame#73', metadata: {}, data: {'type': 'user-speaking'} at 6.97s
2026-01-15 10:31:11.613 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1132, name: 'OutputAudioRawFrame#508', metadata: {} at 6.97s
2026-01-15 10:31:11.613 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1137, name: 'OutputTransportMessageUrgentFrame#81', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.97s
2026-01-15 10:31:11.613 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1136, name: 'RTVIServerMessageFrame#73', metadata: {}, data: {'type': 'user-speaking'} at 6.97s
2026-01-15 10:31:11.613 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#73(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.613 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#508(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.613 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1136, name: 'RTVIServerMessageFrame#73', metadata: {}, data: {'type': 'user-speaking'} at 6.97s
2026-01-15 10:31:11.613 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1132, name: 'OutputAudioRawFrame#508', metadata: {} at 6.97s
2026-01-15 10:31:11.613 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1137, name: 'OutputTransportMessageUrgentFrame#81', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.97s
2026-01-15 10:31:11.613 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1136, name: 'RTVIServerMessageFrame#73', metadata: {}, data: {'type': 'user-speaking'} at 6.97s
2026-01-15 10:31:11.613 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#81(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.613 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#73(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.613 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1136, name: 'RTVIServerMessageFrame#73', metadata: {}, data: {'type': 'user-speaking'} at 6.97s
2026-01-15 10:31:11.613 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1136, name: 'RTVIServerMessageFrame#73', metadata: {}, data: {'type': 'user-speaking'} at 6.97s
2026-01-15 10:31:11.613 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1132, name: 'OutputAudioRawFrame#508', metadata: {} at 6.97s
2026-01-15 10:31:11.613 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1132, name: 'OutputAudioRawFrame#508', metadata: {} at 6.97s
2026-01-15 10:31:11.613 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1137, name: 'OutputTransportMessageUrgentFrame#81', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.97s
2026-01-15 10:31:11.614 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1136, name: 'RTVIServerMessageFrame#73', metadata: {}, data: {'type': 'user-speaking'} at 6.97s
2026-01-15 10:31:11.614 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1136, name: 'RTVIServerMessageFrame#73', metadata: {}, data: {'type': 'user-speaking'} at 6.97s
2026-01-15 10:31:11.614 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1136, name: 'RTVIServerMessageFrame#73', metadata: {}, data: {'type': 'user-speaking'} at 6.97s
2026-01-15 10:31:11.614 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#80(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.614 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1138, name: 'InputTransportMessageFrame#80', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.06s
2026-01-15 10:31:11.614 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#80(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.614 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#80(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.614 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:11.614 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:11.614 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1138, name: 'InputTransportMessageFrame#80', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.06s
2026-01-15 10:31:11.614 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1138, name: 'InputTransportMessageFrame#80', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.06s
2026-01-15 10:31:11.614 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1138, name: 'InputTransportMessageFrame#80', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.06s
2026-01-15 10:31:11.614 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1138, name: 'InputTransportMessageFrame#80', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.06s
2026-01-15 10:31:11.614 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1138, name: 'InputTransportMessageFrame#80', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.06s
2026-01-15 10:31:11.614 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1138, name: 'InputTransportMessageFrame#80', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.06s
2026-01-15 10:31:11.647 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 312, name: 'OutputAudioRawFrame#234', metadata: {} at 6.09s
2026-01-15 10:31:11.647 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 312, name: 'OutputAudioRawFrame#234', metadata: {} at 6.09s
2026-01-15 10:31:11.651 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 1141, name: 'UserSpeakingFrame#148', metadata: {} at 7.01s
2026-01-15 10:31:11.651 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 1142, name: 'UserSpeakingFrame#149', metadata: {} at 7.01s
2026-01-15 10:31:11.651 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 1142, name: 'UserSpeakingFrame#149', metadata: {} at 7.01s
2026-01-15 10:31:11.651 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1139, name: 'OutputAudioRawFrame#509', metadata: {} at 7.01s
2026-01-15 10:31:11.652 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 1141, name: 'UserSpeakingFrame#148', metadata: {} at 7.01s
2026-01-15 10:31:11.652 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1139, name: 'OutputAudioRawFrame#509', metadata: {} at 7.01s
2026-01-15 10:31:11.652 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#148
2026-01-15 10:31:11.652 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#509(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.653 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1143, name: 'RTVIServerMessageFrame#74', metadata: {}, data: {'type': 'user-speaking'} at 7.01s
2026-01-15 10:31:11.653 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1139, name: 'OutputAudioRawFrame#509', metadata: {} at 7.01s
2026-01-15 10:31:11.653 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1144, name: 'OutputTransportMessageUrgentFrame#82', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.01s
2026-01-15 10:31:11.654 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#82(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.654 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#74(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.654 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 1143, name: 'RTVIServerMessageFrame#74', metadata: {}, data: {'type': 'user-speaking'} at 7.01s
2026-01-15 10:31:11.654 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1143, name: 'RTVIServerMessageFrame#74', metadata: {}, data: {'type': 'user-speaking'} at 7.01s
2026-01-15 10:31:11.654 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1139, name: 'OutputAudioRawFrame#509', metadata: {} at 7.01s
2026-01-15 10:31:11.654 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1144, name: 'OutputTransportMessageUrgentFrame#82', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.01s
2026-01-15 10:31:11.654 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1143, name: 'RTVIServerMessageFrame#74', metadata: {}, data: {'type': 'user-speaking'} at 7.01s
2026-01-15 10:31:11.655 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1143, name: 'RTVIServerMessageFrame#74', metadata: {}, data: {'type': 'user-speaking'} at 7.01s
2026-01-15 10:31:11.655 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1139, name: 'OutputAudioRawFrame#509', metadata: {} at 7.01s
2026-01-15 10:31:11.655 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1144, name: 'OutputTransportMessageUrgentFrame#82', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.01s
2026-01-15 10:31:11.655 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1143, name: 'RTVIServerMessageFrame#74', metadata: {}, data: {'type': 'user-speaking'} at 7.01s
2026-01-15 10:31:11.655 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#74(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.655 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#509(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.655 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1143, name: 'RTVIServerMessageFrame#74', metadata: {}, data: {'type': 'user-speaking'} at 7.01s
2026-01-15 10:31:11.655 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1139, name: 'OutputAudioRawFrame#509', metadata: {} at 7.01s
2026-01-15 10:31:11.655 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1144, name: 'OutputTransportMessageUrgentFrame#82', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.01s
2026-01-15 10:31:11.655 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1143, name: 'RTVIServerMessageFrame#74', metadata: {}, data: {'type': 'user-speaking'} at 7.01s
2026-01-15 10:31:11.655 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#82(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.655 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#74(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.655 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1143, name: 'RTVIServerMessageFrame#74', metadata: {}, data: {'type': 'user-speaking'} at 7.01s
2026-01-15 10:31:11.655 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1143, name: 'RTVIServerMessageFrame#74', metadata: {}, data: {'type': 'user-speaking'} at 7.01s
2026-01-15 10:31:11.655 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1139, name: 'OutputAudioRawFrame#509', metadata: {} at 7.01s
2026-01-15 10:31:11.655 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1139, name: 'OutputAudioRawFrame#509', metadata: {} at 7.01s
2026-01-15 10:31:11.655 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1144, name: 'OutputTransportMessageUrgentFrame#82', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.01s
2026-01-15 10:31:11.655 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1143, name: 'RTVIServerMessageFrame#74', metadata: {}, data: {'type': 'user-speaking'} at 7.01s
2026-01-15 10:31:11.656 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1143, name: 'RTVIServerMessageFrame#74', metadata: {}, data: {'type': 'user-speaking'} at 7.01s
2026-01-15 10:31:11.656 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1143, name: 'RTVIServerMessageFrame#74', metadata: {}, data: {'type': 'user-speaking'} at 7.01s
2026-01-15 10:31:11.656 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#81(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.656 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1145, name: 'InputTransportMessageFrame#81', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.10s
2026-01-15 10:31:11.656 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#81(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.656 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#81(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.656 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:11.656 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:11.656 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1145, name: 'InputTransportMessageFrame#81', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.10s
2026-01-15 10:31:11.656 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1145, name: 'InputTransportMessageFrame#81', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.10s
2026-01-15 10:31:11.656 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1145, name: 'InputTransportMessageFrame#81', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.10s
2026-01-15 10:31:11.656 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1145, name: 'InputTransportMessageFrame#81', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.10s
2026-01-15 10:31:11.656 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1145, name: 'InputTransportMessageFrame#81', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.10s
2026-01-15 10:31:11.656 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1145, name: 'InputTransportMessageFrame#81', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.10s
2026-01-15 10:31:11.687 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 313, name: 'OutputAudioRawFrame#235', metadata: {} at 6.13s
2026-01-15 10:31:11.687 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 313, name: 'OutputAudioRawFrame#235', metadata: {} at 6.13s
2026-01-15 10:31:11.690 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 1148, name: 'UserSpeakingFrame#150', metadata: {} at 7.04s
2026-01-15 10:31:11.690 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 1149, name: 'UserSpeakingFrame#151', metadata: {} at 7.04s
2026-01-15 10:31:11.690 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 1149, name: 'UserSpeakingFrame#151', metadata: {} at 7.04s
2026-01-15 10:31:11.690 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1146, name: 'OutputAudioRawFrame#510', metadata: {} at 7.04s
2026-01-15 10:31:11.691 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 1148, name: 'UserSpeakingFrame#150', metadata: {} at 7.04s
2026-01-15 10:31:11.691 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1146, name: 'OutputAudioRawFrame#510', metadata: {} at 7.04s
2026-01-15 10:31:11.691 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#150
2026-01-15 10:31:11.691 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#510(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.691 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1150, name: 'RTVIServerMessageFrame#75', metadata: {}, data: {'type': 'user-speaking'} at 7.05s
2026-01-15 10:31:11.691 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1146, name: 'OutputAudioRawFrame#510', metadata: {} at 7.05s
2026-01-15 10:31:11.691 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1151, name: 'OutputTransportMessageUrgentFrame#83', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.05s
2026-01-15 10:31:11.692 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#83(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.692 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#75(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.692 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 1150, name: 'RTVIServerMessageFrame#75', metadata: {}, data: {'type': 'user-speaking'} at 7.05s
2026-01-15 10:31:11.692 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1150, name: 'RTVIServerMessageFrame#75', metadata: {}, data: {'type': 'user-speaking'} at 7.05s
2026-01-15 10:31:11.692 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1146, name: 'OutputAudioRawFrame#510', metadata: {} at 7.05s
2026-01-15 10:31:11.692 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1151, name: 'OutputTransportMessageUrgentFrame#83', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.05s
2026-01-15 10:31:11.692 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1150, name: 'RTVIServerMessageFrame#75', metadata: {}, data: {'type': 'user-speaking'} at 7.05s
2026-01-15 10:31:11.692 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1150, name: 'RTVIServerMessageFrame#75', metadata: {}, data: {'type': 'user-speaking'} at 7.05s
2026-01-15 10:31:11.692 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1146, name: 'OutputAudioRawFrame#510', metadata: {} at 7.05s
2026-01-15 10:31:11.692 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1151, name: 'OutputTransportMessageUrgentFrame#83', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.05s
2026-01-15 10:31:11.692 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1150, name: 'RTVIServerMessageFrame#75', metadata: {}, data: {'type': 'user-speaking'} at 7.05s
2026-01-15 10:31:11.692 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#75(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.693 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#510(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.693 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1150, name: 'RTVIServerMessageFrame#75', metadata: {}, data: {'type': 'user-speaking'} at 7.05s
2026-01-15 10:31:11.693 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1146, name: 'OutputAudioRawFrame#510', metadata: {} at 7.05s
2026-01-15 10:31:11.693 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1151, name: 'OutputTransportMessageUrgentFrame#83', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.05s
2026-01-15 10:31:11.693 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1150, name: 'RTVIServerMessageFrame#75', metadata: {}, data: {'type': 'user-speaking'} at 7.05s
2026-01-15 10:31:11.693 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#83(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.693 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#75(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.693 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1150, name: 'RTVIServerMessageFrame#75', metadata: {}, data: {'type': 'user-speaking'} at 7.05s
2026-01-15 10:31:11.693 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1150, name: 'RTVIServerMessageFrame#75', metadata: {}, data: {'type': 'user-speaking'} at 7.05s
2026-01-15 10:31:11.693 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1146, name: 'OutputAudioRawFrame#510', metadata: {} at 7.05s
2026-01-15 10:31:11.693 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1146, name: 'OutputAudioRawFrame#510', metadata: {} at 7.05s
2026-01-15 10:31:11.693 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1151, name: 'OutputTransportMessageUrgentFrame#83', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.05s
2026-01-15 10:31:11.693 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1150, name: 'RTVIServerMessageFrame#75', metadata: {}, data: {'type': 'user-speaking'} at 7.05s
2026-01-15 10:31:11.694 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1150, name: 'RTVIServerMessageFrame#75', metadata: {}, data: {'type': 'user-speaking'} at 7.05s
2026-01-15 10:31:11.694 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1150, name: 'RTVIServerMessageFrame#75', metadata: {}, data: {'type': 'user-speaking'} at 7.05s
2026-01-15 10:31:11.694 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#82(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.694 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1152, name: 'InputTransportMessageFrame#82', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.14s
2026-01-15 10:31:11.694 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#82(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.694 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#82(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.694 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:11.694 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:11.694 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1152, name: 'InputTransportMessageFrame#82', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.14s
2026-01-15 10:31:11.694 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1152, name: 'InputTransportMessageFrame#82', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.14s
2026-01-15 10:31:11.694 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1152, name: 'InputTransportMessageFrame#82', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.14s
2026-01-15 10:31:11.694 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1152, name: 'InputTransportMessageFrame#82', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.14s
2026-01-15 10:31:11.694 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1152, name: 'InputTransportMessageFrame#82', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.14s
2026-01-15 10:31:11.694 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1152, name: 'InputTransportMessageFrame#82', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.14s
2026-01-15 10:31:11.727 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 315, name: 'OutputAudioRawFrame#237', metadata: {} at 6.17s
2026-01-15 10:31:11.727 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 315, name: 'OutputAudioRawFrame#237', metadata: {} at 6.17s
2026-01-15 10:31:11.729 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 1155, name: 'UserSpeakingFrame#152', metadata: {} at 7.08s
2026-01-15 10:31:11.729 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 1156, name: 'UserSpeakingFrame#153', metadata: {} at 7.08s
2026-01-15 10:31:11.729 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 1156, name: 'UserSpeakingFrame#153', metadata: {} at 7.08s
2026-01-15 10:31:11.729 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1153, name: 'OutputAudioRawFrame#511', metadata: {} at 7.08s
2026-01-15 10:31:11.729 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 1155, name: 'UserSpeakingFrame#152', metadata: {} at 7.08s
2026-01-15 10:31:11.729 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1153, name: 'OutputAudioRawFrame#511', metadata: {} at 7.08s
2026-01-15 10:31:11.730 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#152
2026-01-15 10:31:11.730 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#511(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.730 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1157, name: 'RTVIServerMessageFrame#76', metadata: {}, data: {'type': 'user-speaking'} at 7.08s
2026-01-15 10:31:11.730 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1153, name: 'OutputAudioRawFrame#511', metadata: {} at 7.08s
2026-01-15 10:31:11.730 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1158, name: 'OutputTransportMessageUrgentFrame#84', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.08s
2026-01-15 10:31:11.731 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#84(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.731 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#76(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.731 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 1157, name: 'RTVIServerMessageFrame#76', metadata: {}, data: {'type': 'user-speaking'} at 7.08s
2026-01-15 10:31:11.731 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1157, name: 'RTVIServerMessageFrame#76', metadata: {}, data: {'type': 'user-speaking'} at 7.08s
2026-01-15 10:31:11.731 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1153, name: 'OutputAudioRawFrame#511', metadata: {} at 7.08s
2026-01-15 10:31:11.731 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1158, name: 'OutputTransportMessageUrgentFrame#84', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.09s
2026-01-15 10:31:11.731 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1157, name: 'RTVIServerMessageFrame#76', metadata: {}, data: {'type': 'user-speaking'} at 7.09s
2026-01-15 10:31:11.731 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1157, name: 'RTVIServerMessageFrame#76', metadata: {}, data: {'type': 'user-speaking'} at 7.09s
2026-01-15 10:31:11.731 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1153, name: 'OutputAudioRawFrame#511', metadata: {} at 7.09s
2026-01-15 10:31:11.731 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1158, name: 'OutputTransportMessageUrgentFrame#84', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.09s
2026-01-15 10:31:11.731 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1157, name: 'RTVIServerMessageFrame#76', metadata: {}, data: {'type': 'user-speaking'} at 7.09s
2026-01-15 10:31:11.731 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#76(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.731 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#511(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.731 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1157, name: 'RTVIServerMessageFrame#76', metadata: {}, data: {'type': 'user-speaking'} at 7.09s
2026-01-15 10:31:11.731 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1153, name: 'OutputAudioRawFrame#511', metadata: {} at 7.09s
2026-01-15 10:31:11.731 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1158, name: 'OutputTransportMessageUrgentFrame#84', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.09s
2026-01-15 10:31:11.731 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1157, name: 'RTVIServerMessageFrame#76', metadata: {}, data: {'type': 'user-speaking'} at 7.09s
2026-01-15 10:31:11.732 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#84(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.732 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#76(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.732 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1157, name: 'RTVIServerMessageFrame#76', metadata: {}, data: {'type': 'user-speaking'} at 7.09s
2026-01-15 10:31:11.732 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1157, name: 'RTVIServerMessageFrame#76', metadata: {}, data: {'type': 'user-speaking'} at 7.09s
2026-01-15 10:31:11.732 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1153, name: 'OutputAudioRawFrame#511', metadata: {} at 7.09s
2026-01-15 10:31:11.732 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1153, name: 'OutputAudioRawFrame#511', metadata: {} at 7.09s
2026-01-15 10:31:11.732 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1158, name: 'OutputTransportMessageUrgentFrame#84', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.09s
2026-01-15 10:31:11.732 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1157, name: 'RTVIServerMessageFrame#76', metadata: {}, data: {'type': 'user-speaking'} at 7.09s
2026-01-15 10:31:11.732 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1157, name: 'RTVIServerMessageFrame#76', metadata: {}, data: {'type': 'user-speaking'} at 7.09s
2026-01-15 10:31:11.732 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1157, name: 'RTVIServerMessageFrame#76', metadata: {}, data: {'type': 'user-speaking'} at 7.09s
2026-01-15 10:31:11.732 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#83(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.732 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1159, name: 'InputTransportMessageFrame#83', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.18s
2026-01-15 10:31:11.733 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#83(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.733 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#83(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.733 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:11.733 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:11.733 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1159, name: 'InputTransportMessageFrame#83', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.18s
2026-01-15 10:31:11.733 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1159, name: 'InputTransportMessageFrame#83', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.18s
2026-01-15 10:31:11.733 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1159, name: 'InputTransportMessageFrame#83', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.18s
2026-01-15 10:31:11.733 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1159, name: 'InputTransportMessageFrame#83', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.18s
2026-01-15 10:31:11.733 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1159, name: 'InputTransportMessageFrame#83', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.18s
2026-01-15 10:31:11.733 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1159, name: 'InputTransportMessageFrame#83', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.18s
2026-01-15 10:31:11.767 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 316, name: 'OutputAudioRawFrame#238', metadata: {} at 6.21s
2026-01-15 10:31:11.767 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 316, name: 'OutputAudioRawFrame#238', metadata: {} at 6.21s
2026-01-15 10:31:11.768 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 1162, name: 'UserSpeakingFrame#154', metadata: {} at 7.12s
2026-01-15 10:31:11.768 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 1163, name: 'UserSpeakingFrame#155', metadata: {} at 7.12s
2026-01-15 10:31:11.768 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 1163, name: 'UserSpeakingFrame#155', metadata: {} at 7.12s
2026-01-15 10:31:11.768 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1160, name: 'OutputAudioRawFrame#512', metadata: {} at 7.12s
2026-01-15 10:31:11.768 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 1162, name: 'UserSpeakingFrame#154', metadata: {} at 7.12s
2026-01-15 10:31:11.768 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1160, name: 'OutputAudioRawFrame#512', metadata: {} at 7.12s
2026-01-15 10:31:11.769 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#154
2026-01-15 10:31:11.769 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#512(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.769 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1164, name: 'RTVIServerMessageFrame#77', metadata: {}, data: {'type': 'user-speaking'} at 7.12s
2026-01-15 10:31:11.769 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1160, name: 'OutputAudioRawFrame#512', metadata: {} at 7.12s
2026-01-15 10:31:11.769 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1165, name: 'OutputTransportMessageUrgentFrame#85', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.12s
2026-01-15 10:31:11.769 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#85(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.769 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#77(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.769 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 1164, name: 'RTVIServerMessageFrame#77', metadata: {}, data: {'type': 'user-speaking'} at 7.12s
2026-01-15 10:31:11.769 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1164, name: 'RTVIServerMessageFrame#77', metadata: {}, data: {'type': 'user-speaking'} at 7.12s
2026-01-15 10:31:11.770 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1160, name: 'OutputAudioRawFrame#512', metadata: {} at 7.12s
2026-01-15 10:31:11.770 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1165, name: 'OutputTransportMessageUrgentFrame#85', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.12s
2026-01-15 10:31:11.770 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1164, name: 'RTVIServerMessageFrame#77', metadata: {}, data: {'type': 'user-speaking'} at 7.12s
2026-01-15 10:31:11.770 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1164, name: 'RTVIServerMessageFrame#77', metadata: {}, data: {'type': 'user-speaking'} at 7.12s
2026-01-15 10:31:11.770 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1160, name: 'OutputAudioRawFrame#512', metadata: {} at 7.12s
2026-01-15 10:31:11.770 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1165, name: 'OutputTransportMessageUrgentFrame#85', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.12s
2026-01-15 10:31:11.770 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1164, name: 'RTVIServerMessageFrame#77', metadata: {}, data: {'type': 'user-speaking'} at 7.12s
2026-01-15 10:31:11.770 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#77(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.770 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#512(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.770 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1164, name: 'RTVIServerMessageFrame#77', metadata: {}, data: {'type': 'user-speaking'} at 7.12s
2026-01-15 10:31:11.770 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1160, name: 'OutputAudioRawFrame#512', metadata: {} at 7.12s
2026-01-15 10:31:11.770 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1165, name: 'OutputTransportMessageUrgentFrame#85', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.12s
2026-01-15 10:31:11.770 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1164, name: 'RTVIServerMessageFrame#77', metadata: {}, data: {'type': 'user-speaking'} at 7.12s
2026-01-15 10:31:11.770 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#85(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.770 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#77(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.770 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1164, name: 'RTVIServerMessageFrame#77', metadata: {}, data: {'type': 'user-speaking'} at 7.12s
2026-01-15 10:31:11.770 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1164, name: 'RTVIServerMessageFrame#77', metadata: {}, data: {'type': 'user-speaking'} at 7.12s
2026-01-15 10:31:11.770 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1160, name: 'OutputAudioRawFrame#512', metadata: {} at 7.12s
2026-01-15 10:31:11.770 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1160, name: 'OutputAudioRawFrame#512', metadata: {} at 7.12s
2026-01-15 10:31:11.770 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1165, name: 'OutputTransportMessageUrgentFrame#85', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.12s
2026-01-15 10:31:11.770 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1164, name: 'RTVIServerMessageFrame#77', metadata: {}, data: {'type': 'user-speaking'} at 7.12s
2026-01-15 10:31:11.771 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1164, name: 'RTVIServerMessageFrame#77', metadata: {}, data: {'type': 'user-speaking'} at 7.12s
2026-01-15 10:31:11.771 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1164, name: 'RTVIServerMessageFrame#77', metadata: {}, data: {'type': 'user-speaking'} at 7.13s
2026-01-15 10:31:11.771 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#84(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.771 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1166, name: 'InputTransportMessageFrame#84', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.21s
2026-01-15 10:31:11.771 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#84(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.771 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#84(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.771 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:11.771 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:11.771 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1166, name: 'InputTransportMessageFrame#84', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.21s
2026-01-15 10:31:11.771 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1166, name: 'InputTransportMessageFrame#84', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.21s
2026-01-15 10:31:11.771 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1166, name: 'InputTransportMessageFrame#84', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.21s
2026-01-15 10:31:11.771 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1166, name: 'InputTransportMessageFrame#84', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.21s
2026-01-15 10:31:11.771 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1166, name: 'InputTransportMessageFrame#84', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.22s
2026-01-15 10:31:11.771 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1166, name: 'InputTransportMessageFrame#84', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.22s
2026-01-15 10:31:11.806 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 318, name: 'OutputAudioRawFrame#240', metadata: {} at 6.25s
2026-01-15 10:31:11.807 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 318, name: 'OutputAudioRawFrame#240', metadata: {} at 6.25s
2026-01-15 10:31:11.808 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 1169, name: 'UserSpeakingFrame#156', metadata: {} at 7.16s
2026-01-15 10:31:11.808 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 1170, name: 'UserSpeakingFrame#157', metadata: {} at 7.16s
2026-01-15 10:31:11.808 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 1170, name: 'UserSpeakingFrame#157', metadata: {} at 7.16s
2026-01-15 10:31:11.808 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1167, name: 'OutputAudioRawFrame#513', metadata: {} at 7.16s
2026-01-15 10:31:11.808 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 1169, name: 'UserSpeakingFrame#156', metadata: {} at 7.16s
2026-01-15 10:31:11.808 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1167, name: 'OutputAudioRawFrame#513', metadata: {} at 7.16s
2026-01-15 10:31:11.808 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#156
2026-01-15 10:31:11.808 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#513(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.809 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1171, name: 'RTVIServerMessageFrame#78', metadata: {}, data: {'type': 'user-speaking'} at 7.16s
2026-01-15 10:31:11.809 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1167, name: 'OutputAudioRawFrame#513', metadata: {} at 7.16s
2026-01-15 10:31:11.809 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1172, name: 'OutputTransportMessageUrgentFrame#86', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.16s
2026-01-15 10:31:11.809 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#86(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.809 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#78(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.809 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 1171, name: 'RTVIServerMessageFrame#78', metadata: {}, data: {'type': 'user-speaking'} at 7.16s
2026-01-15 10:31:11.809 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1171, name: 'RTVIServerMessageFrame#78', metadata: {}, data: {'type': 'user-speaking'} at 7.16s
2026-01-15 10:31:11.809 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1167, name: 'OutputAudioRawFrame#513', metadata: {} at 7.16s
2026-01-15 10:31:11.809 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1172, name: 'OutputTransportMessageUrgentFrame#86', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.16s
2026-01-15 10:31:11.809 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1171, name: 'RTVIServerMessageFrame#78', metadata: {}, data: {'type': 'user-speaking'} at 7.16s
2026-01-15 10:31:11.810 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1171, name: 'RTVIServerMessageFrame#78', metadata: {}, data: {'type': 'user-speaking'} at 7.16s
2026-01-15 10:31:11.810 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1167, name: 'OutputAudioRawFrame#513', metadata: {} at 7.16s
2026-01-15 10:31:11.810 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1172, name: 'OutputTransportMessageUrgentFrame#86', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.16s
2026-01-15 10:31:11.810 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1171, name: 'RTVIServerMessageFrame#78', metadata: {}, data: {'type': 'user-speaking'} at 7.16s
2026-01-15 10:31:11.810 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#78(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.810 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#513(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.810 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1171, name: 'RTVIServerMessageFrame#78', metadata: {}, data: {'type': 'user-speaking'} at 7.16s
2026-01-15 10:31:11.810 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1167, name: 'OutputAudioRawFrame#513', metadata: {} at 7.16s
2026-01-15 10:31:11.810 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1172, name: 'OutputTransportMessageUrgentFrame#86', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.16s
2026-01-15 10:31:11.810 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1171, name: 'RTVIServerMessageFrame#78', metadata: {}, data: {'type': 'user-speaking'} at 7.16s
2026-01-15 10:31:11.810 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#86(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.810 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#78(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.810 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1171, name: 'RTVIServerMessageFrame#78', metadata: {}, data: {'type': 'user-speaking'} at 7.16s
2026-01-15 10:31:11.810 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1171, name: 'RTVIServerMessageFrame#78', metadata: {}, data: {'type': 'user-speaking'} at 7.16s
2026-01-15 10:31:11.810 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1167, name: 'OutputAudioRawFrame#513', metadata: {} at 7.16s
2026-01-15 10:31:11.810 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1167, name: 'OutputAudioRawFrame#513', metadata: {} at 7.16s
2026-01-15 10:31:11.810 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1172, name: 'OutputTransportMessageUrgentFrame#86', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.16s
2026-01-15 10:31:11.810 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1171, name: 'RTVIServerMessageFrame#78', metadata: {}, data: {'type': 'user-speaking'} at 7.16s
2026-01-15 10:31:11.811 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1171, name: 'RTVIServerMessageFrame#78', metadata: {}, data: {'type': 'user-speaking'} at 7.16s
2026-01-15 10:31:11.811 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1171, name: 'RTVIServerMessageFrame#78', metadata: {}, data: {'type': 'user-speaking'} at 7.16s
2026-01-15 10:31:11.811 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#85(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.811 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1173, name: 'InputTransportMessageFrame#85', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.25s
2026-01-15 10:31:11.811 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#85(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.811 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#85(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.811 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:11.811 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:11.811 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1173, name: 'InputTransportMessageFrame#85', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.25s
2026-01-15 10:31:11.811 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1173, name: 'InputTransportMessageFrame#85', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.25s
2026-01-15 10:31:11.811 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1173, name: 'InputTransportMessageFrame#85', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.25s
2026-01-15 10:31:11.811 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1173, name: 'InputTransportMessageFrame#85', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.25s
2026-01-15 10:31:11.811 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1173, name: 'InputTransportMessageFrame#85', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.26s
2026-01-15 10:31:11.811 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1173, name: 'InputTransportMessageFrame#85', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.26s
2026-01-15 10:31:11.847 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 319, name: 'OutputAudioRawFrame#241', metadata: {} at 6.29s
2026-01-15 10:31:11.847 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 319, name: 'OutputAudioRawFrame#241', metadata: {} at 6.29s
2026-01-15 10:31:11.848 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 1176, name: 'UserSpeakingFrame#158', metadata: {} at 7.20s
2026-01-15 10:31:11.848 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 1177, name: 'UserSpeakingFrame#159', metadata: {} at 7.20s
2026-01-15 10:31:11.848 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 1177, name: 'UserSpeakingFrame#159', metadata: {} at 7.20s
2026-01-15 10:31:11.848 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1174, name: 'OutputAudioRawFrame#514', metadata: {} at 7.20s
2026-01-15 10:31:11.848 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 1176, name: 'UserSpeakingFrame#158', metadata: {} at 7.20s
2026-01-15 10:31:11.848 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1174, name: 'OutputAudioRawFrame#514', metadata: {} at 7.20s
2026-01-15 10:31:11.848 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#158
2026-01-15 10:31:11.849 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#514(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.849 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1178, name: 'RTVIServerMessageFrame#79', metadata: {}, data: {'type': 'user-speaking'} at 7.20s
2026-01-15 10:31:11.849 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1174, name: 'OutputAudioRawFrame#514', metadata: {} at 7.20s
2026-01-15 10:31:11.849 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1179, name: 'OutputTransportMessageUrgentFrame#87', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.20s
2026-01-15 10:31:11.849 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#87(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.849 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#79(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.850 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 1178, name: 'RTVIServerMessageFrame#79', metadata: {}, data: {'type': 'user-speaking'} at 7.20s
2026-01-15 10:31:11.850 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1178, name: 'RTVIServerMessageFrame#79', metadata: {}, data: {'type': 'user-speaking'} at 7.20s
2026-01-15 10:31:11.850 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1174, name: 'OutputAudioRawFrame#514', metadata: {} at 7.20s
2026-01-15 10:31:11.850 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1179, name: 'OutputTransportMessageUrgentFrame#87', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.20s
2026-01-15 10:31:11.850 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1178, name: 'RTVIServerMessageFrame#79', metadata: {}, data: {'type': 'user-speaking'} at 7.20s
2026-01-15 10:31:11.850 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1178, name: 'RTVIServerMessageFrame#79', metadata: {}, data: {'type': 'user-speaking'} at 7.20s
2026-01-15 10:31:11.850 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1174, name: 'OutputAudioRawFrame#514', metadata: {} at 7.20s
2026-01-15 10:31:11.850 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1179, name: 'OutputTransportMessageUrgentFrame#87', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.20s
2026-01-15 10:31:11.850 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1178, name: 'RTVIServerMessageFrame#79', metadata: {}, data: {'type': 'user-speaking'} at 7.20s
2026-01-15 10:31:11.850 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#79(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.850 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#514(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.850 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1178, name: 'RTVIServerMessageFrame#79', metadata: {}, data: {'type': 'user-speaking'} at 7.20s
2026-01-15 10:31:11.850 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1174, name: 'OutputAudioRawFrame#514', metadata: {} at 7.20s
2026-01-15 10:31:11.850 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1179, name: 'OutputTransportMessageUrgentFrame#87', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.20s
2026-01-15 10:31:11.850 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1178, name: 'RTVIServerMessageFrame#79', metadata: {}, data: {'type': 'user-speaking'} at 7.20s
2026-01-15 10:31:11.850 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#87(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.851 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#79(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.851 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1178, name: 'RTVIServerMessageFrame#79', metadata: {}, data: {'type': 'user-speaking'} at 7.20s
2026-01-15 10:31:11.851 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1178, name: 'RTVIServerMessageFrame#79', metadata: {}, data: {'type': 'user-speaking'} at 7.20s
2026-01-15 10:31:11.851 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1174, name: 'OutputAudioRawFrame#514', metadata: {} at 7.20s
2026-01-15 10:31:11.851 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1174, name: 'OutputAudioRawFrame#514', metadata: {} at 7.20s
2026-01-15 10:31:11.851 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1179, name: 'OutputTransportMessageUrgentFrame#87', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.20s
2026-01-15 10:31:11.851 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1178, name: 'RTVIServerMessageFrame#79', metadata: {}, data: {'type': 'user-speaking'} at 7.20s
2026-01-15 10:31:11.851 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1178, name: 'RTVIServerMessageFrame#79', metadata: {}, data: {'type': 'user-speaking'} at 7.21s
2026-01-15 10:31:11.851 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1178, name: 'RTVIServerMessageFrame#79', metadata: {}, data: {'type': 'user-speaking'} at 7.21s
2026-01-15 10:31:11.851 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#86(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.851 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1180, name: 'InputTransportMessageFrame#86', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.30s
2026-01-15 10:31:11.851 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#86(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.851 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#86(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.851 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:11.851 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:11.852 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1180, name: 'InputTransportMessageFrame#86', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.30s
2026-01-15 10:31:11.852 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1180, name: 'InputTransportMessageFrame#86', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.30s
2026-01-15 10:31:11.852 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1180, name: 'InputTransportMessageFrame#86', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.30s
2026-01-15 10:31:11.852 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1180, name: 'InputTransportMessageFrame#86', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.30s
2026-01-15 10:31:11.852 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1180, name: 'InputTransportMessageFrame#86', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.30s
2026-01-15 10:31:11.852 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1180, name: 'InputTransportMessageFrame#86', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.30s
2026-01-15 10:31:11.887 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 321, name: 'OutputAudioRawFrame#243', metadata: {} at 6.33s
2026-01-15 10:31:11.887 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 321, name: 'OutputAudioRawFrame#243', metadata: {} at 6.33s
2026-01-15 10:31:11.889 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 1183, name: 'UserSpeakingFrame#160', metadata: {} at 7.24s
2026-01-15 10:31:11.889 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 1184, name: 'UserSpeakingFrame#161', metadata: {} at 7.24s
2026-01-15 10:31:11.889 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 1184, name: 'UserSpeakingFrame#161', metadata: {} at 7.24s
2026-01-15 10:31:11.889 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1181, name: 'OutputAudioRawFrame#515', metadata: {} at 7.24s
2026-01-15 10:31:11.889 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 1183, name: 'UserSpeakingFrame#160', metadata: {} at 7.24s
2026-01-15 10:31:11.889 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1181, name: 'OutputAudioRawFrame#515', metadata: {} at 7.24s
2026-01-15 10:31:11.889 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#160
2026-01-15 10:31:11.889 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#515(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.890 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1185, name: 'RTVIServerMessageFrame#80', metadata: {}, data: {'type': 'user-speaking'} at 7.24s
2026-01-15 10:31:11.890 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1181, name: 'OutputAudioRawFrame#515', metadata: {} at 7.24s
2026-01-15 10:31:11.890 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1186, name: 'OutputTransportMessageUrgentFrame#88', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.24s
2026-01-15 10:31:11.890 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#88(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.890 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#80(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.890 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 1185, name: 'RTVIServerMessageFrame#80', metadata: {}, data: {'type': 'user-speaking'} at 7.24s
2026-01-15 10:31:11.890 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1185, name: 'RTVIServerMessageFrame#80', metadata: {}, data: {'type': 'user-speaking'} at 7.24s
2026-01-15 10:31:11.890 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1181, name: 'OutputAudioRawFrame#515', metadata: {} at 7.24s
2026-01-15 10:31:11.890 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1186, name: 'OutputTransportMessageUrgentFrame#88', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.24s
2026-01-15 10:31:11.890 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1185, name: 'RTVIServerMessageFrame#80', metadata: {}, data: {'type': 'user-speaking'} at 7.24s
2026-01-15 10:31:11.891 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1185, name: 'RTVIServerMessageFrame#80', metadata: {}, data: {'type': 'user-speaking'} at 7.24s
2026-01-15 10:31:11.891 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1181, name: 'OutputAudioRawFrame#515', metadata: {} at 7.24s
2026-01-15 10:31:11.891 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1186, name: 'OutputTransportMessageUrgentFrame#88', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.25s
2026-01-15 10:31:11.891 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1185, name: 'RTVIServerMessageFrame#80', metadata: {}, data: {'type': 'user-speaking'} at 7.25s
2026-01-15 10:31:11.891 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#80(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.891 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#515(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.891 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1185, name: 'RTVIServerMessageFrame#80', metadata: {}, data: {'type': 'user-speaking'} at 7.25s
2026-01-15 10:31:11.891 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1181, name: 'OutputAudioRawFrame#515', metadata: {} at 7.25s
2026-01-15 10:31:11.891 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1186, name: 'OutputTransportMessageUrgentFrame#88', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.25s
2026-01-15 10:31:11.891 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1185, name: 'RTVIServerMessageFrame#80', metadata: {}, data: {'type': 'user-speaking'} at 7.25s
2026-01-15 10:31:11.891 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#88(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.891 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#80(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.891 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1185, name: 'RTVIServerMessageFrame#80', metadata: {}, data: {'type': 'user-speaking'} at 7.25s
2026-01-15 10:31:11.891 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1185, name: 'RTVIServerMessageFrame#80', metadata: {}, data: {'type': 'user-speaking'} at 7.25s
2026-01-15 10:31:11.891 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1181, name: 'OutputAudioRawFrame#515', metadata: {} at 7.25s
2026-01-15 10:31:11.891 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1181, name: 'OutputAudioRawFrame#515', metadata: {} at 7.25s
2026-01-15 10:31:11.891 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1186, name: 'OutputTransportMessageUrgentFrame#88', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.25s
2026-01-15 10:31:11.891 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1185, name: 'RTVIServerMessageFrame#80', metadata: {}, data: {'type': 'user-speaking'} at 7.25s
2026-01-15 10:31:11.892 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1185, name: 'RTVIServerMessageFrame#80', metadata: {}, data: {'type': 'user-speaking'} at 7.25s
2026-01-15 10:31:11.892 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1185, name: 'RTVIServerMessageFrame#80', metadata: {}, data: {'type': 'user-speaking'} at 7.25s
2026-01-15 10:31:11.892 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#87(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.892 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1187, name: 'InputTransportMessageFrame#87', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.34s
2026-01-15 10:31:11.892 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#87(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.892 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#87(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.892 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:11.892 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:11.892 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1187, name: 'InputTransportMessageFrame#87', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.34s
2026-01-15 10:31:11.892 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1187, name: 'InputTransportMessageFrame#87', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.34s
2026-01-15 10:31:11.892 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1187, name: 'InputTransportMessageFrame#87', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.34s
2026-01-15 10:31:11.892 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1187, name: 'InputTransportMessageFrame#87', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.34s
2026-01-15 10:31:11.892 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1187, name: 'InputTransportMessageFrame#87', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.34s
2026-01-15 10:31:11.892 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1187, name: 'InputTransportMessageFrame#87', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.34s
2026-01-15 10:31:11.927 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 322, name: 'OutputAudioRawFrame#244', metadata: {} at 6.37s
2026-01-15 10:31:11.927 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 322, name: 'OutputAudioRawFrame#244', metadata: {} at 6.37s
2026-01-15 10:31:11.928 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 1190, name: 'UserSpeakingFrame#162', metadata: {} at 7.28s
2026-01-15 10:31:11.928 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 1191, name: 'UserSpeakingFrame#163', metadata: {} at 7.28s
2026-01-15 10:31:11.928 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 1191, name: 'UserSpeakingFrame#163', metadata: {} at 7.28s
2026-01-15 10:31:11.928 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1188, name: 'OutputAudioRawFrame#516', metadata: {} at 7.28s
2026-01-15 10:31:11.928 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 1190, name: 'UserSpeakingFrame#162', metadata: {} at 7.28s
2026-01-15 10:31:11.928 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1188, name: 'OutputAudioRawFrame#516', metadata: {} at 7.28s
2026-01-15 10:31:11.929 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#162
2026-01-15 10:31:11.929 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#516(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.929 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1192, name: 'RTVIServerMessageFrame#81', metadata: {}, data: {'type': 'user-speaking'} at 7.28s
2026-01-15 10:31:11.929 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1188, name: 'OutputAudioRawFrame#516', metadata: {} at 7.28s
2026-01-15 10:31:11.929 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1193, name: 'OutputTransportMessageUrgentFrame#89', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.28s
2026-01-15 10:31:11.929 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#89(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.930 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#81(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.930 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 1192, name: 'RTVIServerMessageFrame#81', metadata: {}, data: {'type': 'user-speaking'} at 7.28s
2026-01-15 10:31:11.930 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1192, name: 'RTVIServerMessageFrame#81', metadata: {}, data: {'type': 'user-speaking'} at 7.28s
2026-01-15 10:31:11.930 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1188, name: 'OutputAudioRawFrame#516', metadata: {} at 7.28s
2026-01-15 10:31:11.930 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1193, name: 'OutputTransportMessageUrgentFrame#89', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.28s
2026-01-15 10:31:11.930 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1192, name: 'RTVIServerMessageFrame#81', metadata: {}, data: {'type': 'user-speaking'} at 7.28s
2026-01-15 10:31:11.930 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1192, name: 'RTVIServerMessageFrame#81', metadata: {}, data: {'type': 'user-speaking'} at 7.28s
2026-01-15 10:31:11.930 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1188, name: 'OutputAudioRawFrame#516', metadata: {} at 7.28s
2026-01-15 10:31:11.930 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1193, name: 'OutputTransportMessageUrgentFrame#89', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.28s
2026-01-15 10:31:11.930 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1192, name: 'RTVIServerMessageFrame#81', metadata: {}, data: {'type': 'user-speaking'} at 7.28s
2026-01-15 10:31:11.930 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#81(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.930 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#516(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.930 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1192, name: 'RTVIServerMessageFrame#81', metadata: {}, data: {'type': 'user-speaking'} at 7.28s
2026-01-15 10:31:11.930 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1188, name: 'OutputAudioRawFrame#516', metadata: {} at 7.28s
2026-01-15 10:31:11.930 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1193, name: 'OutputTransportMessageUrgentFrame#89', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.28s
2026-01-15 10:31:11.930 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1192, name: 'RTVIServerMessageFrame#81', metadata: {}, data: {'type': 'user-speaking'} at 7.28s
2026-01-15 10:31:11.931 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#89(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.931 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#81(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.931 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1192, name: 'RTVIServerMessageFrame#81', metadata: {}, data: {'type': 'user-speaking'} at 7.28s
2026-01-15 10:31:11.931 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1192, name: 'RTVIServerMessageFrame#81', metadata: {}, data: {'type': 'user-speaking'} at 7.28s
2026-01-15 10:31:11.931 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1188, name: 'OutputAudioRawFrame#516', metadata: {} at 7.28s
2026-01-15 10:31:11.931 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1188, name: 'OutputAudioRawFrame#516', metadata: {} at 7.28s
2026-01-15 10:31:11.931 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1193, name: 'OutputTransportMessageUrgentFrame#89', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.28s
2026-01-15 10:31:11.931 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1192, name: 'RTVIServerMessageFrame#81', metadata: {}, data: {'type': 'user-speaking'} at 7.28s
2026-01-15 10:31:11.931 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1192, name: 'RTVIServerMessageFrame#81', metadata: {}, data: {'type': 'user-speaking'} at 7.29s
2026-01-15 10:31:11.931 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1192, name: 'RTVIServerMessageFrame#81', metadata: {}, data: {'type': 'user-speaking'} at 7.29s
2026-01-15 10:31:11.931 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#88(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.931 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1194, name: 'InputTransportMessageFrame#88', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.38s
2026-01-15 10:31:11.932 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#88(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.932 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#88(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.932 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:11.932 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:11.932 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1194, name: 'InputTransportMessageFrame#88', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.38s
2026-01-15 10:31:11.932 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1194, name: 'InputTransportMessageFrame#88', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.38s
2026-01-15 10:31:11.932 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1194, name: 'InputTransportMessageFrame#88', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.38s
2026-01-15 10:31:11.932 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1194, name: 'InputTransportMessageFrame#88', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.38s
2026-01-15 10:31:11.932 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1194, name: 'InputTransportMessageFrame#88', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.38s
2026-01-15 10:31:11.932 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1194, name: 'InputTransportMessageFrame#88', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.38s
2026-01-15 10:31:11.967 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 323, name: 'OutputAudioRawFrame#245', metadata: {} at 6.41s
2026-01-15 10:31:11.967 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 323, name: 'OutputAudioRawFrame#245', metadata: {} at 6.41s
2026-01-15 10:31:11.968 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 1197, name: 'UserSpeakingFrame#164', metadata: {} at 7.32s
2026-01-15 10:31:11.968 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 1198, name: 'UserSpeakingFrame#165', metadata: {} at 7.32s
2026-01-15 10:31:11.968 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 1198, name: 'UserSpeakingFrame#165', metadata: {} at 7.32s
2026-01-15 10:31:11.968 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1195, name: 'OutputAudioRawFrame#517', metadata: {} at 7.32s
2026-01-15 10:31:11.968 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 1197, name: 'UserSpeakingFrame#164', metadata: {} at 7.32s
2026-01-15 10:31:11.968 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1195, name: 'OutputAudioRawFrame#517', metadata: {} at 7.32s
2026-01-15 10:31:11.968 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#164
2026-01-15 10:31:11.968 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#517(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.968 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1199, name: 'RTVIServerMessageFrame#82', metadata: {}, data: {'type': 'user-speaking'} at 7.32s
2026-01-15 10:31:11.968 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1195, name: 'OutputAudioRawFrame#517', metadata: {} at 7.32s
2026-01-15 10:31:11.968 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1200, name: 'OutputTransportMessageUrgentFrame#90', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.32s
2026-01-15 10:31:11.968 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#90(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.968 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#82(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.969 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 1199, name: 'RTVIServerMessageFrame#82', metadata: {}, data: {'type': 'user-speaking'} at 7.32s
2026-01-15 10:31:11.969 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1199, name: 'RTVIServerMessageFrame#82', metadata: {}, data: {'type': 'user-speaking'} at 7.32s
2026-01-15 10:31:11.969 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1195, name: 'OutputAudioRawFrame#517', metadata: {} at 7.32s
2026-01-15 10:31:11.969 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1200, name: 'OutputTransportMessageUrgentFrame#90', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.32s
2026-01-15 10:31:11.969 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1199, name: 'RTVIServerMessageFrame#82', metadata: {}, data: {'type': 'user-speaking'} at 7.32s
2026-01-15 10:31:11.969 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1199, name: 'RTVIServerMessageFrame#82', metadata: {}, data: {'type': 'user-speaking'} at 7.32s
2026-01-15 10:31:11.969 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1195, name: 'OutputAudioRawFrame#517', metadata: {} at 7.32s
2026-01-15 10:31:11.969 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1200, name: 'OutputTransportMessageUrgentFrame#90', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.32s
2026-01-15 10:31:11.969 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1199, name: 'RTVIServerMessageFrame#82', metadata: {}, data: {'type': 'user-speaking'} at 7.32s
2026-01-15 10:31:11.969 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#82(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.969 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#517(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:11.969 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1199, name: 'RTVIServerMessageFrame#82', metadata: {}, data: {'type': 'user-speaking'} at 7.32s
2026-01-15 10:31:11.969 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1195, name: 'OutputAudioRawFrame#517', metadata: {} at 7.32s
2026-01-15 10:31:11.969 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1200, name: 'OutputTransportMessageUrgentFrame#90', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.32s
2026-01-15 10:31:11.969 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1199, name: 'RTVIServerMessageFrame#82', metadata: {}, data: {'type': 'user-speaking'} at 7.32s
2026-01-15 10:31:11.969 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#90(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.969 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#82(data: {'type': 'user-speaking'})
2026-01-15 10:31:11.969 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1199, name: 'RTVIServerMessageFrame#82', metadata: {}, data: {'type': 'user-speaking'} at 7.32s
2026-01-15 10:31:11.969 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1199, name: 'RTVIServerMessageFrame#82', metadata: {}, data: {'type': 'user-speaking'} at 7.32s
2026-01-15 10:31:11.969 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1195, name: 'OutputAudioRawFrame#517', metadata: {} at 7.32s
2026-01-15 10:31:11.969 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1195, name: 'OutputAudioRawFrame#517', metadata: {} at 7.32s
2026-01-15 10:31:11.969 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1200, name: 'OutputTransportMessageUrgentFrame#90', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.32s
2026-01-15 10:31:11.969 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1199, name: 'RTVIServerMessageFrame#82', metadata: {}, data: {'type': 'user-speaking'} at 7.32s
2026-01-15 10:31:11.969 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1199, name: 'RTVIServerMessageFrame#82', metadata: {}, data: {'type': 'user-speaking'} at 7.32s
2026-01-15 10:31:11.969 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1199, name: 'RTVIServerMessageFrame#82', metadata: {}, data: {'type': 'user-speaking'} at 7.32s
2026-01-15 10:31:11.970 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#89(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.970 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1201, name: 'InputTransportMessageFrame#89', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.41s
2026-01-15 10:31:11.970 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#89(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.970 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#89(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:11.970 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:11.970 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:11.970 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1201, name: 'InputTransportMessageFrame#89', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.41s
2026-01-15 10:31:11.970 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1201, name: 'InputTransportMessageFrame#89', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.41s
2026-01-15 10:31:11.970 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1201, name: 'InputTransportMessageFrame#89', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.41s
2026-01-15 10:31:11.970 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1201, name: 'InputTransportMessageFrame#89', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.41s
2026-01-15 10:31:11.970 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1201, name: 'InputTransportMessageFrame#89', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.41s
2026-01-15 10:31:11.970 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1201, name: 'InputTransportMessageFrame#89', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.41s
2026-01-15 10:31:12.007 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 325, name: 'OutputAudioRawFrame#247', metadata: {} at 6.45s
2026-01-15 10:31:12.007 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 325, name: 'OutputAudioRawFrame#247', metadata: {} at 6.45s
2026-01-15 10:31:12.008 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 1204, name: 'UserSpeakingFrame#166', metadata: {} at 7.36s
2026-01-15 10:31:12.008 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 1205, name: 'UserSpeakingFrame#167', metadata: {} at 7.36s
2026-01-15 10:31:12.008 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 1205, name: 'UserSpeakingFrame#167', metadata: {} at 7.36s
2026-01-15 10:31:12.008 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1202, name: 'OutputAudioRawFrame#518', metadata: {} at 7.36s
2026-01-15 10:31:12.008 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 1204, name: 'UserSpeakingFrame#166', metadata: {} at 7.36s
2026-01-15 10:31:12.008 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1202, name: 'OutputAudioRawFrame#518', metadata: {} at 7.36s
2026-01-15 10:31:12.008 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#166
2026-01-15 10:31:12.008 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#518(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.008 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1206, name: 'RTVIServerMessageFrame#83', metadata: {}, data: {'type': 'user-speaking'} at 7.36s
2026-01-15 10:31:12.008 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1202, name: 'OutputAudioRawFrame#518', metadata: {} at 7.36s
2026-01-15 10:31:12.008 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1207, name: 'OutputTransportMessageUrgentFrame#91', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.36s
2026-01-15 10:31:12.008 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#91(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:12.008 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#83(data: {'type': 'user-speaking'})
2026-01-15 10:31:12.008 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 1206, name: 'RTVIServerMessageFrame#83', metadata: {}, data: {'type': 'user-speaking'} at 7.36s
2026-01-15 10:31:12.008 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1206, name: 'RTVIServerMessageFrame#83', metadata: {}, data: {'type': 'user-speaking'} at 7.36s
2026-01-15 10:31:12.008 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1202, name: 'OutputAudioRawFrame#518', metadata: {} at 7.36s
2026-01-15 10:31:12.008 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1207, name: 'OutputTransportMessageUrgentFrame#91', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.36s
2026-01-15 10:31:12.008 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1206, name: 'RTVIServerMessageFrame#83', metadata: {}, data: {'type': 'user-speaking'} at 7.36s
2026-01-15 10:31:12.008 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1206, name: 'RTVIServerMessageFrame#83', metadata: {}, data: {'type': 'user-speaking'} at 7.36s
2026-01-15 10:31:12.008 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1202, name: 'OutputAudioRawFrame#518', metadata: {} at 7.36s
2026-01-15 10:31:12.008 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1207, name: 'OutputTransportMessageUrgentFrame#91', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.36s
2026-01-15 10:31:12.009 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1206, name: 'RTVIServerMessageFrame#83', metadata: {}, data: {'type': 'user-speaking'} at 7.36s
2026-01-15 10:31:12.009 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#83(data: {'type': 'user-speaking'})
2026-01-15 10:31:12.009 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#518(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.009 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1206, name: 'RTVIServerMessageFrame#83', metadata: {}, data: {'type': 'user-speaking'} at 7.36s
2026-01-15 10:31:12.009 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1202, name: 'OutputAudioRawFrame#518', metadata: {} at 7.36s
2026-01-15 10:31:12.009 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1207, name: 'OutputTransportMessageUrgentFrame#91', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.36s
2026-01-15 10:31:12.009 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1206, name: 'RTVIServerMessageFrame#83', metadata: {}, data: {'type': 'user-speaking'} at 7.36s
2026-01-15 10:31:12.009 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#91(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:12.009 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#83(data: {'type': 'user-speaking'})
2026-01-15 10:31:12.009 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1206, name: 'RTVIServerMessageFrame#83', metadata: {}, data: {'type': 'user-speaking'} at 7.36s
2026-01-15 10:31:12.009 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1206, name: 'RTVIServerMessageFrame#83', metadata: {}, data: {'type': 'user-speaking'} at 7.36s
2026-01-15 10:31:12.009 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1202, name: 'OutputAudioRawFrame#518', metadata: {} at 7.36s
2026-01-15 10:31:12.009 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1202, name: 'OutputAudioRawFrame#518', metadata: {} at 7.36s
2026-01-15 10:31:12.009 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1207, name: 'OutputTransportMessageUrgentFrame#91', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.36s
2026-01-15 10:31:12.009 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1206, name: 'RTVIServerMessageFrame#83', metadata: {}, data: {'type': 'user-speaking'} at 7.36s
2026-01-15 10:31:12.009 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1206, name: 'RTVIServerMessageFrame#83', metadata: {}, data: {'type': 'user-speaking'} at 7.36s
2026-01-15 10:31:12.009 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1206, name: 'RTVIServerMessageFrame#83', metadata: {}, data: {'type': 'user-speaking'} at 7.36s
2026-01-15 10:31:12.009 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#90(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:12.009 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1208, name: 'InputTransportMessageFrame#90', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.45s
2026-01-15 10:31:12.009 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#90(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:12.009 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#90(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:12.009 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:12.009 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:12.009 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1208, name: 'InputTransportMessageFrame#90', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.45s
2026-01-15 10:31:12.009 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1208, name: 'InputTransportMessageFrame#90', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.45s
2026-01-15 10:31:12.009 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1208, name: 'InputTransportMessageFrame#90', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.45s
2026-01-15 10:31:12.009 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1208, name: 'InputTransportMessageFrame#90', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.45s
2026-01-15 10:31:12.009 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1208, name: 'InputTransportMessageFrame#90', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.45s
2026-01-15 10:31:12.009 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1208, name: 'InputTransportMessageFrame#90', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.45s
2026-01-15 10:31:12.047 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 326, name: 'OutputAudioRawFrame#248', metadata: {} at 6.49s
2026-01-15 10:31:12.047 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 326, name: 'OutputAudioRawFrame#248', metadata: {} at 6.49s
2026-01-15 10:31:12.048 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 1211, name: 'UserSpeakingFrame#168', metadata: {} at 7.40s
2026-01-15 10:31:12.048 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 1212, name: 'UserSpeakingFrame#169', metadata: {} at 7.40s
2026-01-15 10:31:12.048 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 1212, name: 'UserSpeakingFrame#169', metadata: {} at 7.40s
2026-01-15 10:31:12.048 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1209, name: 'OutputAudioRawFrame#519', metadata: {} at 7.40s
2026-01-15 10:31:12.048 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 1211, name: 'UserSpeakingFrame#168', metadata: {} at 7.40s
2026-01-15 10:31:12.048 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1209, name: 'OutputAudioRawFrame#519', metadata: {} at 7.40s
2026-01-15 10:31:12.048 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#168
2026-01-15 10:31:12.048 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#519(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.048 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1213, name: 'RTVIServerMessageFrame#84', metadata: {}, data: {'type': 'user-speaking'} at 7.40s
2026-01-15 10:31:12.048 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1209, name: 'OutputAudioRawFrame#519', metadata: {} at 7.40s
2026-01-15 10:31:12.048 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1214, name: 'OutputTransportMessageUrgentFrame#92', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.40s
2026-01-15 10:31:12.049 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#92(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:12.049 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#84(data: {'type': 'user-speaking'})
2026-01-15 10:31:12.049 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 1213, name: 'RTVIServerMessageFrame#84', metadata: {}, data: {'type': 'user-speaking'} at 7.40s
2026-01-15 10:31:12.049 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1213, name: 'RTVIServerMessageFrame#84', metadata: {}, data: {'type': 'user-speaking'} at 7.40s
2026-01-15 10:31:12.049 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1209, name: 'OutputAudioRawFrame#519', metadata: {} at 7.40s
2026-01-15 10:31:12.049 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1214, name: 'OutputTransportMessageUrgentFrame#92', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.40s
2026-01-15 10:31:12.049 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1213, name: 'RTVIServerMessageFrame#84', metadata: {}, data: {'type': 'user-speaking'} at 7.40s
2026-01-15 10:31:12.049 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1213, name: 'RTVIServerMessageFrame#84', metadata: {}, data: {'type': 'user-speaking'} at 7.40s
2026-01-15 10:31:12.049 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1209, name: 'OutputAudioRawFrame#519', metadata: {} at 7.40s
2026-01-15 10:31:12.049 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1214, name: 'OutputTransportMessageUrgentFrame#92', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.40s
2026-01-15 10:31:12.049 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1213, name: 'RTVIServerMessageFrame#84', metadata: {}, data: {'type': 'user-speaking'} at 7.40s
2026-01-15 10:31:12.049 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#84(data: {'type': 'user-speaking'})
2026-01-15 10:31:12.049 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#519(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.049 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1213, name: 'RTVIServerMessageFrame#84', metadata: {}, data: {'type': 'user-speaking'} at 7.40s
2026-01-15 10:31:12.049 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1209, name: 'OutputAudioRawFrame#519', metadata: {} at 7.40s
2026-01-15 10:31:12.049 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1214, name: 'OutputTransportMessageUrgentFrame#92', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.40s
2026-01-15 10:31:12.049 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1213, name: 'RTVIServerMessageFrame#84', metadata: {}, data: {'type': 'user-speaking'} at 7.40s
2026-01-15 10:31:12.049 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#92(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:12.049 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#84(data: {'type': 'user-speaking'})
2026-01-15 10:31:12.049 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1213, name: 'RTVIServerMessageFrame#84', metadata: {}, data: {'type': 'user-speaking'} at 7.40s
2026-01-15 10:31:12.049 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1213, name: 'RTVIServerMessageFrame#84', metadata: {}, data: {'type': 'user-speaking'} at 7.40s
2026-01-15 10:31:12.049 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1209, name: 'OutputAudioRawFrame#519', metadata: {} at 7.40s
2026-01-15 10:31:12.049 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1209, name: 'OutputAudioRawFrame#519', metadata: {} at 7.40s
2026-01-15 10:31:12.049 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1214, name: 'OutputTransportMessageUrgentFrame#92', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.40s
2026-01-15 10:31:12.049 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1213, name: 'RTVIServerMessageFrame#84', metadata: {}, data: {'type': 'user-speaking'} at 7.40s
2026-01-15 10:31:12.049 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1213, name: 'RTVIServerMessageFrame#84', metadata: {}, data: {'type': 'user-speaking'} at 7.40s
2026-01-15 10:31:12.050 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1213, name: 'RTVIServerMessageFrame#84', metadata: {}, data: {'type': 'user-speaking'} at 7.40s
2026-01-15 10:31:12.050 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#91(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:12.050 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1215, name: 'InputTransportMessageFrame#91', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.49s
2026-01-15 10:31:12.050 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#91(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:12.050 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#91(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:12.050 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:12.050 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:12.050 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1215, name: 'InputTransportMessageFrame#91', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.49s
2026-01-15 10:31:12.050 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1215, name: 'InputTransportMessageFrame#91', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.49s
2026-01-15 10:31:12.050 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1215, name: 'InputTransportMessageFrame#91', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.49s
2026-01-15 10:31:12.050 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1215, name: 'InputTransportMessageFrame#91', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.49s
2026-01-15 10:31:12.050 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1215, name: 'InputTransportMessageFrame#91', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.49s
2026-01-15 10:31:12.050 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1215, name: 'InputTransportMessageFrame#91', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.49s
2026-01-15 10:31:12.087 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 328, name: 'OutputAudioRawFrame#250', metadata: {} at 6.53s
2026-01-15 10:31:12.087 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 328, name: 'OutputAudioRawFrame#250', metadata: {} at 6.53s
2026-01-15 10:31:12.087 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 1218, name: 'UserSpeakingFrame#170', metadata: {} at 7.44s
2026-01-15 10:31:12.088 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 1219, name: 'UserSpeakingFrame#171', metadata: {} at 7.44s
2026-01-15 10:31:12.088 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 1219, name: 'UserSpeakingFrame#171', metadata: {} at 7.44s
2026-01-15 10:31:12.088 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1216, name: 'OutputAudioRawFrame#520', metadata: {} at 7.44s
2026-01-15 10:31:12.088 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 1218, name: 'UserSpeakingFrame#170', metadata: {} at 7.44s
2026-01-15 10:31:12.088 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1216, name: 'OutputAudioRawFrame#520', metadata: {} at 7.44s
2026-01-15 10:31:12.088 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#170
2026-01-15 10:31:12.088 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#520(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.088 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1220, name: 'RTVIServerMessageFrame#85', metadata: {}, data: {'type': 'user-speaking'} at 7.44s
2026-01-15 10:31:12.088 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1216, name: 'OutputAudioRawFrame#520', metadata: {} at 7.44s
2026-01-15 10:31:12.088 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1221, name: 'OutputTransportMessageUrgentFrame#93', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.44s
2026-01-15 10:31:12.088 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#93(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:12.088 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#85(data: {'type': 'user-speaking'})
2026-01-15 10:31:12.088 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 1220, name: 'RTVIServerMessageFrame#85', metadata: {}, data: {'type': 'user-speaking'} at 7.44s
2026-01-15 10:31:12.088 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1220, name: 'RTVIServerMessageFrame#85', metadata: {}, data: {'type': 'user-speaking'} at 7.44s
2026-01-15 10:31:12.088 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1216, name: 'OutputAudioRawFrame#520', metadata: {} at 7.44s
2026-01-15 10:31:12.088 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1221, name: 'OutputTransportMessageUrgentFrame#93', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.44s
2026-01-15 10:31:12.088 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1220, name: 'RTVIServerMessageFrame#85', metadata: {}, data: {'type': 'user-speaking'} at 7.44s
2026-01-15 10:31:12.088 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1220, name: 'RTVIServerMessageFrame#85', metadata: {}, data: {'type': 'user-speaking'} at 7.44s
2026-01-15 10:31:12.088 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1216, name: 'OutputAudioRawFrame#520', metadata: {} at 7.44s
2026-01-15 10:31:12.088 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1221, name: 'OutputTransportMessageUrgentFrame#93', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.44s
2026-01-15 10:31:12.088 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1220, name: 'RTVIServerMessageFrame#85', metadata: {}, data: {'type': 'user-speaking'} at 7.44s
2026-01-15 10:31:12.089 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#85(data: {'type': 'user-speaking'})
2026-01-15 10:31:12.089 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#520(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.089 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1220, name: 'RTVIServerMessageFrame#85', metadata: {}, data: {'type': 'user-speaking'} at 7.44s
2026-01-15 10:31:12.089 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1216, name: 'OutputAudioRawFrame#520', metadata: {} at 7.44s
2026-01-15 10:31:12.089 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1221, name: 'OutputTransportMessageUrgentFrame#93', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.44s
2026-01-15 10:31:12.089 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1220, name: 'RTVIServerMessageFrame#85', metadata: {}, data: {'type': 'user-speaking'} at 7.44s
2026-01-15 10:31:12.089 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#93(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:12.089 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#85(data: {'type': 'user-speaking'})
2026-01-15 10:31:12.089 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1220, name: 'RTVIServerMessageFrame#85', metadata: {}, data: {'type': 'user-speaking'} at 7.44s
2026-01-15 10:31:12.089 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1220, name: 'RTVIServerMessageFrame#85', metadata: {}, data: {'type': 'user-speaking'} at 7.44s
2026-01-15 10:31:12.089 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1216, name: 'OutputAudioRawFrame#520', metadata: {} at 7.44s
2026-01-15 10:31:12.089 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1216, name: 'OutputAudioRawFrame#520', metadata: {} at 7.44s
2026-01-15 10:31:12.089 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1221, name: 'OutputTransportMessageUrgentFrame#93', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.44s
2026-01-15 10:31:12.089 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1220, name: 'RTVIServerMessageFrame#85', metadata: {}, data: {'type': 'user-speaking'} at 7.44s
2026-01-15 10:31:12.089 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1220, name: 'RTVIServerMessageFrame#85', metadata: {}, data: {'type': 'user-speaking'} at 7.44s
2026-01-15 10:31:12.089 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1220, name: 'RTVIServerMessageFrame#85', metadata: {}, data: {'type': 'user-speaking'} at 7.44s
2026-01-15 10:31:12.089 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#92(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:12.089 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1222, name: 'InputTransportMessageFrame#92', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.53s
2026-01-15 10:31:12.089 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#92(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:12.089 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#92(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:12.089 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:12.089 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:12.090 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1222, name: 'InputTransportMessageFrame#92', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.53s
2026-01-15 10:31:12.090 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1222, name: 'InputTransportMessageFrame#92', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.53s
2026-01-15 10:31:12.090 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1222, name: 'InputTransportMessageFrame#92', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.53s
2026-01-15 10:31:12.090 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1222, name: 'InputTransportMessageFrame#92', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.53s
2026-01-15 10:31:12.090 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1222, name: 'InputTransportMessageFrame#92', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.53s
2026-01-15 10:31:12.090 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1222, name: 'InputTransportMessageFrame#92', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.53s
2026-01-15 10:31:12.127 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 329, name: 'OutputAudioRawFrame#251', metadata: {} at 6.57s
2026-01-15 10:31:12.127 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 329, name: 'OutputAudioRawFrame#251', metadata: {} at 6.57s
2026-01-15 10:31:12.128 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 1225, name: 'UserSpeakingFrame#172', metadata: {} at 7.48s
2026-01-15 10:31:12.128 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 1226, name: 'UserSpeakingFrame#173', metadata: {} at 7.48s
2026-01-15 10:31:12.128 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 1226, name: 'UserSpeakingFrame#173', metadata: {} at 7.48s
2026-01-15 10:31:12.128 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1223, name: 'OutputAudioRawFrame#521', metadata: {} at 7.48s
2026-01-15 10:31:12.128 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 1225, name: 'UserSpeakingFrame#172', metadata: {} at 7.48s
2026-01-15 10:31:12.128 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1223, name: 'OutputAudioRawFrame#521', metadata: {} at 7.48s
2026-01-15 10:31:12.128 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#172
2026-01-15 10:31:12.128 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#521(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.128 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1227, name: 'RTVIServerMessageFrame#86', metadata: {}, data: {'type': 'user-speaking'} at 7.48s
2026-01-15 10:31:12.128 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1223, name: 'OutputAudioRawFrame#521', metadata: {} at 7.48s
2026-01-15 10:31:12.128 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1228, name: 'OutputTransportMessageUrgentFrame#94', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.48s
2026-01-15 10:31:12.129 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#94(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:12.129 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#86(data: {'type': 'user-speaking'})
2026-01-15 10:31:12.129 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 1227, name: 'RTVIServerMessageFrame#86', metadata: {}, data: {'type': 'user-speaking'} at 7.48s
2026-01-15 10:31:12.129 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1227, name: 'RTVIServerMessageFrame#86', metadata: {}, data: {'type': 'user-speaking'} at 7.48s
2026-01-15 10:31:12.129 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1223, name: 'OutputAudioRawFrame#521', metadata: {} at 7.48s
2026-01-15 10:31:12.129 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1228, name: 'OutputTransportMessageUrgentFrame#94', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.48s
2026-01-15 10:31:12.129 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1227, name: 'RTVIServerMessageFrame#86', metadata: {}, data: {'type': 'user-speaking'} at 7.48s
2026-01-15 10:31:12.129 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1227, name: 'RTVIServerMessageFrame#86', metadata: {}, data: {'type': 'user-speaking'} at 7.48s
2026-01-15 10:31:12.129 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1223, name: 'OutputAudioRawFrame#521', metadata: {} at 7.48s
2026-01-15 10:31:12.129 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1228, name: 'OutputTransportMessageUrgentFrame#94', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.48s
2026-01-15 10:31:12.129 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1227, name: 'RTVIServerMessageFrame#86', metadata: {}, data: {'type': 'user-speaking'} at 7.48s
2026-01-15 10:31:12.129 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#86(data: {'type': 'user-speaking'})
2026-01-15 10:31:12.129 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#521(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.129 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1227, name: 'RTVIServerMessageFrame#86', metadata: {}, data: {'type': 'user-speaking'} at 7.48s
2026-01-15 10:31:12.129 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1223, name: 'OutputAudioRawFrame#521', metadata: {} at 7.48s
2026-01-15 10:31:12.129 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1228, name: 'OutputTransportMessageUrgentFrame#94', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.48s
2026-01-15 10:31:12.129 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1227, name: 'RTVIServerMessageFrame#86', metadata: {}, data: {'type': 'user-speaking'} at 7.48s
2026-01-15 10:31:12.129 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#94(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:12.129 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#86(data: {'type': 'user-speaking'})
2026-01-15 10:31:12.130 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1227, name: 'RTVIServerMessageFrame#86', metadata: {}, data: {'type': 'user-speaking'} at 7.48s
2026-01-15 10:31:12.130 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1227, name: 'RTVIServerMessageFrame#86', metadata: {}, data: {'type': 'user-speaking'} at 7.48s
2026-01-15 10:31:12.130 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1223, name: 'OutputAudioRawFrame#521', metadata: {} at 7.48s
2026-01-15 10:31:12.130 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1223, name: 'OutputAudioRawFrame#521', metadata: {} at 7.48s
2026-01-15 10:31:12.130 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1228, name: 'OutputTransportMessageUrgentFrame#94', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.48s
2026-01-15 10:31:12.130 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1227, name: 'RTVIServerMessageFrame#86', metadata: {}, data: {'type': 'user-speaking'} at 7.48s
2026-01-15 10:31:12.130 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1227, name: 'RTVIServerMessageFrame#86', metadata: {}, data: {'type': 'user-speaking'} at 7.48s
2026-01-15 10:31:12.130 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1227, name: 'RTVIServerMessageFrame#86', metadata: {}, data: {'type': 'user-speaking'} at 7.48s
2026-01-15 10:31:12.130 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#93(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:12.130 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1229, name: 'InputTransportMessageFrame#93', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.57s
2026-01-15 10:31:12.130 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#93(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:12.130 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#93(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:12.130 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:12.130 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:12.130 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1229, name: 'InputTransportMessageFrame#93', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.57s
2026-01-15 10:31:12.130 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1229, name: 'InputTransportMessageFrame#93', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.57s
2026-01-15 10:31:12.130 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1229, name: 'InputTransportMessageFrame#93', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.57s
2026-01-15 10:31:12.130 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1229, name: 'InputTransportMessageFrame#93', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.57s
2026-01-15 10:31:12.130 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1229, name: 'InputTransportMessageFrame#93', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.57s
2026-01-15 10:31:12.130 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1229, name: 'InputTransportMessageFrame#93', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.57s
2026-01-15 10:31:12.167 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 331, name: 'OutputAudioRawFrame#253', metadata: {} at 6.61s
2026-01-15 10:31:12.167 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 331, name: 'OutputAudioRawFrame#253', metadata: {} at 6.61s
2026-01-15 10:31:12.168 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 1232, name: 'UserSpeakingFrame#174', metadata: {} at 7.52s
2026-01-15 10:31:12.168 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 1233, name: 'UserSpeakingFrame#175', metadata: {} at 7.52s
2026-01-15 10:31:12.168 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 1233, name: 'UserSpeakingFrame#175', metadata: {} at 7.52s
2026-01-15 10:31:12.168 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1230, name: 'OutputAudioRawFrame#522', metadata: {} at 7.52s
2026-01-15 10:31:12.168 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 1232, name: 'UserSpeakingFrame#174', metadata: {} at 7.52s
2026-01-15 10:31:12.168 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1230, name: 'OutputAudioRawFrame#522', metadata: {} at 7.52s
2026-01-15 10:31:12.168 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#174
2026-01-15 10:31:12.168 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#522(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.168 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1234, name: 'RTVIServerMessageFrame#87', metadata: {}, data: {'type': 'user-speaking'} at 7.52s
2026-01-15 10:31:12.168 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1230, name: 'OutputAudioRawFrame#522', metadata: {} at 7.52s
2026-01-15 10:31:12.168 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1235, name: 'OutputTransportMessageUrgentFrame#95', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.52s
2026-01-15 10:31:12.169 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#95(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:12.169 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#87(data: {'type': 'user-speaking'})
2026-01-15 10:31:12.169 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 1234, name: 'RTVIServerMessageFrame#87', metadata: {}, data: {'type': 'user-speaking'} at 7.52s
2026-01-15 10:31:12.169 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1234, name: 'RTVIServerMessageFrame#87', metadata: {}, data: {'type': 'user-speaking'} at 7.52s
2026-01-15 10:31:12.169 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1230, name: 'OutputAudioRawFrame#522', metadata: {} at 7.52s
2026-01-15 10:31:12.169 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1235, name: 'OutputTransportMessageUrgentFrame#95', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.52s
2026-01-15 10:31:12.169 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1234, name: 'RTVIServerMessageFrame#87', metadata: {}, data: {'type': 'user-speaking'} at 7.52s
2026-01-15 10:31:12.169 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1234, name: 'RTVIServerMessageFrame#87', metadata: {}, data: {'type': 'user-speaking'} at 7.52s
2026-01-15 10:31:12.169 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1230, name: 'OutputAudioRawFrame#522', metadata: {} at 7.52s
2026-01-15 10:31:12.169 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1235, name: 'OutputTransportMessageUrgentFrame#95', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.52s
2026-01-15 10:31:12.169 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1234, name: 'RTVIServerMessageFrame#87', metadata: {}, data: {'type': 'user-speaking'} at 7.52s
2026-01-15 10:31:12.169 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#87(data: {'type': 'user-speaking'})
2026-01-15 10:31:12.169 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#522(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.169 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1234, name: 'RTVIServerMessageFrame#87', metadata: {}, data: {'type': 'user-speaking'} at 7.52s
2026-01-15 10:31:12.169 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1230, name: 'OutputAudioRawFrame#522', metadata: {} at 7.52s
2026-01-15 10:31:12.169 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1235, name: 'OutputTransportMessageUrgentFrame#95', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.52s
2026-01-15 10:31:12.169 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1234, name: 'RTVIServerMessageFrame#87', metadata: {}, data: {'type': 'user-speaking'} at 7.52s
2026-01-15 10:31:12.169 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#95(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:12.169 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#87(data: {'type': 'user-speaking'})
2026-01-15 10:31:12.169 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1234, name: 'RTVIServerMessageFrame#87', metadata: {}, data: {'type': 'user-speaking'} at 7.52s
2026-01-15 10:31:12.169 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1234, name: 'RTVIServerMessageFrame#87', metadata: {}, data: {'type': 'user-speaking'} at 7.52s
2026-01-15 10:31:12.169 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1230, name: 'OutputAudioRawFrame#522', metadata: {} at 7.52s
2026-01-15 10:31:12.169 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1230, name: 'OutputAudioRawFrame#522', metadata: {} at 7.52s
2026-01-15 10:31:12.169 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1235, name: 'OutputTransportMessageUrgentFrame#95', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.52s
2026-01-15 10:31:12.169 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1234, name: 'RTVIServerMessageFrame#87', metadata: {}, data: {'type': 'user-speaking'} at 7.52s
2026-01-15 10:31:12.170 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1234, name: 'RTVIServerMessageFrame#87', metadata: {}, data: {'type': 'user-speaking'} at 7.52s
2026-01-15 10:31:12.170 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1234, name: 'RTVIServerMessageFrame#87', metadata: {}, data: {'type': 'user-speaking'} at 7.52s
2026-01-15 10:31:12.170 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#94(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:12.170 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1236, name: 'InputTransportMessageFrame#94', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.61s
2026-01-15 10:31:12.170 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#94(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:12.170 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#94(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:12.170 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:12.170 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:12.170 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1236, name: 'InputTransportMessageFrame#94', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.61s
2026-01-15 10:31:12.170 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1236, name: 'InputTransportMessageFrame#94', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.61s
2026-01-15 10:31:12.170 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1236, name: 'InputTransportMessageFrame#94', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.61s
2026-01-15 10:31:12.170 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1236, name: 'InputTransportMessageFrame#94', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.61s
2026-01-15 10:31:12.170 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1236, name: 'InputTransportMessageFrame#94', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.61s
2026-01-15 10:31:12.170 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1236, name: 'InputTransportMessageFrame#94', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.61s
2026-01-15 10:31:12.206 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 333, name: 'OutputAudioRawFrame#255', metadata: {} at 6.65s
2026-01-15 10:31:12.206 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 333, name: 'OutputAudioRawFrame#255', metadata: {} at 6.65s
2026-01-15 10:31:12.207 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserSpeakingFrame id: 1239, name: 'UserSpeakingFrame#176', metadata: {} at 7.56s
2026-01-15 10:31:12.207 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserSpeakingFrame id: 1240, name: 'UserSpeakingFrame#177', metadata: {} at 7.56s
2026-01-15 10:31:12.207 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserSpeakingFrame id: 1240, name: 'UserSpeakingFrame#177', metadata: {} at 7.56s
2026-01-15 10:31:12.207 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1237, name: 'OutputAudioRawFrame#523', metadata: {} at 7.56s
2026-01-15 10:31:12.207 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserSpeakingFrame id: 1239, name: 'UserSpeakingFrame#176', metadata: {} at 7.56s
2026-01-15 10:31:12.207 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1237, name: 'OutputAudioRawFrame#523', metadata: {} at 7.56s
2026-01-15 10:31:12.207 | INFO     | [BOT-SYS] | input bot frame: UserSpeakingFrame#176
2026-01-15 10:31:12.208 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#523(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.208 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1241, name: 'RTVIServerMessageFrame#88', metadata: {}, data: {'type': 'user-speaking'} at 7.56s
2026-01-15 10:31:12.208 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1237, name: 'OutputAudioRawFrame#523', metadata: {} at 7.56s
2026-01-15 10:31:12.208 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1242, name: 'OutputTransportMessageUrgentFrame#96', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.56s
2026-01-15 10:31:12.208 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#96(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:12.208 | INFO     | [BOT-SYS] | input bot frame: RTVIServerMessageFrame#88(data: {'type': 'user-speaking'})
2026-01-15 10:31:12.208 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: RTVIServerMessageFrame id: 1241, name: 'RTVIServerMessageFrame#88', metadata: {}, data: {'type': 'user-speaking'} at 7.56s
2026-01-15 10:31:12.208 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1241, name: 'RTVIServerMessageFrame#88', metadata: {}, data: {'type': 'user-speaking'} at 7.56s
2026-01-15 10:31:12.208 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1237, name: 'OutputAudioRawFrame#523', metadata: {} at 7.56s
2026-01-15 10:31:12.208 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1242, name: 'OutputTransportMessageUrgentFrame#96', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.56s
2026-01-15 10:31:12.208 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: RTVIServerMessageFrame id: 1241, name: 'RTVIServerMessageFrame#88', metadata: {}, data: {'type': 'user-speaking'} at 7.56s
2026-01-15 10:31:12.208 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1241, name: 'RTVIServerMessageFrame#88', metadata: {}, data: {'type': 'user-speaking'} at 7.56s
2026-01-15 10:31:12.208 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1237, name: 'OutputAudioRawFrame#523', metadata: {} at 7.56s
2026-01-15 10:31:12.208 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1242, name: 'OutputTransportMessageUrgentFrame#96', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.56s
2026-01-15 10:31:12.208 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: RTVIServerMessageFrame id: 1241, name: 'RTVIServerMessageFrame#88', metadata: {}, data: {'type': 'user-speaking'} at 7.56s
2026-01-15 10:31:12.208 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#88(data: {'type': 'user-speaking'})
2026-01-15 10:31:12.208 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#523(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.209 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1241, name: 'RTVIServerMessageFrame#88', metadata: {}, data: {'type': 'user-speaking'} at 7.56s
2026-01-15 10:31:12.209 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1237, name: 'OutputAudioRawFrame#523', metadata: {} at 7.56s
2026-01-15 10:31:12.209 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1242, name: 'OutputTransportMessageUrgentFrame#96', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.56s
2026-01-15 10:31:12.209 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: RTVIServerMessageFrame id: 1241, name: 'RTVIServerMessageFrame#88', metadata: {}, data: {'type': 'user-speaking'} at 7.56s
2026-01-15 10:31:12.209 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#96(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:12.209 | INFO     | [BOT-SYS] | output bot frame: RTVIServerMessageFrame#88(data: {'type': 'user-speaking'})
2026-01-15 10:31:12.209 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1241, name: 'RTVIServerMessageFrame#88', metadata: {}, data: {'type': 'user-speaking'} at 7.56s
2026-01-15 10:31:12.209 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1241, name: 'RTVIServerMessageFrame#88', metadata: {}, data: {'type': 'user-speaking'} at 7.56s
2026-01-15 10:31:12.209 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1237, name: 'OutputAudioRawFrame#523', metadata: {} at 7.56s
2026-01-15 10:31:12.209 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1237, name: 'OutputAudioRawFrame#523', metadata: {} at 7.56s
2026-01-15 10:31:12.209 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1242, name: 'OutputTransportMessageUrgentFrame#96', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 7.56s
2026-01-15 10:31:12.209 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: RTVIServerMessageFrame id: 1241, name: 'RTVIServerMessageFrame#88', metadata: {}, data: {'type': 'user-speaking'} at 7.56s
2026-01-15 10:31:12.209 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: RTVIServerMessageFrame id: 1241, name: 'RTVIServerMessageFrame#88', metadata: {}, data: {'type': 'user-speaking'} at 7.56s
2026-01-15 10:31:12.209 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: RTVIServerMessageFrame id: 1241, name: 'RTVIServerMessageFrame#88', metadata: {}, data: {'type': 'user-speaking'} at 7.56s
2026-01-15 10:31:12.209 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#95(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:12.209 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1243, name: 'InputTransportMessageFrame#95', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.65s
2026-01-15 10:31:12.209 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#95(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:12.209 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#95(message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}})
2026-01-15 10:31:12.209 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:12.209 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:12.209 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1243, name: 'InputTransportMessageFrame#95', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.65s
2026-01-15 10:31:12.209 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1243, name: 'InputTransportMessageFrame#95', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.65s
2026-01-15 10:31:12.209 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1243, name: 'InputTransportMessageFrame#95', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.65s
2026-01-15 10:31:12.210 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1243, name: 'InputTransportMessageFrame#95', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.65s
2026-01-15 10:31:12.210 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1243, name: 'InputTransportMessageFrame#95', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.65s
2026-01-15 10:31:12.210 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1243, name: 'InputTransportMessageFrame#95', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'server-message', 'data': {'type': 'user-speaking'}} at 6.65s
2026-01-15 10:31:12.246 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 334, name: 'OutputAudioRawFrame#256', metadata: {} at 6.69s
2026-01-15 10:31:12.247 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 334, name: 'OutputAudioRawFrame#256', metadata: {} at 6.69s
2026-01-15 10:31:12.248 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: VADUserStoppedSpeakingFrame id: 1246, name: 'VADUserStoppedSpeakingFrame#2', metadata: {} at 7.60s
2026-01-15 10:31:12.248 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: VADUserStoppedSpeakingFrame id: 1246, name: 'VADUserStoppedSpeakingFrame#2', metadata: {} at 7.60s
2026-01-15 10:31:12.248 | INFO     | [BOT-SYS] | input bot frame: VADUserStoppedSpeakingFrame#2
2026-01-15 10:31:12.248 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: VADUserStoppedSpeakingFrame id: 1246, name: 'VADUserStoppedSpeakingFrame#2', metadata: {} at 7.60s
2026-01-15 10:31:12.248 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: VADUserStoppedSpeakingFrame id: 1246, name: 'VADUserStoppedSpeakingFrame#2', metadata: {} at 7.60s
2026-01-15 10:31:12.248 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: VADUserStoppedSpeakingFrame id: 1246, name: 'VADUserStoppedSpeakingFrame#2', metadata: {} at 7.60s
2026-01-15 10:31:12.248 | INFO     | [BOT-SYS] | output bot frame: VADUserStoppedSpeakingFrame#2
2026-01-15 10:31:12.248 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: VADUserStoppedSpeakingFrame id: 1246, name: 'VADUserStoppedSpeakingFrame#2', metadata: {} at 7.60s
2026-01-15 10:31:12.248 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: VADUserStoppedSpeakingFrame id: 1246, name: 'VADUserStoppedSpeakingFrame#2', metadata: {} at 7.60s
2026-01-15 10:31:12.248 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: VADUserStoppedSpeakingFrame id: 1246, name: 'VADUserStoppedSpeakingFrame#2', metadata: {} at 7.60s
2026-01-15 10:31:12.287 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 336, name: 'OutputAudioRawFrame#258', metadata: {} at 6.73s
2026-01-15 10:31:12.287 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 336, name: 'OutputAudioRawFrame#258', metadata: {} at 6.73s
2026-01-15 10:31:12.297 | DEBUG    | [BOT-SYS] | End of Turn result: EndOfTurnState.COMPLETE
2026-01-15 10:31:12.297 | DEBUG    | [BOT-SYS] | User stopped speaking
2026-01-15 10:31:12.297 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: MetricsFrame id: 1249, name: 'MetricsFrame#5', metadata: {}, data: [SmartTurnMetricsData(processor='BaseSmartTurn', model=None, is_complete=True, probability=0.921999990940094, inference_time_ms=0.0, server_total_time_ms=0.0, e2e_processing_time_ms=48.8392080005724)] at 7.65s
2026-01-15 10:31:12.297 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: UserStoppedSpeakingFrame id: 1250, name: 'UserStoppedSpeakingFrame#2', metadata: {}, emulated: False at 7.65s
2026-01-15 10:31:12.297 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â† Pipeline#0::Source: UserStoppedSpeakingFrame id: 1251, name: 'UserStoppedSpeakingFrame#3', metadata: {}, emulated: False at 7.65s
2026-01-15 10:31:12.298 | DEBUG    | [BOT-SYS] | Pipeline#0 â† PipelineTask#0::Source: UserStoppedSpeakingFrame id: 1251, name: 'UserStoppedSpeakingFrame#3', metadata: {}, emulated: False at 7.65s
2026-01-15 10:31:12.298 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1244, name: 'OutputAudioRawFrame#524', metadata: {} at 7.65s
2026-01-15 10:31:12.298 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1252, name: 'OutputTransportMessageUrgentFrame#97', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 7.65s
2026-01-15 10:31:12.298 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1253, name: 'OutputTransportMessageUrgentFrame#98', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'} at 7.65s
2026-01-15 10:31:12.298 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#97(message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}})
2026-01-15 10:31:12.298 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#98(message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'})
2026-01-15 10:31:12.298 | INFO     | [BOT-SYS] | input bot frame: MetricsFrame#5
2026-01-15 10:31:12.298 | INFO     | [BOT-SYS] | input bot frame: UserStoppedSpeakingFrame#2
2026-01-15 10:31:12.298 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#524(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.298 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: MetricsFrame id: 1249, name: 'MetricsFrame#5', metadata: {}, data: [SmartTurnMetricsData(processor='BaseSmartTurn', model=None, is_complete=True, probability=0.921999990940094, inference_time_ms=0.0, server_total_time_ms=0.0, e2e_processing_time_ms=48.8392080005724)] at 7.65s
2026-01-15 10:31:12.298 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: UserStoppedSpeakingFrame id: 1250, name: 'UserStoppedSpeakingFrame#2', metadata: {}, emulated: False at 7.65s
2026-01-15 10:31:12.298 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1244, name: 'OutputAudioRawFrame#524', metadata: {} at 7.65s
2026-01-15 10:31:12.298 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1252, name: 'OutputTransportMessageUrgentFrame#97', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 7.65s
2026-01-15 10:31:12.298 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1253, name: 'OutputTransportMessageUrgentFrame#98', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'} at 7.65s
2026-01-15 10:31:12.298 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: MetricsFrame id: 1249, name: 'MetricsFrame#5', metadata: {}, data: [SmartTurnMetricsData(processor='BaseSmartTurn', model=None, is_complete=True, probability=0.921999990940094, inference_time_ms=0.0, server_total_time_ms=0.0, e2e_processing_time_ms=48.8392080005724)] at 7.65s
2026-01-15 10:31:12.298 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: UserStoppedSpeakingFrame id: 1250, name: 'UserStoppedSpeakingFrame#2', metadata: {}, emulated: False at 7.65s
2026-01-15 10:31:12.298 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1244, name: 'OutputAudioRawFrame#524', metadata: {} at 7.65s
2026-01-15 10:31:12.298 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1252, name: 'OutputTransportMessageUrgentFrame#97', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 7.65s
2026-01-15 10:31:12.299 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1253, name: 'OutputTransportMessageUrgentFrame#98', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'} at 7.65s
2026-01-15 10:31:12.299 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: MetricsFrame id: 1249, name: 'MetricsFrame#5', metadata: {}, data: [SmartTurnMetricsData(processor='BaseSmartTurn', model=None, is_complete=True, probability=0.921999990940094, inference_time_ms=0.0, server_total_time_ms=0.0, e2e_processing_time_ms=48.8392080005724)] at 7.65s
2026-01-15 10:31:12.299 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: UserStoppedSpeakingFrame id: 1250, name: 'UserStoppedSpeakingFrame#2', metadata: {}, emulated: False at 7.65s
2026-01-15 10:31:12.299 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1244, name: 'OutputAudioRawFrame#524', metadata: {} at 7.65s
2026-01-15 10:31:12.299 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1252, name: 'OutputTransportMessageUrgentFrame#97', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 7.65s
2026-01-15 10:31:12.299 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1253, name: 'OutputTransportMessageUrgentFrame#98', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'} at 7.65s
2026-01-15 10:31:12.299 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: MetricsFrame id: 1249, name: 'MetricsFrame#5', metadata: {}, data: [SmartTurnMetricsData(processor='BaseSmartTurn', model=None, is_complete=True, probability=0.921999990940094, inference_time_ms=0.0, server_total_time_ms=0.0, e2e_processing_time_ms=48.8392080005724)] at 7.65s
2026-01-15 10:31:12.299 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: UserStoppedSpeakingFrame id: 1250, name: 'UserStoppedSpeakingFrame#2', metadata: {}, emulated: False at 7.65s
2026-01-15 10:31:12.299 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1244, name: 'OutputAudioRawFrame#524', metadata: {} at 7.65s
2026-01-15 10:31:12.299 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#97(message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}})
2026-01-15 10:31:12.299 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#98(message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'})
2026-01-15 10:31:12.299 | INFO     | [BOT-SYS] | output bot frame: MetricsFrame#5
2026-01-15 10:31:12.299 | INFO     | [BOT-SYS] | output bot frame: UserStoppedSpeakingFrame#2
2026-01-15 10:31:12.299 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#524(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.300 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1252, name: 'OutputTransportMessageUrgentFrame#97', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 7.65s
2026-01-15 10:31:12.300 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1253, name: 'OutputTransportMessageUrgentFrame#98', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'} at 7.65s
2026-01-15 10:31:12.300 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: MetricsFrame id: 1249, name: 'MetricsFrame#5', metadata: {}, data: [SmartTurnMetricsData(processor='BaseSmartTurn', model=None, is_complete=True, probability=0.921999990940094, inference_time_ms=0.0, server_total_time_ms=0.0, e2e_processing_time_ms=48.8392080005724)] at 7.65s
2026-01-15 10:31:12.300 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: UserStoppedSpeakingFrame id: 1250, name: 'UserStoppedSpeakingFrame#2', metadata: {}, emulated: False at 7.65s
2026-01-15 10:31:12.300 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1244, name: 'OutputAudioRawFrame#524', metadata: {} at 7.65s
2026-01-15 10:31:12.300 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1247, name: 'OutputAudioRawFrame#525', metadata: {} at 7.65s
2026-01-15 10:31:12.300 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: MetricsFrame id: 1249, name: 'MetricsFrame#5', metadata: {}, data: [SmartTurnMetricsData(processor='BaseSmartTurn', model=None, is_complete=True, probability=0.921999990940094, inference_time_ms=0.0, server_total_time_ms=0.0, e2e_processing_time_ms=48.8392080005724)] at 7.65s
2026-01-15 10:31:12.300 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: MetricsFrame id: 1249, name: 'MetricsFrame#5', metadata: {}, data: [SmartTurnMetricsData(processor='BaseSmartTurn', model=None, is_complete=True, probability=0.921999990940094, inference_time_ms=0.0, server_total_time_ms=0.0, e2e_processing_time_ms=48.8392080005724)] at 7.65s
2026-01-15 10:31:12.300 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: UserStoppedSpeakingFrame id: 1250, name: 'UserStoppedSpeakingFrame#2', metadata: {}, emulated: False at 7.65s
2026-01-15 10:31:12.300 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: UserStoppedSpeakingFrame id: 1250, name: 'UserStoppedSpeakingFrame#2', metadata: {}, emulated: False at 7.65s
2026-01-15 10:31:12.300 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1244, name: 'OutputAudioRawFrame#524', metadata: {} at 7.65s
2026-01-15 10:31:12.300 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1244, name: 'OutputAudioRawFrame#524', metadata: {} at 7.65s
2026-01-15 10:31:12.300 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1247, name: 'OutputAudioRawFrame#525', metadata: {} at 7.65s
2026-01-15 10:31:12.300 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#525(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.300 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#96(message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}})
2026-01-15 10:31:12.300 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1247, name: 'OutputAudioRawFrame#525', metadata: {} at 7.65s
2026-01-15 10:31:12.301 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1254, name: 'InputTransportMessageFrame#96', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 6.74s
2026-01-15 10:31:12.301 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#96(message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}})
2026-01-15 10:31:12.301 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#96(message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}})
2026-01-15 10:31:12.301 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:12.301 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:12.301 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#97(message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'})
2026-01-15 10:31:12.301 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1247, name: 'OutputAudioRawFrame#525', metadata: {} at 7.66s
2026-01-15 10:31:12.301 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1254, name: 'InputTransportMessageFrame#96', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 6.74s
2026-01-15 10:31:12.301 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1254, name: 'InputTransportMessageFrame#96', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 6.74s
2026-01-15 10:31:12.301 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1254, name: 'InputTransportMessageFrame#96', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 6.74s
2026-01-15 10:31:12.301 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1254, name: 'InputTransportMessageFrame#96', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 6.74s
2026-01-15 10:31:12.301 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1255, name: 'InputTransportMessageFrame#97', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'} at 6.74s
2026-01-15 10:31:12.301 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#97(message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'})
2026-01-15 10:31:12.301 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#97(message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'})
2026-01-15 10:31:12.301 | INFO     | [EVAL-SYS] | is_bot_turn_over: True
2026-01-15 10:31:12.301 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:12.301 | INFO     | [EVAL-SYS] | Setting state to buffering and advancing to next audio file in 5 seconds
2026-01-15 10:31:12.301 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1247, name: 'OutputAudioRawFrame#525', metadata: {} at 7.66s
2026-01-15 10:31:12.301 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#525(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.301 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1254, name: 'InputTransportMessageFrame#96', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 6.75s
2026-01-15 10:31:12.301 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1254, name: 'InputTransportMessageFrame#96', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {}} at 6.75s
2026-01-15 10:31:12.301 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1255, name: 'InputTransportMessageFrame#97', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'} at 6.75s
2026-01-15 10:31:12.302 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1255, name: 'InputTransportMessageFrame#97', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'} at 6.75s
2026-01-15 10:31:12.302 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1255, name: 'InputTransportMessageFrame#97', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'} at 6.75s
2026-01-15 10:31:12.302 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1255, name: 'InputTransportMessageFrame#97', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'} at 6.75s
2026-01-15 10:31:12.302 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1247, name: 'OutputAudioRawFrame#525', metadata: {} at 7.66s
2026-01-15 10:31:12.302 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1255, name: 'InputTransportMessageFrame#97', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'} at 6.75s
2026-01-15 10:31:12.302 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1255, name: 'InputTransportMessageFrame#97', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-stopped-speaking'} at 6.75s
2026-01-15 10:31:12.302 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1247, name: 'OutputAudioRawFrame#525', metadata: {} at 7.66s
2026-01-15 10:31:12.302 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1247, name: 'OutputAudioRawFrame#525', metadata: {} at 7.66s
2026-01-15 10:31:12.327 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 337, name: 'OutputAudioRawFrame#259', metadata: {} at 6.77s
2026-01-15 10:31:12.327 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 337, name: 'OutputAudioRawFrame#259', metadata: {} at 6.77s
2026-01-15 10:31:12.328 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1256, name: 'OutputAudioRawFrame#526', metadata: {} at 7.68s
2026-01-15 10:31:12.328 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1256, name: 'OutputAudioRawFrame#526', metadata: {} at 7.68s
2026-01-15 10:31:12.328 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#526(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.328 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1256, name: 'OutputAudioRawFrame#526', metadata: {} at 7.68s
2026-01-15 10:31:12.328 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1256, name: 'OutputAudioRawFrame#526', metadata: {} at 7.68s
2026-01-15 10:31:12.328 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1256, name: 'OutputAudioRawFrame#526', metadata: {} at 7.68s
2026-01-15 10:31:12.328 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#526(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.328 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1256, name: 'OutputAudioRawFrame#526', metadata: {} at 7.68s
2026-01-15 10:31:12.329 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1256, name: 'OutputAudioRawFrame#526', metadata: {} at 7.68s
2026-01-15 10:31:12.329 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1256, name: 'OutputAudioRawFrame#526', metadata: {} at 7.68s
2026-01-15 10:31:12.367 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 339, name: 'OutputAudioRawFrame#261', metadata: {} at 6.81s
2026-01-15 10:31:12.367 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 339, name: 'OutputAudioRawFrame#261', metadata: {} at 6.81s
2026-01-15 10:31:12.368 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1258, name: 'OutputAudioRawFrame#527', metadata: {} at 7.72s
2026-01-15 10:31:12.368 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1258, name: 'OutputAudioRawFrame#527', metadata: {} at 7.72s
2026-01-15 10:31:12.368 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#527(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.368 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1258, name: 'OutputAudioRawFrame#527', metadata: {} at 7.72s
2026-01-15 10:31:12.368 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1258, name: 'OutputAudioRawFrame#527', metadata: {} at 7.72s
2026-01-15 10:31:12.368 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1258, name: 'OutputAudioRawFrame#527', metadata: {} at 7.72s
2026-01-15 10:31:12.369 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#527(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.369 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1258, name: 'OutputAudioRawFrame#527', metadata: {} at 7.72s
2026-01-15 10:31:12.369 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1258, name: 'OutputAudioRawFrame#527', metadata: {} at 7.72s
2026-01-15 10:31:12.369 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1258, name: 'OutputAudioRawFrame#527', metadata: {} at 7.72s
2026-01-15 10:31:12.406 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 340, name: 'OutputAudioRawFrame#262', metadata: {} at 6.85s
2026-01-15 10:31:12.407 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 340, name: 'OutputAudioRawFrame#262', metadata: {} at 6.85s
2026-01-15 10:31:12.407 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1260, name: 'OutputAudioRawFrame#528', metadata: {} at 7.76s
2026-01-15 10:31:12.408 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1260, name: 'OutputAudioRawFrame#528', metadata: {} at 7.76s
2026-01-15 10:31:12.408 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#528(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.408 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1260, name: 'OutputAudioRawFrame#528', metadata: {} at 7.76s
2026-01-15 10:31:12.408 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1260, name: 'OutputAudioRawFrame#528', metadata: {} at 7.76s
2026-01-15 10:31:12.408 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1260, name: 'OutputAudioRawFrame#528', metadata: {} at 7.76s
2026-01-15 10:31:12.408 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#528(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.408 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1260, name: 'OutputAudioRawFrame#528', metadata: {} at 7.76s
2026-01-15 10:31:12.408 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1260, name: 'OutputAudioRawFrame#528', metadata: {} at 7.76s
2026-01-15 10:31:12.408 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1260, name: 'OutputAudioRawFrame#528', metadata: {} at 7.76s
2026-01-15 10:31:12.446 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 341, name: 'OutputAudioRawFrame#263', metadata: {} at 6.89s
2026-01-15 10:31:12.447 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 341, name: 'OutputAudioRawFrame#263', metadata: {} at 6.89s
2026-01-15 10:31:12.447 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1262, name: 'OutputAudioRawFrame#529', metadata: {} at 7.80s
2026-01-15 10:31:12.447 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1262, name: 'OutputAudioRawFrame#529', metadata: {} at 7.80s
2026-01-15 10:31:12.448 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#529(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.448 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1262, name: 'OutputAudioRawFrame#529', metadata: {} at 7.80s
2026-01-15 10:31:12.448 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1262, name: 'OutputAudioRawFrame#529', metadata: {} at 7.80s
2026-01-15 10:31:12.448 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1262, name: 'OutputAudioRawFrame#529', metadata: {} at 7.80s
2026-01-15 10:31:12.448 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#529(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.448 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1262, name: 'OutputAudioRawFrame#529', metadata: {} at 7.80s
2026-01-15 10:31:12.448 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1262, name: 'OutputAudioRawFrame#529', metadata: {} at 7.80s
2026-01-15 10:31:12.448 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1262, name: 'OutputAudioRawFrame#529', metadata: {} at 7.80s
2026-01-15 10:31:12.486 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 343, name: 'OutputAudioRawFrame#265', metadata: {} at 6.93s
2026-01-15 10:31:12.487 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 343, name: 'OutputAudioRawFrame#265', metadata: {} at 6.93s
2026-01-15 10:31:12.488 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1264, name: 'OutputAudioRawFrame#530', metadata: {} at 7.84s
2026-01-15 10:31:12.488 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1264, name: 'OutputAudioRawFrame#530', metadata: {} at 7.84s
2026-01-15 10:31:12.488 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#530(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.488 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1264, name: 'OutputAudioRawFrame#530', metadata: {} at 7.84s
2026-01-15 10:31:12.489 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1264, name: 'OutputAudioRawFrame#530', metadata: {} at 7.84s
2026-01-15 10:31:12.489 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1264, name: 'OutputAudioRawFrame#530', metadata: {} at 7.84s
2026-01-15 10:31:12.489 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#530(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.489 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1264, name: 'OutputAudioRawFrame#530', metadata: {} at 7.84s
2026-01-15 10:31:12.489 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1264, name: 'OutputAudioRawFrame#530', metadata: {} at 7.84s
2026-01-15 10:31:12.489 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1264, name: 'OutputAudioRawFrame#530', metadata: {} at 7.84s
2026-01-15 10:31:12.527 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 344, name: 'OutputAudioRawFrame#266', metadata: {} at 6.97s
2026-01-15 10:31:12.527 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 344, name: 'OutputAudioRawFrame#266', metadata: {} at 6.97s
2026-01-15 10:31:12.528 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1266, name: 'OutputAudioRawFrame#531', metadata: {} at 7.88s
2026-01-15 10:31:12.528 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1266, name: 'OutputAudioRawFrame#531', metadata: {} at 7.88s
2026-01-15 10:31:12.528 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#531(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.529 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1266, name: 'OutputAudioRawFrame#531', metadata: {} at 7.88s
2026-01-15 10:31:12.529 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1266, name: 'OutputAudioRawFrame#531', metadata: {} at 7.88s
2026-01-15 10:31:12.529 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1266, name: 'OutputAudioRawFrame#531', metadata: {} at 7.88s
2026-01-15 10:31:12.529 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#531(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.529 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1266, name: 'OutputAudioRawFrame#531', metadata: {} at 7.88s
2026-01-15 10:31:12.529 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1266, name: 'OutputAudioRawFrame#531', metadata: {} at 7.88s
2026-01-15 10:31:12.529 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1266, name: 'OutputAudioRawFrame#531', metadata: {} at 7.88s
2026-01-15 10:31:12.566 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 346, name: 'OutputAudioRawFrame#268', metadata: {} at 7.01s
2026-01-15 10:31:12.567 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 346, name: 'OutputAudioRawFrame#268', metadata: {} at 7.01s
2026-01-15 10:31:12.568 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1268, name: 'OutputAudioRawFrame#532', metadata: {} at 7.92s
2026-01-15 10:31:12.568 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1268, name: 'OutputAudioRawFrame#532', metadata: {} at 7.92s
2026-01-15 10:31:12.568 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#532(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.568 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1268, name: 'OutputAudioRawFrame#532', metadata: {} at 7.92s
2026-01-15 10:31:12.568 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1268, name: 'OutputAudioRawFrame#532', metadata: {} at 7.92s
2026-01-15 10:31:12.568 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1268, name: 'OutputAudioRawFrame#532', metadata: {} at 7.92s
2026-01-15 10:31:12.568 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#532(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.568 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1268, name: 'OutputAudioRawFrame#532', metadata: {} at 7.92s
2026-01-15 10:31:12.569 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1268, name: 'OutputAudioRawFrame#532', metadata: {} at 7.92s
2026-01-15 10:31:12.569 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1268, name: 'OutputAudioRawFrame#532', metadata: {} at 7.92s
2026-01-15 10:31:12.607 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 347, name: 'OutputAudioRawFrame#269', metadata: {} at 7.05s
2026-01-15 10:31:12.607 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 347, name: 'OutputAudioRawFrame#269', metadata: {} at 7.05s
2026-01-15 10:31:12.608 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1270, name: 'OutputAudioRawFrame#533', metadata: {} at 7.96s
2026-01-15 10:31:12.608 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1270, name: 'OutputAudioRawFrame#533', metadata: {} at 7.96s
2026-01-15 10:31:12.608 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#533(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.608 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1270, name: 'OutputAudioRawFrame#533', metadata: {} at 7.96s
2026-01-15 10:31:12.608 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1270, name: 'OutputAudioRawFrame#533', metadata: {} at 7.96s
2026-01-15 10:31:12.609 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1270, name: 'OutputAudioRawFrame#533', metadata: {} at 7.96s
2026-01-15 10:31:12.609 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#533(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.609 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1270, name: 'OutputAudioRawFrame#533', metadata: {} at 7.96s
2026-01-15 10:31:12.609 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1270, name: 'OutputAudioRawFrame#533', metadata: {} at 7.96s
2026-01-15 10:31:12.609 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1270, name: 'OutputAudioRawFrame#533', metadata: {} at 7.96s
2026-01-15 10:31:12.650 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 349, name: 'OutputAudioRawFrame#271', metadata: {} at 7.09s
2026-01-15 10:31:12.650 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 349, name: 'OutputAudioRawFrame#271', metadata: {} at 7.09s
2026-01-15 10:31:12.653 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1272, name: 'OutputAudioRawFrame#534', metadata: {} at 8.01s
2026-01-15 10:31:12.653 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1272, name: 'OutputAudioRawFrame#534', metadata: {} at 8.01s
2026-01-15 10:31:12.654 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#534(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.654 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1272, name: 'OutputAudioRawFrame#534', metadata: {} at 8.01s
2026-01-15 10:31:12.655 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1272, name: 'OutputAudioRawFrame#534', metadata: {} at 8.01s
2026-01-15 10:31:12.655 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1272, name: 'OutputAudioRawFrame#534', metadata: {} at 8.01s
2026-01-15 10:31:12.655 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#534(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.655 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1272, name: 'OutputAudioRawFrame#534', metadata: {} at 8.01s
2026-01-15 10:31:12.655 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1272, name: 'OutputAudioRawFrame#534', metadata: {} at 8.01s
2026-01-15 10:31:12.655 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1272, name: 'OutputAudioRawFrame#534', metadata: {} at 8.01s
2026-01-15 10:31:12.686 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 351, name: 'OutputAudioRawFrame#273', metadata: {} at 7.13s
2026-01-15 10:31:12.686 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 351, name: 'OutputAudioRawFrame#273', metadata: {} at 7.13s
2026-01-15 10:31:12.690 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1274, name: 'OutputAudioRawFrame#535', metadata: {} at 8.04s
2026-01-15 10:31:12.690 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1274, name: 'OutputAudioRawFrame#535', metadata: {} at 8.04s
2026-01-15 10:31:12.690 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#535(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.690 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1274, name: 'OutputAudioRawFrame#535', metadata: {} at 8.04s
2026-01-15 10:31:12.691 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1274, name: 'OutputAudioRawFrame#535', metadata: {} at 8.05s
2026-01-15 10:31:12.691 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1274, name: 'OutputAudioRawFrame#535', metadata: {} at 8.05s
2026-01-15 10:31:12.691 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#535(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.691 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1274, name: 'OutputAudioRawFrame#535', metadata: {} at 8.05s
2026-01-15 10:31:12.691 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1274, name: 'OutputAudioRawFrame#535', metadata: {} at 8.05s
2026-01-15 10:31:12.691 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1274, name: 'OutputAudioRawFrame#535', metadata: {} at 8.05s
2026-01-15 10:31:12.703 | DEBUG    | [BOT-SYS] | Received response: type='events' data=EventsData(event_type=None, timestamp=None, signal_type='END_SPEECH', occured_at=1768453272.7396219)
2026-01-15 10:31:12.703 | DEBUG    | [BOT-SYS] | VAD Signal: END_SPEECH, Occurred at: 1768453272.7396219
2026-01-15 10:31:12.727 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 352, name: 'OutputAudioRawFrame#274', metadata: {} at 7.17s
2026-01-15 10:31:12.727 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 352, name: 'OutputAudioRawFrame#274', metadata: {} at 7.17s
2026-01-15 10:31:12.728 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1276, name: 'OutputAudioRawFrame#536', metadata: {} at 8.08s
2026-01-15 10:31:12.728 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1276, name: 'OutputAudioRawFrame#536', metadata: {} at 8.08s
2026-01-15 10:31:12.728 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#536(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.728 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1276, name: 'OutputAudioRawFrame#536', metadata: {} at 8.08s
2026-01-15 10:31:12.728 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1276, name: 'OutputAudioRawFrame#536', metadata: {} at 8.08s
2026-01-15 10:31:12.728 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1276, name: 'OutputAudioRawFrame#536', metadata: {} at 8.08s
2026-01-15 10:31:12.728 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#536(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.728 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1276, name: 'OutputAudioRawFrame#536', metadata: {} at 8.08s
2026-01-15 10:31:12.728 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1276, name: 'OutputAudioRawFrame#536', metadata: {} at 8.08s
2026-01-15 10:31:12.728 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1276, name: 'OutputAudioRawFrame#536', metadata: {} at 8.08s
2026-01-15 10:31:12.767 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 354, name: 'OutputAudioRawFrame#276', metadata: {} at 7.21s
2026-01-15 10:31:12.767 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 354, name: 'OutputAudioRawFrame#276', metadata: {} at 7.21s
2026-01-15 10:31:12.768 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1278, name: 'OutputAudioRawFrame#537', metadata: {} at 8.12s
2026-01-15 10:31:12.768 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1278, name: 'OutputAudioRawFrame#537', metadata: {} at 8.12s
2026-01-15 10:31:12.768 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#537(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.768 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1278, name: 'OutputAudioRawFrame#537', metadata: {} at 8.12s
2026-01-15 10:31:12.768 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1278, name: 'OutputAudioRawFrame#537', metadata: {} at 8.12s
2026-01-15 10:31:12.768 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1278, name: 'OutputAudioRawFrame#537', metadata: {} at 8.12s
2026-01-15 10:31:12.768 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#537(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.768 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1278, name: 'OutputAudioRawFrame#537', metadata: {} at 8.12s
2026-01-15 10:31:12.768 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1278, name: 'OutputAudioRawFrame#537', metadata: {} at 8.12s
2026-01-15 10:31:12.768 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1278, name: 'OutputAudioRawFrame#537', metadata: {} at 8.12s
2026-01-15 10:31:12.807 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 355, name: 'OutputAudioRawFrame#277', metadata: {} at 7.25s
2026-01-15 10:31:12.807 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 355, name: 'OutputAudioRawFrame#277', metadata: {} at 7.25s
2026-01-15 10:31:12.808 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1280, name: 'OutputAudioRawFrame#538', metadata: {} at 8.16s
2026-01-15 10:31:12.808 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1280, name: 'OutputAudioRawFrame#538', metadata: {} at 8.16s
2026-01-15 10:31:12.808 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#538(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.808 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1280, name: 'OutputAudioRawFrame#538', metadata: {} at 8.16s
2026-01-15 10:31:12.808 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1280, name: 'OutputAudioRawFrame#538', metadata: {} at 8.16s
2026-01-15 10:31:12.808 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1280, name: 'OutputAudioRawFrame#538', metadata: {} at 8.16s
2026-01-15 10:31:12.808 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#538(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.808 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1280, name: 'OutputAudioRawFrame#538', metadata: {} at 8.16s
2026-01-15 10:31:12.808 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1280, name: 'OutputAudioRawFrame#538', metadata: {} at 8.16s
2026-01-15 10:31:12.808 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1280, name: 'OutputAudioRawFrame#538', metadata: {} at 8.16s
2026-01-15 10:31:12.847 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 357, name: 'OutputAudioRawFrame#279', metadata: {} at 7.29s
2026-01-15 10:31:12.847 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 357, name: 'OutputAudioRawFrame#279', metadata: {} at 7.29s
2026-01-15 10:31:12.848 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1282, name: 'OutputAudioRawFrame#539', metadata: {} at 8.20s
2026-01-15 10:31:12.848 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1282, name: 'OutputAudioRawFrame#539', metadata: {} at 8.20s
2026-01-15 10:31:12.848 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#539(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.848 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1282, name: 'OutputAudioRawFrame#539', metadata: {} at 8.20s
2026-01-15 10:31:12.849 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1282, name: 'OutputAudioRawFrame#539', metadata: {} at 8.20s
2026-01-15 10:31:12.849 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1282, name: 'OutputAudioRawFrame#539', metadata: {} at 8.20s
2026-01-15 10:31:12.849 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#539(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.849 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1282, name: 'OutputAudioRawFrame#539', metadata: {} at 8.20s
2026-01-15 10:31:12.849 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1282, name: 'OutputAudioRawFrame#539', metadata: {} at 8.20s
2026-01-15 10:31:12.849 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1282, name: 'OutputAudioRawFrame#539', metadata: {} at 8.20s
2026-01-15 10:31:12.886 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 358, name: 'OutputAudioRawFrame#280', metadata: {} at 7.33s
2026-01-15 10:31:12.886 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 358, name: 'OutputAudioRawFrame#280', metadata: {} at 7.33s
2026-01-15 10:31:12.887 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1284, name: 'OutputAudioRawFrame#540', metadata: {} at 8.24s
2026-01-15 10:31:12.887 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1284, name: 'OutputAudioRawFrame#540', metadata: {} at 8.24s
2026-01-15 10:31:12.887 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#540(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.888 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1284, name: 'OutputAudioRawFrame#540', metadata: {} at 8.24s
2026-01-15 10:31:12.888 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1284, name: 'OutputAudioRawFrame#540', metadata: {} at 8.24s
2026-01-15 10:31:12.888 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1284, name: 'OutputAudioRawFrame#540', metadata: {} at 8.24s
2026-01-15 10:31:12.888 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#540(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.888 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1284, name: 'OutputAudioRawFrame#540', metadata: {} at 8.24s
2026-01-15 10:31:12.888 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1284, name: 'OutputAudioRawFrame#540', metadata: {} at 8.24s
2026-01-15 10:31:12.888 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1284, name: 'OutputAudioRawFrame#540', metadata: {} at 8.24s
2026-01-15 10:31:12.906 | DEBUG    | [BOT-SYS] | Received response: type='data' data=SpeechToTextTranscriptionData(request_id='20260115_4d89d847-9563-4b34-9aad-bcf8d640b3d6', transcript='Please write Rekha Kumari sister.', timestamps=None, diarized_transcript=None, language_code='en-IN', metrics=TranscriptionMetrics(audio_duration=5.44, processing_latency=0.16158461570739746))
2026-01-15 10:31:12.906 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: TranscriptionFrame id: 1286, name: 'TranscriptionFrame#0', metadata: {}, text: 'Please write Rekha Kumari sister.', includes_inter_frame_spaces: False, append_to_context: True, user_id: '', timestamp: '2026-01-15T05:01:12.906+00:00', language: <Language.EN_IN: 'en-IN'>, result: {'type': 'data', 'data': {'request_id': '20260115_4d89d847-9563-4b34-9aad-bcf8d640b3d6', 'transcript': 'Please write Rekha Kumari sister.', 'language_code': 'en-IN', 'metrics': {'audio_duration': 5.44, 'processing_latency': 0.16158461570739746}, 'timestamps': None, 'diarized_transcript': None}} at 8.26s
2026-01-15 10:31:12.907 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: OutputTransportMessageUrgentFrame id: 1287, name: 'OutputTransportMessageUrgentFrame#99', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-transcription', 'data': {'text': 'Please write Rekha Kumari sister.', 'user_id': '', 'timestamp': '2026-01-15T05:01:12.906+00:00', 'final': True}} at 8.26s
2026-01-15 10:31:12.907 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#99(message: {'label': 'rtvi-ai', 'type': 'user-transcription', 'data': {'text': 'Please write Rekha Kumari sister.', 'user_id': '', 'timestamp': '2026-01-15T05:01:12.906+00:00', 'final': True}})
2026-01-15 10:31:12.907 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: OutputTransportMessageUrgentFrame id: 1287, name: 'OutputTransportMessageUrgentFrame#99', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-transcription', 'data': {'text': 'Please write Rekha Kumari sister.', 'user_id': '', 'timestamp': '2026-01-15T05:01:12.906+00:00', 'final': True}} at 8.26s
2026-01-15 10:31:12.907 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: TranscriptionUpdateFrame id: 1288, name: 'TranscriptionUpdateFrame#0', metadata: {}, messages: [TranscriptionMessage(role='user', content='Please write Rekha Kumari sister.', user_id='', timestamp='2026-01-15T05:01:12.906+00:00')] at 8.26s
2026-01-15 10:31:12.907 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: TranscriptionFrame id: 1286, name: 'TranscriptionFrame#0', metadata: {}, text: 'Please write Rekha Kumari sister.', includes_inter_frame_spaces: False, append_to_context: True, user_id: '', timestamp: '2026-01-15T05:01:12.906+00:00', language: <Language.EN_IN: 'en-IN'>, result: {'type': 'data', 'data': {'request_id': '20260115_4d89d847-9563-4b34-9aad-bcf8d640b3d6', 'transcript': 'Please write Rekha Kumari sister.', 'language_code': 'en-IN', 'metrics': {'audio_duration': 5.44, 'processing_latency': 0.16158461570739746}, 'timestamps': None, 'diarized_transcript': None}} at 8.26s
2026-01-15 10:31:12.907 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: OutputTransportMessageUrgentFrame id: 1287, name: 'OutputTransportMessageUrgentFrame#99', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-transcription', 'data': {'text': 'Please write Rekha Kumari sister.', 'user_id': '', 'timestamp': '2026-01-15T05:01:12.906+00:00', 'final': True}} at 8.26s
2026-01-15 10:31:12.907 | INFO     | [BOT-SYS] | output bot frame: TranscriptionUpdateFrame#0(pts: None, messages: 1)
2026-01-15 10:31:12.907 | INFO     | [BOT-SYS] | output bot frame: TranscriptionFrame#0(user: , text: [Please write Rekha Kumari sister.], language: en-IN, timestamp: 2026-01-15T05:01:12.906+00:00)
2026-01-15 10:31:12.907 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: OutputTransportMessageUrgentFrame id: 1287, name: 'OutputTransportMessageUrgentFrame#99', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-transcription', 'data': {'text': 'Please write Rekha Kumari sister.', 'user_id': '', 'timestamp': '2026-01-15T05:01:12.906+00:00', 'final': True}} at 8.26s
2026-01-15 10:31:12.907 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: TranscriptionUpdateFrame id: 1288, name: 'TranscriptionUpdateFrame#0', metadata: {}, messages: [TranscriptionMessage(role='user', content='Please write Rekha Kumari sister.', user_id='', timestamp='2026-01-15T05:01:12.906+00:00')] at 8.26s
2026-01-15 10:31:12.907 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: TranscriptionFrame id: 1286, name: 'TranscriptionFrame#0', metadata: {}, text: 'Please write Rekha Kumari sister.', includes_inter_frame_spaces: False, append_to_context: True, user_id: '', timestamp: '2026-01-15T05:01:12.906+00:00', language: <Language.EN_IN: 'en-IN'>, result: {'type': 'data', 'data': {'request_id': '20260115_4d89d847-9563-4b34-9aad-bcf8d640b3d6', 'transcript': 'Please write Rekha Kumari sister.', 'language_code': 'en-IN', 'metrics': {'audio_duration': 5.44, 'processing_latency': 0.16158461570739746}, 'timestamps': None, 'diarized_transcript': None}} at 8.26s
2026-01-15 10:31:12.907 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#99(message: {'label': 'rtvi-ai', 'type': 'user-transcription', 'data': {'text': 'Please write Rekha Kumari sister.', 'user_id': '', 'timestamp': '2026-01-15T05:01:12.906+00:00', 'final': True}})
2026-01-15 10:31:12.907 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: OutputTransportMessageUrgentFrame id: 1287, name: 'OutputTransportMessageUrgentFrame#99', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-transcription', 'data': {'text': 'Please write Rekha Kumari sister.', 'user_id': '', 'timestamp': '2026-01-15T05:01:12.906+00:00', 'final': True}} at 8.26s
2026-01-15 10:31:12.908 | DEBUG    | [EVAL-SYS] | ProtobufFrameSerializer: Transport message InputTransportMessageFrame#98(message: {'label': 'rtvi-ai', 'type': 'user-transcription', 'data': {'text': 'Please write Rekha Kumari sister.', 'user_id': '', 'timestamp': '2026-01-15T05:01:12.906+00:00', 'final': True}})
2026-01-15 10:31:12.908 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: InputTransportMessageFrame id: 1289, name: 'InputTransportMessageFrame#98', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-transcription', 'data': {'text': 'Please write Rekha Kumari sister.', 'user_id': '', 'timestamp': '2026-01-15T05:01:12.906+00:00', 'final': True}} at 7.35s
2026-01-15 10:31:12.908 | INFO     | [EVAL-SYS] | eval frame: InputTransportMessageFrame#98(message: {'label': 'rtvi-ai', 'type': 'user-transcription', 'data': {'text': 'Please write Rekha Kumari sister.', 'user_id': '', 'timestamp': '2026-01-15T05:01:12.906+00:00', 'final': True}})
2026-01-15 10:31:12.908 | INFO     | [EVAL-SYS] | frame transcription logger: InputTransportMessageFrame#98(message: {'label': 'rtvi-ai', 'type': 'user-transcription', 'data': {'text': 'Please write Rekha Kumari sister.', 'user_id': '', 'timestamp': '2026-01-15T05:01:12.906+00:00', 'final': True}})
2026-01-15 10:31:12.908 | INFO     | [EVAL-SYS] | [93mappending to last user transcript: Please write Rekha Kumari sister.[0m
2026-01-15 10:31:12.909 | INFO     | [EVAL-SYS] | is_bot_turn_over: True
2026-01-15 10:31:12.909 | INFO     | [EVAL-SYS] | User started speaking during buffering, cancelling pending advance
2026-01-15 10:31:12.909 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:12.909 | INFO     | [EVAL-SYS] | Setting state to buffering and advancing to next audio file in 5 seconds
2026-01-15 10:31:12.909 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: TranscriptionUpdateFrame id: 1288, name: 'TranscriptionUpdateFrame#0', metadata: {}, messages: [TranscriptionMessage(role='user', content='Please write Rekha Kumari sister.', user_id='', timestamp='2026-01-15T05:01:12.906+00:00')] at 8.26s
2026-01-15 10:31:12.909 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: TranscriptionUpdateFrame id: 1288, name: 'TranscriptionUpdateFrame#0', metadata: {}, messages: [TranscriptionMessage(role='user', content='Please write Rekha Kumari sister.', user_id='', timestamp='2026-01-15T05:01:12.906+00:00')] at 8.26s
2026-01-15 10:31:12.909 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: InputTransportMessageFrame id: 1289, name: 'InputTransportMessageFrame#98', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-transcription', 'data': {'text': 'Please write Rekha Kumari sister.', 'user_id': '', 'timestamp': '2026-01-15T05:01:12.906+00:00', 'final': True}} at 7.35s
2026-01-15 10:31:12.909 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â† IOLogger#2: TranscriptionFrame id: 1290, name: 'TranscriptionFrame#1', metadata: {}, text: 'Please write Rekha Kumari sister.', includes_inter_frame_spaces: False, append_to_context: True, user_id: '', timestamp: '2026-01-15T10:31:12.908971' at 7.35s
2026-01-15 10:31:12.909 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: InputTransportMessageFrame id: 1289, name: 'InputTransportMessageFrame#98', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-transcription', 'data': {'text': 'Please write Rekha Kumari sister.', 'user_id': '', 'timestamp': '2026-01-15T05:01:12.906+00:00', 'final': True}} at 7.35s
2026-01-15 10:31:12.909 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: InputTransportMessageFrame id: 1289, name: 'InputTransportMessageFrame#98', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-transcription', 'data': {'text': 'Please write Rekha Kumari sister.', 'user_id': '', 'timestamp': '2026-01-15T05:01:12.906+00:00', 'final': True}} at 7.35s
2026-01-15 10:31:12.909 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: InputTransportMessageFrame id: 1289, name: 'InputTransportMessageFrame#98', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-transcription', 'data': {'text': 'Please write Rekha Kumari sister.', 'user_id': '', 'timestamp': '2026-01-15T05:01:12.906+00:00', 'final': True}} at 7.35s
2026-01-15 10:31:12.909 | INFO     | [EVAL-SYS] | eval frame: TranscriptionFrame#1(user: , text: [Please write Rekha Kumari sister.], language: None, timestamp: 2026-01-15T10:31:12.908971)
2026-01-15 10:31:12.909 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: InputTransportMessageFrame id: 1289, name: 'InputTransportMessageFrame#98', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-transcription', 'data': {'text': 'Please write Rekha Kumari sister.', 'user_id': '', 'timestamp': '2026-01-15T05:01:12.906+00:00', 'final': True}} at 7.35s
2026-01-15 10:31:12.909 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: InputTransportMessageFrame id: 1289, name: 'InputTransportMessageFrame#98', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'user-transcription', 'data': {'text': 'Please write Rekha Kumari sister.', 'user_id': '', 'timestamp': '2026-01-15T05:01:12.906+00:00', 'final': True}} at 7.35s
2026-01-15 10:31:12.909 | DEBUG    | [EVAL-SYS] | IOLogger#2 â† WebsocketClientInputTransport#0: TranscriptionFrame id: 1290, name: 'TranscriptionFrame#1', metadata: {}, text: 'Please write Rekha Kumari sister.', includes_inter_frame_spaces: False, append_to_context: True, user_id: '', timestamp: '2026-01-15T10:31:12.908971' at 7.35s
2026-01-15 10:31:12.909 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: TranscriptionFrame id: 1286, name: 'TranscriptionFrame#0', metadata: {}, text: 'Please write Rekha Kumari sister.', includes_inter_frame_spaces: False, append_to_context: True, user_id: '', timestamp: '2026-01-15T05:01:12.906+00:00', language: <Language.EN_IN: 'en-IN'>, result: {'type': 'data', 'data': {'request_id': '20260115_4d89d847-9563-4b34-9aad-bcf8d640b3d6', 'transcript': 'Please write Rekha Kumari sister.', 'language_code': 'en-IN', 'metrics': {'audio_duration': 5.44, 'processing_latency': 0.16158461570739746}, 'timestamps': None, 'diarized_transcript': None}} at 8.26s
2026-01-15 10:31:12.909 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: TranscriptionFrame id: 1286, name: 'TranscriptionFrame#0', metadata: {}, text: 'Please write Rekha Kumari sister.', includes_inter_frame_spaces: False, append_to_context: True, user_id: '', timestamp: '2026-01-15T05:01:12.906+00:00', language: <Language.EN_IN: 'en-IN'>, result: {'type': 'data', 'data': {'request_id': '20260115_4d89d847-9563-4b34-9aad-bcf8d640b3d6', 'transcript': 'Please write Rekha Kumari sister.', 'language_code': 'en-IN', 'metrics': {'audio_duration': 5.44, 'processing_latency': 0.16158461570739746}, 'timestamps': None, 'diarized_transcript': None}} at 8.26s
2026-01-15 10:31:12.909 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â† Pipeline#2::Source: TranscriptionFrame id: 1290, name: 'TranscriptionFrame#1', metadata: {}, text: 'Please write Rekha Kumari sister.', includes_inter_frame_spaces: False, append_to_context: True, user_id: '', timestamp: '2026-01-15T10:31:12.908971' at 7.35s
2026-01-15 10:31:12.909 | DEBUG    | [EVAL-SYS] | Pipeline#2 â† PipelineTask#1::Source: TranscriptionFrame id: 1290, name: 'TranscriptionFrame#1', metadata: {}, text: 'Please write Rekha Kumari sister.', includes_inter_frame_spaces: False, append_to_context: True, user_id: '', timestamp: '2026-01-15T10:31:12.908971' at 7.35s
2026-01-15 10:31:12.927 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 359, name: 'OutputAudioRawFrame#281', metadata: {} at 7.37s
2026-01-15 10:31:12.927 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 359, name: 'OutputAudioRawFrame#281', metadata: {} at 7.37s
2026-01-15 10:31:12.928 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1291, name: 'OutputAudioRawFrame#541', metadata: {} at 8.28s
2026-01-15 10:31:12.928 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1291, name: 'OutputAudioRawFrame#541', metadata: {} at 8.28s
2026-01-15 10:31:12.928 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#541(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.928 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1291, name: 'OutputAudioRawFrame#541', metadata: {} at 8.28s
2026-01-15 10:31:12.929 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1291, name: 'OutputAudioRawFrame#541', metadata: {} at 8.28s
2026-01-15 10:31:12.929 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1291, name: 'OutputAudioRawFrame#541', metadata: {} at 8.28s
2026-01-15 10:31:12.929 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#541(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.929 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1291, name: 'OutputAudioRawFrame#541', metadata: {} at 8.28s
2026-01-15 10:31:12.929 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1291, name: 'OutputAudioRawFrame#541', metadata: {} at 8.28s
2026-01-15 10:31:12.929 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1291, name: 'OutputAudioRawFrame#541', metadata: {} at 8.28s
2026-01-15 10:31:12.967 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 361, name: 'OutputAudioRawFrame#283', metadata: {} at 7.41s
2026-01-15 10:31:12.967 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 361, name: 'OutputAudioRawFrame#283', metadata: {} at 7.41s
2026-01-15 10:31:12.968 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1293, name: 'OutputAudioRawFrame#542', metadata: {} at 8.32s
2026-01-15 10:31:12.968 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1293, name: 'OutputAudioRawFrame#542', metadata: {} at 8.32s
2026-01-15 10:31:12.968 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#542(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.968 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1293, name: 'OutputAudioRawFrame#542', metadata: {} at 8.32s
2026-01-15 10:31:12.968 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1293, name: 'OutputAudioRawFrame#542', metadata: {} at 8.32s
2026-01-15 10:31:12.969 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1293, name: 'OutputAudioRawFrame#542', metadata: {} at 8.32s
2026-01-15 10:31:12.969 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#542(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:12.969 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1293, name: 'OutputAudioRawFrame#542', metadata: {} at 8.32s
2026-01-15 10:31:12.969 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1293, name: 'OutputAudioRawFrame#542', metadata: {} at 8.32s
2026-01-15 10:31:12.969 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1293, name: 'OutputAudioRawFrame#542', metadata: {} at 8.32s
2026-01-15 10:31:13.007 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 362, name: 'OutputAudioRawFrame#284', metadata: {} at 7.45s
2026-01-15 10:31:13.007 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 362, name: 'OutputAudioRawFrame#284', metadata: {} at 7.45s
2026-01-15 10:31:13.008 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1295, name: 'OutputAudioRawFrame#543', metadata: {} at 8.36s
2026-01-15 10:31:13.008 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1295, name: 'OutputAudioRawFrame#543', metadata: {} at 8.36s
2026-01-15 10:31:13.008 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#543(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.008 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1295, name: 'OutputAudioRawFrame#543', metadata: {} at 8.36s
2026-01-15 10:31:13.009 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1295, name: 'OutputAudioRawFrame#543', metadata: {} at 8.36s
2026-01-15 10:31:13.009 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1295, name: 'OutputAudioRawFrame#543', metadata: {} at 8.36s
2026-01-15 10:31:13.009 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#543(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.009 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1295, name: 'OutputAudioRawFrame#543', metadata: {} at 8.36s
2026-01-15 10:31:13.009 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1295, name: 'OutputAudioRawFrame#543', metadata: {} at 8.36s
2026-01-15 10:31:13.009 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1295, name: 'OutputAudioRawFrame#543', metadata: {} at 8.36s
2026-01-15 10:31:13.047 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 364, name: 'OutputAudioRawFrame#286', metadata: {} at 7.49s
2026-01-15 10:31:13.047 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 364, name: 'OutputAudioRawFrame#286', metadata: {} at 7.49s
2026-01-15 10:31:13.048 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1297, name: 'OutputAudioRawFrame#544', metadata: {} at 8.40s
2026-01-15 10:31:13.048 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1297, name: 'OutputAudioRawFrame#544', metadata: {} at 8.40s
2026-01-15 10:31:13.049 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#544(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.049 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1297, name: 'OutputAudioRawFrame#544', metadata: {} at 8.40s
2026-01-15 10:31:13.049 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1297, name: 'OutputAudioRawFrame#544', metadata: {} at 8.40s
2026-01-15 10:31:13.049 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1297, name: 'OutputAudioRawFrame#544', metadata: {} at 8.40s
2026-01-15 10:31:13.049 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#544(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.049 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1297, name: 'OutputAudioRawFrame#544', metadata: {} at 8.40s
2026-01-15 10:31:13.049 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1297, name: 'OutputAudioRawFrame#544', metadata: {} at 8.40s
2026-01-15 10:31:13.049 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1297, name: 'OutputAudioRawFrame#544', metadata: {} at 8.40s
2026-01-15 10:31:13.086 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 365, name: 'OutputAudioRawFrame#287', metadata: {} at 7.53s
2026-01-15 10:31:13.086 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 365, name: 'OutputAudioRawFrame#287', metadata: {} at 7.53s
2026-01-15 10:31:13.088 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1299, name: 'OutputAudioRawFrame#545', metadata: {} at 8.44s
2026-01-15 10:31:13.088 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1299, name: 'OutputAudioRawFrame#545', metadata: {} at 8.44s
2026-01-15 10:31:13.088 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#545(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.088 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1299, name: 'OutputAudioRawFrame#545', metadata: {} at 8.44s
2026-01-15 10:31:13.089 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1299, name: 'OutputAudioRawFrame#545', metadata: {} at 8.44s
2026-01-15 10:31:13.089 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1299, name: 'OutputAudioRawFrame#545', metadata: {} at 8.44s
2026-01-15 10:31:13.089 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#545(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.089 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1299, name: 'OutputAudioRawFrame#545', metadata: {} at 8.44s
2026-01-15 10:31:13.089 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1299, name: 'OutputAudioRawFrame#545', metadata: {} at 8.44s
2026-01-15 10:31:13.089 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1299, name: 'OutputAudioRawFrame#545', metadata: {} at 8.44s
2026-01-15 10:31:13.127 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 369, name: 'OutputAudioRawFrame#290', metadata: {} at 7.57s
2026-01-15 10:31:13.127 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 369, name: 'OutputAudioRawFrame#290', metadata: {} at 7.57s
2026-01-15 10:31:13.131 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1301, name: 'OutputAudioRawFrame#546', metadata: {} at 8.49s
2026-01-15 10:31:13.131 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1301, name: 'OutputAudioRawFrame#546', metadata: {} at 8.49s
2026-01-15 10:31:13.131 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#546(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.131 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1301, name: 'OutputAudioRawFrame#546', metadata: {} at 8.49s
2026-01-15 10:31:13.132 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1301, name: 'OutputAudioRawFrame#546', metadata: {} at 8.49s
2026-01-15 10:31:13.132 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1301, name: 'OutputAudioRawFrame#546', metadata: {} at 8.49s
2026-01-15 10:31:13.132 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#546(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.133 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1301, name: 'OutputAudioRawFrame#546', metadata: {} at 8.49s
2026-01-15 10:31:13.133 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1301, name: 'OutputAudioRawFrame#546', metadata: {} at 8.49s
2026-01-15 10:31:13.133 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1301, name: 'OutputAudioRawFrame#546', metadata: {} at 8.49s
2026-01-15 10:31:13.167 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 373, name: 'OutputAudioRawFrame#293', metadata: {} at 7.61s
2026-01-15 10:31:13.167 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 373, name: 'OutputAudioRawFrame#293', metadata: {} at 7.61s
2026-01-15 10:31:13.171 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1303, name: 'OutputAudioRawFrame#547', metadata: {} at 8.53s
2026-01-15 10:31:13.171 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1303, name: 'OutputAudioRawFrame#547', metadata: {} at 8.53s
2026-01-15 10:31:13.171 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#547(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.171 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1303, name: 'OutputAudioRawFrame#547', metadata: {} at 8.53s
2026-01-15 10:31:13.172 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1303, name: 'OutputAudioRawFrame#547', metadata: {} at 8.53s
2026-01-15 10:31:13.172 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1303, name: 'OutputAudioRawFrame#547', metadata: {} at 8.53s
2026-01-15 10:31:13.172 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#547(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.172 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1303, name: 'OutputAudioRawFrame#547', metadata: {} at 8.53s
2026-01-15 10:31:13.172 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1303, name: 'OutputAudioRawFrame#547', metadata: {} at 8.53s
2026-01-15 10:31:13.172 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1303, name: 'OutputAudioRawFrame#547', metadata: {} at 8.53s
2026-01-15 10:31:13.207 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 374, name: 'OutputAudioRawFrame#294', metadata: {} at 7.65s
2026-01-15 10:31:13.208 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 374, name: 'OutputAudioRawFrame#294', metadata: {} at 7.65s
2026-01-15 10:31:13.211 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1305, name: 'OutputAudioRawFrame#548', metadata: {} at 8.57s
2026-01-15 10:31:13.212 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1305, name: 'OutputAudioRawFrame#548', metadata: {} at 8.57s
2026-01-15 10:31:13.212 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#548(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.212 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1305, name: 'OutputAudioRawFrame#548', metadata: {} at 8.57s
2026-01-15 10:31:13.213 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1305, name: 'OutputAudioRawFrame#548', metadata: {} at 8.57s
2026-01-15 10:31:13.213 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1305, name: 'OutputAudioRawFrame#548', metadata: {} at 8.57s
2026-01-15 10:31:13.213 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#548(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.213 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1305, name: 'OutputAudioRawFrame#548', metadata: {} at 8.57s
2026-01-15 10:31:13.213 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1305, name: 'OutputAudioRawFrame#548', metadata: {} at 8.57s
2026-01-15 10:31:13.213 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1305, name: 'OutputAudioRawFrame#548', metadata: {} at 8.57s
2026-01-15 10:31:13.248 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 378, name: 'OutputAudioRawFrame#297', metadata: {} at 7.69s
2026-01-15 10:31:13.248 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 378, name: 'OutputAudioRawFrame#297', metadata: {} at 7.69s
2026-01-15 10:31:13.250 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1307, name: 'OutputAudioRawFrame#549', metadata: {} at 8.60s
2026-01-15 10:31:13.251 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1307, name: 'OutputAudioRawFrame#549', metadata: {} at 8.60s
2026-01-15 10:31:13.251 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#549(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.251 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1307, name: 'OutputAudioRawFrame#549', metadata: {} at 8.61s
2026-01-15 10:31:13.251 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1307, name: 'OutputAudioRawFrame#549', metadata: {} at 8.61s
2026-01-15 10:31:13.251 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1307, name: 'OutputAudioRawFrame#549', metadata: {} at 8.61s
2026-01-15 10:31:13.252 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#549(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.252 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1307, name: 'OutputAudioRawFrame#549', metadata: {} at 8.61s
2026-01-15 10:31:13.252 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1307, name: 'OutputAudioRawFrame#549', metadata: {} at 8.61s
2026-01-15 10:31:13.252 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1307, name: 'OutputAudioRawFrame#549', metadata: {} at 8.61s
2026-01-15 10:31:13.286 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 379, name: 'OutputAudioRawFrame#298', metadata: {} at 7.73s
2026-01-15 10:31:13.287 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 379, name: 'OutputAudioRawFrame#298', metadata: {} at 7.73s
2026-01-15 10:31:13.290 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1309, name: 'OutputAudioRawFrame#550', metadata: {} at 8.64s
2026-01-15 10:31:13.290 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1309, name: 'OutputAudioRawFrame#550', metadata: {} at 8.64s
2026-01-15 10:31:13.290 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#550(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.290 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1309, name: 'OutputAudioRawFrame#550', metadata: {} at 8.64s
2026-01-15 10:31:13.291 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1309, name: 'OutputAudioRawFrame#550', metadata: {} at 8.65s
2026-01-15 10:31:13.291 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1309, name: 'OutputAudioRawFrame#550', metadata: {} at 8.65s
2026-01-15 10:31:13.291 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#550(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.291 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1309, name: 'OutputAudioRawFrame#550', metadata: {} at 8.65s
2026-01-15 10:31:13.291 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1309, name: 'OutputAudioRawFrame#550', metadata: {} at 8.65s
2026-01-15 10:31:13.291 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1309, name: 'OutputAudioRawFrame#550', metadata: {} at 8.65s
2026-01-15 10:31:13.327 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 383, name: 'OutputAudioRawFrame#301', metadata: {} at 7.77s
2026-01-15 10:31:13.327 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 383, name: 'OutputAudioRawFrame#301', metadata: {} at 7.77s
2026-01-15 10:31:13.329 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1311, name: 'OutputAudioRawFrame#551', metadata: {} at 8.68s
2026-01-15 10:31:13.330 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1311, name: 'OutputAudioRawFrame#551', metadata: {} at 8.68s
2026-01-15 10:31:13.330 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#551(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.330 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1311, name: 'OutputAudioRawFrame#551', metadata: {} at 8.68s
2026-01-15 10:31:13.331 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1311, name: 'OutputAudioRawFrame#551', metadata: {} at 8.68s
2026-01-15 10:31:13.331 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1311, name: 'OutputAudioRawFrame#551', metadata: {} at 8.69s
2026-01-15 10:31:13.331 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#551(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.331 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1311, name: 'OutputAudioRawFrame#551', metadata: {} at 8.69s
2026-01-15 10:31:13.331 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1311, name: 'OutputAudioRawFrame#551', metadata: {} at 8.69s
2026-01-15 10:31:13.331 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1311, name: 'OutputAudioRawFrame#551', metadata: {} at 8.69s
2026-01-15 10:31:13.367 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 384, name: 'OutputAudioRawFrame#302', metadata: {} at 7.81s
2026-01-15 10:31:13.367 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 384, name: 'OutputAudioRawFrame#302', metadata: {} at 7.81s
2026-01-15 10:31:13.369 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1313, name: 'OutputAudioRawFrame#552', metadata: {} at 8.72s
2026-01-15 10:31:13.369 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1313, name: 'OutputAudioRawFrame#552', metadata: {} at 8.72s
2026-01-15 10:31:13.369 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#552(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.369 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1313, name: 'OutputAudioRawFrame#552', metadata: {} at 8.72s
2026-01-15 10:31:13.370 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1313, name: 'OutputAudioRawFrame#552', metadata: {} at 8.72s
2026-01-15 10:31:13.370 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1313, name: 'OutputAudioRawFrame#552', metadata: {} at 8.72s
2026-01-15 10:31:13.370 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#552(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.370 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1313, name: 'OutputAudioRawFrame#552', metadata: {} at 8.72s
2026-01-15 10:31:13.370 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1313, name: 'OutputAudioRawFrame#552', metadata: {} at 8.72s
2026-01-15 10:31:13.370 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1313, name: 'OutputAudioRawFrame#552', metadata: {} at 8.72s
2026-01-15 10:31:13.407 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 385, name: 'OutputAudioRawFrame#303', metadata: {} at 7.85s
2026-01-15 10:31:13.407 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 385, name: 'OutputAudioRawFrame#303', metadata: {} at 7.85s
2026-01-15 10:31:13.408 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1315, name: 'OutputAudioRawFrame#553', metadata: {} at 8.76s
2026-01-15 10:31:13.408 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1315, name: 'OutputAudioRawFrame#553', metadata: {} at 8.76s
2026-01-15 10:31:13.408 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#553(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.408 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1315, name: 'OutputAudioRawFrame#553', metadata: {} at 8.76s
2026-01-15 10:31:13.408 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1315, name: 'OutputAudioRawFrame#553', metadata: {} at 8.76s
2026-01-15 10:31:13.408 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1315, name: 'OutputAudioRawFrame#553', metadata: {} at 8.76s
2026-01-15 10:31:13.408 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#553(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.409 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1315, name: 'OutputAudioRawFrame#553', metadata: {} at 8.76s
2026-01-15 10:31:13.409 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1315, name: 'OutputAudioRawFrame#553', metadata: {} at 8.76s
2026-01-15 10:31:13.409 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1315, name: 'OutputAudioRawFrame#553', metadata: {} at 8.76s
2026-01-15 10:31:13.446 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 389, name: 'OutputAudioRawFrame#306', metadata: {} at 7.89s
2026-01-15 10:31:13.446 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 389, name: 'OutputAudioRawFrame#306', metadata: {} at 7.89s
2026-01-15 10:31:13.447 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1317, name: 'OutputAudioRawFrame#554', metadata: {} at 8.80s
2026-01-15 10:31:13.447 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1317, name: 'OutputAudioRawFrame#554', metadata: {} at 8.80s
2026-01-15 10:31:13.447 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#554(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.447 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1317, name: 'OutputAudioRawFrame#554', metadata: {} at 8.80s
2026-01-15 10:31:13.448 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1317, name: 'OutputAudioRawFrame#554', metadata: {} at 8.80s
2026-01-15 10:31:13.448 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1317, name: 'OutputAudioRawFrame#554', metadata: {} at 8.80s
2026-01-15 10:31:13.448 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#554(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.448 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1317, name: 'OutputAudioRawFrame#554', metadata: {} at 8.80s
2026-01-15 10:31:13.448 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1317, name: 'OutputAudioRawFrame#554', metadata: {} at 8.80s
2026-01-15 10:31:13.448 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1317, name: 'OutputAudioRawFrame#554', metadata: {} at 8.80s
2026-01-15 10:31:13.487 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 390, name: 'OutputAudioRawFrame#307', metadata: {} at 7.93s
2026-01-15 10:31:13.487 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 390, name: 'OutputAudioRawFrame#307', metadata: {} at 7.93s
2026-01-15 10:31:13.489 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1319, name: 'OutputAudioRawFrame#555', metadata: {} at 8.84s
2026-01-15 10:31:13.489 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1319, name: 'OutputAudioRawFrame#555', metadata: {} at 8.84s
2026-01-15 10:31:13.489 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#555(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.489 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1319, name: 'OutputAudioRawFrame#555', metadata: {} at 8.84s
2026-01-15 10:31:13.489 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1319, name: 'OutputAudioRawFrame#555', metadata: {} at 8.84s
2026-01-15 10:31:13.489 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1319, name: 'OutputAudioRawFrame#555', metadata: {} at 8.84s
2026-01-15 10:31:13.490 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#555(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.490 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1319, name: 'OutputAudioRawFrame#555', metadata: {} at 8.84s
2026-01-15 10:31:13.490 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1319, name: 'OutputAudioRawFrame#555', metadata: {} at 8.84s
2026-01-15 10:31:13.490 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1319, name: 'OutputAudioRawFrame#555', metadata: {} at 8.84s
2026-01-15 10:31:13.527 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 394, name: 'OutputAudioRawFrame#310', metadata: {} at 7.97s
2026-01-15 10:31:13.527 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 394, name: 'OutputAudioRawFrame#310', metadata: {} at 7.97s
2026-01-15 10:31:13.528 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1321, name: 'OutputAudioRawFrame#556', metadata: {} at 8.88s
2026-01-15 10:31:13.528 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1321, name: 'OutputAudioRawFrame#556', metadata: {} at 8.88s
2026-01-15 10:31:13.528 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#556(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.528 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1321, name: 'OutputAudioRawFrame#556', metadata: {} at 8.88s
2026-01-15 10:31:13.528 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1321, name: 'OutputAudioRawFrame#556', metadata: {} at 8.88s
2026-01-15 10:31:13.528 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1321, name: 'OutputAudioRawFrame#556', metadata: {} at 8.88s
2026-01-15 10:31:13.528 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#556(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.528 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1321, name: 'OutputAudioRawFrame#556', metadata: {} at 8.88s
2026-01-15 10:31:13.528 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1321, name: 'OutputAudioRawFrame#556', metadata: {} at 8.88s
2026-01-15 10:31:13.528 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1321, name: 'OutputAudioRawFrame#556', metadata: {} at 8.88s
2026-01-15 10:31:13.566 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 395, name: 'OutputAudioRawFrame#311', metadata: {} at 8.01s
2026-01-15 10:31:13.567 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 395, name: 'OutputAudioRawFrame#311', metadata: {} at 8.01s
2026-01-15 10:31:13.568 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1323, name: 'OutputAudioRawFrame#557', metadata: {} at 8.92s
2026-01-15 10:31:13.568 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1323, name: 'OutputAudioRawFrame#557', metadata: {} at 8.92s
2026-01-15 10:31:13.568 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#557(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.568 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1323, name: 'OutputAudioRawFrame#557', metadata: {} at 8.92s
2026-01-15 10:31:13.568 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1323, name: 'OutputAudioRawFrame#557', metadata: {} at 8.92s
2026-01-15 10:31:13.568 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1323, name: 'OutputAudioRawFrame#557', metadata: {} at 8.92s
2026-01-15 10:31:13.568 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#557(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.568 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1323, name: 'OutputAudioRawFrame#557', metadata: {} at 8.92s
2026-01-15 10:31:13.568 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1323, name: 'OutputAudioRawFrame#557', metadata: {} at 8.92s
2026-01-15 10:31:13.568 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1323, name: 'OutputAudioRawFrame#557', metadata: {} at 8.92s
2026-01-15 10:31:13.607 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 399, name: 'OutputAudioRawFrame#314', metadata: {} at 8.05s
2026-01-15 10:31:13.607 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 399, name: 'OutputAudioRawFrame#314', metadata: {} at 8.05s
2026-01-15 10:31:13.608 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1325, name: 'OutputAudioRawFrame#558', metadata: {} at 8.96s
2026-01-15 10:31:13.608 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1325, name: 'OutputAudioRawFrame#558', metadata: {} at 8.96s
2026-01-15 10:31:13.608 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#558(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.608 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1325, name: 'OutputAudioRawFrame#558', metadata: {} at 8.96s
2026-01-15 10:31:13.608 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1325, name: 'OutputAudioRawFrame#558', metadata: {} at 8.96s
2026-01-15 10:31:13.608 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1325, name: 'OutputAudioRawFrame#558', metadata: {} at 8.96s
2026-01-15 10:31:13.608 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#558(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.608 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1325, name: 'OutputAudioRawFrame#558', metadata: {} at 8.96s
2026-01-15 10:31:13.608 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1325, name: 'OutputAudioRawFrame#558', metadata: {} at 8.96s
2026-01-15 10:31:13.608 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1325, name: 'OutputAudioRawFrame#558', metadata: {} at 8.96s
2026-01-15 10:31:13.647 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 403, name: 'OutputAudioRawFrame#317', metadata: {} at 8.09s
2026-01-15 10:31:13.647 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 403, name: 'OutputAudioRawFrame#317', metadata: {} at 8.09s
2026-01-15 10:31:13.648 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1327, name: 'OutputAudioRawFrame#559', metadata: {} at 9.00s
2026-01-15 10:31:13.648 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1327, name: 'OutputAudioRawFrame#559', metadata: {} at 9.00s
2026-01-15 10:31:13.648 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#559(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.648 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1327, name: 'OutputAudioRawFrame#559', metadata: {} at 9.00s
2026-01-15 10:31:13.648 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1327, name: 'OutputAudioRawFrame#559', metadata: {} at 9.00s
2026-01-15 10:31:13.648 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1327, name: 'OutputAudioRawFrame#559', metadata: {} at 9.00s
2026-01-15 10:31:13.648 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#559(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.648 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1327, name: 'OutputAudioRawFrame#559', metadata: {} at 9.00s
2026-01-15 10:31:13.648 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1327, name: 'OutputAudioRawFrame#559', metadata: {} at 9.00s
2026-01-15 10:31:13.648 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1327, name: 'OutputAudioRawFrame#559', metadata: {} at 9.00s
2026-01-15 10:31:13.686 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 404, name: 'OutputAudioRawFrame#318', metadata: {} at 8.13s
2026-01-15 10:31:13.687 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 404, name: 'OutputAudioRawFrame#318', metadata: {} at 8.13s
2026-01-15 10:31:13.687 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1329, name: 'OutputAudioRawFrame#560', metadata: {} at 9.04s
2026-01-15 10:31:13.688 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1329, name: 'OutputAudioRawFrame#560', metadata: {} at 9.04s
2026-01-15 10:31:13.688 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#560(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.688 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1329, name: 'OutputAudioRawFrame#560', metadata: {} at 9.04s
2026-01-15 10:31:13.688 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1329, name: 'OutputAudioRawFrame#560', metadata: {} at 9.04s
2026-01-15 10:31:13.688 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1329, name: 'OutputAudioRawFrame#560', metadata: {} at 9.04s
2026-01-15 10:31:13.688 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#560(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.688 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1329, name: 'OutputAudioRawFrame#560', metadata: {} at 9.04s
2026-01-15 10:31:13.689 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1329, name: 'OutputAudioRawFrame#560', metadata: {} at 9.04s
2026-01-15 10:31:13.689 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1329, name: 'OutputAudioRawFrame#560', metadata: {} at 9.04s
2026-01-15 10:31:13.727 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 409, name: 'OutputAudioRawFrame#322', metadata: {} at 8.17s
2026-01-15 10:31:13.727 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 409, name: 'OutputAudioRawFrame#322', metadata: {} at 8.17s
2026-01-15 10:31:13.728 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1331, name: 'OutputAudioRawFrame#561', metadata: {} at 9.08s
2026-01-15 10:31:13.728 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1331, name: 'OutputAudioRawFrame#561', metadata: {} at 9.08s
2026-01-15 10:31:13.728 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#561(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.728 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1331, name: 'OutputAudioRawFrame#561', metadata: {} at 9.08s
2026-01-15 10:31:13.728 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1331, name: 'OutputAudioRawFrame#561', metadata: {} at 9.08s
2026-01-15 10:31:13.728 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1331, name: 'OutputAudioRawFrame#561', metadata: {} at 9.08s
2026-01-15 10:31:13.728 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#561(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.728 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1331, name: 'OutputAudioRawFrame#561', metadata: {} at 9.08s
2026-01-15 10:31:13.728 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1331, name: 'OutputAudioRawFrame#561', metadata: {} at 9.08s
2026-01-15 10:31:13.728 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1331, name: 'OutputAudioRawFrame#561', metadata: {} at 9.08s
2026-01-15 10:31:13.767 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 410, name: 'OutputAudioRawFrame#323', metadata: {} at 8.21s
2026-01-15 10:31:13.767 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 410, name: 'OutputAudioRawFrame#323', metadata: {} at 8.21s
2026-01-15 10:31:13.768 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1333, name: 'OutputAudioRawFrame#562', metadata: {} at 9.12s
2026-01-15 10:31:13.768 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1333, name: 'OutputAudioRawFrame#562', metadata: {} at 9.12s
2026-01-15 10:31:13.768 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#562(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.768 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1333, name: 'OutputAudioRawFrame#562', metadata: {} at 9.12s
2026-01-15 10:31:13.768 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1333, name: 'OutputAudioRawFrame#562', metadata: {} at 9.12s
2026-01-15 10:31:13.768 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1333, name: 'OutputAudioRawFrame#562', metadata: {} at 9.12s
2026-01-15 10:31:13.768 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#562(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.768 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1333, name: 'OutputAudioRawFrame#562', metadata: {} at 9.12s
2026-01-15 10:31:13.768 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1333, name: 'OutputAudioRawFrame#562', metadata: {} at 9.12s
2026-01-15 10:31:13.768 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1333, name: 'OutputAudioRawFrame#562', metadata: {} at 9.12s
2026-01-15 10:31:13.807 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 415, name: 'OutputAudioRawFrame#326', metadata: {} at 8.25s
2026-01-15 10:31:13.807 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 415, name: 'OutputAudioRawFrame#326', metadata: {} at 8.25s
2026-01-15 10:31:13.808 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1335, name: 'OutputAudioRawFrame#563', metadata: {} at 9.16s
2026-01-15 10:31:13.808 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1335, name: 'OutputAudioRawFrame#563', metadata: {} at 9.16s
2026-01-15 10:31:13.808 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#563(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.808 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1335, name: 'OutputAudioRawFrame#563', metadata: {} at 9.16s
2026-01-15 10:31:13.808 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1335, name: 'OutputAudioRawFrame#563', metadata: {} at 9.16s
2026-01-15 10:31:13.808 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1335, name: 'OutputAudioRawFrame#563', metadata: {} at 9.16s
2026-01-15 10:31:13.808 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#563(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.808 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1335, name: 'OutputAudioRawFrame#563', metadata: {} at 9.16s
2026-01-15 10:31:13.809 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1335, name: 'OutputAudioRawFrame#563', metadata: {} at 9.16s
2026-01-15 10:31:13.809 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1335, name: 'OutputAudioRawFrame#563', metadata: {} at 9.16s
2026-01-15 10:31:13.846 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 416, name: 'OutputAudioRawFrame#327', metadata: {} at 8.29s
2026-01-15 10:31:13.847 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 416, name: 'OutputAudioRawFrame#327', metadata: {} at 8.29s
2026-01-15 10:31:13.847 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1337, name: 'OutputAudioRawFrame#564', metadata: {} at 9.20s
2026-01-15 10:31:13.848 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1337, name: 'OutputAudioRawFrame#564', metadata: {} at 9.20s
2026-01-15 10:31:13.848 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#564(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.848 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1337, name: 'OutputAudioRawFrame#564', metadata: {} at 9.20s
2026-01-15 10:31:13.848 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1337, name: 'OutputAudioRawFrame#564', metadata: {} at 9.20s
2026-01-15 10:31:13.848 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1337, name: 'OutputAudioRawFrame#564', metadata: {} at 9.20s
2026-01-15 10:31:13.848 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#564(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.848 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1337, name: 'OutputAudioRawFrame#564', metadata: {} at 9.20s
2026-01-15 10:31:13.848 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1337, name: 'OutputAudioRawFrame#564', metadata: {} at 9.20s
2026-01-15 10:31:13.848 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1337, name: 'OutputAudioRawFrame#564', metadata: {} at 9.20s
2026-01-15 10:31:13.886 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 417, name: 'OutputAudioRawFrame#328', metadata: {} at 8.33s
2026-01-15 10:31:13.886 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 417, name: 'OutputAudioRawFrame#328', metadata: {} at 8.33s
2026-01-15 10:31:13.887 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1339, name: 'OutputAudioRawFrame#565', metadata: {} at 9.24s
2026-01-15 10:31:13.887 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1339, name: 'OutputAudioRawFrame#565', metadata: {} at 9.24s
2026-01-15 10:31:13.887 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#565(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.887 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1339, name: 'OutputAudioRawFrame#565', metadata: {} at 9.24s
2026-01-15 10:31:13.887 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1339, name: 'OutputAudioRawFrame#565', metadata: {} at 9.24s
2026-01-15 10:31:13.887 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1339, name: 'OutputAudioRawFrame#565', metadata: {} at 9.24s
2026-01-15 10:31:13.887 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#565(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.887 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1339, name: 'OutputAudioRawFrame#565', metadata: {} at 9.24s
2026-01-15 10:31:13.887 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1339, name: 'OutputAudioRawFrame#565', metadata: {} at 9.24s
2026-01-15 10:31:13.887 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1339, name: 'OutputAudioRawFrame#565', metadata: {} at 9.24s
2026-01-15 10:31:13.927 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 421, name: 'OutputAudioRawFrame#331', metadata: {} at 8.37s
2026-01-15 10:31:13.927 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 421, name: 'OutputAudioRawFrame#331', metadata: {} at 8.37s
2026-01-15 10:31:13.928 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1341, name: 'OutputAudioRawFrame#566', metadata: {} at 9.28s
2026-01-15 10:31:13.928 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1341, name: 'OutputAudioRawFrame#566', metadata: {} at 9.28s
2026-01-15 10:31:13.928 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#566(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.928 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1341, name: 'OutputAudioRawFrame#566', metadata: {} at 9.28s
2026-01-15 10:31:13.928 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1341, name: 'OutputAudioRawFrame#566', metadata: {} at 9.28s
2026-01-15 10:31:13.928 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1341, name: 'OutputAudioRawFrame#566', metadata: {} at 9.28s
2026-01-15 10:31:13.928 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#566(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.928 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1341, name: 'OutputAudioRawFrame#566', metadata: {} at 9.28s
2026-01-15 10:31:13.928 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1341, name: 'OutputAudioRawFrame#566', metadata: {} at 9.28s
2026-01-15 10:31:13.928 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1341, name: 'OutputAudioRawFrame#566', metadata: {} at 9.28s
2026-01-15 10:31:13.966 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 422, name: 'OutputAudioRawFrame#332', metadata: {} at 8.41s
2026-01-15 10:31:13.966 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 422, name: 'OutputAudioRawFrame#332', metadata: {} at 8.41s
2026-01-15 10:31:13.967 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1343, name: 'OutputAudioRawFrame#567', metadata: {} at 9.32s
2026-01-15 10:31:13.968 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1343, name: 'OutputAudioRawFrame#567', metadata: {} at 9.32s
2026-01-15 10:31:13.968 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#567(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.968 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1343, name: 'OutputAudioRawFrame#567', metadata: {} at 9.32s
2026-01-15 10:31:13.968 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1343, name: 'OutputAudioRawFrame#567', metadata: {} at 9.32s
2026-01-15 10:31:13.968 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1343, name: 'OutputAudioRawFrame#567', metadata: {} at 9.32s
2026-01-15 10:31:13.968 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#567(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:13.968 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1343, name: 'OutputAudioRawFrame#567', metadata: {} at 9.32s
2026-01-15 10:31:13.968 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1343, name: 'OutputAudioRawFrame#567', metadata: {} at 9.32s
2026-01-15 10:31:13.968 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1343, name: 'OutputAudioRawFrame#567', metadata: {} at 9.32s
2026-01-15 10:31:14.007 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 426, name: 'OutputAudioRawFrame#335', metadata: {} at 8.45s
2026-01-15 10:31:14.007 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 426, name: 'OutputAudioRawFrame#335', metadata: {} at 8.45s
2026-01-15 10:31:14.008 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1345, name: 'OutputAudioRawFrame#568', metadata: {} at 9.36s
2026-01-15 10:31:14.008 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1345, name: 'OutputAudioRawFrame#568', metadata: {} at 9.36s
2026-01-15 10:31:14.008 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#568(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.008 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1345, name: 'OutputAudioRawFrame#568', metadata: {} at 9.36s
2026-01-15 10:31:14.009 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1345, name: 'OutputAudioRawFrame#568', metadata: {} at 9.36s
2026-01-15 10:31:14.009 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1345, name: 'OutputAudioRawFrame#568', metadata: {} at 9.36s
2026-01-15 10:31:14.009 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#568(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.009 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1345, name: 'OutputAudioRawFrame#568', metadata: {} at 9.36s
2026-01-15 10:31:14.009 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1345, name: 'OutputAudioRawFrame#568', metadata: {} at 9.36s
2026-01-15 10:31:14.009 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1345, name: 'OutputAudioRawFrame#568', metadata: {} at 9.36s
2026-01-15 10:31:14.047 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 427, name: 'OutputAudioRawFrame#336', metadata: {} at 8.49s
2026-01-15 10:31:14.047 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 427, name: 'OutputAudioRawFrame#336', metadata: {} at 8.49s
2026-01-15 10:31:14.049 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1347, name: 'OutputAudioRawFrame#569', metadata: {} at 9.40s
2026-01-15 10:31:14.049 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1347, name: 'OutputAudioRawFrame#569', metadata: {} at 9.40s
2026-01-15 10:31:14.049 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#569(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.049 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1347, name: 'OutputAudioRawFrame#569', metadata: {} at 9.40s
2026-01-15 10:31:14.050 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1347, name: 'OutputAudioRawFrame#569', metadata: {} at 9.40s
2026-01-15 10:31:14.050 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1347, name: 'OutputAudioRawFrame#569', metadata: {} at 9.40s
2026-01-15 10:31:14.050 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#569(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.050 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1347, name: 'OutputAudioRawFrame#569', metadata: {} at 9.40s
2026-01-15 10:31:14.050 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1347, name: 'OutputAudioRawFrame#569', metadata: {} at 9.40s
2026-01-15 10:31:14.051 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1347, name: 'OutputAudioRawFrame#569', metadata: {} at 9.40s
2026-01-15 10:31:14.087 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 431, name: 'OutputAudioRawFrame#339', metadata: {} at 8.53s
2026-01-15 10:31:14.087 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 431, name: 'OutputAudioRawFrame#339', metadata: {} at 8.53s
2026-01-15 10:31:14.090 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1349, name: 'OutputAudioRawFrame#570', metadata: {} at 9.44s
2026-01-15 10:31:14.090 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1349, name: 'OutputAudioRawFrame#570', metadata: {} at 9.44s
2026-01-15 10:31:14.090 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#570(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.091 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1349, name: 'OutputAudioRawFrame#570', metadata: {} at 9.44s
2026-01-15 10:31:14.092 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1349, name: 'OutputAudioRawFrame#570', metadata: {} at 9.45s
2026-01-15 10:31:14.092 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1349, name: 'OutputAudioRawFrame#570', metadata: {} at 9.45s
2026-01-15 10:31:14.092 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#570(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.092 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1349, name: 'OutputAudioRawFrame#570', metadata: {} at 9.45s
2026-01-15 10:31:14.092 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1349, name: 'OutputAudioRawFrame#570', metadata: {} at 9.45s
2026-01-15 10:31:14.093 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1349, name: 'OutputAudioRawFrame#570', metadata: {} at 9.45s
2026-01-15 10:31:14.127 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 435, name: 'OutputAudioRawFrame#342', metadata: {} at 8.57s
2026-01-15 10:31:14.127 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 435, name: 'OutputAudioRawFrame#342', metadata: {} at 8.57s
2026-01-15 10:31:14.131 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1351, name: 'OutputAudioRawFrame#571', metadata: {} at 9.49s
2026-01-15 10:31:14.131 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1351, name: 'OutputAudioRawFrame#571', metadata: {} at 9.49s
2026-01-15 10:31:14.132 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#571(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.132 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1351, name: 'OutputAudioRawFrame#571', metadata: {} at 9.49s
2026-01-15 10:31:14.133 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1351, name: 'OutputAudioRawFrame#571', metadata: {} at 9.49s
2026-01-15 10:31:14.133 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1351, name: 'OutputAudioRawFrame#571', metadata: {} at 9.49s
2026-01-15 10:31:14.133 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#571(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.133 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1351, name: 'OutputAudioRawFrame#571', metadata: {} at 9.49s
2026-01-15 10:31:14.133 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1351, name: 'OutputAudioRawFrame#571', metadata: {} at 9.49s
2026-01-15 10:31:14.134 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1351, name: 'OutputAudioRawFrame#571', metadata: {} at 9.49s
2026-01-15 10:31:14.166 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 436, name: 'OutputAudioRawFrame#343', metadata: {} at 8.61s
2026-01-15 10:31:14.166 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 436, name: 'OutputAudioRawFrame#343', metadata: {} at 8.61s
2026-01-15 10:31:14.169 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1353, name: 'OutputAudioRawFrame#572', metadata: {} at 9.52s
2026-01-15 10:31:14.169 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1353, name: 'OutputAudioRawFrame#572', metadata: {} at 9.52s
2026-01-15 10:31:14.170 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#572(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.170 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1353, name: 'OutputAudioRawFrame#572', metadata: {} at 9.52s
2026-01-15 10:31:14.171 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1353, name: 'OutputAudioRawFrame#572', metadata: {} at 9.53s
2026-01-15 10:31:14.171 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1353, name: 'OutputAudioRawFrame#572', metadata: {} at 9.53s
2026-01-15 10:31:14.171 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#572(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.171 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1353, name: 'OutputAudioRawFrame#572', metadata: {} at 9.53s
2026-01-15 10:31:14.171 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1353, name: 'OutputAudioRawFrame#572', metadata: {} at 9.53s
2026-01-15 10:31:14.172 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1353, name: 'OutputAudioRawFrame#572', metadata: {} at 9.53s
2026-01-15 10:31:14.206 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 440, name: 'OutputAudioRawFrame#346', metadata: {} at 8.65s
2026-01-15 10:31:14.206 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 440, name: 'OutputAudioRawFrame#346', metadata: {} at 8.65s
2026-01-15 10:31:14.209 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1355, name: 'OutputAudioRawFrame#573', metadata: {} at 9.56s
2026-01-15 10:31:14.210 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1355, name: 'OutputAudioRawFrame#573', metadata: {} at 9.56s
2026-01-15 10:31:14.210 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#573(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.210 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1355, name: 'OutputAudioRawFrame#573', metadata: {} at 9.56s
2026-01-15 10:31:14.211 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1355, name: 'OutputAudioRawFrame#573', metadata: {} at 9.57s
2026-01-15 10:31:14.211 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1355, name: 'OutputAudioRawFrame#573', metadata: {} at 9.57s
2026-01-15 10:31:14.211 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#573(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.211 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1355, name: 'OutputAudioRawFrame#573', metadata: {} at 9.57s
2026-01-15 10:31:14.212 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1355, name: 'OutputAudioRawFrame#573', metadata: {} at 9.57s
2026-01-15 10:31:14.212 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1355, name: 'OutputAudioRawFrame#573', metadata: {} at 9.57s
2026-01-15 10:31:14.247 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 441, name: 'OutputAudioRawFrame#347', metadata: {} at 8.69s
2026-01-15 10:31:14.247 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 441, name: 'OutputAudioRawFrame#347', metadata: {} at 8.69s
2026-01-15 10:31:14.250 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1357, name: 'OutputAudioRawFrame#574', metadata: {} at 9.60s
2026-01-15 10:31:14.250 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1357, name: 'OutputAudioRawFrame#574', metadata: {} at 9.60s
2026-01-15 10:31:14.250 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#574(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.251 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1357, name: 'OutputAudioRawFrame#574', metadata: {} at 9.60s
2026-01-15 10:31:14.252 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1357, name: 'OutputAudioRawFrame#574', metadata: {} at 9.61s
2026-01-15 10:31:14.252 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1357, name: 'OutputAudioRawFrame#574', metadata: {} at 9.61s
2026-01-15 10:31:14.252 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#574(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.252 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1357, name: 'OutputAudioRawFrame#574', metadata: {} at 9.61s
2026-01-15 10:31:14.252 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1357, name: 'OutputAudioRawFrame#574', metadata: {} at 9.61s
2026-01-15 10:31:14.253 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1357, name: 'OutputAudioRawFrame#574', metadata: {} at 9.61s
2026-01-15 10:31:14.287 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 445, name: 'OutputAudioRawFrame#350', metadata: {} at 8.73s
2026-01-15 10:31:14.287 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 445, name: 'OutputAudioRawFrame#350', metadata: {} at 8.73s
2026-01-15 10:31:14.290 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1359, name: 'OutputAudioRawFrame#575', metadata: {} at 9.64s
2026-01-15 10:31:14.290 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1359, name: 'OutputAudioRawFrame#575', metadata: {} at 9.64s
2026-01-15 10:31:14.290 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#575(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.290 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1359, name: 'OutputAudioRawFrame#575', metadata: {} at 9.64s
2026-01-15 10:31:14.291 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1359, name: 'OutputAudioRawFrame#575', metadata: {} at 9.65s
2026-01-15 10:31:14.291 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1359, name: 'OutputAudioRawFrame#575', metadata: {} at 9.65s
2026-01-15 10:31:14.291 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#575(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.291 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1359, name: 'OutputAudioRawFrame#575', metadata: {} at 9.65s
2026-01-15 10:31:14.291 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1359, name: 'OutputAudioRawFrame#575', metadata: {} at 9.65s
2026-01-15 10:31:14.291 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1359, name: 'OutputAudioRawFrame#575', metadata: {} at 9.65s
2026-01-15 10:31:14.327 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 446, name: 'OutputAudioRawFrame#351', metadata: {} at 8.77s
2026-01-15 10:31:14.327 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 446, name: 'OutputAudioRawFrame#351', metadata: {} at 8.77s
2026-01-15 10:31:14.330 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1361, name: 'OutputAudioRawFrame#576', metadata: {} at 9.68s
2026-01-15 10:31:14.330 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1361, name: 'OutputAudioRawFrame#576', metadata: {} at 9.68s
2026-01-15 10:31:14.330 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#576(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.331 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1361, name: 'OutputAudioRawFrame#576', metadata: {} at 9.68s
2026-01-15 10:31:14.331 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1361, name: 'OutputAudioRawFrame#576', metadata: {} at 9.69s
2026-01-15 10:31:14.332 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1361, name: 'OutputAudioRawFrame#576', metadata: {} at 9.69s
2026-01-15 10:31:14.332 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#576(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.332 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1361, name: 'OutputAudioRawFrame#576', metadata: {} at 9.69s
2026-01-15 10:31:14.332 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1361, name: 'OutputAudioRawFrame#576', metadata: {} at 9.69s
2026-01-15 10:31:14.332 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1361, name: 'OutputAudioRawFrame#576', metadata: {} at 9.69s
2026-01-15 10:31:14.367 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 447, name: 'OutputAudioRawFrame#352', metadata: {} at 8.81s
2026-01-15 10:31:14.367 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 447, name: 'OutputAudioRawFrame#352', metadata: {} at 8.81s
2026-01-15 10:31:14.370 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1363, name: 'OutputAudioRawFrame#577', metadata: {} at 9.72s
2026-01-15 10:31:14.370 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1363, name: 'OutputAudioRawFrame#577', metadata: {} at 9.72s
2026-01-15 10:31:14.370 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#577(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.370 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1363, name: 'OutputAudioRawFrame#577', metadata: {} at 9.72s
2026-01-15 10:31:14.371 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1363, name: 'OutputAudioRawFrame#577', metadata: {} at 9.73s
2026-01-15 10:31:14.371 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1363, name: 'OutputAudioRawFrame#577', metadata: {} at 9.73s
2026-01-15 10:31:14.371 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#577(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.372 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1363, name: 'OutputAudioRawFrame#577', metadata: {} at 9.73s
2026-01-15 10:31:14.372 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1363, name: 'OutputAudioRawFrame#577', metadata: {} at 9.73s
2026-01-15 10:31:14.372 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1363, name: 'OutputAudioRawFrame#577', metadata: {} at 9.73s
2026-01-15 10:31:14.406 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 451, name: 'OutputAudioRawFrame#355', metadata: {} at 8.85s
2026-01-15 10:31:14.407 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 451, name: 'OutputAudioRawFrame#355', metadata: {} at 8.85s
2026-01-15 10:31:14.408 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1365, name: 'OutputAudioRawFrame#578', metadata: {} at 9.76s
2026-01-15 10:31:14.409 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1365, name: 'OutputAudioRawFrame#578', metadata: {} at 9.76s
2026-01-15 10:31:14.409 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#578(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.409 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1365, name: 'OutputAudioRawFrame#578', metadata: {} at 9.76s
2026-01-15 10:31:14.409 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1365, name: 'OutputAudioRawFrame#578', metadata: {} at 9.76s
2026-01-15 10:31:14.409 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1365, name: 'OutputAudioRawFrame#578', metadata: {} at 9.76s
2026-01-15 10:31:14.410 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#578(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.410 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1365, name: 'OutputAudioRawFrame#578', metadata: {} at 9.76s
2026-01-15 10:31:14.410 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1365, name: 'OutputAudioRawFrame#578', metadata: {} at 9.76s
2026-01-15 10:31:14.410 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1365, name: 'OutputAudioRawFrame#578', metadata: {} at 9.76s
2026-01-15 10:31:14.447 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 452, name: 'OutputAudioRawFrame#356', metadata: {} at 8.89s
2026-01-15 10:31:14.447 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 452, name: 'OutputAudioRawFrame#356', metadata: {} at 8.89s
2026-01-15 10:31:14.448 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1367, name: 'OutputAudioRawFrame#579', metadata: {} at 9.80s
2026-01-15 10:31:14.448 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1367, name: 'OutputAudioRawFrame#579', metadata: {} at 9.80s
2026-01-15 10:31:14.448 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#579(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.448 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1367, name: 'OutputAudioRawFrame#579', metadata: {} at 9.80s
2026-01-15 10:31:14.449 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1367, name: 'OutputAudioRawFrame#579', metadata: {} at 9.80s
2026-01-15 10:31:14.449 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1367, name: 'OutputAudioRawFrame#579', metadata: {} at 9.80s
2026-01-15 10:31:14.449 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#579(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.449 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1367, name: 'OutputAudioRawFrame#579', metadata: {} at 9.80s
2026-01-15 10:31:14.449 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1367, name: 'OutputAudioRawFrame#579', metadata: {} at 9.80s
2026-01-15 10:31:14.449 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1367, name: 'OutputAudioRawFrame#579', metadata: {} at 9.80s
2026-01-15 10:31:14.487 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 456, name: 'OutputAudioRawFrame#359', metadata: {} at 8.93s
2026-01-15 10:31:14.487 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 456, name: 'OutputAudioRawFrame#359', metadata: {} at 8.93s
2026-01-15 10:31:14.488 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1369, name: 'OutputAudioRawFrame#580', metadata: {} at 9.84s
2026-01-15 10:31:14.488 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1369, name: 'OutputAudioRawFrame#580', metadata: {} at 9.84s
2026-01-15 10:31:14.488 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#580(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.488 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1369, name: 'OutputAudioRawFrame#580', metadata: {} at 9.84s
2026-01-15 10:31:14.489 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1369, name: 'OutputAudioRawFrame#580', metadata: {} at 9.84s
2026-01-15 10:31:14.489 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1369, name: 'OutputAudioRawFrame#580', metadata: {} at 9.84s
2026-01-15 10:31:14.489 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#580(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.489 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1369, name: 'OutputAudioRawFrame#580', metadata: {} at 9.84s
2026-01-15 10:31:14.489 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1369, name: 'OutputAudioRawFrame#580', metadata: {} at 9.84s
2026-01-15 10:31:14.489 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1369, name: 'OutputAudioRawFrame#580', metadata: {} at 9.84s
2026-01-15 10:31:14.527 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 457, name: 'OutputAudioRawFrame#360', metadata: {} at 8.97s
2026-01-15 10:31:14.527 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 457, name: 'OutputAudioRawFrame#360', metadata: {} at 8.97s
2026-01-15 10:31:14.529 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1371, name: 'OutputAudioRawFrame#581', metadata: {} at 9.88s
2026-01-15 10:31:14.529 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1371, name: 'OutputAudioRawFrame#581', metadata: {} at 9.88s
2026-01-15 10:31:14.529 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#581(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.529 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1371, name: 'OutputAudioRawFrame#581', metadata: {} at 9.88s
2026-01-15 10:31:14.529 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1371, name: 'OutputAudioRawFrame#581', metadata: {} at 9.88s
2026-01-15 10:31:14.529 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1371, name: 'OutputAudioRawFrame#581', metadata: {} at 9.88s
2026-01-15 10:31:14.530 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#581(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.530 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1371, name: 'OutputAudioRawFrame#581', metadata: {} at 9.88s
2026-01-15 10:31:14.530 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1371, name: 'OutputAudioRawFrame#581', metadata: {} at 9.88s
2026-01-15 10:31:14.530 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1371, name: 'OutputAudioRawFrame#581', metadata: {} at 9.88s
2026-01-15 10:31:14.567 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 461, name: 'OutputAudioRawFrame#363', metadata: {} at 9.01s
2026-01-15 10:31:14.567 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 461, name: 'OutputAudioRawFrame#363', metadata: {} at 9.01s
2026-01-15 10:31:14.568 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1373, name: 'OutputAudioRawFrame#582', metadata: {} at 9.92s
2026-01-15 10:31:14.568 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1373, name: 'OutputAudioRawFrame#582', metadata: {} at 9.92s
2026-01-15 10:31:14.568 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#582(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.568 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1373, name: 'OutputAudioRawFrame#582', metadata: {} at 9.92s
2026-01-15 10:31:14.569 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1373, name: 'OutputAudioRawFrame#582', metadata: {} at 9.92s
2026-01-15 10:31:14.569 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1373, name: 'OutputAudioRawFrame#582', metadata: {} at 9.92s
2026-01-15 10:31:14.569 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#582(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.569 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1373, name: 'OutputAudioRawFrame#582', metadata: {} at 9.92s
2026-01-15 10:31:14.569 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1373, name: 'OutputAudioRawFrame#582', metadata: {} at 9.92s
2026-01-15 10:31:14.569 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1373, name: 'OutputAudioRawFrame#582', metadata: {} at 9.92s
2026-01-15 10:31:14.607 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 465, name: 'OutputAudioRawFrame#366', metadata: {} at 9.05s
2026-01-15 10:31:14.607 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 465, name: 'OutputAudioRawFrame#366', metadata: {} at 9.05s
2026-01-15 10:31:14.609 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1375, name: 'OutputAudioRawFrame#583', metadata: {} at 9.96s
2026-01-15 10:31:14.609 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1375, name: 'OutputAudioRawFrame#583', metadata: {} at 9.96s
2026-01-15 10:31:14.609 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#583(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.609 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1375, name: 'OutputAudioRawFrame#583', metadata: {} at 9.96s
2026-01-15 10:31:14.610 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1375, name: 'OutputAudioRawFrame#583', metadata: {} at 9.96s
2026-01-15 10:31:14.610 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1375, name: 'OutputAudioRawFrame#583', metadata: {} at 9.96s
2026-01-15 10:31:14.610 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#583(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.610 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1375, name: 'OutputAudioRawFrame#583', metadata: {} at 9.96s
2026-01-15 10:31:14.610 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1375, name: 'OutputAudioRawFrame#583', metadata: {} at 9.96s
2026-01-15 10:31:14.610 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1375, name: 'OutputAudioRawFrame#583', metadata: {} at 9.96s
2026-01-15 10:31:14.646 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 466, name: 'OutputAudioRawFrame#367', metadata: {} at 9.09s
2026-01-15 10:31:14.646 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 466, name: 'OutputAudioRawFrame#367', metadata: {} at 9.09s
2026-01-15 10:31:14.650 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1377, name: 'OutputAudioRawFrame#584', metadata: {} at 10.00s
2026-01-15 10:31:14.650 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1377, name: 'OutputAudioRawFrame#584', metadata: {} at 10.00s
2026-01-15 10:31:14.651 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#584(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.651 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1377, name: 'OutputAudioRawFrame#584', metadata: {} at 10.01s
2026-01-15 10:31:14.652 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1377, name: 'OutputAudioRawFrame#584', metadata: {} at 10.01s
2026-01-15 10:31:14.652 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1377, name: 'OutputAudioRawFrame#584', metadata: {} at 10.01s
2026-01-15 10:31:14.652 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#584(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.652 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1377, name: 'OutputAudioRawFrame#584', metadata: {} at 10.01s
2026-01-15 10:31:14.652 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1377, name: 'OutputAudioRawFrame#584', metadata: {} at 10.01s
2026-01-15 10:31:14.652 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1377, name: 'OutputAudioRawFrame#584', metadata: {} at 10.01s
2026-01-15 10:31:14.686 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 470, name: 'OutputAudioRawFrame#370', metadata: {} at 9.13s
2026-01-15 10:31:14.686 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 470, name: 'OutputAudioRawFrame#370', metadata: {} at 9.13s
2026-01-15 10:31:14.690 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1379, name: 'OutputAudioRawFrame#585', metadata: {} at 10.04s
2026-01-15 10:31:14.690 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1379, name: 'OutputAudioRawFrame#585', metadata: {} at 10.04s
2026-01-15 10:31:14.690 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#585(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.690 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1379, name: 'OutputAudioRawFrame#585', metadata: {} at 10.04s
2026-01-15 10:31:14.691 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1379, name: 'OutputAudioRawFrame#585', metadata: {} at 10.05s
2026-01-15 10:31:14.692 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1379, name: 'OutputAudioRawFrame#585', metadata: {} at 10.05s
2026-01-15 10:31:14.692 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#585(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.692 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1379, name: 'OutputAudioRawFrame#585', metadata: {} at 10.05s
2026-01-15 10:31:14.692 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1379, name: 'OutputAudioRawFrame#585', metadata: {} at 10.05s
2026-01-15 10:31:14.693 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1379, name: 'OutputAudioRawFrame#585', metadata: {} at 10.05s
2026-01-15 10:31:14.727 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 471, name: 'OutputAudioRawFrame#371', metadata: {} at 9.17s
2026-01-15 10:31:14.727 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 471, name: 'OutputAudioRawFrame#371', metadata: {} at 9.17s
2026-01-15 10:31:14.728 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1381, name: 'OutputAudioRawFrame#586', metadata: {} at 10.08s
2026-01-15 10:31:14.728 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1381, name: 'OutputAudioRawFrame#586', metadata: {} at 10.08s
2026-01-15 10:31:14.728 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#586(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.728 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1381, name: 'OutputAudioRawFrame#586', metadata: {} at 10.08s
2026-01-15 10:31:14.728 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1381, name: 'OutputAudioRawFrame#586', metadata: {} at 10.08s
2026-01-15 10:31:14.729 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1381, name: 'OutputAudioRawFrame#586', metadata: {} at 10.08s
2026-01-15 10:31:14.729 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#586(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.729 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1381, name: 'OutputAudioRawFrame#586', metadata: {} at 10.08s
2026-01-15 10:31:14.729 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1381, name: 'OutputAudioRawFrame#586', metadata: {} at 10.08s
2026-01-15 10:31:14.729 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1381, name: 'OutputAudioRawFrame#586', metadata: {} at 10.08s
2026-01-15 10:31:14.767 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 475, name: 'OutputAudioRawFrame#374', metadata: {} at 9.21s
2026-01-15 10:31:14.767 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 475, name: 'OutputAudioRawFrame#374', metadata: {} at 9.21s
2026-01-15 10:31:14.768 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1383, name: 'OutputAudioRawFrame#587', metadata: {} at 10.12s
2026-01-15 10:31:14.768 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1383, name: 'OutputAudioRawFrame#587', metadata: {} at 10.12s
2026-01-15 10:31:14.768 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#587(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.768 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1383, name: 'OutputAudioRawFrame#587', metadata: {} at 10.12s
2026-01-15 10:31:14.769 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1383, name: 'OutputAudioRawFrame#587', metadata: {} at 10.12s
2026-01-15 10:31:14.769 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1383, name: 'OutputAudioRawFrame#587', metadata: {} at 10.12s
2026-01-15 10:31:14.769 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#587(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.769 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1383, name: 'OutputAudioRawFrame#587', metadata: {} at 10.12s
2026-01-15 10:31:14.769 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1383, name: 'OutputAudioRawFrame#587', metadata: {} at 10.12s
2026-01-15 10:31:14.769 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1383, name: 'OutputAudioRawFrame#587', metadata: {} at 10.12s
2026-01-15 10:31:14.807 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 476, name: 'OutputAudioRawFrame#375', metadata: {} at 9.25s
2026-01-15 10:31:14.807 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 476, name: 'OutputAudioRawFrame#375', metadata: {} at 9.25s
2026-01-15 10:31:14.808 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1385, name: 'OutputAudioRawFrame#588', metadata: {} at 10.16s
2026-01-15 10:31:14.808 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1385, name: 'OutputAudioRawFrame#588', metadata: {} at 10.16s
2026-01-15 10:31:14.808 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#588(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.808 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1385, name: 'OutputAudioRawFrame#588', metadata: {} at 10.16s
2026-01-15 10:31:14.808 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1385, name: 'OutputAudioRawFrame#588', metadata: {} at 10.16s
2026-01-15 10:31:14.808 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1385, name: 'OutputAudioRawFrame#588', metadata: {} at 10.16s
2026-01-15 10:31:14.808 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#588(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.808 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1385, name: 'OutputAudioRawFrame#588', metadata: {} at 10.16s
2026-01-15 10:31:14.808 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1385, name: 'OutputAudioRawFrame#588', metadata: {} at 10.16s
2026-01-15 10:31:14.808 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1385, name: 'OutputAudioRawFrame#588', metadata: {} at 10.16s
2026-01-15 10:31:14.846 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 477, name: 'OutputAudioRawFrame#376', metadata: {} at 9.29s
2026-01-15 10:31:14.847 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 477, name: 'OutputAudioRawFrame#376', metadata: {} at 9.29s
2026-01-15 10:31:14.848 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1387, name: 'OutputAudioRawFrame#589', metadata: {} at 10.20s
2026-01-15 10:31:14.848 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1387, name: 'OutputAudioRawFrame#589', metadata: {} at 10.20s
2026-01-15 10:31:14.848 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#589(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.848 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1387, name: 'OutputAudioRawFrame#589', metadata: {} at 10.20s
2026-01-15 10:31:14.849 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1387, name: 'OutputAudioRawFrame#589', metadata: {} at 10.20s
2026-01-15 10:31:14.849 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1387, name: 'OutputAudioRawFrame#589', metadata: {} at 10.20s
2026-01-15 10:31:14.849 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#589(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.849 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1387, name: 'OutputAudioRawFrame#589', metadata: {} at 10.20s
2026-01-15 10:31:14.849 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1387, name: 'OutputAudioRawFrame#589', metadata: {} at 10.20s
2026-01-15 10:31:14.849 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1387, name: 'OutputAudioRawFrame#589', metadata: {} at 10.20s
2026-01-15 10:31:14.886 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 481, name: 'OutputAudioRawFrame#379', metadata: {} at 9.33s
2026-01-15 10:31:14.886 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 481, name: 'OutputAudioRawFrame#379', metadata: {} at 9.33s
2026-01-15 10:31:14.888 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1389, name: 'OutputAudioRawFrame#590', metadata: {} at 10.24s
2026-01-15 10:31:14.888 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1389, name: 'OutputAudioRawFrame#590', metadata: {} at 10.24s
2026-01-15 10:31:14.888 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#590(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.888 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1389, name: 'OutputAudioRawFrame#590', metadata: {} at 10.24s
2026-01-15 10:31:14.888 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1389, name: 'OutputAudioRawFrame#590', metadata: {} at 10.24s
2026-01-15 10:31:14.888 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1389, name: 'OutputAudioRawFrame#590', metadata: {} at 10.24s
2026-01-15 10:31:14.888 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#590(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.889 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1389, name: 'OutputAudioRawFrame#590', metadata: {} at 10.24s
2026-01-15 10:31:14.889 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1389, name: 'OutputAudioRawFrame#590', metadata: {} at 10.24s
2026-01-15 10:31:14.889 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1389, name: 'OutputAudioRawFrame#590', metadata: {} at 10.24s
2026-01-15 10:31:14.927 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 482, name: 'OutputAudioRawFrame#380', metadata: {} at 9.37s
2026-01-15 10:31:14.927 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 482, name: 'OutputAudioRawFrame#380', metadata: {} at 9.37s
2026-01-15 10:31:14.931 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1391, name: 'OutputAudioRawFrame#591', metadata: {} at 10.29s
2026-01-15 10:31:14.931 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1391, name: 'OutputAudioRawFrame#591', metadata: {} at 10.29s
2026-01-15 10:31:14.931 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#591(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.931 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1391, name: 'OutputAudioRawFrame#591', metadata: {} at 10.29s
2026-01-15 10:31:14.932 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1391, name: 'OutputAudioRawFrame#591', metadata: {} at 10.29s
2026-01-15 10:31:14.932 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1391, name: 'OutputAudioRawFrame#591', metadata: {} at 10.29s
2026-01-15 10:31:14.932 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#591(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.932 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1391, name: 'OutputAudioRawFrame#591', metadata: {} at 10.29s
2026-01-15 10:31:14.932 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1391, name: 'OutputAudioRawFrame#591', metadata: {} at 10.29s
2026-01-15 10:31:14.932 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1391, name: 'OutputAudioRawFrame#591', metadata: {} at 10.29s
2026-01-15 10:31:14.967 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 486, name: 'OutputAudioRawFrame#383', metadata: {} at 9.41s
2026-01-15 10:31:14.967 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 486, name: 'OutputAudioRawFrame#383', metadata: {} at 9.41s
2026-01-15 10:31:14.969 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1393, name: 'OutputAudioRawFrame#592', metadata: {} at 10.32s
2026-01-15 10:31:14.969 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1393, name: 'OutputAudioRawFrame#592', metadata: {} at 10.32s
2026-01-15 10:31:14.969 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#592(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.969 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1393, name: 'OutputAudioRawFrame#592', metadata: {} at 10.32s
2026-01-15 10:31:14.970 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1393, name: 'OutputAudioRawFrame#592', metadata: {} at 10.32s
2026-01-15 10:31:14.970 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1393, name: 'OutputAudioRawFrame#592', metadata: {} at 10.32s
2026-01-15 10:31:14.970 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#592(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:14.970 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1393, name: 'OutputAudioRawFrame#592', metadata: {} at 10.32s
2026-01-15 10:31:14.970 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1393, name: 'OutputAudioRawFrame#592', metadata: {} at 10.32s
2026-01-15 10:31:14.970 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1393, name: 'OutputAudioRawFrame#592', metadata: {} at 10.32s
2026-01-15 10:31:15.007 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 487, name: 'OutputAudioRawFrame#384', metadata: {} at 9.45s
2026-01-15 10:31:15.007 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 487, name: 'OutputAudioRawFrame#384', metadata: {} at 9.45s
2026-01-15 10:31:17.910 | INFO     | [EVAL-SYS] | incrementing audio index: 1
2026-01-15 10:31:17.914 | INFO     | [EVAL-SYS] | Saved intermediate results: 1 transcripts
2026-01-15 10:31:17.914 | INFO     | [EVAL-SYS] | --------------------------------
2026-01-15 10:31:17.914 | INFO     | [EVAL-SYS] | [93mCreated new user transcript[0m
2026-01-15 10:31:17.914 | INFO     | [EVAL-SYS] | transcripts length: 2
2026-01-15 10:31:17.914 | INFO     | [EVAL-SYS] | Starting new audio streaming 2/123: /Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_1_english_speak_slowly.wav
2026-01-15 10:31:17.915 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1395, name: 'OutputAudioRawFrame#593', metadata: {} at 12.36s
2026-01-15 10:31:17.915 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1396, name: 'OutputAudioRawFrame#594', metadata: {} at 12.36s
2026-01-15 10:31:17.915 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1396, name: 'OutputAudioRawFrame#594', metadata: {} at 12.36s
2026-01-15 10:31:17.916 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1399, name: 'OutputAudioRawFrame#596', metadata: {} at 12.36s
2026-01-15 10:31:17.917 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1397, name: 'OutputAudioRawFrame#595', metadata: {} at 13.27s
2026-01-15 10:31:17.917 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1404, name: 'OutputAudioRawFrame#600', metadata: {} at 12.36s
2026-01-15 10:31:17.917 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1397, name: 'OutputAudioRawFrame#595', metadata: {} at 13.27s
2026-01-15 10:31:17.918 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#595(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:17.918 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1397, name: 'OutputAudioRawFrame#595', metadata: {} at 13.27s
2026-01-15 10:31:17.918 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1397, name: 'OutputAudioRawFrame#595', metadata: {} at 13.27s
2026-01-15 10:31:17.918 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1397, name: 'OutputAudioRawFrame#595', metadata: {} at 13.27s
2026-01-15 10:31:17.919 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#595(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:17.919 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1397, name: 'OutputAudioRawFrame#595', metadata: {} at 13.27s
2026-01-15 10:31:17.919 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1407, name: 'OutputAudioRawFrame#603', metadata: {} at 12.36s
2026-01-15 10:31:17.919 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1397, name: 'OutputAudioRawFrame#595', metadata: {} at 13.27s
2026-01-15 10:31:17.919 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1397, name: 'OutputAudioRawFrame#595', metadata: {} at 13.27s
2026-01-15 10:31:17.919 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1402, name: 'OutputAudioRawFrame#599', metadata: {} at 13.27s
2026-01-15 10:31:17.919 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1402, name: 'OutputAudioRawFrame#599', metadata: {} at 13.27s
2026-01-15 10:31:17.919 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#599(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:17.919 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1402, name: 'OutputAudioRawFrame#599', metadata: {} at 13.27s
2026-01-15 10:31:17.920 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1402, name: 'OutputAudioRawFrame#599', metadata: {} at 13.27s
2026-01-15 10:31:17.920 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1402, name: 'OutputAudioRawFrame#599', metadata: {} at 13.27s
2026-01-15 10:31:17.920 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#599(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:17.920 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1402, name: 'OutputAudioRawFrame#599', metadata: {} at 13.27s
2026-01-15 10:31:17.920 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1410, name: 'OutputAudioRawFrame#606', metadata: {} at 12.36s
2026-01-15 10:31:17.920 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1402, name: 'OutputAudioRawFrame#599', metadata: {} at 13.27s
2026-01-15 10:31:17.920 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1402, name: 'OutputAudioRawFrame#599', metadata: {} at 13.27s
2026-01-15 10:31:17.921 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1412, name: 'OutputAudioRawFrame#608', metadata: {} at 12.37s
2026-01-15 10:31:17.923 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1415, name: 'OutputAudioRawFrame#611', metadata: {} at 12.37s
2026-01-15 10:31:17.924 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1419, name: 'OutputAudioRawFrame#615', metadata: {} at 12.37s
2026-01-15 10:31:17.925 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1422, name: 'OutputAudioRawFrame#618', metadata: {} at 12.37s
2026-01-15 10:31:17.926 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1425, name: 'OutputAudioRawFrame#621', metadata: {} at 12.37s
2026-01-15 10:31:17.927 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1428, name: 'OutputAudioRawFrame#624', metadata: {} at 12.37s
2026-01-15 10:31:17.929 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1430, name: 'OutputAudioRawFrame#626', metadata: {} at 12.37s
2026-01-15 10:31:17.930 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1433, name: 'OutputAudioRawFrame#629', metadata: {} at 12.37s
2026-01-15 10:31:17.931 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1437, name: 'OutputAudioRawFrame#633', metadata: {} at 12.37s
2026-01-15 10:31:17.932 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1440, name: 'OutputAudioRawFrame#636', metadata: {} at 12.38s
2026-01-15 10:31:17.935 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1443, name: 'OutputAudioRawFrame#639', metadata: {} at 12.38s
2026-01-15 10:31:17.936 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1446, name: 'OutputAudioRawFrame#642', metadata: {} at 12.38s
2026-01-15 10:31:17.937 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1448, name: 'OutputAudioRawFrame#644', metadata: {} at 12.38s
2026-01-15 10:31:17.938 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1451, name: 'OutputAudioRawFrame#647', metadata: {} at 12.38s
2026-01-15 10:31:17.940 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1454, name: 'OutputAudioRawFrame#650', metadata: {} at 12.38s
2026-01-15 10:31:17.941 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1458, name: 'OutputAudioRawFrame#654', metadata: {} at 12.38s
2026-01-15 10:31:17.942 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1461, name: 'OutputAudioRawFrame#657', metadata: {} at 12.39s
2026-01-15 10:31:17.943 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1464, name: 'OutputAudioRawFrame#660', metadata: {} at 12.39s
2026-01-15 10:31:17.944 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1466, name: 'OutputAudioRawFrame#662', metadata: {} at 12.39s
2026-01-15 10:31:17.945 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1469, name: 'OutputAudioRawFrame#665', metadata: {} at 12.39s
2026-01-15 10:31:17.947 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1472, name: 'OutputAudioRawFrame#668', metadata: {} at 12.39s
2026-01-15 10:31:17.948 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1476, name: 'OutputAudioRawFrame#672', metadata: {} at 12.39s
2026-01-15 10:31:17.949 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1479, name: 'OutputAudioRawFrame#675', metadata: {} at 12.39s
2026-01-15 10:31:17.950 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1482, name: 'OutputAudioRawFrame#678', metadata: {} at 12.39s
2026-01-15 10:31:17.951 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1484, name: 'OutputAudioRawFrame#680', metadata: {} at 12.40s
2026-01-15 10:31:17.953 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1487, name: 'OutputAudioRawFrame#683', metadata: {} at 12.40s
2026-01-15 10:31:17.954 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1490, name: 'OutputAudioRawFrame#686', metadata: {} at 12.40s
2026-01-15 10:31:17.955 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1494, name: 'OutputAudioRawFrame#690', metadata: {} at 12.40s
2026-01-15 10:31:17.955 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1400, name: 'OutputAudioRawFrame#597', metadata: {} at 12.40s
2026-01-15 10:31:17.955 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1400, name: 'OutputAudioRawFrame#597', metadata: {} at 12.40s
2026-01-15 10:31:17.956 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1499, name: 'OutputAudioRawFrame#694', metadata: {} at 12.40s
2026-01-15 10:31:17.957 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1497, name: 'OutputAudioRawFrame#693', metadata: {} at 13.31s
2026-01-15 10:31:17.957 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1497, name: 'OutputAudioRawFrame#693', metadata: {} at 13.31s
2026-01-15 10:31:17.957 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#693(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:17.957 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1497, name: 'OutputAudioRawFrame#693', metadata: {} at 13.31s
2026-01-15 10:31:17.958 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1497, name: 'OutputAudioRawFrame#693', metadata: {} at 13.31s
2026-01-15 10:31:17.958 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1497, name: 'OutputAudioRawFrame#693', metadata: {} at 13.31s
2026-01-15 10:31:17.958 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#693(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:17.958 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1502, name: 'OutputAudioRawFrame#697', metadata: {} at 12.40s
2026-01-15 10:31:17.958 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1497, name: 'OutputAudioRawFrame#693', metadata: {} at 13.31s
2026-01-15 10:31:17.958 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1497, name: 'OutputAudioRawFrame#693', metadata: {} at 13.31s
2026-01-15 10:31:17.958 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1497, name: 'OutputAudioRawFrame#693', metadata: {} at 13.31s
2026-01-15 10:31:17.959 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1504, name: 'OutputAudioRawFrame#699', metadata: {} at 12.40s
2026-01-15 10:31:17.960 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1507, name: 'OutputAudioRawFrame#702', metadata: {} at 12.40s
2026-01-15 10:31:17.961 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1510, name: 'OutputAudioRawFrame#705', metadata: {} at 12.40s
2026-01-15 10:31:17.962 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1514, name: 'OutputAudioRawFrame#709', metadata: {} at 12.41s
2026-01-15 10:31:17.964 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1517, name: 'OutputAudioRawFrame#712', metadata: {} at 12.41s
2026-01-15 10:31:17.965 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1520, name: 'OutputAudioRawFrame#715', metadata: {} at 12.41s
2026-01-15 10:31:17.966 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1522, name: 'OutputAudioRawFrame#717', metadata: {} at 12.41s
2026-01-15 10:31:17.967 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1525, name: 'OutputAudioRawFrame#720', metadata: {} at 12.41s
2026-01-15 10:31:17.968 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1528, name: 'OutputAudioRawFrame#723', metadata: {} at 12.41s
2026-01-15 10:31:17.969 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1532, name: 'OutputAudioRawFrame#727', metadata: {} at 12.41s
2026-01-15 10:31:17.971 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1535, name: 'OutputAudioRawFrame#730', metadata: {} at 12.41s
2026-01-15 10:31:17.972 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1538, name: 'OutputAudioRawFrame#733', metadata: {} at 12.42s
2026-01-15 10:31:17.973 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1541, name: 'OutputAudioRawFrame#736', metadata: {} at 12.42s
2026-01-15 10:31:17.974 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1543, name: 'OutputAudioRawFrame#738', metadata: {} at 12.42s
2026-01-15 10:31:17.975 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1546, name: 'OutputAudioRawFrame#741', metadata: {} at 12.42s
2026-01-15 10:31:17.976 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1550, name: 'OutputAudioRawFrame#745', metadata: {} at 12.42s
2026-01-15 10:31:17.978 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1553, name: 'OutputAudioRawFrame#748', metadata: {} at 12.42s
2026-01-15 10:31:17.979 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1556, name: 'OutputAudioRawFrame#751', metadata: {} at 12.42s
2026-01-15 10:31:17.980 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1559, name: 'OutputAudioRawFrame#754', metadata: {} at 12.42s
2026-01-15 10:31:17.981 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1561, name: 'OutputAudioRawFrame#756', metadata: {} at 12.42s
2026-01-15 10:31:17.982 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1564, name: 'OutputAudioRawFrame#759', metadata: {} at 12.43s
2026-01-15 10:31:17.983 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1568, name: 'OutputAudioRawFrame#763', metadata: {} at 12.43s
2026-01-15 10:31:17.985 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1571, name: 'OutputAudioRawFrame#766', metadata: {} at 12.43s
2026-01-15 10:31:17.986 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1574, name: 'OutputAudioRawFrame#769', metadata: {} at 12.43s
2026-01-15 10:31:17.987 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1577, name: 'OutputAudioRawFrame#772', metadata: {} at 12.43s
2026-01-15 10:31:17.988 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1579, name: 'OutputAudioRawFrame#774', metadata: {} at 12.43s
2026-01-15 10:31:17.989 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1582, name: 'OutputAudioRawFrame#777', metadata: {} at 12.43s
2026-01-15 10:31:17.991 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1586, name: 'OutputAudioRawFrame#781', metadata: {} at 12.43s
2026-01-15 10:31:17.992 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1589, name: 'OutputAudioRawFrame#784', metadata: {} at 12.44s
2026-01-15 10:31:17.993 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1592, name: 'OutputAudioRawFrame#787', metadata: {} at 12.44s
2026-01-15 10:31:17.994 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1595, name: 'OutputAudioRawFrame#790', metadata: {} at 12.44s
2026-01-15 10:31:17.995 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1597, name: 'OutputAudioRawFrame#792', metadata: {} at 12.44s
2026-01-15 10:31:17.995 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1401, name: 'OutputAudioRawFrame#598', metadata: {} at 12.44s
2026-01-15 10:31:17.996 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1401, name: 'OutputAudioRawFrame#598', metadata: {} at 12.44s
2026-01-15 10:31:17.997 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1600, name: 'OutputAudioRawFrame#795', metadata: {} at 13.35s
2026-01-15 10:31:17.997 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1602, name: 'OutputAudioRawFrame#796', metadata: {} at 12.44s
2026-01-15 10:31:17.997 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1600, name: 'OutputAudioRawFrame#795', metadata: {} at 13.35s
2026-01-15 10:31:17.997 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#795(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:17.997 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1600, name: 'OutputAudioRawFrame#795', metadata: {} at 13.35s
2026-01-15 10:31:17.997 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1600, name: 'OutputAudioRawFrame#795', metadata: {} at 13.35s
2026-01-15 10:31:17.998 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1600, name: 'OutputAudioRawFrame#795', metadata: {} at 13.35s
2026-01-15 10:31:17.998 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#795(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:17.998 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1600, name: 'OutputAudioRawFrame#795', metadata: {} at 13.35s
2026-01-15 10:31:17.998 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1600, name: 'OutputAudioRawFrame#795', metadata: {} at 13.35s
2026-01-15 10:31:17.998 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1600, name: 'OutputAudioRawFrame#795', metadata: {} at 13.35s
2026-01-15 10:31:17.998 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1606, name: 'OutputAudioRawFrame#800', metadata: {} at 12.44s
2026-01-15 10:31:17.999 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1609, name: 'OutputAudioRawFrame#803', metadata: {} at 12.44s
2026-01-15 10:31:18.000 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1612, name: 'OutputAudioRawFrame#806', metadata: {} at 12.44s
2026-01-15 10:31:18.001 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1615, name: 'OutputAudioRawFrame#809', metadata: {} at 12.45s
2026-01-15 10:31:18.003 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1617, name: 'OutputAudioRawFrame#811', metadata: {} at 12.45s
2026-01-15 10:31:18.004 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1620, name: 'OutputAudioRawFrame#814', metadata: {} at 12.45s
2026-01-15 10:31:18.005 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1623, name: 'OutputAudioRawFrame#817', metadata: {} at 12.45s
2026-01-15 10:31:18.006 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1627, name: 'OutputAudioRawFrame#821', metadata: {} at 12.45s
2026-01-15 10:31:18.007 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1630, name: 'OutputAudioRawFrame#824', metadata: {} at 12.45s
2026-01-15 10:31:18.008 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1633, name: 'OutputAudioRawFrame#827', metadata: {} at 12.45s
2026-01-15 10:31:18.010 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1635, name: 'OutputAudioRawFrame#829', metadata: {} at 12.45s
2026-01-15 10:31:18.011 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1638, name: 'OutputAudioRawFrame#832', metadata: {} at 12.45s
2026-01-15 10:31:18.012 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1641, name: 'OutputAudioRawFrame#835', metadata: {} at 12.46s
2026-01-15 10:31:18.013 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1645, name: 'OutputAudioRawFrame#839', metadata: {} at 12.46s
2026-01-15 10:31:18.014 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1648, name: 'OutputAudioRawFrame#842', metadata: {} at 12.46s
2026-01-15 10:31:18.015 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1651, name: 'OutputAudioRawFrame#845', metadata: {} at 12.46s
2026-01-15 10:31:18.017 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1653, name: 'OutputAudioRawFrame#847', metadata: {} at 12.46s
2026-01-15 10:31:18.018 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1656, name: 'OutputAudioRawFrame#850', metadata: {} at 12.46s
2026-01-15 10:31:18.019 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1659, name: 'OutputAudioRawFrame#853', metadata: {} at 12.46s
2026-01-15 10:31:18.020 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1663, name: 'OutputAudioRawFrame#857', metadata: {} at 12.46s
2026-01-15 10:31:18.021 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1666, name: 'OutputAudioRawFrame#860', metadata: {} at 12.47s
2026-01-15 10:31:18.022 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1669, name: 'OutputAudioRawFrame#863', metadata: {} at 12.47s
2026-01-15 10:31:18.024 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1671, name: 'OutputAudioRawFrame#865', metadata: {} at 12.47s
2026-01-15 10:31:18.025 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1674, name: 'OutputAudioRawFrame#868', metadata: {} at 12.47s
2026-01-15 10:31:18.026 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1677, name: 'OutputAudioRawFrame#871', metadata: {} at 12.47s
2026-01-15 10:31:18.027 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1681, name: 'OutputAudioRawFrame#875', metadata: {} at 12.47s
2026-01-15 10:31:18.028 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1684, name: 'OutputAudioRawFrame#878', metadata: {} at 12.47s
2026-01-15 10:31:18.029 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1687, name: 'OutputAudioRawFrame#881', metadata: {} at 12.47s
2026-01-15 10:31:18.031 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1689, name: 'OutputAudioRawFrame#883', metadata: {} at 12.47s
2026-01-15 10:31:18.032 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1692, name: 'OutputAudioRawFrame#886', metadata: {} at 12.48s
2026-01-15 10:31:18.033 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1695, name: 'OutputAudioRawFrame#889', metadata: {} at 12.48s
2026-01-15 10:31:18.034 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1699, name: 'OutputAudioRawFrame#893', metadata: {} at 12.48s
2026-01-15 10:31:18.035 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1702, name: 'OutputAudioRawFrame#896', metadata: {} at 12.48s
2026-01-15 10:31:18.035 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1405, name: 'OutputAudioRawFrame#601', metadata: {} at 12.48s
2026-01-15 10:31:18.036 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1405, name: 'OutputAudioRawFrame#601', metadata: {} at 12.48s
2026-01-15 10:31:18.036 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1707, name: 'OutputAudioRawFrame#900', metadata: {} at 12.48s
2026-01-15 10:31:18.037 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1705, name: 'OutputAudioRawFrame#899', metadata: {} at 13.39s
2026-01-15 10:31:18.037 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1705, name: 'OutputAudioRawFrame#899', metadata: {} at 13.39s
2026-01-15 10:31:18.037 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#899(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.037 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1705, name: 'OutputAudioRawFrame#899', metadata: {} at 13.39s
2026-01-15 10:31:18.038 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1705, name: 'OutputAudioRawFrame#899', metadata: {} at 13.39s
2026-01-15 10:31:18.038 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1705, name: 'OutputAudioRawFrame#899', metadata: {} at 13.39s
2026-01-15 10:31:18.038 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#899(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.038 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1705, name: 'OutputAudioRawFrame#899', metadata: {} at 13.39s
2026-01-15 10:31:18.038 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1710, name: 'OutputAudioRawFrame#903', metadata: {} at 12.48s
2026-01-15 10:31:18.038 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1705, name: 'OutputAudioRawFrame#899', metadata: {} at 13.39s
2026-01-15 10:31:18.038 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1705, name: 'OutputAudioRawFrame#899', metadata: {} at 13.39s
2026-01-15 10:31:18.039 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1712, name: 'OutputAudioRawFrame#905', metadata: {} at 12.48s
2026-01-15 10:31:18.040 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1715, name: 'OutputAudioRawFrame#908', metadata: {} at 12.48s
2026-01-15 10:31:18.041 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1719, name: 'OutputAudioRawFrame#912', metadata: {} at 12.49s
2026-01-15 10:31:18.042 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1722, name: 'OutputAudioRawFrame#915', metadata: {} at 12.49s
2026-01-15 10:31:18.044 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1725, name: 'OutputAudioRawFrame#918', metadata: {} at 12.49s
2026-01-15 10:31:18.045 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1728, name: 'OutputAudioRawFrame#921', metadata: {} at 12.49s
2026-01-15 10:31:18.046 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1730, name: 'OutputAudioRawFrame#923', metadata: {} at 12.49s
2026-01-15 10:31:18.047 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1733, name: 'OutputAudioRawFrame#926', metadata: {} at 12.49s
2026-01-15 10:31:18.048 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1737, name: 'OutputAudioRawFrame#930', metadata: {} at 12.49s
2026-01-15 10:31:18.050 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1740, name: 'OutputAudioRawFrame#933', metadata: {} at 12.49s
2026-01-15 10:31:18.051 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1743, name: 'OutputAudioRawFrame#936', metadata: {} at 12.49s
2026-01-15 10:31:18.052 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1746, name: 'OutputAudioRawFrame#939', metadata: {} at 12.50s
2026-01-15 10:31:18.053 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1748, name: 'OutputAudioRawFrame#941', metadata: {} at 12.50s
2026-01-15 10:31:18.054 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1751, name: 'OutputAudioRawFrame#944', metadata: {} at 12.50s
2026-01-15 10:31:18.055 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1755, name: 'OutputAudioRawFrame#948', metadata: {} at 12.50s
2026-01-15 10:31:18.057 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1758, name: 'OutputAudioRawFrame#951', metadata: {} at 12.50s
2026-01-15 10:31:18.058 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1761, name: 'OutputAudioRawFrame#954', metadata: {} at 12.50s
2026-01-15 10:31:18.059 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1764, name: 'OutputAudioRawFrame#957', metadata: {} at 12.50s
2026-01-15 10:31:18.060 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1766, name: 'OutputAudioRawFrame#959', metadata: {} at 12.50s
2026-01-15 10:31:18.061 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1769, name: 'OutputAudioRawFrame#962', metadata: {} at 12.51s
2026-01-15 10:31:18.063 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1773, name: 'OutputAudioRawFrame#966', metadata: {} at 12.51s
2026-01-15 10:31:18.064 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1776, name: 'OutputAudioRawFrame#969', metadata: {} at 12.51s
2026-01-15 10:31:18.076 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1406, name: 'OutputAudioRawFrame#602', metadata: {} at 12.52s
2026-01-15 10:31:18.076 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1406, name: 'OutputAudioRawFrame#602', metadata: {} at 12.52s
2026-01-15 10:31:18.078 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1779, name: 'OutputAudioRawFrame#972', metadata: {} at 13.43s
2026-01-15 10:31:18.078 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1779, name: 'OutputAudioRawFrame#972', metadata: {} at 13.43s
2026-01-15 10:31:18.078 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#972(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.078 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1779, name: 'OutputAudioRawFrame#972', metadata: {} at 13.43s
2026-01-15 10:31:18.079 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1779, name: 'OutputAudioRawFrame#972', metadata: {} at 13.43s
2026-01-15 10:31:18.079 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1779, name: 'OutputAudioRawFrame#972', metadata: {} at 13.43s
2026-01-15 10:31:18.079 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#972(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.079 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1779, name: 'OutputAudioRawFrame#972', metadata: {} at 13.43s
2026-01-15 10:31:18.079 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1779, name: 'OutputAudioRawFrame#972', metadata: {} at 13.43s
2026-01-15 10:31:18.079 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1779, name: 'OutputAudioRawFrame#972', metadata: {} at 13.43s
2026-01-15 10:31:18.105 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1781, name: 'OutputAudioRawFrame#973', metadata: {} at 12.55s
2026-01-15 10:31:18.116 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1408, name: 'OutputAudioRawFrame#604', metadata: {} at 12.56s
2026-01-15 10:31:18.116 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1408, name: 'OutputAudioRawFrame#604', metadata: {} at 12.56s
2026-01-15 10:31:18.118 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1784, name: 'OutputAudioRawFrame#976', metadata: {} at 13.47s
2026-01-15 10:31:18.118 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1784, name: 'OutputAudioRawFrame#976', metadata: {} at 13.47s
2026-01-15 10:31:18.119 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#976(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.119 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1784, name: 'OutputAudioRawFrame#976', metadata: {} at 13.47s
2026-01-15 10:31:18.119 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1784, name: 'OutputAudioRawFrame#976', metadata: {} at 13.47s
2026-01-15 10:31:18.119 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1784, name: 'OutputAudioRawFrame#976', metadata: {} at 13.47s
2026-01-15 10:31:18.119 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#976(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.119 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1784, name: 'OutputAudioRawFrame#976', metadata: {} at 13.47s
2026-01-15 10:31:18.119 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1784, name: 'OutputAudioRawFrame#976', metadata: {} at 13.47s
2026-01-15 10:31:18.119 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1784, name: 'OutputAudioRawFrame#976', metadata: {} at 13.47s
2026-01-15 10:31:18.146 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1786, name: 'OutputAudioRawFrame#977', metadata: {} at 12.59s
2026-01-15 10:31:18.157 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1409, name: 'OutputAudioRawFrame#605', metadata: {} at 12.60s
2026-01-15 10:31:18.157 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1409, name: 'OutputAudioRawFrame#605', metadata: {} at 12.60s
2026-01-15 10:31:18.161 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1788, name: 'OutputAudioRawFrame#979', metadata: {} at 13.51s
2026-01-15 10:31:18.161 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1788, name: 'OutputAudioRawFrame#979', metadata: {} at 13.52s
2026-01-15 10:31:18.161 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#979(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.161 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1788, name: 'OutputAudioRawFrame#979', metadata: {} at 13.52s
2026-01-15 10:31:18.162 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1788, name: 'OutputAudioRawFrame#979', metadata: {} at 13.52s
2026-01-15 10:31:18.162 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1788, name: 'OutputAudioRawFrame#979', metadata: {} at 13.52s
2026-01-15 10:31:18.162 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#979(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.163 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1788, name: 'OutputAudioRawFrame#979', metadata: {} at 13.52s
2026-01-15 10:31:18.163 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1788, name: 'OutputAudioRawFrame#979', metadata: {} at 13.52s
2026-01-15 10:31:18.163 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1788, name: 'OutputAudioRawFrame#979', metadata: {} at 13.52s
2026-01-15 10:31:18.188 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1790, name: 'OutputAudioRawFrame#980', metadata: {} at 12.63s
2026-01-15 10:31:18.196 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1411, name: 'OutputAudioRawFrame#607', metadata: {} at 12.64s
2026-01-15 10:31:18.196 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1411, name: 'OutputAudioRawFrame#607', metadata: {} at 12.64s
2026-01-15 10:31:18.198 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1793, name: 'OutputAudioRawFrame#983', metadata: {} at 13.55s
2026-01-15 10:31:18.198 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1793, name: 'OutputAudioRawFrame#983', metadata: {} at 13.55s
2026-01-15 10:31:18.198 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#983(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.198 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1793, name: 'OutputAudioRawFrame#983', metadata: {} at 13.55s
2026-01-15 10:31:18.199 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1793, name: 'OutputAudioRawFrame#983', metadata: {} at 13.55s
2026-01-15 10:31:18.199 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1793, name: 'OutputAudioRawFrame#983', metadata: {} at 13.55s
2026-01-15 10:31:18.199 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#983(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.199 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1793, name: 'OutputAudioRawFrame#983', metadata: {} at 13.55s
2026-01-15 10:31:18.199 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1793, name: 'OutputAudioRawFrame#983', metadata: {} at 13.55s
2026-01-15 10:31:18.199 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1793, name: 'OutputAudioRawFrame#983', metadata: {} at 13.55s
2026-01-15 10:31:18.229 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1795, name: 'OutputAudioRawFrame#984', metadata: {} at 12.67s
2026-01-15 10:31:18.236 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1413, name: 'OutputAudioRawFrame#609', metadata: {} at 12.68s
2026-01-15 10:31:18.236 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1413, name: 'OutputAudioRawFrame#609', metadata: {} at 12.68s
2026-01-15 10:31:18.238 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1798, name: 'OutputAudioRawFrame#987', metadata: {} at 13.59s
2026-01-15 10:31:18.239 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1798, name: 'OutputAudioRawFrame#987', metadata: {} at 13.59s
2026-01-15 10:31:18.239 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#987(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.239 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1798, name: 'OutputAudioRawFrame#987', metadata: {} at 13.59s
2026-01-15 10:31:18.240 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1798, name: 'OutputAudioRawFrame#987', metadata: {} at 13.59s
2026-01-15 10:31:18.240 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1798, name: 'OutputAudioRawFrame#987', metadata: {} at 13.59s
2026-01-15 10:31:18.240 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#987(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.240 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1798, name: 'OutputAudioRawFrame#987', metadata: {} at 13.59s
2026-01-15 10:31:18.240 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1798, name: 'OutputAudioRawFrame#987', metadata: {} at 13.59s
2026-01-15 10:31:18.240 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1798, name: 'OutputAudioRawFrame#987', metadata: {} at 13.59s
2026-01-15 10:31:18.270 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1800, name: 'OutputAudioRawFrame#988', metadata: {} at 12.71s
2026-01-15 10:31:18.276 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1414, name: 'OutputAudioRawFrame#610', metadata: {} at 12.72s
2026-01-15 10:31:18.276 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1414, name: 'OutputAudioRawFrame#610', metadata: {} at 12.72s
2026-01-15 10:31:18.278 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1804, name: 'OutputAudioRawFrame#992', metadata: {} at 13.63s
2026-01-15 10:31:18.279 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1804, name: 'OutputAudioRawFrame#992', metadata: {} at 13.63s
2026-01-15 10:31:18.279 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#992(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.279 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1804, name: 'OutputAudioRawFrame#992', metadata: {} at 13.63s
2026-01-15 10:31:18.279 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1804, name: 'OutputAudioRawFrame#992', metadata: {} at 13.63s
2026-01-15 10:31:18.279 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1804, name: 'OutputAudioRawFrame#992', metadata: {} at 13.63s
2026-01-15 10:31:18.280 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#992(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.280 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1804, name: 'OutputAudioRawFrame#992', metadata: {} at 13.63s
2026-01-15 10:31:18.280 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1804, name: 'OutputAudioRawFrame#992', metadata: {} at 13.63s
2026-01-15 10:31:18.280 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1804, name: 'OutputAudioRawFrame#992', metadata: {} at 13.63s
2026-01-15 10:31:18.311 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1806, name: 'OutputAudioRawFrame#993', metadata: {} at 12.75s
2026-01-15 10:31:18.316 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1416, name: 'OutputAudioRawFrame#612', metadata: {} at 12.76s
2026-01-15 10:31:18.317 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1416, name: 'OutputAudioRawFrame#612', metadata: {} at 12.76s
2026-01-15 10:31:18.319 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1809, name: 'OutputAudioRawFrame#996', metadata: {} at 13.67s
2026-01-15 10:31:18.319 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1809, name: 'OutputAudioRawFrame#996', metadata: {} at 13.67s
2026-01-15 10:31:18.319 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#996(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.319 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1809, name: 'OutputAudioRawFrame#996', metadata: {} at 13.67s
2026-01-15 10:31:18.320 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1809, name: 'OutputAudioRawFrame#996', metadata: {} at 13.67s
2026-01-15 10:31:18.320 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1809, name: 'OutputAudioRawFrame#996', metadata: {} at 13.67s
2026-01-15 10:31:18.320 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#996(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.320 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1809, name: 'OutputAudioRawFrame#996', metadata: {} at 13.67s
2026-01-15 10:31:18.320 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1809, name: 'OutputAudioRawFrame#996', metadata: {} at 13.67s
2026-01-15 10:31:18.320 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1809, name: 'OutputAudioRawFrame#996', metadata: {} at 13.67s
2026-01-15 10:31:18.352 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1811, name: 'OutputAudioRawFrame#997', metadata: {} at 12.80s
2026-01-15 10:31:18.356 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1417, name: 'OutputAudioRawFrame#613', metadata: {} at 12.80s
2026-01-15 10:31:18.356 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1417, name: 'OutputAudioRawFrame#613', metadata: {} at 12.80s
2026-01-15 10:31:18.359 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1814, name: 'OutputAudioRawFrame#1000', metadata: {} at 13.71s
2026-01-15 10:31:18.359 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1814, name: 'OutputAudioRawFrame#1000', metadata: {} at 13.71s
2026-01-15 10:31:18.359 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1000(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.359 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1814, name: 'OutputAudioRawFrame#1000', metadata: {} at 13.71s
2026-01-15 10:31:18.360 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1814, name: 'OutputAudioRawFrame#1000', metadata: {} at 13.71s
2026-01-15 10:31:18.360 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1814, name: 'OutputAudioRawFrame#1000', metadata: {} at 13.71s
2026-01-15 10:31:18.361 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1000(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.361 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1814, name: 'OutputAudioRawFrame#1000', metadata: {} at 13.72s
2026-01-15 10:31:18.361 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1814, name: 'OutputAudioRawFrame#1000', metadata: {} at 13.72s
2026-01-15 10:31:18.361 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1814, name: 'OutputAudioRawFrame#1000', metadata: {} at 13.72s
2026-01-15 10:31:18.394 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1816, name: 'OutputAudioRawFrame#1001', metadata: {} at 12.84s
2026-01-15 10:31:18.396 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1418, name: 'OutputAudioRawFrame#614', metadata: {} at 12.84s
2026-01-15 10:31:18.396 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1418, name: 'OutputAudioRawFrame#614', metadata: {} at 12.84s
2026-01-15 10:31:18.399 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1818, name: 'OutputAudioRawFrame#1003', metadata: {} at 13.75s
2026-01-15 10:31:18.399 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1818, name: 'OutputAudioRawFrame#1003', metadata: {} at 13.75s
2026-01-15 10:31:18.399 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1003(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.400 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1818, name: 'OutputAudioRawFrame#1003', metadata: {} at 13.75s
2026-01-15 10:31:18.400 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1818, name: 'OutputAudioRawFrame#1003', metadata: {} at 13.75s
2026-01-15 10:31:18.401 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1818, name: 'OutputAudioRawFrame#1003', metadata: {} at 13.76s
2026-01-15 10:31:18.401 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1003(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.401 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1818, name: 'OutputAudioRawFrame#1003', metadata: {} at 13.76s
2026-01-15 10:31:18.401 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1818, name: 'OutputAudioRawFrame#1003', metadata: {} at 13.76s
2026-01-15 10:31:18.401 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1818, name: 'OutputAudioRawFrame#1003', metadata: {} at 13.76s
2026-01-15 10:31:18.435 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1820, name: 'OutputAudioRawFrame#1004', metadata: {} at 12.88s
2026-01-15 10:31:18.436 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1420, name: 'OutputAudioRawFrame#616', metadata: {} at 12.88s
2026-01-15 10:31:18.436 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1420, name: 'OutputAudioRawFrame#616', metadata: {} at 12.88s
2026-01-15 10:31:18.439 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1823, name: 'OutputAudioRawFrame#1007', metadata: {} at 13.79s
2026-01-15 10:31:18.440 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1823, name: 'OutputAudioRawFrame#1007', metadata: {} at 13.79s
2026-01-15 10:31:18.440 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1007(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.440 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1823, name: 'OutputAudioRawFrame#1007', metadata: {} at 13.79s
2026-01-15 10:31:18.441 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1823, name: 'OutputAudioRawFrame#1007', metadata: {} at 13.79s
2026-01-15 10:31:18.441 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1823, name: 'OutputAudioRawFrame#1007', metadata: {} at 13.80s
2026-01-15 10:31:18.441 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1007(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.441 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1823, name: 'OutputAudioRawFrame#1007', metadata: {} at 13.80s
2026-01-15 10:31:18.441 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1823, name: 'OutputAudioRawFrame#1007', metadata: {} at 13.80s
2026-01-15 10:31:18.442 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1823, name: 'OutputAudioRawFrame#1007', metadata: {} at 13.80s
2026-01-15 10:31:18.476 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1825, name: 'OutputAudioRawFrame#1008', metadata: {} at 12.92s
2026-01-15 10:31:18.476 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1421, name: 'OutputAudioRawFrame#617', metadata: {} at 12.92s
2026-01-15 10:31:18.476 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1421, name: 'OutputAudioRawFrame#617', metadata: {} at 12.92s
2026-01-15 10:31:18.480 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1828, name: 'OutputAudioRawFrame#1011', metadata: {} at 13.83s
2026-01-15 10:31:18.480 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1828, name: 'OutputAudioRawFrame#1011', metadata: {} at 13.83s
2026-01-15 10:31:18.480 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1011(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.480 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1828, name: 'OutputAudioRawFrame#1011', metadata: {} at 13.83s
2026-01-15 10:31:18.481 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1828, name: 'OutputAudioRawFrame#1011', metadata: {} at 13.84s
2026-01-15 10:31:18.481 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1828, name: 'OutputAudioRawFrame#1011', metadata: {} at 13.84s
2026-01-15 10:31:18.482 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1011(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.482 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1828, name: 'OutputAudioRawFrame#1011', metadata: {} at 13.84s
2026-01-15 10:31:18.482 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1828, name: 'OutputAudioRawFrame#1011', metadata: {} at 13.84s
2026-01-15 10:31:18.482 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1828, name: 'OutputAudioRawFrame#1011', metadata: {} at 13.84s
2026-01-15 10:31:18.517 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1423, name: 'OutputAudioRawFrame#619', metadata: {} at 12.96s
2026-01-15 10:31:18.517 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1423, name: 'OutputAudioRawFrame#619', metadata: {} at 12.96s
2026-01-15 10:31:18.518 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1830, name: 'OutputAudioRawFrame#1012', metadata: {} at 12.96s
2026-01-15 10:31:18.523 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1834, name: 'OutputAudioRawFrame#1016', metadata: {} at 13.88s
2026-01-15 10:31:18.523 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1834, name: 'OutputAudioRawFrame#1016', metadata: {} at 13.88s
2026-01-15 10:31:18.524 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1016(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.524 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1834, name: 'OutputAudioRawFrame#1016', metadata: {} at 13.88s
2026-01-15 10:31:18.526 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1834, name: 'OutputAudioRawFrame#1016', metadata: {} at 13.88s
2026-01-15 10:31:18.526 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1834, name: 'OutputAudioRawFrame#1016', metadata: {} at 13.88s
2026-01-15 10:31:18.526 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1016(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.526 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1834, name: 'OutputAudioRawFrame#1016', metadata: {} at 13.88s
2026-01-15 10:31:18.526 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1834, name: 'OutputAudioRawFrame#1016', metadata: {} at 13.88s
2026-01-15 10:31:18.526 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1834, name: 'OutputAudioRawFrame#1016', metadata: {} at 13.88s
2026-01-15 10:31:18.556 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1424, name: 'OutputAudioRawFrame#620', metadata: {} at 13.00s
2026-01-15 10:31:18.557 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1424, name: 'OutputAudioRawFrame#620', metadata: {} at 13.00s
2026-01-15 10:31:18.557 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1838, name: 'OutputAudioRawFrame#1018', metadata: {} at 13.00s
2026-01-15 10:31:18.558 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1836, name: 'OutputAudioRawFrame#1017', metadata: {} at 13.91s
2026-01-15 10:31:18.558 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1836, name: 'OutputAudioRawFrame#1017', metadata: {} at 13.91s
2026-01-15 10:31:18.558 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1017(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.558 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1836, name: 'OutputAudioRawFrame#1017', metadata: {} at 13.91s
2026-01-15 10:31:18.559 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1836, name: 'OutputAudioRawFrame#1017', metadata: {} at 13.91s
2026-01-15 10:31:18.559 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1836, name: 'OutputAudioRawFrame#1017', metadata: {} at 13.91s
2026-01-15 10:31:18.559 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1017(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.559 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1836, name: 'OutputAudioRawFrame#1017', metadata: {} at 13.91s
2026-01-15 10:31:18.559 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1836, name: 'OutputAudioRawFrame#1017', metadata: {} at 13.91s
2026-01-15 10:31:18.559 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1836, name: 'OutputAudioRawFrame#1017', metadata: {} at 13.91s
2026-01-15 10:31:18.596 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1426, name: 'OutputAudioRawFrame#622', metadata: {} at 13.04s
2026-01-15 10:31:18.596 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1426, name: 'OutputAudioRawFrame#622', metadata: {} at 13.04s
2026-01-15 10:31:18.597 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1843, name: 'OutputAudioRawFrame#1022', metadata: {} at 13.04s
2026-01-15 10:31:18.598 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1841, name: 'OutputAudioRawFrame#1021', metadata: {} at 13.95s
2026-01-15 10:31:18.598 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1841, name: 'OutputAudioRawFrame#1021', metadata: {} at 13.95s
2026-01-15 10:31:18.598 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1021(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.598 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1841, name: 'OutputAudioRawFrame#1021', metadata: {} at 13.95s
2026-01-15 10:31:18.599 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1841, name: 'OutputAudioRawFrame#1021', metadata: {} at 13.95s
2026-01-15 10:31:18.599 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1841, name: 'OutputAudioRawFrame#1021', metadata: {} at 13.95s
2026-01-15 10:31:18.599 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1021(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.599 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1841, name: 'OutputAudioRawFrame#1021', metadata: {} at 13.95s
2026-01-15 10:31:18.599 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1841, name: 'OutputAudioRawFrame#1021', metadata: {} at 13.95s
2026-01-15 10:31:18.599 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1841, name: 'OutputAudioRawFrame#1021', metadata: {} at 13.95s
2026-01-15 10:31:18.637 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1427, name: 'OutputAudioRawFrame#623', metadata: {} at 13.08s
2026-01-15 10:31:18.637 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1427, name: 'OutputAudioRawFrame#623', metadata: {} at 13.08s
2026-01-15 10:31:18.637 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1848, name: 'OutputAudioRawFrame#1026', metadata: {} at 13.08s
2026-01-15 10:31:18.638 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1846, name: 'OutputAudioRawFrame#1025', metadata: {} at 13.99s
2026-01-15 10:31:18.638 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1846, name: 'OutputAudioRawFrame#1025', metadata: {} at 13.99s
2026-01-15 10:31:18.638 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1025(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.638 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1846, name: 'OutputAudioRawFrame#1025', metadata: {} at 13.99s
2026-01-15 10:31:18.638 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1846, name: 'OutputAudioRawFrame#1025', metadata: {} at 13.99s
2026-01-15 10:31:18.639 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1846, name: 'OutputAudioRawFrame#1025', metadata: {} at 13.99s
2026-01-15 10:31:18.639 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1025(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.639 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1846, name: 'OutputAudioRawFrame#1025', metadata: {} at 13.99s
2026-01-15 10:31:18.639 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1846, name: 'OutputAudioRawFrame#1025', metadata: {} at 13.99s
2026-01-15 10:31:18.639 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1846, name: 'OutputAudioRawFrame#1025', metadata: {} at 13.99s
2026-01-15 10:31:18.676 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1429, name: 'OutputAudioRawFrame#625', metadata: {} at 13.12s
2026-01-15 10:31:18.676 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1429, name: 'OutputAudioRawFrame#625', metadata: {} at 13.12s
2026-01-15 10:31:18.678 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1852, name: 'OutputAudioRawFrame#1029', metadata: {} at 13.12s
2026-01-15 10:31:18.678 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1850, name: 'OutputAudioRawFrame#1028', metadata: {} at 14.03s
2026-01-15 10:31:18.678 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1850, name: 'OutputAudioRawFrame#1028', metadata: {} at 14.03s
2026-01-15 10:31:18.678 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1028(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.678 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1850, name: 'OutputAudioRawFrame#1028', metadata: {} at 14.03s
2026-01-15 10:31:18.679 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1850, name: 'OutputAudioRawFrame#1028', metadata: {} at 14.03s
2026-01-15 10:31:18.679 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1850, name: 'OutputAudioRawFrame#1028', metadata: {} at 14.03s
2026-01-15 10:31:18.679 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1028(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.679 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1850, name: 'OutputAudioRawFrame#1028', metadata: {} at 14.03s
2026-01-15 10:31:18.679 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1850, name: 'OutputAudioRawFrame#1028', metadata: {} at 14.03s
2026-01-15 10:31:18.679 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1850, name: 'OutputAudioRawFrame#1028', metadata: {} at 14.03s
2026-01-15 10:31:18.716 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1431, name: 'OutputAudioRawFrame#627', metadata: {} at 13.16s
2026-01-15 10:31:18.717 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1431, name: 'OutputAudioRawFrame#627', metadata: {} at 13.16s
2026-01-15 10:31:18.718 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1857, name: 'OutputAudioRawFrame#1033', metadata: {} at 13.16s
2026-01-15 10:31:18.718 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1855, name: 'OutputAudioRawFrame#1032', metadata: {} at 14.07s
2026-01-15 10:31:18.718 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1855, name: 'OutputAudioRawFrame#1032', metadata: {} at 14.07s
2026-01-15 10:31:18.718 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1032(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.718 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1855, name: 'OutputAudioRawFrame#1032', metadata: {} at 14.07s
2026-01-15 10:31:18.719 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1855, name: 'OutputAudioRawFrame#1032', metadata: {} at 14.07s
2026-01-15 10:31:18.719 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1855, name: 'OutputAudioRawFrame#1032', metadata: {} at 14.07s
2026-01-15 10:31:18.719 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1032(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.719 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1855, name: 'OutputAudioRawFrame#1032', metadata: {} at 14.07s
2026-01-15 10:31:18.719 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1855, name: 'OutputAudioRawFrame#1032', metadata: {} at 14.07s
2026-01-15 10:31:18.719 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1855, name: 'OutputAudioRawFrame#1032', metadata: {} at 14.07s
2026-01-15 10:31:18.756 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1432, name: 'OutputAudioRawFrame#628', metadata: {} at 13.20s
2026-01-15 10:31:18.756 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1432, name: 'OutputAudioRawFrame#628', metadata: {} at 13.20s
2026-01-15 10:31:18.758 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1860, name: 'OutputAudioRawFrame#1036', metadata: {} at 14.11s
2026-01-15 10:31:18.758 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1862, name: 'OutputAudioRawFrame#1037', metadata: {} at 13.20s
2026-01-15 10:31:18.758 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1860, name: 'OutputAudioRawFrame#1036', metadata: {} at 14.11s
2026-01-15 10:31:18.758 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1036(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.758 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1860, name: 'OutputAudioRawFrame#1036', metadata: {} at 14.11s
2026-01-15 10:31:18.759 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1860, name: 'OutputAudioRawFrame#1036', metadata: {} at 14.11s
2026-01-15 10:31:18.759 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1860, name: 'OutputAudioRawFrame#1036', metadata: {} at 14.11s
2026-01-15 10:31:18.759 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1036(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.759 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1860, name: 'OutputAudioRawFrame#1036', metadata: {} at 14.11s
2026-01-15 10:31:18.759 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1860, name: 'OutputAudioRawFrame#1036', metadata: {} at 14.11s
2026-01-15 10:31:18.759 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1860, name: 'OutputAudioRawFrame#1036', metadata: {} at 14.11s
2026-01-15 10:31:18.796 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1434, name: 'OutputAudioRawFrame#630', metadata: {} at 13.24s
2026-01-15 10:31:18.796 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1434, name: 'OutputAudioRawFrame#630', metadata: {} at 13.24s
2026-01-15 10:31:18.797 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1866, name: 'OutputAudioRawFrame#1041', metadata: {} at 14.15s
2026-01-15 10:31:18.797 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1866, name: 'OutputAudioRawFrame#1041', metadata: {} at 14.15s
2026-01-15 10:31:18.797 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1041(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.797 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1866, name: 'OutputAudioRawFrame#1041', metadata: {} at 14.15s
2026-01-15 10:31:18.798 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1866, name: 'OutputAudioRawFrame#1041', metadata: {} at 14.15s
2026-01-15 10:31:18.798 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1866, name: 'OutputAudioRawFrame#1041', metadata: {} at 14.15s
2026-01-15 10:31:18.798 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1041(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.798 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1866, name: 'OutputAudioRawFrame#1041', metadata: {} at 14.15s
2026-01-15 10:31:18.798 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1866, name: 'OutputAudioRawFrame#1041', metadata: {} at 14.15s
2026-01-15 10:31:18.798 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1866, name: 'OutputAudioRawFrame#1041', metadata: {} at 14.15s
2026-01-15 10:31:18.798 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1868, name: 'OutputAudioRawFrame#1042', metadata: {} at 13.24s
2026-01-15 10:31:18.836 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1435, name: 'OutputAudioRawFrame#631', metadata: {} at 13.28s
2026-01-15 10:31:18.836 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1435, name: 'OutputAudioRawFrame#631', metadata: {} at 13.28s
2026-01-15 10:31:18.838 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1871, name: 'OutputAudioRawFrame#1045', metadata: {} at 14.19s
2026-01-15 10:31:18.838 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1871, name: 'OutputAudioRawFrame#1045', metadata: {} at 14.19s
2026-01-15 10:31:18.838 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1045(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.838 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1871, name: 'OutputAudioRawFrame#1045', metadata: {} at 14.19s
2026-01-15 10:31:18.839 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1871, name: 'OutputAudioRawFrame#1045', metadata: {} at 14.19s
2026-01-15 10:31:18.839 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1871, name: 'OutputAudioRawFrame#1045', metadata: {} at 14.19s
2026-01-15 10:31:18.839 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1045(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.839 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1873, name: 'OutputAudioRawFrame#1046', metadata: {} at 13.28s
2026-01-15 10:31:18.839 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1871, name: 'OutputAudioRawFrame#1045', metadata: {} at 14.19s
2026-01-15 10:31:18.840 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1871, name: 'OutputAudioRawFrame#1045', metadata: {} at 14.19s
2026-01-15 10:31:18.840 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1871, name: 'OutputAudioRawFrame#1045', metadata: {} at 14.19s
2026-01-15 10:31:18.876 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1436, name: 'OutputAudioRawFrame#632', metadata: {} at 13.32s
2026-01-15 10:31:18.876 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1436, name: 'OutputAudioRawFrame#632', metadata: {} at 13.32s
2026-01-15 10:31:18.878 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1876, name: 'OutputAudioRawFrame#1049', metadata: {} at 14.23s
2026-01-15 10:31:18.878 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1876, name: 'OutputAudioRawFrame#1049', metadata: {} at 14.23s
2026-01-15 10:31:18.878 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1049(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.878 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1876, name: 'OutputAudioRawFrame#1049', metadata: {} at 14.23s
2026-01-15 10:31:18.879 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1876, name: 'OutputAudioRawFrame#1049', metadata: {} at 14.23s
2026-01-15 10:31:18.879 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1876, name: 'OutputAudioRawFrame#1049', metadata: {} at 14.23s
2026-01-15 10:31:18.879 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1049(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.879 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1876, name: 'OutputAudioRawFrame#1049', metadata: {} at 14.23s
2026-01-15 10:31:18.879 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1876, name: 'OutputAudioRawFrame#1049', metadata: {} at 14.23s
2026-01-15 10:31:18.879 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1876, name: 'OutputAudioRawFrame#1049', metadata: {} at 14.23s
2026-01-15 10:31:18.879 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1878, name: 'OutputAudioRawFrame#1050', metadata: {} at 13.32s
2026-01-15 10:31:18.917 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1438, name: 'OutputAudioRawFrame#634', metadata: {} at 13.36s
2026-01-15 10:31:18.917 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1438, name: 'OutputAudioRawFrame#634', metadata: {} at 13.36s
2026-01-15 10:31:18.919 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1880, name: 'OutputAudioRawFrame#1052', metadata: {} at 14.27s
2026-01-15 10:31:18.919 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1880, name: 'OutputAudioRawFrame#1052', metadata: {} at 14.27s
2026-01-15 10:31:18.919 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1052(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.919 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1880, name: 'OutputAudioRawFrame#1052', metadata: {} at 14.27s
2026-01-15 10:31:18.920 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1880, name: 'OutputAudioRawFrame#1052', metadata: {} at 14.27s
2026-01-15 10:31:18.920 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1880, name: 'OutputAudioRawFrame#1052', metadata: {} at 14.27s
2026-01-15 10:31:18.920 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1052(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.920 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1882, name: 'OutputAudioRawFrame#1053', metadata: {} at 13.36s
2026-01-15 10:31:18.920 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1880, name: 'OutputAudioRawFrame#1052', metadata: {} at 14.27s
2026-01-15 10:31:18.920 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1880, name: 'OutputAudioRawFrame#1052', metadata: {} at 14.27s
2026-01-15 10:31:18.921 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1880, name: 'OutputAudioRawFrame#1052', metadata: {} at 14.27s
2026-01-15 10:31:18.957 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1439, name: 'OutputAudioRawFrame#635', metadata: {} at 13.40s
2026-01-15 10:31:18.957 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1439, name: 'OutputAudioRawFrame#635', metadata: {} at 13.40s
2026-01-15 10:31:18.959 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1885, name: 'OutputAudioRawFrame#1056', metadata: {} at 14.31s
2026-01-15 10:31:18.959 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1885, name: 'OutputAudioRawFrame#1056', metadata: {} at 14.31s
2026-01-15 10:31:18.959 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1056(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.959 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1885, name: 'OutputAudioRawFrame#1056', metadata: {} at 14.31s
2026-01-15 10:31:18.960 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1885, name: 'OutputAudioRawFrame#1056', metadata: {} at 14.31s
2026-01-15 10:31:18.960 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1885, name: 'OutputAudioRawFrame#1056', metadata: {} at 14.31s
2026-01-15 10:31:18.960 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1056(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.960 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1885, name: 'OutputAudioRawFrame#1056', metadata: {} at 14.31s
2026-01-15 10:31:18.960 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1885, name: 'OutputAudioRawFrame#1056', metadata: {} at 14.31s
2026-01-15 10:31:18.960 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1885, name: 'OutputAudioRawFrame#1056', metadata: {} at 14.31s
2026-01-15 10:31:18.960 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1887, name: 'OutputAudioRawFrame#1057', metadata: {} at 13.40s
2026-01-15 10:31:18.996 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1441, name: 'OutputAudioRawFrame#637', metadata: {} at 13.44s
2026-01-15 10:31:18.996 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1441, name: 'OutputAudioRawFrame#637', metadata: {} at 13.44s
2026-01-15 10:31:18.998 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1890, name: 'OutputAudioRawFrame#1060', metadata: {} at 14.35s
2026-01-15 10:31:18.998 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1890, name: 'OutputAudioRawFrame#1060', metadata: {} at 14.35s
2026-01-15 10:31:18.998 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1060(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.998 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1890, name: 'OutputAudioRawFrame#1060', metadata: {} at 14.35s
2026-01-15 10:31:18.999 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1890, name: 'OutputAudioRawFrame#1060', metadata: {} at 14.35s
2026-01-15 10:31:18.999 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1890, name: 'OutputAudioRawFrame#1060', metadata: {} at 14.35s
2026-01-15 10:31:18.999 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1060(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:18.999 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1890, name: 'OutputAudioRawFrame#1060', metadata: {} at 14.35s
2026-01-15 10:31:18.999 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1890, name: 'OutputAudioRawFrame#1060', metadata: {} at 14.35s
2026-01-15 10:31:18.999 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1890, name: 'OutputAudioRawFrame#1060', metadata: {} at 14.35s
2026-01-15 10:31:19.001 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1892, name: 'OutputAudioRawFrame#1061', metadata: {} at 13.44s
2026-01-15 10:31:19.036 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1442, name: 'OutputAudioRawFrame#638', metadata: {} at 13.48s
2026-01-15 10:31:19.037 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1442, name: 'OutputAudioRawFrame#638', metadata: {} at 13.48s
2026-01-15 10:31:19.038 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1896, name: 'OutputAudioRawFrame#1065', metadata: {} at 14.39s
2026-01-15 10:31:19.038 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1896, name: 'OutputAudioRawFrame#1065', metadata: {} at 14.39s
2026-01-15 10:31:19.038 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1065(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.038 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1896, name: 'OutputAudioRawFrame#1065', metadata: {} at 14.39s
2026-01-15 10:31:19.039 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1896, name: 'OutputAudioRawFrame#1065', metadata: {} at 14.39s
2026-01-15 10:31:19.039 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1896, name: 'OutputAudioRawFrame#1065', metadata: {} at 14.39s
2026-01-15 10:31:19.039 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1065(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.039 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1896, name: 'OutputAudioRawFrame#1065', metadata: {} at 14.39s
2026-01-15 10:31:19.039 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1896, name: 'OutputAudioRawFrame#1065', metadata: {} at 14.39s
2026-01-15 10:31:19.039 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1896, name: 'OutputAudioRawFrame#1065', metadata: {} at 14.39s
2026-01-15 10:31:19.041 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: OutputAudioRawFrame sample_rate: 48000, num_channels: 2, num_frames: 1920, id: 1898, name: 'OutputAudioRawFrame#1066', metadata: {} at 13.48s
2026-01-15 10:31:19.076 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1444, name: 'OutputAudioRawFrame#640', metadata: {} at 13.52s
2026-01-15 10:31:19.076 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1444, name: 'OutputAudioRawFrame#640', metadata: {} at 13.52s
2026-01-15 10:31:19.078 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1901, name: 'OutputAudioRawFrame#1069', metadata: {} at 14.43s
2026-01-15 10:31:19.078 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1901, name: 'OutputAudioRawFrame#1069', metadata: {} at 14.43s
2026-01-15 10:31:19.078 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1069(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.078 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1901, name: 'OutputAudioRawFrame#1069', metadata: {} at 14.43s
2026-01-15 10:31:19.079 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1901, name: 'OutputAudioRawFrame#1069', metadata: {} at 14.43s
2026-01-15 10:31:19.079 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1901, name: 'OutputAudioRawFrame#1069', metadata: {} at 14.43s
2026-01-15 10:31:19.079 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1069(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.079 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1901, name: 'OutputAudioRawFrame#1069', metadata: {} at 14.43s
2026-01-15 10:31:19.079 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1901, name: 'OutputAudioRawFrame#1069', metadata: {} at 14.43s
2026-01-15 10:31:19.079 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1901, name: 'OutputAudioRawFrame#1069', metadata: {} at 14.43s
2026-01-15 10:31:19.081 | INFO     | [EVAL-SYS] | Finished streaming audio: /Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_1_english_speak_slowly.wav
2026-01-15 10:31:19.117 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1445, name: 'OutputAudioRawFrame#641', metadata: {} at 13.56s
2026-01-15 10:31:19.117 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1445, name: 'OutputAudioRawFrame#641', metadata: {} at 13.56s
2026-01-15 10:31:19.118 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1903, name: 'OutputAudioRawFrame#1070', metadata: {} at 14.47s
2026-01-15 10:31:19.118 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1903, name: 'OutputAudioRawFrame#1070', metadata: {} at 14.47s
2026-01-15 10:31:19.118 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1070(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.118 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1903, name: 'OutputAudioRawFrame#1070', metadata: {} at 14.47s
2026-01-15 10:31:19.119 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1903, name: 'OutputAudioRawFrame#1070', metadata: {} at 14.47s
2026-01-15 10:31:19.119 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1903, name: 'OutputAudioRawFrame#1070', metadata: {} at 14.47s
2026-01-15 10:31:19.119 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1070(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.119 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1903, name: 'OutputAudioRawFrame#1070', metadata: {} at 14.47s
2026-01-15 10:31:19.119 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1903, name: 'OutputAudioRawFrame#1070', metadata: {} at 14.47s
2026-01-15 10:31:19.119 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1903, name: 'OutputAudioRawFrame#1070', metadata: {} at 14.47s
2026-01-15 10:31:19.156 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1447, name: 'OutputAudioRawFrame#643', metadata: {} at 13.60s
2026-01-15 10:31:19.156 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1447, name: 'OutputAudioRawFrame#643', metadata: {} at 13.60s
2026-01-15 10:31:19.158 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1905, name: 'OutputAudioRawFrame#1071', metadata: {} at 14.51s
2026-01-15 10:31:19.158 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1905, name: 'OutputAudioRawFrame#1071', metadata: {} at 14.51s
2026-01-15 10:31:19.158 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1071(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.158 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1905, name: 'OutputAudioRawFrame#1071', metadata: {} at 14.51s
2026-01-15 10:31:19.159 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1905, name: 'OutputAudioRawFrame#1071', metadata: {} at 14.51s
2026-01-15 10:31:19.159 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1905, name: 'OutputAudioRawFrame#1071', metadata: {} at 14.51s
2026-01-15 10:31:19.159 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1071(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.159 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1905, name: 'OutputAudioRawFrame#1071', metadata: {} at 14.51s
2026-01-15 10:31:19.159 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1905, name: 'OutputAudioRawFrame#1071', metadata: {} at 14.51s
2026-01-15 10:31:19.159 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1905, name: 'OutputAudioRawFrame#1071', metadata: {} at 14.51s
2026-01-15 10:31:19.197 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1449, name: 'OutputAudioRawFrame#645', metadata: {} at 13.64s
2026-01-15 10:31:19.197 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1449, name: 'OutputAudioRawFrame#645', metadata: {} at 13.64s
2026-01-15 10:31:19.201 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1907, name: 'OutputAudioRawFrame#1072', metadata: {} at 14.56s
2026-01-15 10:31:19.201 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1907, name: 'OutputAudioRawFrame#1072', metadata: {} at 14.56s
2026-01-15 10:31:19.201 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1072(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.202 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1907, name: 'OutputAudioRawFrame#1072', metadata: {} at 14.56s
2026-01-15 10:31:19.203 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1907, name: 'OutputAudioRawFrame#1072', metadata: {} at 14.56s
2026-01-15 10:31:19.203 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1907, name: 'OutputAudioRawFrame#1072', metadata: {} at 14.56s
2026-01-15 10:31:19.203 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1072(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.203 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1907, name: 'OutputAudioRawFrame#1072', metadata: {} at 14.56s
2026-01-15 10:31:19.204 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1907, name: 'OutputAudioRawFrame#1072', metadata: {} at 14.56s
2026-01-15 10:31:19.204 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1907, name: 'OutputAudioRawFrame#1072', metadata: {} at 14.56s
2026-01-15 10:31:19.237 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1450, name: 'OutputAudioRawFrame#646', metadata: {} at 13.68s
2026-01-15 10:31:19.237 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1450, name: 'OutputAudioRawFrame#646', metadata: {} at 13.68s
2026-01-15 10:31:19.241 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1909, name: 'OutputAudioRawFrame#1073', metadata: {} at 14.60s
2026-01-15 10:31:19.241 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1909, name: 'OutputAudioRawFrame#1073', metadata: {} at 14.60s
2026-01-15 10:31:19.242 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1073(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.242 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1909, name: 'OutputAudioRawFrame#1073', metadata: {} at 14.60s
2026-01-15 10:31:19.243 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1909, name: 'OutputAudioRawFrame#1073', metadata: {} at 14.60s
2026-01-15 10:31:19.243 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1909, name: 'OutputAudioRawFrame#1073', metadata: {} at 14.60s
2026-01-15 10:31:19.243 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1073(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.243 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1909, name: 'OutputAudioRawFrame#1073', metadata: {} at 14.60s
2026-01-15 10:31:19.244 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1909, name: 'OutputAudioRawFrame#1073', metadata: {} at 14.60s
2026-01-15 10:31:19.244 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1909, name: 'OutputAudioRawFrame#1073', metadata: {} at 14.60s
2026-01-15 10:31:19.277 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1452, name: 'OutputAudioRawFrame#648', metadata: {} at 13.72s
2026-01-15 10:31:19.277 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1452, name: 'OutputAudioRawFrame#648', metadata: {} at 13.72s
2026-01-15 10:31:19.279 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1911, name: 'OutputAudioRawFrame#1074', metadata: {} at 14.63s
2026-01-15 10:31:19.280 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1911, name: 'OutputAudioRawFrame#1074', metadata: {} at 14.63s
2026-01-15 10:31:19.280 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1074(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.280 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1911, name: 'OutputAudioRawFrame#1074', metadata: {} at 14.63s
2026-01-15 10:31:19.280 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1911, name: 'OutputAudioRawFrame#1074', metadata: {} at 14.63s
2026-01-15 10:31:19.281 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1911, name: 'OutputAudioRawFrame#1074', metadata: {} at 14.63s
2026-01-15 10:31:19.281 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1074(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.281 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1911, name: 'OutputAudioRawFrame#1074', metadata: {} at 14.64s
2026-01-15 10:31:19.281 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1911, name: 'OutputAudioRawFrame#1074', metadata: {} at 14.64s
2026-01-15 10:31:19.281 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1911, name: 'OutputAudioRawFrame#1074', metadata: {} at 14.64s
2026-01-15 10:31:19.317 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1453, name: 'OutputAudioRawFrame#649', metadata: {} at 13.76s
2026-01-15 10:31:19.317 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1453, name: 'OutputAudioRawFrame#649', metadata: {} at 13.76s
2026-01-15 10:31:19.319 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1913, name: 'OutputAudioRawFrame#1075', metadata: {} at 14.67s
2026-01-15 10:31:19.319 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1913, name: 'OutputAudioRawFrame#1075', metadata: {} at 14.67s
2026-01-15 10:31:19.319 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1075(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.319 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1913, name: 'OutputAudioRawFrame#1075', metadata: {} at 14.67s
2026-01-15 10:31:19.320 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1913, name: 'OutputAudioRawFrame#1075', metadata: {} at 14.67s
2026-01-15 10:31:19.320 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1913, name: 'OutputAudioRawFrame#1075', metadata: {} at 14.67s
2026-01-15 10:31:19.320 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1075(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.320 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1913, name: 'OutputAudioRawFrame#1075', metadata: {} at 14.67s
2026-01-15 10:31:19.320 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1913, name: 'OutputAudioRawFrame#1075', metadata: {} at 14.67s
2026-01-15 10:31:19.320 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1913, name: 'OutputAudioRawFrame#1075', metadata: {} at 14.67s
2026-01-15 10:31:19.356 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1455, name: 'OutputAudioRawFrame#651', metadata: {} at 13.80s
2026-01-15 10:31:19.357 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1455, name: 'OutputAudioRawFrame#651', metadata: {} at 13.80s
2026-01-15 10:31:19.359 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1915, name: 'OutputAudioRawFrame#1076', metadata: {} at 14.71s
2026-01-15 10:31:19.359 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1915, name: 'OutputAudioRawFrame#1076', metadata: {} at 14.71s
2026-01-15 10:31:19.359 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1076(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.359 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1915, name: 'OutputAudioRawFrame#1076', metadata: {} at 14.71s
2026-01-15 10:31:19.360 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1915, name: 'OutputAudioRawFrame#1076', metadata: {} at 14.71s
2026-01-15 10:31:19.360 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1915, name: 'OutputAudioRawFrame#1076', metadata: {} at 14.71s
2026-01-15 10:31:19.360 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1076(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.360 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1915, name: 'OutputAudioRawFrame#1076', metadata: {} at 14.71s
2026-01-15 10:31:19.360 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1915, name: 'OutputAudioRawFrame#1076', metadata: {} at 14.71s
2026-01-15 10:31:19.360 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1915, name: 'OutputAudioRawFrame#1076', metadata: {} at 14.71s
2026-01-15 10:31:19.396 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1456, name: 'OutputAudioRawFrame#652', metadata: {} at 13.84s
2026-01-15 10:31:19.396 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1456, name: 'OutputAudioRawFrame#652', metadata: {} at 13.84s
2026-01-15 10:31:19.398 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1917, name: 'OutputAudioRawFrame#1077', metadata: {} at 14.75s
2026-01-15 10:31:19.398 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1917, name: 'OutputAudioRawFrame#1077', metadata: {} at 14.75s
2026-01-15 10:31:19.398 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1077(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.398 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1917, name: 'OutputAudioRawFrame#1077', metadata: {} at 14.75s
2026-01-15 10:31:19.399 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1917, name: 'OutputAudioRawFrame#1077', metadata: {} at 14.75s
2026-01-15 10:31:19.399 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1917, name: 'OutputAudioRawFrame#1077', metadata: {} at 14.75s
2026-01-15 10:31:19.399 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1077(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.399 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1917, name: 'OutputAudioRawFrame#1077', metadata: {} at 14.75s
2026-01-15 10:31:19.399 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1917, name: 'OutputAudioRawFrame#1077', metadata: {} at 14.75s
2026-01-15 10:31:19.399 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1917, name: 'OutputAudioRawFrame#1077', metadata: {} at 14.75s
2026-01-15 10:31:19.436 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1457, name: 'OutputAudioRawFrame#653', metadata: {} at 13.88s
2026-01-15 10:31:19.436 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1457, name: 'OutputAudioRawFrame#653', metadata: {} at 13.88s
2026-01-15 10:31:19.438 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1919, name: 'OutputAudioRawFrame#1078', metadata: {} at 14.79s
2026-01-15 10:31:19.438 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1919, name: 'OutputAudioRawFrame#1078', metadata: {} at 14.79s
2026-01-15 10:31:19.438 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1078(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.438 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1919, name: 'OutputAudioRawFrame#1078', metadata: {} at 14.79s
2026-01-15 10:31:19.438 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1919, name: 'OutputAudioRawFrame#1078', metadata: {} at 14.79s
2026-01-15 10:31:19.439 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1919, name: 'OutputAudioRawFrame#1078', metadata: {} at 14.79s
2026-01-15 10:31:19.439 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1078(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.439 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1919, name: 'OutputAudioRawFrame#1078', metadata: {} at 14.79s
2026-01-15 10:31:19.439 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1919, name: 'OutputAudioRawFrame#1078', metadata: {} at 14.79s
2026-01-15 10:31:19.439 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1919, name: 'OutputAudioRawFrame#1078', metadata: {} at 14.79s
2026-01-15 10:31:19.476 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1459, name: 'OutputAudioRawFrame#655', metadata: {} at 13.92s
2026-01-15 10:31:19.476 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1459, name: 'OutputAudioRawFrame#655', metadata: {} at 13.92s
2026-01-15 10:31:19.478 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1921, name: 'OutputAudioRawFrame#1079', metadata: {} at 14.83s
2026-01-15 10:31:19.478 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1921, name: 'OutputAudioRawFrame#1079', metadata: {} at 14.83s
2026-01-15 10:31:19.478 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1079(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.478 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1921, name: 'OutputAudioRawFrame#1079', metadata: {} at 14.83s
2026-01-15 10:31:19.479 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1921, name: 'OutputAudioRawFrame#1079', metadata: {} at 14.83s
2026-01-15 10:31:19.479 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1921, name: 'OutputAudioRawFrame#1079', metadata: {} at 14.83s
2026-01-15 10:31:19.479 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1079(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.479 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1921, name: 'OutputAudioRawFrame#1079', metadata: {} at 14.83s
2026-01-15 10:31:19.479 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1921, name: 'OutputAudioRawFrame#1079', metadata: {} at 14.83s
2026-01-15 10:31:19.479 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1921, name: 'OutputAudioRawFrame#1079', metadata: {} at 14.83s
2026-01-15 10:31:19.516 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1460, name: 'OutputAudioRawFrame#656', metadata: {} at 13.96s
2026-01-15 10:31:19.517 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1460, name: 'OutputAudioRawFrame#656', metadata: {} at 13.96s
2026-01-15 10:31:19.518 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1923, name: 'OutputAudioRawFrame#1080', metadata: {} at 14.87s
2026-01-15 10:31:19.519 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1923, name: 'OutputAudioRawFrame#1080', metadata: {} at 14.87s
2026-01-15 10:31:19.519 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1080(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.519 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1923, name: 'OutputAudioRawFrame#1080', metadata: {} at 14.87s
2026-01-15 10:31:19.519 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1923, name: 'OutputAudioRawFrame#1080', metadata: {} at 14.87s
2026-01-15 10:31:19.519 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1923, name: 'OutputAudioRawFrame#1080', metadata: {} at 14.87s
2026-01-15 10:31:19.520 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1080(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.520 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1923, name: 'OutputAudioRawFrame#1080', metadata: {} at 14.87s
2026-01-15 10:31:19.520 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1923, name: 'OutputAudioRawFrame#1080', metadata: {} at 14.87s
2026-01-15 10:31:19.520 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1923, name: 'OutputAudioRawFrame#1080', metadata: {} at 14.87s
2026-01-15 10:31:19.557 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1462, name: 'OutputAudioRawFrame#658', metadata: {} at 14.00s
2026-01-15 10:31:19.557 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1462, name: 'OutputAudioRawFrame#658', metadata: {} at 14.00s
2026-01-15 10:31:19.560 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1925, name: 'OutputAudioRawFrame#1081', metadata: {} at 14.91s
2026-01-15 10:31:19.560 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1925, name: 'OutputAudioRawFrame#1081', metadata: {} at 14.91s
2026-01-15 10:31:19.560 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1081(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.560 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1925, name: 'OutputAudioRawFrame#1081', metadata: {} at 14.91s
2026-01-15 10:31:19.561 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1925, name: 'OutputAudioRawFrame#1081', metadata: {} at 14.91s
2026-01-15 10:31:19.561 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1925, name: 'OutputAudioRawFrame#1081', metadata: {} at 14.92s
2026-01-15 10:31:19.561 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1081(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.561 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1925, name: 'OutputAudioRawFrame#1081', metadata: {} at 14.92s
2026-01-15 10:31:19.561 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1925, name: 'OutputAudioRawFrame#1081', metadata: {} at 14.92s
2026-01-15 10:31:19.561 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1925, name: 'OutputAudioRawFrame#1081', metadata: {} at 14.92s
2026-01-15 10:31:19.596 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1463, name: 'OutputAudioRawFrame#659', metadata: {} at 14.04s
2026-01-15 10:31:19.596 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1463, name: 'OutputAudioRawFrame#659', metadata: {} at 14.04s
2026-01-15 10:31:19.600 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1927, name: 'OutputAudioRawFrame#1082', metadata: {} at 14.95s
2026-01-15 10:31:19.600 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1927, name: 'OutputAudioRawFrame#1082', metadata: {} at 14.95s
2026-01-15 10:31:19.600 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1082(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.601 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1927, name: 'OutputAudioRawFrame#1082', metadata: {} at 14.95s
2026-01-15 10:31:19.602 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1927, name: 'OutputAudioRawFrame#1082', metadata: {} at 14.96s
2026-01-15 10:31:19.602 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1927, name: 'OutputAudioRawFrame#1082', metadata: {} at 14.96s
2026-01-15 10:31:19.602 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1082(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.602 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1927, name: 'OutputAudioRawFrame#1082', metadata: {} at 14.96s
2026-01-15 10:31:19.602 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1927, name: 'OutputAudioRawFrame#1082', metadata: {} at 14.96s
2026-01-15 10:31:19.602 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1927, name: 'OutputAudioRawFrame#1082', metadata: {} at 14.96s
2026-01-15 10:31:19.637 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1465, name: 'OutputAudioRawFrame#661', metadata: {} at 14.08s
2026-01-15 10:31:19.637 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1465, name: 'OutputAudioRawFrame#661', metadata: {} at 14.08s
2026-01-15 10:31:19.641 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1929, name: 'OutputAudioRawFrame#1083', metadata: {} at 14.99s
2026-01-15 10:31:19.641 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1929, name: 'OutputAudioRawFrame#1083', metadata: {} at 15.00s
2026-01-15 10:31:19.641 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1083(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.642 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1929, name: 'OutputAudioRawFrame#1083', metadata: {} at 15.00s
2026-01-15 10:31:19.643 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1929, name: 'OutputAudioRawFrame#1083', metadata: {} at 15.00s
2026-01-15 10:31:19.643 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1929, name: 'OutputAudioRawFrame#1083', metadata: {} at 15.00s
2026-01-15 10:31:19.643 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1083(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.644 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1929, name: 'OutputAudioRawFrame#1083', metadata: {} at 15.00s
2026-01-15 10:31:19.644 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1929, name: 'OutputAudioRawFrame#1083', metadata: {} at 15.00s
2026-01-15 10:31:19.644 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1929, name: 'OutputAudioRawFrame#1083', metadata: {} at 15.00s
2026-01-15 10:31:19.677 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1467, name: 'OutputAudioRawFrame#663', metadata: {} at 14.12s
2026-01-15 10:31:19.677 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1467, name: 'OutputAudioRawFrame#663', metadata: {} at 14.12s
2026-01-15 10:31:19.680 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1931, name: 'OutputAudioRawFrame#1084', metadata: {} at 15.03s
2026-01-15 10:31:19.681 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1931, name: 'OutputAudioRawFrame#1084', metadata: {} at 15.03s
2026-01-15 10:31:19.681 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1084(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.681 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1931, name: 'OutputAudioRawFrame#1084', metadata: {} at 15.04s
2026-01-15 10:31:19.682 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1931, name: 'OutputAudioRawFrame#1084', metadata: {} at 15.04s
2026-01-15 10:31:19.682 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1931, name: 'OutputAudioRawFrame#1084', metadata: {} at 15.04s
2026-01-15 10:31:19.682 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1084(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.682 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1931, name: 'OutputAudioRawFrame#1084', metadata: {} at 15.04s
2026-01-15 10:31:19.682 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1931, name: 'OutputAudioRawFrame#1084', metadata: {} at 15.04s
2026-01-15 10:31:19.682 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1931, name: 'OutputAudioRawFrame#1084', metadata: {} at 15.04s
2026-01-15 10:31:19.716 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1468, name: 'OutputAudioRawFrame#664', metadata: {} at 14.16s
2026-01-15 10:31:19.717 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1468, name: 'OutputAudioRawFrame#664', metadata: {} at 14.16s
2026-01-15 10:31:19.721 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1933, name: 'OutputAudioRawFrame#1085', metadata: {} at 15.07s
2026-01-15 10:31:19.721 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1933, name: 'OutputAudioRawFrame#1085', metadata: {} at 15.08s
2026-01-15 10:31:19.721 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1085(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.721 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1933, name: 'OutputAudioRawFrame#1085', metadata: {} at 15.08s
2026-01-15 10:31:19.722 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1933, name: 'OutputAudioRawFrame#1085', metadata: {} at 15.08s
2026-01-15 10:31:19.723 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1933, name: 'OutputAudioRawFrame#1085', metadata: {} at 15.08s
2026-01-15 10:31:19.723 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1085(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.723 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1933, name: 'OutputAudioRawFrame#1085', metadata: {} at 15.08s
2026-01-15 10:31:19.723 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1933, name: 'OutputAudioRawFrame#1085', metadata: {} at 15.08s
2026-01-15 10:31:19.723 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1933, name: 'OutputAudioRawFrame#1085', metadata: {} at 15.08s
2026-01-15 10:31:19.757 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1470, name: 'OutputAudioRawFrame#666', metadata: {} at 14.20s
2026-01-15 10:31:19.757 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1470, name: 'OutputAudioRawFrame#666', metadata: {} at 14.20s
2026-01-15 10:31:19.759 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1935, name: 'OutputAudioRawFrame#1086', metadata: {} at 15.11s
2026-01-15 10:31:19.760 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1935, name: 'OutputAudioRawFrame#1086', metadata: {} at 15.11s
2026-01-15 10:31:19.760 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1086(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.760 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1935, name: 'OutputAudioRawFrame#1086', metadata: {} at 15.11s
2026-01-15 10:31:19.761 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1935, name: 'OutputAudioRawFrame#1086', metadata: {} at 15.12s
2026-01-15 10:31:19.761 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1935, name: 'OutputAudioRawFrame#1086', metadata: {} at 15.12s
2026-01-15 10:31:19.761 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1086(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.762 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1935, name: 'OutputAudioRawFrame#1086', metadata: {} at 15.12s
2026-01-15 10:31:19.762 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1935, name: 'OutputAudioRawFrame#1086', metadata: {} at 15.12s
2026-01-15 10:31:19.762 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1935, name: 'OutputAudioRawFrame#1086', metadata: {} at 15.12s
2026-01-15 10:31:19.797 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1471, name: 'OutputAudioRawFrame#667', metadata: {} at 14.24s
2026-01-15 10:31:19.797 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: OutputAudioRawFrame sample_rate: 16000, num_channels: 2, num_frames: 320, id: 1471, name: 'OutputAudioRawFrame#667', metadata: {} at 14.24s
2026-01-15 10:31:19.800 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1937, name: 'OutputAudioRawFrame#1087', metadata: {} at 15.15s
2026-01-15 10:31:19.800 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1937, name: 'OutputAudioRawFrame#1087', metadata: {} at 15.15s
2026-01-15 10:31:19.800 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#1087(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.800 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1937, name: 'OutputAudioRawFrame#1087', metadata: {} at 15.15s
2026-01-15 10:31:19.801 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1937, name: 'OutputAudioRawFrame#1087', metadata: {} at 15.16s
2026-01-15 10:31:19.801 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1937, name: 'OutputAudioRawFrame#1087', metadata: {} at 15.16s
2026-01-15 10:31:19.802 | INFO     | [BOT-SYS] | output bot frame: OutputAudioRawFrame#1087(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
2026-01-15 10:31:19.802 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1937, name: 'OutputAudioRawFrame#1087', metadata: {} at 15.16s
2026-01-15 10:31:19.802 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1937, name: 'OutputAudioRawFrame#1087', metadata: {} at 15.16s
2026-01-15 10:31:19.802 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: InputAudioRawFrame sample_rate: 16000, num_channels: 1, num_frames: 640, id: 1937, name: 'OutputAudioRawFrame#1087', metadata: {} at 15.16s
2026-01-15 10:31:19.815 | DEBUG    | [EVAL-SYS] | Pipeline task PipelineTask#1 got cancelled from outside...
2026-01-15 10:31:19.815 | DEBUG    | [EVAL-SYS] | Cancelling pipeline task PipelineTask#1
2026-01-15 10:31:19.815 | DEBUG    | [EVAL-SYS] | PipelineTask#1: Closing. Waiting for CancelFrame#0(reason: None) to reach the end of the pipeline...
2026-01-15 10:31:19.815 | DEBUG    | [EVAL-SYS] | PipelineTask#1::Source â†’ Pipeline#2: CancelFrame id: 1939, name: 'CancelFrame#0', metadata: {} at 14.26s
2026-01-15 10:31:19.816 | DEBUG    | [EVAL-SYS] | Pipeline#2::Source â†’ WebsocketClientInputTransport#0: CancelFrame id: 1939, name: 'CancelFrame#0', metadata: {} at 14.26s
2026-01-15 10:31:19.816 | DEBUG    | [EVAL-SYS] | Ended tracing for Turn 1
2026-01-15 10:31:19.816 | DEBUG    | [EVAL-SYS] | WebsocketClientInputTransport#0 â†’ IOLogger#2: CancelFrame id: 1939, name: 'CancelFrame#0', metadata: {} at 14.26s
2026-01-15 10:31:19.816 | INFO     | [EVAL-SYS] | eval frame: CancelFrame#0(reason: None)
2026-01-15 10:31:19.816 | INFO     | [EVAL-SYS] | frame transcription logger: CancelFrame#0(reason: None)
2026-01-15 10:31:19.816 | INFO     | [EVAL-SYS] | is_bot_turn_over: False
2026-01-15 10:31:19.816 | INFO     | [EVAL-SYS] | state: stream_complete
2026-01-15 10:31:19.816 | DEBUG    | [EVAL-SYS] | IOLogger#2 â†’ TranscriptionWriter: CancelFrame id: 1939, name: 'CancelFrame#0', metadata: {} at 14.26s
2026-01-15 10:31:19.816 | DEBUG    | [EVAL-SYS] | TranscriptionWriter â†’ MetricsLogger: CancelFrame id: 1939, name: 'CancelFrame#0', metadata: {} at 14.26s
2026-01-15 10:31:19.817 | DEBUG    | [EVAL-SYS] | MetricsLogger â†’ BotTurnAudioStreamer: CancelFrame id: 1939, name: 'CancelFrame#0', metadata: {} at 14.26s
2026-01-15 10:31:19.817 | DEBUG    | [EVAL-SYS] | BotTurnAudioStreamer â†’ WebsocketClientOutputTransport#0: CancelFrame id: 1939, name: 'CancelFrame#0', metadata: {} at 14.26s
2026-01-15 10:31:19.818 | WARNING  | [BOT-SYS] | Only one client allowed, using new connection
2026-01-15 10:31:19.818 | INFO     | [BOT-SYS] | Client ('::1', 52905, 0, 0) disconnected
2026-01-15 10:31:19.818 | DEBUG    | [EVAL-SYS] | WebsocketClientOutputTransport#0 â†’ Pipeline#2::Sink: CancelFrame id: 1939, name: 'CancelFrame#0', metadata: {} at 14.26s
2026-01-15 10:31:19.818 | DEBUG    | [EVAL-SYS] | Pipeline#2 â†’ PipelineTask#1::Sink: CancelFrame id: 1939, name: 'CancelFrame#0', metadata: {} at 14.26s
2026-01-15 10:31:19.818 | INFO     | [BOT-SYS] | Client disconnected from STT bot
2026-01-15 10:31:19.818 | DEBUG    | [BOT-SYS] | Cancelling pipeline task PipelineTask#0
2026-01-15 10:31:19.818 | DEBUG    | [BOT-SYS] | PipelineTask#0: Closing. Waiting for CancelFrame#1(reason: None) to reach the end of the pipeline...
2026-01-15 10:31:19.818 | DEBUG    | [EVAL-SYS] | PipelineTask#1: CancelFrame#0(reason: None) reached the end of the pipeline.
2026-01-15 10:31:19.818 | DEBUG    | [EVAL-SYS] | Ended tracing for Conversation 2bc3594b-faeb-45e6-8c7f-369fa5ad5eb0
2026-01-15 10:31:19.819 | DEBUG    | [BOT-SYS] | PipelineTask#0::Source â†’ Pipeline#0: CancelFrame id: 1940, name: 'CancelFrame#1', metadata: {} at 15.17s
2026-01-15 10:31:19.819 | DEBUG    | [BOT-SYS] | Pipeline#0::Source â†’ WebsocketServerInputTransport#0: CancelFrame id: 1940, name: 'CancelFrame#1', metadata: {} at 15.17s
2026-01-15 10:31:19.819 | DEBUG    | [BOT-SYS] | Ended tracing for Turn 1
2026-01-15 10:31:19.819 | DEBUG    | [EVAL-SYS] | Pipeline task PipelineTask#1 is finishing...
2026-01-15 10:31:19.819 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#0 â†’ RTVIProcessor#0: CancelFrame id: 1940, name: 'CancelFrame#1', metadata: {} at 15.17s
2026-01-15 10:31:19.820 | DEBUG    | [EVAL-SYS] | Pipeline task PipelineTask#1 has finished
2026-01-15 10:31:19.820 | DEBUG    | [EVAL-SYS] | Runner PipelineRunner#1 finished running PipelineTask#1
2026-01-15 10:31:19.820 | DEBUG    | [BOT-SYS] | Pipeline task PipelineTask#0 got cancelled from outside...
2026-01-15 10:31:19.820 | DEBUG    | [BOT-SYS] | RTVIProcessor#0 â†’ IOLogger#0: CancelFrame id: 1940, name: 'CancelFrame#1', metadata: {} at 15.17s
2026-01-15 10:31:19.820 | INFO     | [BOT-SYS] | input bot frame: CancelFrame#1(reason: None)
2026-01-15 10:31:19.820 | DEBUG    | [BOT-SYS] | IOLogger#0 â†’ SarvamSTTService#0: CancelFrame id: 1940, name: 'CancelFrame#1', metadata: {} at 15.17s
2026-01-15 10:31:19.872 | DEBUG    | [BOT-SYS] | Disconnected from Sarvam WebSocket
2026-01-15 10:31:19.873 | DEBUG    | [BOT-SYS] | SarvamSTTService#0 â†’ UserTranscriptProcessor#0: CancelFrame id: 1940, name: 'CancelFrame#1', metadata: {} at 15.23s
2026-01-15 10:31:19.873 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#0 â†’ IOLogger#1: CancelFrame id: 1940, name: 'CancelFrame#1', metadata: {} at 15.23s
2026-01-15 10:31:19.873 | INFO     | [BOT-SYS] | output bot frame: CancelFrame#1(reason: None)
2026-01-15 10:31:19.873 | DEBUG    | [BOT-SYS] | IOLogger#1 â†’ WebsocketServerOutputTransport#0: CancelFrame id: 1940, name: 'CancelFrame#1', metadata: {} at 15.23s
2026-01-15 10:31:19.874 | WARNING  | [BOT-SYS] | Frame type <class 'pipecat.frames.frames.CancelFrame'> is not serializable
2026-01-15 10:31:19.874 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#0 â†’ Pipeline#0::Sink: CancelFrame id: 1940, name: 'CancelFrame#1', metadata: {} at 15.23s
2026-01-15 10:31:19.874 | DEBUG    | [BOT-SYS] | Pipeline#0 â†’ PipelineTask#0::Sink: CancelFrame id: 1940, name: 'CancelFrame#1', metadata: {} at 15.23s
2026-01-15 10:31:19.874 | DEBUG    | [BOT-SYS] | PipelineTask#0: CancelFrame#1(reason: None) reached the end of the pipeline.
2026-01-15 10:31:19.874 | DEBUG    | [BOT-SYS] | Ended tracing for Conversation c89d8f47-1ed7-4649-8b45-b173edc3550f
2026-01-15 10:31:19.875 | DEBUG    | [BOT-SYS] | Pipeline task PipelineTask#0 is finishing...
2026-01-15 10:31:19.875 | DEBUG    | [BOT-SYS] | Pipeline task PipelineTask#0 has finished
2026-01-15 10:31:19.875 | DEBUG    | [BOT-SYS] | Runner PipelineRunner#0 finished running PipelineTask#0
2026-01-15 10:31:19.876 | INFO     | [EVAL-SYS] | Only 1/123 processed, retrying...
2026-01-15 10:31:19.879 | INFO     | [EVAL-SYS] | Resuming: 1 processed, 122 remaining
2026-01-15 10:31:19.880 | INFO     | [EVAL-SYS] | Loading audio files: [PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_1_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_1_english_speak_closer.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_1_english_repeat_same_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_3_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_3_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_5_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_5_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_7_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_7_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_9_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_9_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_9_english_repeat_other_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_11_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_11_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_13_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_13_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_15_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_15_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_17_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_17_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_19_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_19_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_19_english_speak_farther_away.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_21_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_21_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_23_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_23_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_23_english_repeat_same_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_23_english_repeat_other_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_25_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_25_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_27_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_27_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_29_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_29_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_29_english_speak_farther_away.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_29_english_repeat_same_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_31_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_31_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_31_english_speak_closer.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_33_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_33_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_35_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_35_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_35_english_filler_words.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_37_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_37_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_37_english_speak_closer.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_39_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_39_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_41_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_41_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_41_english_filler_words.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_43_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_43_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_43_english_speak_closer.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_45_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_45_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_45_english_speak_closer.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_47_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_47_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_1_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_1_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_3_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_3_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_5_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_5_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_5_english_speak_farther_away.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_7_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_7_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_9_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_9_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_9_english_speak_closer.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_9_english_repeat_other_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_11_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_11_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_13_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_13_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_13_english_repeat_other_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_15_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_15_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_17_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_17_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_19_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_19_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_19_english_speak_farther_away.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_19_english_repeat_same_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_21_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_21_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_21_english_speak_farther_away.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_23_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_23_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_25_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_25_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_27_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_27_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_27_english_filler_words.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_29_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_29_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_31_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_31_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_31_english_speak_farther_away.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_33_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_33_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_33_english_repeat_same_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_35_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_35_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_37_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_37_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_37_english_speak_farther_away.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_39_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_39_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_41_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_41_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_43_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_43_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_45_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_45_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_45_english_repeat_other_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_47_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_47_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_47_english_repeat_other_speaker.wav')]
2026-01-15 10:31:19.880 | INFO     | [EVAL-SYS] | audio_files: [PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_1_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_1_english_speak_closer.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_1_english_repeat_same_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_3_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_3_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_5_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_5_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_7_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_7_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_9_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_9_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_9_english_repeat_other_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_11_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_11_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_13_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_13_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_15_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_15_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_17_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_17_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_19_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_19_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_19_english_speak_farther_away.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_21_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_21_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_23_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_23_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_23_english_repeat_same_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_23_english_repeat_other_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_25_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_25_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_27_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_27_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_29_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_29_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_29_english_speak_farther_away.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_29_english_repeat_same_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_31_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_31_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_31_english_speak_closer.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_33_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_33_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_35_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_35_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_35_english_filler_words.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_37_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_37_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_37_english_speak_closer.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_39_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_39_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_41_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_41_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_41_english_filler_words.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_43_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_43_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_43_english_speak_closer.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_45_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_45_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_45_english_speak_closer.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_47_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/3_47_english_speak_slowly.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_1_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_1_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_3_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_3_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_5_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_5_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_5_english_speak_farther_away.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_7_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_7_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_9_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_9_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_9_english_speak_closer.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_9_english_repeat_other_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_11_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_11_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_13_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_13_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_13_english_repeat_other_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_15_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_15_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_17_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_17_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_19_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_19_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_19_english_speak_farther_away.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_19_english_repeat_same_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_21_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_21_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_21_english_speak_farther_away.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_23_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_23_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_25_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_25_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_27_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_27_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_27_english_filler_words.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_29_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_29_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_31_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_31_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_31_english_speak_farther_away.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_33_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_33_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_33_english_repeat_same_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_35_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_35_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_37_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_37_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_37_english_speak_farther_away.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_39_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_39_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_41_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_41_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_43_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_43_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_45_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_45_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_45_english_repeat_other_speaker.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_47_english_baseline.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_47_english_speak_faster.wav'), PosixPath('/Users/aman/Documents/repos/artpark/voice-ai/agentloop/data/anc_visit_basic/audios/human/cleaned/v3/english/audios/wav/10_47_english_repeat_other_speaker.wav')]
2026-01-15 10:31:19.882 | DEBUG    | [BOT-SYS] | Loading Silero VAD model...
2026-01-15 10:31:19.935 | DEBUG    | [BOT-SYS] | Loaded Silero VAD
2026-01-15 10:31:19.936 | DEBUG    | [BOT-SYS] | Loading Local Smart Turn v3.x model from /Users/aman/Documents/repos/artpark/agentloop/.venv/lib/python3.11/site-packages/pipecat/audio/turn/smart_turn/data/smart-turn-v3.1-cpu.onnx...
2026-01-15 10:31:19.962 | DEBUG    | [BOT-SYS] | Loaded Local Smart Turn v3.x
2026-01-15 10:31:19.967 | DEBUG    | [BOT-SYS] | Linking Pipeline#4::Source -> WebsocketServerInputTransport#1
2026-01-15 10:31:19.967 | DEBUG    | [BOT-SYS] | Linking WebsocketServerInputTransport#1 -> RTVIProcessor#1
2026-01-15 10:31:19.967 | DEBUG    | [BOT-SYS] | Linking RTVIProcessor#1 -> IOLogger#3
2026-01-15 10:31:19.967 | DEBUG    | [BOT-SYS] | Linking IOLogger#3 -> SarvamSTTService#1
2026-01-15 10:31:19.967 | DEBUG    | [BOT-SYS] | Linking SarvamSTTService#1 -> UserTranscriptProcessor#1
2026-01-15 10:31:19.967 | DEBUG    | [BOT-SYS] | Linking UserTranscriptProcessor#1 -> IOLogger#4
2026-01-15 10:31:19.967 | DEBUG    | [BOT-SYS] | Linking IOLogger#4 -> WebsocketServerOutputTransport#1
2026-01-15 10:31:19.967 | DEBUG    | [BOT-SYS] | Linking WebsocketServerOutputTransport#1 -> Pipeline#4::Sink
2026-01-15 10:31:19.967 | DEBUG    | [BOT-SYS] | Linking PipelineTask#2::Source -> Pipeline#4
2026-01-15 10:31:19.967 | DEBUG    | [BOT-SYS] | Linking Pipeline#4 -> PipelineTask#2::Sink
2026-01-15 10:31:19.967 | INFO     | [BOT-SYS] | STT bot ready and waiting for connections
2026-01-15 10:31:19.967 | DEBUG    | [BOT-SYS] | Runner PipelineRunner#2 started running PipelineTask#2
2026-01-15 10:31:19.967 | DEBUG    | [BOT-SYS] | PipelineTask#2: Starting. Waiting for StartFrame#2 to reach the end of the pipeline...
2026-01-15 10:31:19.968 | DEBUG    | [BOT-SYS] | PipelineTask#2::Source â†’ Pipeline#4: StartFrame id: 1976, name: 'StartFrame#2', metadata: {}, audio_in_sample_rate: 16000, audio_out_sample_rate: 24000, allow_interruptions: True, enable_metrics: True, enable_tracing: True, enable_usage_metrics: False, interruption_strategies: [], report_only_initial_ttfb: False at 0.00s
2026-01-15 10:31:19.968 | DEBUG    | [BOT-SYS] | Pipeline#4::Source â†’ WebsocketServerInputTransport#1: StartFrame id: 1976, name: 'StartFrame#2', metadata: {}, audio_in_sample_rate: 16000, audio_out_sample_rate: 24000, allow_interruptions: True, enable_metrics: True, enable_tracing: True, enable_usage_metrics: False, interruption_strategies: [], report_only_initial_ttfb: False at 0.00s
2026-01-15 10:31:19.968 | DEBUG    | [BOT-SYS] | Setting VAD params to: confidence=0.7 start_secs=0.2 stop_secs=0.2 min_volume=0.6
2026-01-15 10:31:19.968 | DEBUG    | [BOT-SYS] | Generated new conversation ID: c5b71de4-9d58-40dd-ad50-e94fe630be94
2026-01-15 10:31:19.968 | DEBUG    | [BOT-SYS] | Started tracing for Conversation c5b71de4-9d58-40dd-ad50-e94fe630be94
2026-01-15 10:31:19.968 | DEBUG    | [BOT-SYS] | Started tracing for Turn 1
2026-01-15 10:31:19.968 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#1 â†’ RTVIProcessor#1: StartFrame id: 1976, name: 'StartFrame#2', metadata: {}, audio_in_sample_rate: 16000, audio_out_sample_rate: 24000, allow_interruptions: True, enable_metrics: True, enable_tracing: True, enable_usage_metrics: False, interruption_strategies: [], report_only_initial_ttfb: False at 0.00s
2026-01-15 10:31:19.968 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#1 â†’ RTVIProcessor#1: SpeechControlParamsFrame id: 1977, name: 'SpeechControlParamsFrame#1', metadata: {}, vad_params: confidence=0.7 start_secs=0.2 stop_secs=0.2 min_volume=0.6, turn_params: stop_secs=3 pre_speech_ms=0 max_duration_secs=8 at 0.00s
2026-01-15 10:31:19.968 | INFO     | [BOT-SYS] | Starting websocket server on localhost:8765
2026-01-15 10:31:19.968 | DEBUG    | [BOT-SYS] | RTVIProcessor#1 â†’ IOLogger#3: StartFrame id: 1976, name: 'StartFrame#2', metadata: {}, audio_in_sample_rate: 16000, audio_out_sample_rate: 24000, allow_interruptions: True, enable_metrics: True, enable_tracing: True, enable_usage_metrics: False, interruption_strategies: [], report_only_initial_ttfb: False at 0.00s
2026-01-15 10:31:19.968 | DEBUG    | [BOT-SYS] | RTVIProcessor#1 â†’ IOLogger#3: SpeechControlParamsFrame id: 1977, name: 'SpeechControlParamsFrame#1', metadata: {}, vad_params: confidence=0.7 start_secs=0.2 stop_secs=0.2 min_volume=0.6, turn_params: stop_secs=3 pre_speech_ms=0 max_duration_secs=8 at 0.00s
2026-01-15 10:31:19.968 | INFO     | [BOT-SYS] | input bot frame: StartFrame#2
2026-01-15 10:31:19.968 | INFO     | [BOT-SYS] | input bot frame: SpeechControlParamsFrame#1
2026-01-15 10:31:19.968 | DEBUG    | [BOT-SYS] | IOLogger#3 â†’ SarvamSTTService#1: StartFrame id: 1976, name: 'StartFrame#2', metadata: {}, audio_in_sample_rate: 16000, audio_out_sample_rate: 24000, allow_interruptions: True, enable_metrics: True, enable_tracing: True, enable_usage_metrics: False, interruption_strategies: [], report_only_initial_ttfb: False at 0.00s
2026-01-15 10:31:19.968 | DEBUG    | [BOT-SYS] | IOLogger#3 â†’ SarvamSTTService#1: SpeechControlParamsFrame id: 1977, name: 'SpeechControlParamsFrame#1', metadata: {}, vad_params: confidence=0.7 start_secs=0.2 stop_secs=0.2 min_volume=0.6, turn_params: stop_secs=3 pre_speech_ms=0 max_duration_secs=8 at 0.00s
2026-01-15 10:31:19.968 | DEBUG    | [BOT-SYS] | Connecting to Sarvam
2026-01-15 10:31:20.133 | INFO     | [BOT-SYS] | Connected to Sarvam successfully
2026-01-15 10:31:20.133 | DEBUG    | [BOT-SYS] | SarvamSTTService#1 â†’ UserTranscriptProcessor#1: StartFrame id: 1976, name: 'StartFrame#2', metadata: {}, audio_in_sample_rate: 16000, audio_out_sample_rate: 24000, allow_interruptions: True, enable_metrics: True, enable_tracing: True, enable_usage_metrics: False, interruption_strategies: [], report_only_initial_ttfb: False at 0.17s
2026-01-15 10:31:20.133 | DEBUG    | [BOT-SYS] | SarvamSTTService#1 â†’ UserTranscriptProcessor#1: SpeechControlParamsFrame id: 1977, name: 'SpeechControlParamsFrame#1', metadata: {}, vad_params: confidence=0.7 start_secs=0.2 stop_secs=0.2 min_volume=0.6, turn_params: stop_secs=3 pre_speech_ms=0 max_duration_secs=8 at 0.17s
2026-01-15 10:31:20.133 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#1 â†’ IOLogger#4: StartFrame id: 1976, name: 'StartFrame#2', metadata: {}, audio_in_sample_rate: 16000, audio_out_sample_rate: 24000, allow_interruptions: True, enable_metrics: True, enable_tracing: True, enable_usage_metrics: False, interruption_strategies: [], report_only_initial_ttfb: False at 0.17s
2026-01-15 10:31:20.133 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#1 â†’ IOLogger#4: SpeechControlParamsFrame id: 1977, name: 'SpeechControlParamsFrame#1', metadata: {}, vad_params: confidence=0.7 start_secs=0.2 stop_secs=0.2 min_volume=0.6, turn_params: stop_secs=3 pre_speech_ms=0 max_duration_secs=8 at 0.17s
2026-01-15 10:31:20.133 | INFO     | [BOT-SYS] | output bot frame: StartFrame#2
2026-01-15 10:31:20.133 | INFO     | [BOT-SYS] | output bot frame: SpeechControlParamsFrame#1
2026-01-15 10:31:20.134 | DEBUG    | [BOT-SYS] | IOLogger#4 â†’ WebsocketServerOutputTransport#1: StartFrame id: 1976, name: 'StartFrame#2', metadata: {}, audio_in_sample_rate: 16000, audio_out_sample_rate: 24000, allow_interruptions: True, enable_metrics: True, enable_tracing: True, enable_usage_metrics: False, interruption_strategies: [], report_only_initial_ttfb: False at 0.17s
2026-01-15 10:31:20.134 | DEBUG    | [BOT-SYS] | IOLogger#4 â†’ WebsocketServerOutputTransport#1: SpeechControlParamsFrame id: 1977, name: 'SpeechControlParamsFrame#1', metadata: {}, vad_params: confidence=0.7 start_secs=0.2 stop_secs=0.2 min_volume=0.6, turn_params: stop_secs=3 pre_speech_ms=0 max_duration_secs=8 at 0.17s
2026-01-15 10:31:20.134 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#1 â†’ Pipeline#4::Sink: StartFrame id: 1976, name: 'StartFrame#2', metadata: {}, audio_in_sample_rate: 16000, audio_out_sample_rate: 24000, allow_interruptions: True, enable_metrics: True, enable_tracing: True, enable_usage_metrics: False, interruption_strategies: [], report_only_initial_ttfb: False at 0.17s
2026-01-15 10:31:20.134 | DEBUG    | [BOT-SYS] | Pipeline#4 â†’ PipelineTask#2::Sink: StartFrame id: 1976, name: 'StartFrame#2', metadata: {}, audio_in_sample_rate: 16000, audio_out_sample_rate: 24000, allow_interruptions: True, enable_metrics: True, enable_tracing: True, enable_usage_metrics: False, interruption_strategies: [], report_only_initial_ttfb: False at 0.17s
2026-01-15 10:31:20.134 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#1 â† IOLogger#4: OutputTransportReadyFrame id: 1978, name: 'OutputTransportReadyFrame#2', metadata: {} at 0.17s
2026-01-15 10:31:20.134 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#1 â†’ Pipeline#4::Sink: SpeechControlParamsFrame id: 1977, name: 'SpeechControlParamsFrame#1', metadata: {}, vad_params: confidence=0.7 start_secs=0.2 stop_secs=0.2 min_volume=0.6, turn_params: stop_secs=3 pre_speech_ms=0 max_duration_secs=8 at 0.17s
2026-01-15 10:31:20.134 | DEBUG    | [BOT-SYS] | Pipeline#4 â†’ PipelineTask#2::Sink: SpeechControlParamsFrame id: 1977, name: 'SpeechControlParamsFrame#1', metadata: {}, vad_params: confidence=0.7 start_secs=0.2 stop_secs=0.2 min_volume=0.6, turn_params: stop_secs=3 pre_speech_ms=0 max_duration_secs=8 at 0.17s
2026-01-15 10:31:20.134 | DEBUG    | [BOT-SYS] | PipelineTask#2: StartFrame#2 reached the end of the pipeline, pipeline is now ready.
2026-01-15 10:31:20.134 | DEBUG    | [BOT-SYS] | PipelineTask#2::Source â†’ Pipeline#4: MetricsFrame id: 1979, name: 'MetricsFrame#6', metadata: {}, data: [TTFBMetricsData(processor='SarvamSTTService#1', model=None, value=0.0), ProcessingMetricsData(processor='SarvamSTTService#1', model=None, value=0.0)] at 0.17s
2026-01-15 10:31:20.134 | DEBUG    | [BOT-SYS] | Pipeline#4::Source â†’ WebsocketServerInputTransport#1: MetricsFrame id: 1979, name: 'MetricsFrame#6', metadata: {}, data: [TTFBMetricsData(processor='SarvamSTTService#1', model=None, value=0.0), ProcessingMetricsData(processor='SarvamSTTService#1', model=None, value=0.0)] at 0.17s
2026-01-15 10:31:20.134 | DEBUG    | [BOT-SYS] | RTVIProcessor#1 â†’ IOLogger#3: OutputTransportMessageUrgentFrame id: 1980, name: 'OutputTransportMessageUrgentFrame#100', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'ttfb': [{'processor': 'SarvamSTTService#1', 'value': 0.0}], 'processing': [{'processor': 'SarvamSTTService#1', 'value': 0.0}]}} at 0.17s
2026-01-15 10:31:20.134 | INFO     | [BOT-SYS] | output bot frame: OutputTransportReadyFrame#2
2026-01-15 10:31:20.134 | INFO     | [BOT-SYS] | input bot frame: OutputTransportMessageUrgentFrame#100(message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'ttfb': [{'processor': 'SarvamSTTService#1', 'value': 0.0}], 'processing': [{'processor': 'SarvamSTTService#1', 'value': 0.0}]}})
2026-01-15 10:31:20.135 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#1 â†’ RTVIProcessor#1: MetricsFrame id: 1979, name: 'MetricsFrame#6', metadata: {}, data: [TTFBMetricsData(processor='SarvamSTTService#1', model=None, value=0.0), ProcessingMetricsData(processor='SarvamSTTService#1', model=None, value=0.0)] at 0.17s
2026-01-15 10:31:20.135 | DEBUG    | [BOT-SYS] | IOLogger#4 â† UserTranscriptProcessor#1: OutputTransportReadyFrame id: 1978, name: 'OutputTransportReadyFrame#2', metadata: {} at 0.17s
2026-01-15 10:31:20.135 | DEBUG    | [BOT-SYS] | IOLogger#3 â†’ SarvamSTTService#1: OutputTransportMessageUrgentFrame id: 1980, name: 'OutputTransportMessageUrgentFrame#100', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'ttfb': [{'processor': 'SarvamSTTService#1', 'value': 0.0}], 'processing': [{'processor': 'SarvamSTTService#1', 'value': 0.0}]}} at 0.17s
2026-01-15 10:31:20.135 | DEBUG    | [BOT-SYS] | RTVIProcessor#1 â†’ IOLogger#3: MetricsFrame id: 1979, name: 'MetricsFrame#6', metadata: {}, data: [TTFBMetricsData(processor='SarvamSTTService#1', model=None, value=0.0), ProcessingMetricsData(processor='SarvamSTTService#1', model=None, value=0.0)] at 0.17s
2026-01-15 10:31:20.135 | DEBUG    | [BOT-SYS] | SarvamSTTService#1 â†’ UserTranscriptProcessor#1: OutputTransportMessageUrgentFrame id: 1980, name: 'OutputTransportMessageUrgentFrame#100', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'ttfb': [{'processor': 'SarvamSTTService#1', 'value': 0.0}], 'processing': [{'processor': 'SarvamSTTService#1', 'value': 0.0}]}} at 0.17s
2026-01-15 10:31:20.135 | INFO     | [BOT-SYS] | input bot frame: MetricsFrame#6
2026-01-15 10:31:20.135 | DEBUG    | [BOT-SYS] | IOLogger#3 â†’ SarvamSTTService#1: MetricsFrame id: 1979, name: 'MetricsFrame#6', metadata: {}, data: [TTFBMetricsData(processor='SarvamSTTService#1', model=None, value=0.0), ProcessingMetricsData(processor='SarvamSTTService#1', model=None, value=0.0)] at 0.17s
2026-01-15 10:31:20.135 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#1 â† SarvamSTTService#1: OutputTransportReadyFrame id: 1978, name: 'OutputTransportReadyFrame#2', metadata: {} at 0.17s
2026-01-15 10:31:20.135 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#1 â†’ IOLogger#4: OutputTransportMessageUrgentFrame id: 1980, name: 'OutputTransportMessageUrgentFrame#100', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'ttfb': [{'processor': 'SarvamSTTService#1', 'value': 0.0}], 'processing': [{'processor': 'SarvamSTTService#1', 'value': 0.0}]}} at 0.17s
2026-01-15 10:31:20.135 | INFO     | [BOT-SYS] | output bot frame: OutputTransportMessageUrgentFrame#100(message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'ttfb': [{'processor': 'SarvamSTTService#1', 'value': 0.0}], 'processing': [{'processor': 'SarvamSTTService#1', 'value': 0.0}]}})
2026-01-15 10:31:20.135 | DEBUG    | [BOT-SYS] | SarvamSTTService#1 â†’ UserTranscriptProcessor#1: MetricsFrame id: 1979, name: 'MetricsFrame#6', metadata: {}, data: [TTFBMetricsData(processor='SarvamSTTService#1', model=None, value=0.0), ProcessingMetricsData(processor='SarvamSTTService#1', model=None, value=0.0)] at 0.17s
2026-01-15 10:31:20.135 | DEBUG    | [BOT-SYS] | IOLogger#4 â†’ WebsocketServerOutputTransport#1: OutputTransportMessageUrgentFrame id: 1980, name: 'OutputTransportMessageUrgentFrame#100', metadata: {}, message: {'label': 'rtvi-ai', 'type': 'metrics', 'data': {'ttfb': [{'processor': 'SarvamSTTService#1', 'value': 0.0}], 'processing': [{'processor': 'SarvamSTTService#1', 'value': 0.0}]}} at 0.17s
2026-01-15 10:31:20.135 | DEBUG    | [BOT-SYS] | UserTranscriptProcessor#1 â†’ IOLogger#4: MetricsFrame id: 1979, name: 'MetricsFrame#6', metadata: {}, data: [TTFBMetricsData(processor='SarvamSTTService#1', model=None, value=0.0), ProcessingMetricsData(processor='SarvamSTTService#1', model=None, value=0.0)] at 0.17s
2026-01-15 10:31:20.135 | DEBUG    | [BOT-SYS] | SarvamSTTService#1 â† IOLogger#3: OutputTransportReadyFrame id: 1978, name: 'OutputTransportReadyFrame#2', metadata: {} at 0.17s
2026-01-15 10:31:20.135 | INFO     | [BOT-SYS] | output bot frame: MetricsFrame#6
2026-01-15 10:31:20.135 | DEBUG    | [BOT-SYS] | IOLogger#4 â†’ WebsocketServerOutputTransport#1: MetricsFrame id: 1979, name: 'MetricsFrame#6', metadata: {}, data: [TTFBMetricsData(processor='SarvamSTTService#1', model=None, value=0.0), ProcessingMetricsData(processor='SarvamSTTService#1', model=None, value=0.0)] at 0.17s
2026-01-15 10:31:20.135 | INFO     | [BOT-SYS] | input bot frame: OutputTransportReadyFrame#2
2026-01-15 10:31:20.136 | DEBUG    | [BOT-SYS] | WebsocketServerOutputTransport#1 â†’ Pipeline#4::Sink: MetricsFrame id: 1979, name: 'MetricsFrame#6', metadata: {}, data: [TTFBMetricsData(processor='SarvamSTTService#1', model=None, value=0.0), ProcessingMetricsData(processor='SarvamSTTService#1', model=None, value=0.0)] at 0.17s
2026-01-15 10:31:20.136 | DEBUG    | [BOT-SYS] | Pipeline#4 â†’ PipelineTask#2::Sink: MetricsFrame id: 1979, name: 'MetricsFrame#6', metadata: {}, data: [TTFBMetricsData(processor='SarvamSTTService#1', model=None, value=0.0), ProcessingMetricsData(processor='SarvamSTTService#1', model=None, value=0.0)] at 0.17s
2026-01-15 10:31:20.136 | DEBUG    | [BOT-SYS] | IOLogger#3 â† RTVIProcessor#1: OutputTransportReadyFrame id: 1978, name: 'OutputTransportReadyFrame#2', metadata: {} at 0.17s
2026-01-15 10:31:20.136 | DEBUG    | [BOT-SYS] | RTVIProcessor#1 â† WebsocketServerInputTransport#1: OutputTransportReadyFrame id: 1978, name: 'OutputTransportReadyFrame#2', metadata: {} at 0.17s
2026-01-15 10:31:20.136 | DEBUG    | [BOT-SYS] | WebsocketServerInputTransport#1 â† Pipeline#4::Source: OutputTransportReadyFrame id: 1978, name: 'OutputTransportReadyFrame#2', metadata: {} at 0.17s
2026-01-15 10:31:20.136 | DEBUG    | [BOT-SYS] | Pipeline#4 â† PipelineTask#2::Source: OutputTransportReadyFrame id: 1978, name: 'OutputTransportReadyFrame#2', metadata: {} at 0.17s
2026-01-15 10:31:20.638 | DEBUG    | [BOT-SYS] | Pipeline task PipelineTask#2 got cancelled from outside...
2026-01-15 10:31:20.639 | DEBUG    | [BOT-SYS] | Cancelling pipeline task PipelineTask#2

---
logs are attached

---

_**Agent (model composer-1, mode Agent)**_



---



---


Investigating why Sarvam STT gets stuck. Examining the relevant code sections.


---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: pense/agent/bot.py</summary>

</details>
</tool-use>

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: pense/agent/bot.py</summary>

</details>
</tool-use>

---

<tool-use data-tool-type="search" data-tool-name="codebase_search">
<details>
                <summary>Tool use: **codebase_search** â€¢ Searched codebase "How does SarvamSTTService process audio frames and handle timeouts?" â€¢ **8** results</summary>
            
| File | Lines |
|------|-------|
| `pense/integrations/smallest/stt.py` | L33-386 |
| `pense/stt/eval.py` | L238-646 |
| `pense/agent/run_simulation.py` | L183-463 |
| `pense/agent/bot.py` | L131-577 |
| `pense/integrations/smallest/tts.py` | L70-277 |
| `pense/agent/run_simulation.py` | L466-546 |
| `pense/llm/run_simulation.py` | L87-195 |
| `pense/agent/run_simulation.py` | L146-463 |

</details>
</tool-use>

---

<tool-use data-tool-type="search" data-tool-name="grep">
<details>
<summary>Tool use: **grep** â€¢ Grep for "Forcing user stopped speaking due to timeout" â€¢ 0 matches</summary>

Output mode: content


_No matches found_

</details>
</tool-use>

---



---


Checking how SarvamSTTService handles audio and whether sample_rate is required:


---

<tool-use data-tool-type="search" data-tool-name="grep">
<details>
<summary>Tool use: **grep** â€¢ Grep for "SarvamSTTService" â€¢ 11 matches</summary>

Output mode: content


| File | Content | Line |
|------|------|------|
| `./pense/agent/bot.py` | `from pipecat.services.sarvam.stt import SarvamSTTService` | L67 |
| `./pense/agent/bot.py` | `stt = SarvamSTTService(` | L198 |
| `./pense/agent/bot.py` | `params=SarvamSTTService.InputParams(` | L200 |
| `./pense/stt/eval.py` | `from pipecat.services.sarvam.stt import SarvamSTTService` | L56 |
| `./pense/stt/eval.py` | `stt = SarvamSTTService(` | L145 |
| `./pense/stt/eval.py` | `params=SarvamSTTService.InputParams(language=stt_language.value),` | L147 |
| `./README.md` | `"processor": "SarvamSTTService#0",` | L193 |
| `./README.md` | `"processor": "SarvamSTTService#0",` | L206 |
| `./pense/agent/test.py` | `from pipecat.services.sarvam.stt import SarvamSTTService` | L51 |
| `./pense/agent/test.py` | `stt = SarvamSTTService(` | L231 |
| `./pense/agent/test.py` | `params=SarvamSTTService.InputParams(language=sarvam_lang.value),` | L233 |


</details>
</tool-use>

---

<tool-use data-tool-type="search" data-tool-name="codebase_search">
<details>
                <summary>Tool use: **codebase_search** â€¢ Searched codebase "What parameters does SarvamSTTService accept and how does it process audio frames?" â€¢ **12** results</summary>
            
| File | Lines |
|------|-------|
| `pense/stt/eval.py` | L77-238 |
| `pense/integrations/smallest/stt.py` | L31-386 |
| `pense/agent/bot.py` | L131-577 |
| `pense/integrations/smallest/stt.py` | L33-386 |
| `pense/agent/test.py` | L141-513 |
| `pense/stt/eval.py` | L56 |
| `pense/stt/eval.py` | L238-646 |
| `pense/agent/bot.py` | L58 |
| `pense/agent/bot.py` | L129-577 |
| `pense/agent/run_simulation.py` | L466-546 |
| `pense/integrations/smallest/tts.py` | L66-277 |
| `pense/integrations/smallest/tts.py` | L70-277 |

</details>
</tool-use>

---

<tool-use data-tool-type="search" data-tool-name="grep">
<details>
<summary>Tool use: **grep** â€¢ Grep for "sample_rate" in "pense/agent/bot.py" â€¢ 3 matches</summary>

Output mode: content


| File | Content | Line |
|------|------|------|
| `pense/agent/bot.py` | `sample_rate=16000,` | L170 |
| `pense/agent/bot.py` | `audio_in_sample_rate=16000,` | L538 |
| `pense/agent/bot.py` | `audio_out_sample_rate=16000,` | L539 |


</details>
</tool-use>

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: pense/agent/run_simulation.py</summary>

</details>
</tool-use>

---



---


Checking how other STT services are initialized and whether SarvamSTTService needs a sample_rate parameter:


---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: pense/agent/bot.py</summary>

</details>
</tool-use>

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: pense/agent/test.py</summary>

</details>
</tool-use>

---

<tool-use data-tool-type="search" data-tool-name="web_search">
<details>
            <summary>Tool use: **web_search** â€¢ Searched web `pipecat SarvamSTTService sample_rate parameter initialization` â€¢ **1** results</summary>
        
| Title | URL | Chunk |
|-------|-----|-------|
| Web Search Results |  | The issue with Sarvam STT getting stuck during simulations, as indicated by the timeout error "Forcing user stopped speaking due to timeout receiving audio frame," suggests that the service isn't processing audio as expected. This behavior contrasts with the successful operation observed in `pense/stt/eval.py`.<br/><br/>**Key Differences and Recommendations:**<br/><br/>1. **Audio Sample Rate Configuration:**<br/>   - Sarvam STT requires specific sample rate settings for optimal performance.<br/>   - In `pense/stt/eval.py`, ensure that the `input_sample_rate` and `output_sample_rate` are set appropriately.<br/>   - In the simulation setup, verify that these parameters match the expected values.<br/><br/>2. **Voice Activity Detection (VAD) Parameters:**<br/>   - Sarvam STT utilizes VAD to detect speech segments.<br/>   - The `silence_threshold` and `silence_duration` parameters control how silence is detected and handled.<br/>   - Ensure that these parameters are configured consistently between the evaluation and simulation environments.<br/><br/>3. **Model and Language Settings:**<br/>   - Confirm that the same model (e.g., `saarika:v2`) and language settings are used in both environments.<br/>   - Discrepancies in these settings can lead to inconsistent behavior.<br/><br/>4. **Error Handling and Logging:**<br/>   - Implement comprehensive error handling to capture and log issues during audio processing.<br/>   - Detailed logs can provide insights into where the process is failing.<br/><br/>**Next Steps:**<br/><br/>- Review the configuration parameters in both `pense/stt/eval.py` and the simulation setup to ensure consistency.<br/>- Pay special attention to sample rates, VAD settings, and model configurations.<br/>- Enhance logging to capture detailed information during the STT process.<br/><br/>By aligning the configurations and improving error handling, you can identify and resolve the discrepancies causing the STT service to get stuck during simulations. |

</details>
</tool-use>

---



---


GoogleSTTService sets `sample_rate=16000`, and the pipeline uses 16000 Hz, but SarvamSTTService doesn't specify it. This mismatch likely causes the timeout. Adding `sample_rate=16000` to SarvamSTTService initialization:


---

<tool-use data-tool-type="write" data-tool-name="search_replace">

<details><summary>Tool use: **search_replace** â€¢ Edit file: pense/agent/bot.py</summary>

**Chunk 1**
Lines added: 1, lines removed: undefined

```diff
@@ -201,4 +201,5 @@
                  language=stt_language.value,
              ),
+             sample_rate=16000,
          )
      elif stt_config.provider == "cartesia":
```

</details>

</tool-use>

---



---


Checking for other potential issues in the simulation setup that could cause timeouts:


---

<tool-use data-tool-type="search" data-tool-name="codebase_search">
<details>
                <summary>Tool use: **codebase_search** â€¢ Searched codebase "How does the simulation handle audio frame timeouts and user stopped speaking events?" â€¢ **7** results</summary>
            
| File | Lines |
|------|-------|
| `pense/agent/run_simulation.py` | L183-463 |
| `pense/agent/bot.py` | L131-578 |
| `pense/agent/run_simulation.py` | L672-1051 |
| `pense/agent/test.py` | L178-513 |
| `pense/agent/run_simulation.py` | L146-463 |
| `pense/agent/run_simulation.py` | L579-1051 |
| `pense/agent/run_simulation.py` | L466-546 |

</details>
</tool-use>

---

<tool-use data-tool-type="generic" data-tool-name="read_lints">
<details>
          <summary>Tool use: **read_lints** â€¢ Read lints for 1 file</summary>
      
Lint paths:

- `pense/agent/bot.py`

Lint results

Lint errors for `pense/agent/bot.py`


| Message | Range | Severity |
|-------|-------|----------|
| Import "InterruptionTaskFrame" is not accessed | 12:5-12:26 | DIAGNOSTIC_SEVERITY_HINT |
| Import "LLMRunFrame" is not accessed | 13:5-13:16 | DIAGNOSTIC_SEVERITY_HINT |
| Import "InputAudioRawFrame" is not accessed | 16:5-16:23 | DIAGNOSTIC_SEVERITY_HINT |
| Import "VADUserStartedSpeakingFrame" is not accessed | 17:5-17:32 | DIAGNOSTIC_SEVERITY_HINT |
| Import "VADUserStoppedSpeakingFrame" is not accessed | 18:5-18:32 | DIAGNOSTIC_SEVERITY_HINT |
| Import "InterruptionFrame" is not accessed | 19:5-19:22 | DIAGNOSTIC_SEVERITY_HINT |
| Import "OutputAudioRawFrame" is not accessed | 20:5-20:24 | DIAGNOSTIC_SEVERITY_HINT |
| Import "OutputTransportMessageUrgentFrame" is not accessed | 21:5-21:38 | DIAGNOSTIC_SEVERITY_HINT |
| Import "InputTransportMessageFrame" is not accessed | 22:5-22:31 | DIAGNOSTIC_SEVERITY_HINT |
| Import "create_transport" is not accessed | 43:34-43:50 | DIAGNOSTIC_SEVERITY_HINT |
| Import "GroqLLMService" is not accessed | 59:39-59:53 | DIAGNOSTIC_SEVERITY_HINT |
| Import "GoogleLLMService" is not accessed | 63:41-63:57 | DIAGNOSTIC_SEVERITY_HINT |
| Import "TransportParams" is not accessed | 76:62-76:77 | DIAGNOSTIC_SEVERITY_HINT |
| Code is unreachable | 211:9-217:10 | DIAGNOSTIC_SEVERITY_HINT |
| Code is unreachable | 261:9-263:10 | DIAGNOSTIC_SEVERITY_HINT |
| Code is unreachable | 295:9-301:10 | DIAGNOSTIC_SEVERITY_HINT |
| Function "on_client_connected" is not accessed | 551:15-551:34 | DIAGNOSTIC_SEVERITY_HINT |
| "transport" is not accessed | 551:35-551:44 | DIAGNOSTIC_SEVERITY_HINT |
| "client" is not accessed | 551:46-551:52 | DIAGNOSTIC_SEVERITY_HINT |
| Function "on_client_disconnected" is not accessed | 560:15-560:37 | DIAGNOSTIC_SEVERITY_HINT |
| "transport" is not accessed | 560:38-560:47 | DIAGNOSTIC_SEVERITY_HINT |
| "client" is not accessed | 560:49-560:55 | DIAGNOSTIC_SEVERITY_HINT |
| Function "handle_transcript_update" is not accessed | 565:15-565:39 | DIAGNOSTIC_SEVERITY_HINT |
| "processor" is not accessed | 565:40-565:49 | DIAGNOSTIC_SEVERITY_HINT |
| Function "on_client_ready" is not accessed | 574:15-574:30 | DIAGNOSTIC_SEVERITY_HINT |


</details>
</tool-use>

---



---


Added `sample_rate=16000` to the SarvamSTTService initialization to match the pipeline configuration. The timeout likely occurred because the STT service wasn't configured for the sample rate the pipeline sends.

## Summary of the fix:

The issue was that `SarvamSTTService` was initialized without a `sample_rate` parameter, while:
- The pipeline is configured with `audio_in_sample_rate=16000` and `audio_out_sample_rate=16000` (in `run_simulation.py`)
- Other STT services like `GoogleSTTService` explicitly set `sample_rate=16000`

This mismatch can cause the STT service to not process audio frames correctly, leading to the timeout warning: "Forcing user stopped speaking due to timeout receiving audio frame!"

The fix ensures that `SarvamSTTService` expects audio at 16kHz, matching what the pipeline sends.

**Note:** If the issue persists after this change, it could indicate:
1. A connection issue with the Sarvam API
2. The STT service waiting for additional configuration
3. A problem with how audio frames are being sent to the service

Test the simulation again with Sarvam STT to see if this resolves the timeout issue.

---

_**User (2026-01-15 01:14Z)**_

no but it was working in @pense/stt/eval.py without this sample rate and still does not work with this fix when used with @pense/llm/run_simulation.py in @pense/agent/bot.py 

---

_**Agent (model claude-4.5-opus-high-thinking, mode Agent)**_

<think><details><summary>Thought Process</summary>
The user is saying that:
1. Sarvam STT works in `pense/stt/eval.py` without the `sample_rate` parameter
2. Adding `sample_rate=16000` to `pense/agent/bot.py` didn't fix the issue when used with `pense/agent/run_simulation.py`

Let me compare the two setups more carefully to understand the difference.

Looking at `pense/stt/eval.py`:
- It uses `WebsocketServerTransport` for the bot (lines 85-96)
- The STT bot has `audio_in_enabled=True, audio_out_enabled=False`
- Pipeline params: `audio_in_sample_rate=16000` (line 219)
- SarvamSTTService is initialized without `sample_rate` (lines 145-148)

Looking at `pense/agent/bot.py`:
- It uses a transport passed from `run_simulation.py`
- Pipeline params: `audio_in_sample_rate=16000, audio_out_sample_rate=16000` (lines 539-540)
- SarvamSTTService now has `sample_rate=16000`

The key difference might be in how the simulation works. Let me look at `pense/agent/run_simulation.py` to understand the flow better.

In the simulation:
1. `start_bot` creates a WebSocket server and calls `run_bot` from `bot.py`
2. `run_simulation` creates a WebSocket client that connects to the bot
3. The simulation sends audio frames to the bot

Looking at the logs provided earlier:
```
2026-01-15 10:20:49.827 | WARNING  | [BOT-SYS] | Forcing user stopped speaking due to timeout receiving audio frame!
```

This timeout message suggests the STT service is waiting for audio but not receiving it in time. 

The timeout could stem from audio frame timing issues, how audio flows through the WebSocket, or VAD configuration differences between the two setups. The logs show the user started speaking but then hit a timeout, which points to a disconnect between when audio is being sent and when the service expects to receive it. I should examine how `run_simulation.py` configures the transport and audio handling compared to `stt/eval.py`. that Sarvam STT detects "user started speaking" but then times out waiting for audio frames. This suggests the audio frames aren't reaching Sarvam STT properly, or there's a timing mismatch in how audio gets buffered and transmitted. The eval simulation might be sending audio differently than the agent simulation does.

I should examine `pense/agent/run_simulation.py` to trace the audio flowâ€”specifically how the transport is set up for the bot and the mechanism for delivering audio frames from the simulation.</details></think>

---

Let me look more closely at the differences between how the STT eval and agent simulation handle audio flow.

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: /Users/aman/Documents/repos/artpark/agentloop/pense/agent/run_simulation.py</summary>

</details>
</tool-use>

---

<tool-use data-tool-type="search" data-tool-name="grep">
<details>
<summary>Tool use: **grep** â€¢ Grep for "WebsocketServerTransport|WebsocketServerParams" in "/Users/aman/Documents/repos/artpark/agentloop/pense/agent/run_simulation.py" â€¢ 4 matches</summary>

Output mode: content


| File | Content | Line |
|------|------|------|
| `pense/agent/run_simulation.py` | `WebsocketServerParams,` | L99 |
| `pense/agent/run_simulation.py` | `WebsocketServerTransport,` | L100 |
| `pense/agent/run_simulation.py` | `transport = WebsocketServerTransport(` | L158 |
| `pense/agent/run_simulation.py` | `params=WebsocketServerParams(` | L160 |


</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
Now I see - the agent simulation has both `audio_in_enabled=True` and `audio_out_enabled=True`, and has VAD analyzer and turn analyzer configured. The STT eval only has `audio_in_enabled=True, audio_out_enabled=False`.

Let me compare with the STT eval transport config:

From `pense/stt/eval.py`:
```python
transport = WebsocketServerTransport(
    port=port,
    params=WebsocketServerParams(
        serializer=ProtobufFrameSerializer(),
        audio_in_enabled=True,
        audio_out_enabled=False,
        add_wav_header=False,
        # audio_in_filter=KrispVivaFilter(),
        vad_analyzer=SileroVADAnalyzer(params=VADParams(stop_secs=0.2)),
        turn_analyzer=LocalSmartTurnAnalyzerV3(),
    ),
)
```

From `pense/agent/run_simulation.py`:
```python
transport = WebsocketServerTransport(
    port=port,
    params=WebsocketServerParams(
        serializer=ProtobufFrameSerializer(),
        audio_in_enabled=True,
        audio_out_enabled=True,
        add_wav_header=False,
        vad_analyzer=SileroVADAnalyzer(params=VADParams(stop_secs=0.2)),
        turn_analyzer=LocalSmartTurnAnalyzerV3(),
        session_timeout=60 * 3,  # 3 minutes
    ),
)
```

The configs are almost identical. The difference is `audio_out_enabled`.

Let me also look at where the "Forcing user stopped speaking due to timeout receiving audio frame!" message comes from - it's likely from Sarvam STT service in pipecat.

Let me check what parameters the Sarvam STT service accepts. 

I should look at the Sarvam STT implementation in the pipecat package to understand what's triggering that timeout message and what configuration options might help.</details></think>

---

Let me look at the pipecat SarvamSTTService to understand what parameters it accepts and how it handles audio:

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: /Users/aman/Documents/repos/artpark/agentloop/.venv/lib/python3.11/site-packages/pipecat/services/sarvam/stt.py</summary>

</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
I see - the SarvamSTTService accepts a `sample_rate` parameter that defaults to `None` and then defaults to 16000 in the parent class if not specified. So my fix shouldn't make a difference since it's already defaulting to 16000.

Let me look at more of the Sarvam STT service to see where the timeout message might come from:</details></think>

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: /Users/aman/Documents/repos/artpark/agentloop/.venv/lib/python3.11/site-packages/pipecat/services/sarvam/stt.py</summary>

</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
Looking at this, I see that the Sarvam STT uses `input_audio_codec="wav"` by default. Let me check if this is configured differently in the simulation vs eval.

The "Forcing user stopped speaking due to timeout receiving audio frame!" message is not from SarvamSTTService itself. Let me search for where this message comes from - it's likely in the pipecat transport or VAD analyzer.

Let me search for this message in the pipecat codebase.</details></think>

---

<tool-use data-tool-type="search" data-tool-name="grep">
<details>
<summary>Tool use: **grep** â€¢ Grep for "Forcing user stopped speaking due to timeout" in "/Users/aman/Documents/repos/artpark/agentloop/.venv/lib/python3.11/site-packages/pipecat" â€¢ 0 matches</summary>

Output mode: content


_No matches found_

</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
The grep didn't find the message in the pipecat library. Maybe it's in sarvamai SDK. Let me search in the terminal output to understand the flow better.

Looking at the logs again:
```
2026-01-15 10:20:49.827 | WARNING  | [BOT-SYS] | Forcing user stopped speaking due to timeout receiving audio frame!
2026-01-15 10:20:49.827 | DEBUG    | [BOT-SYS] | User stopped speaking
```

This warning appears to be from the BOT-SYS context, which is the bot side. Let me search in the sarvamai package or maybe it's in a different location.</details></think>

---

<tool-use data-tool-type="shell" data-tool-name="run_terminal_cmd">
<details><summary>Tool use: **run_terminal_cmd** â€¢ Run command: grep -r "Forcing user stopped speaking" /Users/aman/Documents/repos/artpark/agentloop/.venv/lib/python3.11/site-packages/ 2>/dev/null | head -20</summary>

```bash
grep -r "Forcing user stopped speaking" /Users/aman/Documents/repos/artpark/agentloop/.venv/lib/python3.11/site-packages/ 2>/dev/null | head -20
```

```
/Users/aman/Documents/repos/artpark/agentloop/.venv/lib/python3.11/site-packages/pipecat/transports/base_input.py:                        "Forcing user stopped speaking due to timeout receiving audio frame!"
Binary file /Users/aman/Documents/repos/artpark/agentloop/.venv/lib/python3.11/site-packages/pipecat/transports/__pycache__/base_input.cpython-311.pyc matches

```
</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
Found it! The message comes from `pipecat/transports/base_input.py`. Let me read that file to understand what triggers this timeout.</details></think>

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: /Users/aman/Documents/repos/artpark/agentloop/.venv/lib/python3.11/site-packages/pipecat/transports/base_input.py</summary>

</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
The timeout is defined as `AUDIO_INPUT_TIMEOUT_SECS = 0.5`. Let me search for where this timeout is used to understand the logic better.</details></think>

---

<tool-use data-tool-type="search" data-tool-name="grep">
<details>
<summary>Tool use: **grep** â€¢ Grep for "AUDIO_INPUT_TIMEOUT|Forcing user stopped" in "/Users/aman/Documents/repos/artpark/agentloop/.venv/lib/python3.11/site-packages/pipecat/transports/base_input.py" â€¢ 3 matches</summary>

Output mode: content


| File | Content | Line |
|------|------|------|
| `.venv/lib/python3.11/site-packages/pipecat/transports/base_input.py` | `AUDIO_INPUT_TIMEOUT_SECS = 0.5` | L50 |
| `.venv/lib/python3.11/site-packages/pipecat/transports/base_input.py` | `self._audio_in_queue.get(), timeout=AUDIO_INPUT_TIMEOUT_SECS` | L459 |
| `.venv/lib/python3.11/site-packages/pipecat/transports/base_input.py` | `"Forcing user stopped speaking due to timeout receiving audio frame!"` | L486 |


</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
Now I understand! The issue is:

The bot receives audio from the WebSocket client (the eval simulation). If no audio frame is received for 0.5 seconds while `self._user_speaking` is True, it forcibly triggers "user stopped speaking" due to timeout.

This means the eval simulation isn't sending audio frames quickly enough, OR there's a gap in audio frame transmission. Let me look at how the eval simulation sends audio in `pense/agent/run_simulation.py` vs `pense/stt/eval.py`.

In the STT eval (`pense/stt/eval.py`):
- Audio is streamed via `BotTurnAudioStreamer._stream_audio()` which reads from WAV files
- After each chunk, it does `await asyncio.sleep(1 / 1000.0)` (1ms)
- At the end, it pads with silence

In the agent simulation (`pense/agent/run_simulation.py`), I need to look at how audio is sent.

Let me look at the agent simulation's audio sending mechanism.</details></think>

---

<tool-use data-tool-type="search" data-tool-name="codebase_search">
<details>
                <summary>Tool use: **codebase_search** â€¢ Searched codebase "How does the agent simulation send audio frames to the bot in run_simulation?" â€¢ **11** results</summary>
            
| File | Lines |
|------|-------|
| `pense/agent/run_simulation.py` | L672-1051 |
| `pense/agent/run_simulation.py` | L183-463 |
| `pense/agent/run_simulation.py` | L579-1051 |
| `pense/agent/bot.py` | L131-577 |
| `pense/agent/test.py` | L178-513 |
| `pense/agent/run_simulation.py` | L47-106 |
| `pense/agent/run_simulation.py` | L126-463 |
| `pense/agent/run_simulation.py` | L466-546 |
| `pense/agent/run_simulation.py` | L1051-1240 |
| `pense/agent/run_simulation.py` | L576-672 |
| `pense/agent/run_simulation.py` | L146-463 |

</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
I need to understand how audio flows in the agent simulation. Looking at the logs provided by the user:

```
2026-01-15 10:20:48.246 | INFO     | [BOT-SYS] | input bot frame: OutputAudioRawFrame#0(pts: None, source: None, size: 1280, frames: 640, sample_rate: 16000, channels: 1)
...
2026-01-15 10:20:48.846 | DEBUG    | [BOT-SYS] | User started speaking
...
2026-01-15 10:20:49.827 | WARNING  | [BOT-SYS] | Forcing user stopped speaking due to timeout receiving audio frame!
```

The bot is receiving `OutputAudioRawFrame` from the simulation client. After "User started speaking" at 10:20:48.846, there's a timeout at 10:20:49.827 (about 1 second later). 

Looking at the frame sequence:- The bot receives audio frames until about 10:20:49.326
- Then there's a gap of ~0.5 seconds before the timeout at 10:20:49.827

The key difference between the STT eval and agent simulation is:

**STT eval (`pense/stt/eval.py`):**
- `run_stt_bot` creates a WebSocket server
- `run_stt_eval` creates a WebSocket client that streams pre-recorded audio files
- The client uses `BotTurnAudioStreamer` which actively streams audio from WAV files
- No TTS or LLM involved - just STT

**Agent simulation (`pense/agent/run_simulation.py`):**
- `start_bot` creates a WebSocket server with the full bot pipeline (STT â†’ LLM â†’ TTS)
- `run_simulation` creates a WebSocket client that runs the "user" side


- The user side generates audio via TTS (like `GoogleTTSService`) from LLM text responses, which then gets sent to the bot over the websocket. The problem appears to be a timing mismatch where audio frames stop flowing while the STT service still believes the user is actively speaking. At 10:20:49.712, the bot stops speaking, but the STT timeout fires shortly after, suggesting the user's audio stream isn't being properly terminated or the frame generation is stalling. d of speech, and then the transport timed out waiting for more audio. Looking at the Sarvam logs more closely, I see a START_SPEECH signal at 10:20:49.011 indicating the VAD detected speech onset, but there's no corresponding END_SPEECH signal in the logs. This suggests Sarvam's voice activity detection failed to recognize when the user stopped speaking, causing the system to keep the audio stream open and eventually timeout.

The pipecat Sarvam integration has VAD signals enabled by default, so the issue likely stems from how audio is being fed into the system. The STT evaluation pipeline pads audio with 1 second of silence after streaming, which helps signal the end of speech. The agent simulation, however, relies on TTS-generated audio that may lack this trailing silence, preventing Sarvam from properly detecting speech boundaries.

The discrepancy with Google STT suggests different handling of end-of-audio conditionsâ€”Google's streaming RPC may be more forgiving of abrupt audio termination, while Sarvam depends more heavily on VAD signals or explicit stream closure. Adding silence padding to the simulation client's TTS output, or ensuring a proper end-of-stream signal reaches Sarvam, could resolve the timeout issue.</details></think>

---

Let me look at how the simulation pipeline sends audio to the bot and compare with STT eval:

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: /Users/aman/Documents/repos/artpark/agentloop/pense/agent/run_simulation.py</summary>

</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
Now I see the structure. The simulation client:1. Uses `GoogleTTSService` to convert user LLM text to audio
2. Audio is sent over WebSocket to the bot3. Bot uses STT (Sarvam in this case) to transcribe

The issue is that when the TTS stops generating audio, the transport on the bot side times out if it's still expecting the user to be speaking.Looking at the logs again:```2026-01-15 10:20:49.011 | DEBUG    | [BOT-SYS] | Received response: type='events' data=EventsData(event_type=None, timestamp=None, signal_type='START_SPEECH', occured_at=1768452649.0263512)2026-01-15 10:20:49.011 | DEBUG    | [BOT-SYS] | VAD Signal: START_SPEECH, Occurred at: 1768452649.0263512
2026-01-15 10:20:49.011 | DEBUG    | [BOT-SYS] | User started speaking
```Then later:```2026-01-15 10:20:49.827 | WARNING  | [BOT-SYS] | Forcing user stopped speaking due to timeout receiving audio frame!```Sarvam sent START_SPEECH but never sent END_SPEECH before the timeout. This means either:1. Sarvam's VAD didn't detect end of speech because the audio abruptly stopped without trailing silence2. There's something wrong with how Sarvam processes the audio

Looking at the STT eval, it pads 1 second of silence after each audio:```python
# Pad a short burst of silence so downstream STT services (e.g. Google)
# see a clean end-of-stream and flush their final transcripts before the# server times out the streaming RPC.
silence_duration_ms = 1000silence_chunks = max(1, int(silence_duration_ms / self._chunk_ms))


```

The silence padding creates zero-valued audio frames and sends them downstream with proper timing. The agent simulation doesn't implement thisâ€”when TTS finishes generating audio, it stops immediately without appending silence frames, so Sarvam's VAD never gets the signal to end the speech segment.

Adding silence padding to the simulation pipeline would be a substantial modification. Looking at the actual architecture, the bot transport has VAD enabled with Silero, which should handle state transitions independently. The flow involves the simulation client sending audio to the bot transport, which runs Silero VAD detection and emits `UserStartedSpeakingFrame` events before passing audio to Sarvam STT. Sarvam itself has VAD that generates START_SPEECH events. The problem appears to be that Silero VAD isn't properly detecting the end of speech when audio stops abruptly.

When the TTS finishes without trailing silence, Silero VAD fails to recognize the speech boundary quickly enough, and Sarvam's VAD doesn't emit an END_SPEECH event either. The transport's `_audio_task` enforces a 0.5-second timeoutâ€”if no frames arrive while `_user_speaking` remains True, it forces a stop event. Google STT avoids this issue because it handles the transcription differently regardless of the silence gap.

Looking back at the logs, the user's initial "Namaste" was transcribed successfully before the bot began responding. The actual problem emerges during the bot's TTS output back to the simulation client, not the user's incoming speech. The sequence shows the evaluation system sending audio to the bot, the bot receiving it and triggering VAD detection, then the bot generating its responseâ€”but somewhere in this flow, the VAD and transport mechanisms misalign.

The message flow clarifies the architecture: the evaluation system acts as the simulated user generating audio via Google TTS and transmitting it to the bot server, which then runs Sarvam STT on the received audio. The transcript file being saved at the eval system level (labeled "0_user.wav") is actually capturing audio flowing from the bot back outward, not the original user input.

Tracing the sequence: the simulation sends "Namaste" as TTS audio to the bot, the bot transcribes it with Sarvam, and should generate a response. The "Bot stopped speaking" log entry indicates the eval system detected the bot's TTS output ending. The subsequent timeout warning shows the bot-side process forced a user-stopped-speaking state after failing to receive audio frames, suggesting a breakdown in the expected audio stream between the two systems.

The core issue appears to be timingâ€”there's a gap between when the eval client finishes transmitting TTS audio and when the bot's voice activity detection and transport layer recognize the speech has ended. The bot initiates speech detection and transcription when audio arrives, but the audio stream terminates before the bot properly detects the end of speech, triggering the timeout mechanism instead.

Looking at the timestamps, the last audio frame arrives at 10:20:49.328, and the timeout fires exactly 0.5 seconds later at 10:20:49.827â€”matching the AUDIO_INPUT_TIMEOUT_SECS value. This suggests the eval client stops sending audio after TTS completes, leaving the bot waiting. The fix could involve padding silence after TTS output in the simulation, adjusting the timeout threshold, or improving how Sarvam detects speech boundaries. The current implementation forces UserStoppedSpeaking when the timeout occurs, which is a fallback mechanism in the base_input.py code. Looking at how SarvamSTTService processes the UserStoppedSpeakingFrame to understand where the transcription might be getting blocked. The timeout forces a user stopped speaking event, but if Sarvam doesn't properly handle that frame or return a result, the simulation could hang waiting for the transcription to come back.</details></think>

---

Let me look at how Sarvam STT handles user stopped speaking and the difference in flow:

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: /Users/aman/Documents/repos/artpark/agentloop/.venv/lib/python3.11/site-packages/pipecat/services/sarvam/stt.py</summary>

</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
I see! Looking at the Sarvam STT message handler, it:1. Handles `START_SPEECH` VAD events - starts metrics, logs "User started speaking"2. Handles `data` type messages - transcription results

But I don't see any handling of `END_SPEECH` or `STOP_SPEECH` VAD events. When `START_SPEECH` is detected, the service starts expecting a transcription, but there's no explicit handling for when speech ends.

Looking at the code flow:1. Sarvam receives audio via `run_stt()`2. Sarvam's backend detects speech start â†’ sends `START_SPEECH` event3. Sarvam's backend should eventually send transcription data in `data` type messageThe issue might be that Sarvam never receives enough audio to produce a final transcription because:- The TTS audio ends abruptly
- No silence padding is sent- Sarvam is still waiting for more audio to complete the utterance

Let me check if Sarvam STT has any mechanism to handle UserStoppedSpeakingFrame like some other STT services do.</details></think>

---

<tool-use data-tool-type="search" data-tool-name="grep">
<details>
<summary>Tool use: **grep** â€¢ Grep for "UserStoppedSpeakingFrame|END_SPEECH|process_frame" in "/Users/aman/Documents/repos/artpark/agentloop/.venv/lib/python3.11/site-packages/pipecat/services/sarvam/stt.py" â€¢ 0 matches</summary>

Output mode: content


_No matches found_

</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
Sarvam STT doesn't have any special handling for `UserStoppedSpeakingFrame`. Let me check how Google STT handles this since it works.</details></think>

---

<tool-use data-tool-type="search" data-tool-name="grep">
<details>
<summary>Tool use: **grep** â€¢ Grep for "UserStoppedSpeakingFrame|process_frame" in "/Users/aman/Documents/repos/artpark/agentloop/.venv/lib/python3.11/site-packages/pipecat/services/google/stt.py" â€¢ 0 matches</summary>

Output mode: content


_No matches found_

</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
Let me check the base STTService class to see how UserStoppedSpeakingFrame is typically handled.</details></think>

---

<tool-use data-tool-type="search" data-tool-name="grep">
<details>
<summary>Tool use: **grep** â€¢ Grep for "UserStoppedSpeakingFrame|process_frame" in "/Users/aman/Documents/repos/artpark/agentloop/.venv/lib/python3.11/site-packages/pipecat/services/stt_service.py" â€¢ 7 matches</summary>

Output mode: content


| File | Content | Line |
|------|------|------|
| `.venv/lib/python3.11/site-packages/pipecat/services/stt_service.py` | `UserStoppedSpeakingFrame,` | L24 |
| `.venv/lib/python3.11/site-packages/pipecat/services/stt_service.py` | `async def process_frame(self, frame: Frame, direction: FrameDirection):` | L191 |
| `.venv/lib/python3.11/site-packages/pipecat/services/stt_service.py` | `await super().process_frame(frame, direction)` | L198 |
| `.venv/lib/python3.11/site-packages/pipecat/services/stt_service.py` | `async def process_frame(self, frame: Frame, direction: FrameDirection):` | L251 |
| `.venv/lib/python3.11/site-packages/pipecat/services/stt_service.py` | `await super().process_frame(frame, direction)` | L253 |
| `.venv/lib/python3.11/site-packages/pipecat/services/stt_service.py` | `elif isinstance(frame, UserStoppedSpeakingFrame):` | L257 |
| `.venv/lib/python3.11/site-packages/pipecat/services/stt_service.py` | `async def _handle_user_stopped_speaking(self, frame: UserStoppedSpeakingFrame):` | L265 |


</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
Now I understand. Looking at the STTService base class, there are two types of STT services:1. Regular `STTService` - processes audio in real-time (streaming)
2. Some subclass that handles `UserStoppedSpeakingFrame` - accumulates audio and processes when user stops speaking (segment-based)The `SegmentedSTTService` (I see from line 251) handles `UserStoppedSpeakingFrame` by:
1. Accumulating audio in `_audio_buffer`
2. When user stops speaking, creates a WAV from the buffer and calls `run_stt()`

SarvamSTTService extends `STTService` (line 64: `class SarvamSTTService(STTService):`), which is the streaming base class, not the segmented one.

For streaming STT services like Sarvam:
- Audio is sent in real-time via WebSocket to Sarvam's backend- Sarvam's backend processes audio and returns transcriptions when it detects utterances- The service relies on Sarvam's own VAD to detect utterance boundariesThe issue in the agent simulation is:1. TTS generates audio for "Namaste" 
2. Audio is sent to the bot's STT (Sarvam)3. Sarvam receives audio and starts processing4. TTS finishes, no more audio comes5. Sarvam's backend is still waiting for more audio or silence to determine utterance end6. Bot's transport times out after 0.5s of no audio, forces UserStoppedSpeaking7. But by this time, Sarvam may not have returned a transcription yetLet me check if the STT eval adds trailing silence that helps Sarvam complete transcription.

In `pense/stt/eval.py`, I saw:```python# Pad a short burst of silence so downstream STT services (e.g. Google)
# see a clean end-of-stream and flush their final transcripts before the# server times out the streaming RPC.silence_duration_ms = 1000


```

That 1 second of silence gives STT services time to detect speech end and return results. The simulation doesn't include this paddingâ€”when TTS finishes, audio just cuts off. I need to add silence after TTS output completes, but the challenge is detecting when TTS is done and inserting silence into the pipeline before the audio reaches the bot's STT.

Looking at the bot side, the VAD should be catching speech end through Silero's 0.2-second silence threshold rather than relying on timeouts. The warning about forcing user stopped speaking suggests the VAD isn't triggering properly, which points back to the missing silence padding in the simulation's audio stream.

```

python
vad_analyzer=SileroVADAnalyzer(params=VADParams(stop_secs=0.2))
```

When TTS completes, the simulation client stops sending frames entirely instead of padding with silence. The bot's transport expects continuous audio inputâ€”without it, the system times out at 0.5 seconds. The STT evaluator handles this correctly by appending silence chunks after each audio file, but the simulation pipeline doesn't follow the same pattern.

I need to add silence padding to the agent simulation, either as a processor that responds to TTSStoppedFrame events or by modifying the transport layer to handle audio gaps. The cleanest approach would be inserting silence frames into the pipeline after TTS completes. First, I should revert the sample_rate change since that wasn't the actual problem, then implement proper silence handling.

The user confirmed Sarvam works in stt/eval.py without sample_rate, so that's not the root cause. Looking at the eval configuration, it doesn't specify sample_rate eitherâ€”the real difference lies in how STT evaluation streams audio versus how the agent simulation handles it.

The eval uses pre-recorded files with silence padding, while the agent simulation streams TTS output directly without padding. I should add silence padding to match the eval behavior. A FrameProcessor that intercepts TTSStoppedFrame and injects silence frames would be the cleanest solutionâ€”it would pass through normal frames and generate padding when TTS completes.</details></think>

---

Now I understand the issue. Looking at the code:

1. **In `pense/stt/eval.py`**: After streaming each audio file, it sends **1 second of silence padding** (lines 553-568). This gives STT services time to flush their final transcriptions.

2. **In `pense/agent/run_simulation.py`**: When the TTS finishes generating audio, audio frames simply stop. No silence is sent.

3. **The timeout**: The bot transport has `AUDIO_INPUT_TIMEOUT_SECS = 0.5`. When no audio frame arrives for 0.5 seconds while the user is "speaking", it forces a `UserStoppedSpeakingFrame`.

The issue is that Sarvam STT needs audio data (including silence) to properly detect end of speech and flush transcriptions. When audio abruptly stops without trailing silence, Sarvam may not return the transcription before the timeout.

**The `sample_rate` fix isn't the solution** - let me revert that and instead add silence padding after TTS in the simulation.

---

The string to replace was not found in the file.

---

<think><details><summary>Thought Process</summary>
The file already has the correct version without `sample_rate=16000`. It seems my earlier change wasn't actually applied or was reverted. Let me read the current file state to confirm.</details></think>

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: /Users/aman/Documents/repos/artpark/agentloop/pense/agent/bot.py</summary>

</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
Good - the file doesn't have `sample_rate=16000`. So my earlier edit was reverted or never applied. The issue is the lack of silence padding.Now let me add a silence padding mechanism to the simulation. I need to add a FrameProcessor in the simulation client pipeline that:1. Passes through audio frames
2. When TTS stops (TTSStoppedFrame), generates and sends silence framesLet me look at the simulation pipeline to understand where to add this.</details></think>

---

The file doesn't have `sample_rate`. The real issue is the lack of silence padding in the agent simulation. Let me look at the simulation pipeline to add a silence padding processor:

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: /Users/aman/Documents/repos/artpark/agentloop/pense/agent/run_simulation.py</summary>

</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
I see the pipeline. The TTS output goes directly to `transport.output()`. I need to add a silence padding processor between `tts` and `transport.output()` that detects when TTS is done and sends silence frames.

Let me check what frame TTS emits when it's done. It's likely `TTSStoppedFrame`.</details></think>

---

<tool-use data-tool-type="search" data-tool-name="grep">
<details>
<summary>Tool use: **grep** â€¢ Grep for "TTSStoppedFrame" in "/Users/aman/Documents/repos/artpark/agentloop/.venv/lib/python3.11/site-packages/pipecat" â€¢ 0 matches</summary>

Output mode: files_with_matches


_No matches found_

</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
Let me search for TTS stop frame or similar.</details></think>

---

<tool-use data-tool-type="search" data-tool-name="grep">
<details>
<summary>Tool use: **grep** â€¢ Grep for "BotStoppedSpeaking|TTSStop" in "/Users/aman/Documents/repos/artpark/agentloop/.venv/lib/python3.11/site-packages/pipecat/frames/frames.py" â€¢ 3 matches</summary>

Output mode: content


| File | Content | Line |
|------|------|------|
| `.venv/lib/python3.11/site-packages/pipecat/frames/frames.py` | `class BotStoppedSpeakingFrame(SystemFrame):` | L1160 |
| `.venv/lib/python3.11/site-packages/pipecat/frames/frames.py` | `TTSStoppedFrame. These frames can be used for aggregating audio frames in a` | L1801 |
| `.venv/lib/python3.11/site-packages/pipecat/frames/frames.py` | `class TTSStoppedFrame(ControlFrame):` | L1810 |


</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
`TTSStoppedFrame` is what I need. I'll create a `SilencePadder` processor that:
1. Passes through all frames
2. When it sees `TTSStoppedFrame`, generates silence frames before pushing `TTSStoppedFrame`

Let me add this processor to `run_simulation.py` in the simulation client pipeline (between TTS and transport output).</details></think>

---

Now I'll add a `SilencePadder` processor to the simulation pipeline that adds silence after TTS audio finishes. This will give Sarvam STT time to flush its transcription:

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: /Users/aman/Documents/repos/artpark/agentloop/pense/agent/run_simulation.py</summary>

</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
I need to:1. Import `TTSStoppedFrame` 2. Add a `SilencePadder` FrameProcessor class3. Insert it in the pipeline after TTSLet me look at the imports and find a good place to add the class.</details></think>

---

<tool-use data-tool-type="write" data-tool-name="search_replace">

<details><summary>Tool use: **search_replace** â€¢ Edit file: /Users/aman/Documents/repos/artpark/agentloop/pense/agent/run_simulation.py</summary>

**Chunk 1**
Lines added: 1, lines removed: undefined

```diff
@@ -75,4 +75,5 @@
      Frame,
      InterruptionFrame,
+     TTSStoppedFrame,
  )
  from pipecat.pipeline.pipeline import Pipeline
```

</details>

</tool-use>

---

<think><details><summary>Thought Process</summary>
Now I need to add the SilencePadder class and use it in the pipeline. Let me find a good location to add the class, probably near the other FrameProcessor classes.</details></think>

---

Now let me add the `SilencePadder` class. Let me find where the other FrameProcessor classes are defined:

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: /Users/aman/Documents/repos/artpark/agentloop/pense/agent/run_simulation.py</summary>

</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
Good, I found where the FrameProcessor classes are. I'll add the `SilencePadder` class after `IOLogger`. Let me find where `IOLogger` ends.</details></think>

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: /Users/aman/Documents/repos/artpark/agentloop/pense/agent/run_simulation.py</summary>

</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
I'll add the `SilencePadder` class after `IOLogger` and before `MaxTurnsEndProcessor`. This class will:1. Track the last audio sample rate and channels2. When it sees `TTSStoppedFrame`, generate and push silence frames3. Pass through all other framesLet me add the class.</details></think>

---

<tool-use data-tool-type="write" data-tool-name="search_replace">

<details><summary>Tool use: **search_replace** â€¢ Edit file: /Users/aman/Documents/repos/artpark/agentloop/pense/agent/run_simulation.py</summary>

**Chunk 1**
Lines added: 47, lines removed: undefined

```diff
@@ -548,4 +548,51 @@
          await self.push_frame(frame, direction)
  
+ 
+ class SilencePadder(FrameProcessor):
+     """Adds silence padding after TTS audio to help STT services flush transcriptions.
+ 
+     Some STT services (like Sarvam) need trailing silence to properly detect
+     end of speech and return final transcriptions.
+     """
+ 
+     def __init__(self, silence_duration_ms: int = 1000, chunk_ms: int = 40):
+         super().__init__(enable_direct_mode=True, name="SilencePadder")
+         self._silence_duration_ms = silence_duration_ms
+         self._chunk_ms = chunk_ms
+         self._last_sample_rate = 16000
+         self._last_num_channels = 1
+ 
+     async def process_frame(self, frame, direction):
+         await super().process_frame(frame, direction)
+ 
+         # Track audio parameters from outgoing audio frames
+         if isinstance(frame, OutputAudioRawFrame):
+             self._last_sample_rate = frame.sample_rate
+             self._last_num_channels = frame.num_channels
+ 
+         # When TTS stops, add silence padding before pushing the frame
+         if isinstance(frame, TTSStoppedFrame):
+             await self._push_silence()
+ 
+         await self.push_frame(frame, direction)
+ 
+     async def _push_silence(self):
+         """Generate and push silence frames."""
+         frames_per_chunk = max(
+             1, int(self._last_sample_rate * (self._chunk_ms / 1000.0))
+         )
+         silence_chunks = max(1, int(self._silence_duration_ms / self._chunk_ms))
+         # 16-bit audio: 2 bytes per sample
+         silence_audio = b"\x00" * (frames_per_chunk * self._last_num_channels * 2)
+ 
+         for _ in range(silence_chunks):
+             frame = OutputAudioRawFrame(
+                 audio=silence_audio,
+                 sample_rate=self._last_sample_rate,
+                 num_channels=self._last_num_channels,
+             )
+             await self.push_frame(frame, FrameDirection.DOWNSTREAM)
+             await asyncio.sleep(self._chunk_ms / 1000.0)
+ 
  
  class MaxTurnsEndProcessor(FrameProcessor):
```

</details>

</tool-use>

---

<think><details><summary>Thought Process</summary>
Now I need to add the `SilencePadder` to the pipeline. Let me find the pipeline and add it after `tts` and before `output_logger`.</details></think>

---

Now let me add the `SilencePadder` to the pipeline after TTS:

---

<tool-use data-tool-type="read" data-tool-name="read_file">
<details><summary>Tool use: **read_file** â€¢ Read file: /Users/aman/Documents/repos/artpark/agentloop/pense/agent/run_simulation.py</summary>

</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
I need to:1. Instantiate `SilencePadder` before the pipeline
2. Add it to the pipeline after `tts` and before `output_logger`Let me do both:</details></think>

---

<tool-use data-tool-type="write" data-tool-name="search_replace">

<details><summary>Tool use: **search_replace** â€¢ Edit file: /Users/aman/Documents/repos/artpark/agentloop/pense/agent/run_simulation.py</summary>

**Chunk 1**
Lines added: 3, lines removed: undefined

```diff
@@ -860,4 +860,7 @@
  
      output_logger = IOLogger()
+ 
+     # Add silence padding after TTS to help STT services (like Sarvam) flush transcriptions
+     silence_padder = SilencePadder(silence_duration_ms=1000, chunk_ms=40)
  
      max_turns_end_processor = MaxTurnsEndProcessor(
```

**Chunk 2**
Lines added: 1, lines removed: undefined

```diff
@@ -879,4 +882,5 @@
              max_turns_end_processor,  # Check and end after assistant processing if max_turns reached
              tts,  # TTS
+             silence_padder,  # Add silence padding after TTS for STT flush
              output_logger,
              transport.output(),  # Transport bot output
```

</details>

</tool-use>

---

<think><details><summary>Thought Process</summary>
Now let me check for linting errors.</details></think>

---

<tool-use data-tool-type="generic" data-tool-name="read_lints">
<details>
          <summary>Tool use: **read_lints** â€¢ Read lints for 1 file</summary>
      
Lint paths:

- `/Users/aman/Documents/repos/artpark/agentloop/pense/agent/run_simulation.py`

Lint results

Lint errors for `pense/agent/run_simulation.py`


| Message | Range | Severity |
|-------|-------|----------|
| Import "datetime" is not accessed | 8:22-8:30 | DIAGNOSTIC_SEVERITY_HINT |
| Import "List" is not accessed | 10:25-10:29 | DIAGNOSTIC_SEVERITY_HINT |
| Import "Tuple" is not accessed | 10:41-10:46 | DIAGNOSTIC_SEVERITY_HINT |
| Import "LiveOptions" is not accessed | 13:22-13:33 | DIAGNOSTIC_SEVERITY_HINT |
| Import "ImageFile" is not accessed | 15:27-15:36 | DIAGNOSTIC_SEVERITY_HINT |
| Import "dataclass" is not accessed | 16:25-16:34 | DIAGNOSTIC_SEVERITY_HINT |
| Import "FunctionSchema" is not accessed | 45:54-45:68 | DIAGNOSTIC_SEVERITY_HINT |
| Import "ToolsSchema" is not accessed | 46:51-46:62 | DIAGNOSTIC_SEVERITY_HINT |
| Import "AggregatedTextFrame" is not accessed | 53:5-53:24 | DIAGNOSTIC_SEVERITY_HINT |
| Import "LLMContextFrame" is not accessed | 55:5-55:20 | DIAGNOSTIC_SEVERITY_HINT |
| Import "StopFrame" is not accessed | 56:5-56:14 | DIAGNOSTIC_SEVERITY_HINT |
| Import "BotStartedSpeakingFrame" is not accessed | 63:5-63:28 | DIAGNOSTIC_SEVERITY_HINT |
| Import "BotStoppedSpeakingFrame" is not accessed | 64:5-64:28 | DIAGNOSTIC_SEVERITY_HINT |
| Import "InputAudioRawFrame" is not accessed | 67:5-67:23 | DIAGNOSTIC_SEVERITY_HINT |
| Import "LLMMessagesAppendFrame" is not accessed | 69:5-69:27 | DIAGNOSTIC_SEVERITY_HINT |
| Import "LLMFullResponseEndFrame" is not accessed | 71:5-71:28 | DIAGNOSTIC_SEVERITY_HINT |
| Import "TextFrame" is not accessed | 72:5-72:14 | DIAGNOSTIC_SEVERITY_HINT |
| Import "Frame" is not accessed | 75:5-75:10 | DIAGNOSTIC_SEVERITY_HINT |
| Import "InterruptionFrame" is not accessed | 76:5-76:22 | DIAGNOSTIC_SEVERITY_HINT |
| Import "CartesiaTTSService" is not accessed | 90:43-90:61 | DIAGNOSTIC_SEVERITY_HINT |
| Import "DeepgramSTTService" is not accessed | 91:43-91:61 | DIAGNOSTIC_SEVERITY_HINT |
| Import "FunctionCallParams" is not accessed | 92:42-92:60 | DIAGNOSTIC_SEVERITY_HINT |
| Function "on_user_turn_audio_data" is not accessed | 917:15-917:38 | DIAGNOSTIC_SEVERITY_HINT |
| "buffer" is not accessed | 917:39-917:45 | DIAGNOSTIC_SEVERITY_HINT |
| Function "on_bot_turn_audio_data" is not accessed | 926:15-926:37 | DIAGNOSTIC_SEVERITY_HINT |
| "buffer" is not accessed | 926:38-926:44 | DIAGNOSTIC_SEVERITY_HINT |
| Function "on_connected" is not accessed | 935:15-935:27 | DIAGNOSTIC_SEVERITY_HINT |
| "transport" is not accessed | 935:28-935:37 | DIAGNOSTIC_SEVERITY_HINT |
| "client" is not accessed | 935:39-935:45 | DIAGNOSTIC_SEVERITY_HINT |
| Function "on_disconnected" is not accessed | 946:15-946:30 | DIAGNOSTIC_SEVERITY_HINT |
| "transport" is not accessed | 946:31-946:40 | DIAGNOSTIC_SEVERITY_HINT |
| "client" is not accessed | 946:42-946:48 | DIAGNOSTIC_SEVERITY_HINT |
| Function "handle_transcript_update" is not accessed | 951:15-951:39 | DIAGNOSTIC_SEVERITY_HINT |
| "processor" is not accessed | 951:40-951:49 | DIAGNOSTIC_SEVERITY_HINT |


</details>
</tool-use>

---

<think><details><summary>Thought Process</summary>
No linting errors. Let me summarize what I've done and explain why this should fix the issue.</details></think>

---

I've added a `SilencePadder` processor to the agent simulation pipeline. Here's what the fix does:

## Summary of the Fix

**Root Cause:** When the TTS finishes generating audio in the agent simulation, audio frames simply stop. The bot's transport expects continuous audio frames - when they stop for 0.5 seconds while `_user_speaking` is True, it times out with the warning "Forcing user stopped speaking due to timeout receiving audio frame!". 

Sarvam STT (and some other STT services) needs trailing silence to properly detect end of speech and flush their final transcriptions. Without it, Sarvam may not return transcriptions before the timeout occurs.

**The Fix:** Added a `SilencePadder` FrameProcessor that:
1. Tracks the audio sample rate and channels from outgoing audio frames
2. When it detects `TTSStoppedFrame` (indicating TTS has finished), it generates and pushes 1 second of silence frames
3. This gives Sarvam STT time to detect end of speech and return the final transcription

**Why STT eval worked without this:** In `pense/stt/eval.py`, the `BotTurnAudioStreamer` explicitly pads 1 second of silence after streaming each audio file (lines 553-568). The agent simulation didn't have this padding.

The `SilencePadder` is placed in the pipeline after `tts` and before `output_logger`:

```python
tts,  # TTS
silence_padder,  # Add silence padding after TTS for STT flush
output_logger,
transport.output(),
```

Try running the simulation again with Sarvam STT - the silence padding should allow Sarvam to properly flush transcriptions before the transport timeout.

---

