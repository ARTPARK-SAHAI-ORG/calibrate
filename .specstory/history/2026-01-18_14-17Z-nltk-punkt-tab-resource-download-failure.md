<!-- Generated by SpecStory, Markdown v2.1.0 -->

<!-- cursor Session a07311f4-f4d5-4d33-a1b9-8a29685563c5 (2026-01-18 14:17Z) -->

# NLTK punkt_tab resource download failure (2026-01-18 14:17Z)

_**User (2026-01-17 15:03Z)**_

STT eval failed: 2026-01-18 14:02:59.464 | INFO | pipecat:<module>:14 - ·ìö·òè·ó¢ Pipecat 0.0.99 (Python 3.11.14 (main, Jan 13 2026, 03:12:14) [GCC 14.2.0]) ·ìö·òè·ó¢ Traceback (most recent call last): File "/usr/local/lib/python3.11/site-packages/pipecat/utils/string.py", line 30, in <module> nltk.data.find("tokenizers/punkt_tab") File "/usr/local/lib/python3.11/site-packages/nltk/data.py", line 579, in find raise LookupError(resource_not_found) LookupError: ********************************************************************** Resource [93mpunkt_tab[0m not found. Please use the NLTK Downloader to obtain the resource: [31m>>> import nltk >>> nltk.download('punkt_tab') [0m For more information see: https://www.nltk.org/data.html Attempted to load [93mtokenizers/punkt_tab[0m Searched in: - '/root/nltk_data' - '/usr/local/nltk_data' - '/usr/local/share/nltk_data' - '/usr/local/lib/nltk_data' - '/usr/share/nltk_data' - '/usr/local/share/nltk_data' - '/usr/lib/nltk_data' - '/usr/local/lib/nltk_data' ********************************************************************** During handling of the above exception, another exception occurred: Traceback (most recent call last): File "/usr/local/bin/pense", line 8, in <module> sys.exit(main()) ^^^^^^ File "/usr/local/lib/python3.11/site-packages/pense/cli.py", line 225, in main from pense.stt.eval import main as stt_main File "/usr/local/lib/python3.11/site-packages/pense/stt/eval.py", line 38, in <module> from pipecat.processors.frameworks.rtvi import RTVIServerMessageFrame File "/usr/local/lib/python3.11/site-packages/pipecat/processors/frameworks/rtvi.py", line 87, in <module> from pipecat.utils.string import match_endofsentence File "/usr/local/lib/python3.11/site-packages/pipecat/utils/string.py", line 33, in <module> nltk.download("punkt_tab", quiet=True) File "/usr/local/lib/python3.11/site-packages/nltk/downloader.py", line 762, in download for msg in self.incr_download(info_or_id, download_dir, force): File "/usr/local/lib/python3.11/site-packages/nltk/downloader.py", line 630, in incr_download yield from self._download_package(info, download_dir, force) File "/usr/local/lib/python3.11/site-packages/nltk/downloader.py", line 721, in _download_package for msg in _unzip_iter(filepath, zipdir, verbose=False): File "/usr/local/lib/python3.11/site-packages/nltk/downloader.py", line 2302, in _unzip_iter zf.extractall(root) File "/usr/local/lib/python3.11/zipfile.py", line 1715, in extractall self._extract_member(zipinfo, path, pwd) File "/usr/local/lib/python3.11/zipfile.py", line 1770, in _extract_member shutil.copyfileobj(source, target) File "/usr/local/lib/python3.11/shutil.py", line 197, in copyfileobj buf = fsrc_read(length) ^^^^^^^^^^^^^^^^^ File "/usr/local/lib/python3.11/zipfile.py", line 982, in read data = self._read1(n) ^^^^^^^^^^^^^^ File "/usr/local/lib/python3.11/zipfile.py", line 1050, in _read1 data += self._read2(n - len(data)) ^^^^^^^^^^^^^^^^^^^^^^^^^^ File "/usr/local/lib/python3.11/zipfile.py", line 1085, in _read2 raise EOFError EOFError


wtf is this error when trying to run pense as subprocess in a fastapi server on an ec2 instance

---

_**Agent (model claude-4.5-opus-high-thinking, mode Agent)**_

<think><details><summary>Thought Process</summary>
The user is encountering an error when running `pense` (their CLI tool) as a subprocess in a FastAPI server on an EC2 instance. Let me analyze the error:

1. The error is related to NLTK's `punkt_tab` tokenizer not being found
2. When pipecat tries to download it automatically (`nltk.download("punkt_tab", quiet=True)`), the download fails with an `EOFError`

The issue is that:
1. NLTK's `punkt_tab` resource isn't installed
2. When pipecat tries to auto-download it, there's an `EOFError` during the zip extraction - this typically happens when:
   - The download was interrupted/corrupted
   - There's a disk space issue
   - Network issues during download
   - The zip file is incomplete

This is happening because the `pense/stt/eval.py` imports pipecat, which then tries to use NLTK.

Let me look at the relevant code to understand the import chain and see if there's anything that can be done on the pense side.

The traceback shows:
1. `pense/cli.py` line 225 imports `pense.stt.eval`
2. `pense/stt/eval.py` line 38 imports from pipecat
3. pipecat then tries to use NLTK

The user is asking "wtf is this error" - they want to understand what's happening and likely want a solution.

The solution options are:
1. Pre-install the NLTK data before running pense (outside of the subprocess)
2. Fix any corrupted NLTK data
3. Ensure network access and disk space

Let me check if there's anything in the pense codebase that could be modified to help with this, but really this is an environmental issue on their EC2 instance.</details></think>

---

This error is caused by NLTK's `punkt_tab` tokenizer data being missing, and when pipecat tries to auto-download it, the download fails with an `EOFError` (corrupted/incomplete zip file).

The issue is:
1. **pipecat** (which `pense/stt/eval.py` imports) requires NLTK's `punkt_tab` tokenizer
2. NLTK tries to auto-download it but fails - likely due to network issues, interrupted download, or corrupted cached data on your EC2 instance

**Quick Fix** - Pre-download the NLTK data before running pense. Add this to your FastAPI server startup or run it once on the EC2 instance:

```python
import nltk
nltk.download('punkt_tab')
```

Or via command line on your EC2:

```bash
python -c "import nltk; nltk.download('punkt_tab')"
```

**If that still fails** (same EOFError), it means there's a corrupted partial download. Clear the NLTK cache first:

```bash
rm -rf /root/nltk_data
python -c "import nltk; nltk.download('punkt_tab')"
```

**Alternative: Pre-bake into your deployment** - If you're using Docker or a setup script, add this to ensure the data is always present:

```dockerfile
RUN python -c "import nltk; nltk.download('punkt_tab', download_dir='/usr/local/share/nltk_data')"
```

The root cause is that pipecat unconditionally tries to download NLTK data at import time (in `/pipecat/utils/string.py`), and in restricted/flaky network environments (common on EC2 with certain security groups), this can fail. Pre-installing the data avoids the runtime download attempt.

---

_**User (2026-01-17 15:03Z)**_

when I ran this in my docker container I got this

---

_**Agent (model claude-4.5-opus-high-thinking, mode Agent)**_

<think><details><summary>Thought Process</summary>
The user ran `python -c "import nltk; nltk.download('punkt_tab')"` in their Docker container and it says "Package punkt_tab is already up-to-date!" - meaning the NLTK data IS already installed.

So the issue isn't that the data is missing - it's something else. Let me think about what could be happening:

1. The data exists in `/root/nltk_data` (as shown in the output)
2. But when pense runs as a subprocess, it might be running as a different user or in a different environment where the NLTK data path is different

The original error showed it searched in:
- '/root/nltk_data'
- '/usr/local/nltk_data'
- etc.

And then it tried to download and failed with EOFError.

Wait, but the user is now running this command directly in the container and it works. So why would the subprocess fail?

Possible reasons:
1. **Different user** - If the FastAPI server runs as a different user (not root), it won't have access to `/root/nltk_data`
2. **Different Python environment** - The subprocess might be using a different Python installation
3. **Race condition** - Multiple subprocesses trying to download simultaneously causing corruption
4. **HOME environment variable** - NLTK looks at `~/nltk_data` which depends on the HOME env var

The most likely issue is that when running as a subprocess from FastAPI, the process might be running as a different user or with a different HOME environment variable, so it can't find the data in `/root/nltk_data`.

The user should check:
1. What user the FastAPI server runs as
2. If the HOME env var is set correctly when running the subprocess

Or they could install the NLTK data to a system-wide location like `/usr/local/share/nltk_data` or `/usr/share/nltk_data`.</details></think>

---

The data is already there in `/root/nltk_data`. So the issue is likely that **your FastAPI subprocess runs as a different user** or with a different `HOME` environment variable, so it can't find the data installed under `/root`.

**Check what user your FastAPI server runs as:**

```bash
# In your FastAPI code or container, check:
import os
print(os.getenv('HOME'))
print(os.getuid())
```

**Fix: Install NLTK data to a system-wide location that all users can access:**

```bash
python -c "import nltk; nltk.download('punkt_tab', download_dir='/usr/local/share/nltk_data')"
```

Or set the `NLTK_DATA` environment variable when running the subprocess:

```python
import subprocess
import os

env = os.environ.copy()
env['NLTK_DATA'] = '/root/nltk_data'  # or wherever it's installed

subprocess.run(['pense', ...], env=env)
```

**Or in your Dockerfile**, ensure the data is in a globally accessible location:

```dockerfile
RUN python -c "import nltk; nltk.download('punkt_tab', download_dir='/usr/local/share/nltk_data')"
```

The root cause: NLTK defaults to looking in `~/nltk_data` (based on `HOME`), and if your subprocess runs with a different `HOME` or user, it won't find the data you installed as root.

---

