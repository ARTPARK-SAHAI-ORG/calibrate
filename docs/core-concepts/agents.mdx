---
title: "Agents"
description: "Create AI agents to evaluate and improve"
---

An agent is a core building block of Calibrate. Agents can:

- Process voice conversations using Speech To Text (STT) and Text To Speech (TTS)
- Respond intelligently using LLM models following the instructions given to them
- Use tools for structured data extraction

## Quickstart

### Navigate to Agents

From the sidebar, click **Agents** to view your existing agents or create a new one.

<Frame>
  <img src="./images/agents-1.png" alt="Agents List" />
</Frame>

### Create a new agent

Click the **New agent** button in the top right corner, fill the name of the agent and hit **Create agent**.

<Frame>
  <img src="./images/agents-2.png" alt="Create Agent" />
</Frame>

Once ready, you'll be taken to the agent configuration page with multiple tabs.

## Configure your agent

### Add instructions and select providers

Configure the core agent behavior.

<Frame>
  <img src="./images/agents-3.png" alt="Agent tab" />
</Frame>

**System prompt**

Define the context for the agent, its persona, how it should behave, and any guidelines it should follow. Write clear instructions.

<Tip>
  Be specific about the agent's tone, capabilities, and limitations in the
  system prompt.
</Tip>

For detailed guidance on writing effective system prompts, see [ElevenLabs Prompting Guide](https://elevenlabs.io/docs/agents-platform/best-practices/prompting-guide) and [OpenAI Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering).

**Speech To Text**

Select the STT provider for the agent.

**Text To Speech**

Select the TTS provider for the agent.

**LLM**

Select the provider and model for the agent.

Click **Save** in the top right to save your configuration.

### Add tools

Add tools to enable structured outputs by the agent.

<Frame>
  <img src="./images/agents-4.png" alt="Tools tab" />
</Frame>

Click **Add tool** to attach tools to your agent. See the [Tools guide](/core-concepts/tools) for how to create tools.

**In-built tools**

The platform provides built-in tools like "End conversation" that are automatically available to all agents.

### Define data extraction fields

Define fields for extracting structured data from conversations.

<Frame>
  <img src="./images/agents-5.png" alt="Data extraction tab" />
</Frame>

Click **Add field** to define custom data specifications to extract from conversation transcripts.

### Add tests

Add tests to evaluate your agent's performance.

<Frame>
  <img src="./images/agents-6.png" alt="Tests tab" />
</Frame>

- Click **Add test** to attach tests to your agent
- Click **Run all tests** to execute all tests for this agent
- Click **Compare models** to benchmark different LLMs

See the [LLM Testing guide](/quickstart/text-to-text) for how to create tests.

### Configure advanced settings

Configure advanced agent behavior.

<Frame>
  <img src="./images/agents-7.png" alt="Settings tab" />
</Frame>

**Agent speaks first**

Toggle whether the agent should initiate the conversation.

**Max assistant turns**

Set the maximum number of assistant turns before ending the call.

Click **Save** in the top right to save your configuration.

## Next Steps

<CardGroup cols={2}>
  <Card title="Run LLM Tests" icon="flask" href="/quickstart/text-to-text">
    Test your agent's responses and tool usage
  </Card>
  <Card title="Run Simulations" icon="play" href="/quickstart/simulations">
    Simulate conversations with the agent to identify issues before deployment
  </Card>
</CardGroup>
