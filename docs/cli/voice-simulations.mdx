---
title: "Voice Simulations"
description: "Run voice agent simulations via CLI"
---

Run voice agent simulations with Speech to Text, LLM, and Text to Speech, or interact with an agent in real-time.

<Card
  title="Learn about simulations"
  icon="comments"
  href="/quickstart/simulations"
>
  Step-by-step guide to creating and running simulations
</Card>

## Configuration

Create a JSON configuration file that defines your agent, personas, scenarios, and evaluation criteria.

### System Prompt

Define your agent's role and instructions:

```json
{
  "system_prompt": "You are a helpful nurse filling out a medical form. Ask questions one at a time and be empathetic."
}
```

**Best Practices:**

- Clearly define the agent's role
- Include tool usage instructions
- Specify conversation style
- Mention constraints or rules

### Tools

Tools extend your agent's capabilities:

<Card title="Understanding Tools" icon="wrench" href="/core-concepts/tools">
  Learn about webhook and structured output tools
</Card>

```json
{
  "tools": [
    {
      "type": "client",
      "name": "plan_next_question",
      "description": "Call after user answers to track progress",
      "parameters": [
        {
          "id": "next_unanswered_question_index",
          "type": "integer",
          "description": "Index of next question (1-indexed)",
          "required": true
        }
      ]
    }
  ]
}
```

### Personas

Define WHO the simulated user is and HOW they behave:

<Card title="Understanding Personas" icon="user" href="/core-concepts/personas">
  Best practices for creating realistic personas
</Card>

```json
{
  "personas": [
    {
      "characteristics": "You are Geeta Prasad, a 39-year-old pregnant mother. You are shy and reserved, giving short answers.",
      "gender": "female",
      "language": "english",
      "interruption_sensitivity": "medium"
    }
  ]
}
```

**Field Descriptions:**

- `characteristics`: Who the person is and how they behave (name, age, background, communication style, personality)
- `gender`: Voice gender (`"male"` or `"female"`)
- `language`: Primary language (`"english"`, `"hindi"`, `"kannada"`, etc.)
- `interruption_sensitivity`: How often the user interrupts the agent (optional)

**Interruption Sensitivity:**

- `none`: Never interrupts (0%)
- `low`: Rarely interrupts (25%)
- `medium`: Sometimes interrupts (50%)
- `high`: Frequently interrupts (80%)

**Best Practices:**

- Be specific: Name, age, occupation, location
- Define communication style: Formal, casual, slow, fast
- Include limitations: Language proficiency, technical knowledge
- Set interruption level matching persona type

### Scenarios

Define WHAT the simulated user should accomplish:

<Card
  title="Understanding Scenarios"
  icon="file-lines"
  href="/core-concepts/scenarios"
>
  How to write effective scenarios
</Card>

```json
{
  "scenarios": [
    {
      "description": "The user completes the form smoothly without hesitation"
    },
    {
      "description": "The user hesitates and asks to skip questions before eventually providing information"
    }
  ]
}
```

**Field Descriptions:**

- `description`: The goal, task, or situation (what happens, not who the person is)

**Best Practices:**

- Set clear objectives
- Include realistic context
- Add conversation flow hints
- Specify edge cases to test

### Evaluation Criteria

Define how to measure agent success:

```json
{
  "evaluation_criteria": [
    {
      "name": "question_completeness",
      "description": "The assistant asked all required questions: name, age, address, phone number"
    },
    {
      "name": "assistant_behavior",
      "description": "The assistant asked one concise question per turn and was empathetic"
    }
  ]
}
```

**Field Descriptions:**

- `name`: Short metric identifier
- `description`: Detailed success criteria (be specific and measurable)

**Best Practices:**

- Be specific and measurable
- Focus on one aspect per criterion
- Make it objective for the LLM judge

### Provider Configuration

Configure STT, TTS, and LLM providers:

```json
{
  "stt": { "provider": "google" },
  "tts": { "provider": "google" },
  "llm": { "provider": "openrouter", "model": "openai/gpt-4.1" }
}
```

**Supported Providers:**

- **STT**: deepgram, google, openai, elevenlabs, sarvam, cartesia
- **LLM**: openrouter, openai
- **TTS**: elevenlabs, cartesia, google, openai, deepgram, sarvam

### Settings

```json
{
  "settings": {
    "agent_speaks_first": true,
    "max_turns": 50
  }
}
```

**Field Descriptions:**

- `agent_speaks_first`: Whether agent starts the conversation
- `max_turns`: Maximum assistant turns (conversation ends after this limit)

### Complete Example

```json
{
  "system_prompt": "You are a helpful nurse filling out a form...",
  "tools": [
    {
      "type": "client",
      "name": "plan_next_question",
      "description": "Plan the next question",
      "parameters": [
        {
          "id": "next_unanswered_question_index",
          "type": "integer",
          "required": true
        }
      ]
    }
  ],
  "personas": [
    {
      "characteristics": "A shy mother named Geeta, 39 years old, gives short answers",
      "gender": "female",
      "language": "english",
      "interruption_sensitivity": "medium"
    }
  ],
  "scenarios": [
    { "description": "User completes the form without any issues" },
    { "description": "User hesitates and wants to skip some questions" }
  ],
  "evaluation_criteria": [
    {
      "name": "question_completeness",
      "description": "Whether all the questions in the form were covered"
    }
  ],
  "stt": { "provider": "google" },
  "tts": { "provider": "google" },
  "llm": { "provider": "openrouter", "model": "openai/gpt-4.1" },
  "settings": {
    "agent_speaks_first": true,
    "max_turns": 50
  }
}
```

---

## Run Simulation

Run automated voice agent simulations.

```bash
calibrate agent simulation -c <config_file> -o <output_dir> --port <port>
```

### Arguments

| Flag | Long           | Type   | Required | Default | Description                                |
| ---- | -------------- | ------ | -------- | ------- | ------------------------------------------ |
| `-c` | `--config`     | string | Yes      | -       | Path to simulation configuration JSON file |
| `-o` | `--output-dir` | string | No       | `./out` | Path to output directory                   |
|      | `--port`       | int    | No       | `8765`  | Base WebSocket port                        |

### Examples

**Basic:**

```bash
calibrate agent simulation -c ./config.json -o ./out
```

**Custom port:**

```bash
calibrate agent simulation -c ./config.json -o ./out --port 9000
```

### Output

```
/path/to/output/
├── simulation_persona_1_scenario_1/
│   ├── audios/
│   │   ├── 0_user.wav
│   │   ├── 1_bot.wav
│   │   └── ...
│   ├── conversation.wav         # Combined audio
│   ├── transcript.json          # Full conversation
│   ├── stt_outputs.json         # Speech to Text transcriptions
│   ├── tool_calls.json          # Tool calls made
│   ├── evaluation_results.csv   # Evaluation + latency metrics
│   ├── stt_results.csv          # Speech to Text accuracy evaluation
│   ├── metrics.json             # Per-processor latency
│   ├── config.json              # Persona and scenario
│   ├── results.log
│   └── logs
├── simulation_persona_1_scenario_2/
│   └── ...
├── results.csv                  # Aggregated results
└── metrics.json                 # Summary statistics
```

**audios/** contains alternating user and bot audio files for each turn.

**conversation.wav** is a combined audio file of the entire conversation.

**evaluation_results.csv** contains evaluation criteria, latency metrics, and Speech to Text scores:

| name                  | value | reasoning                     |
| --------------------- | ----- | ----------------------------- |
| question_completeness | 1     | All questions were covered... |
| assistant_behavior    | 1     | One question per turn...      |
| ttft                  | 0.62  |                               |
| processing_time       | 0.62  |                               |
| stt_llm_judge_score   | 0.95  |                               |

**stt_results.csv** contains per-turn Speech to Text evaluation:

| reference     | prediction   | score | reasoning                          |
| ------------- | ------------ | ----- | ---------------------------------- |
| Geeta Prasad. | Gita Prasad. | 0     | Name 'Geeta' transcribed as 'Gita' |

**results.csv** aggregates match scores across all simulations:

| name                            | question_completeness | assistant_behavior | stt_llm_judge_score |
| ------------------------------- | --------------------- | ------------------ | ------------------- |
| simulation_persona_1_scenario_1 | 1.0                   | 1.0                | 0.95                |
| simulation_persona_1_scenario_2 | 1.0                   | 0.0                | 0.92                |

---

## Interactive Testing

Test your agent interactively through your browser.

```bash
calibrate agent test -c <config_file> -o <output_dir>
```

### Arguments

| Flag | Long           | Type   | Required | Default | Description                           |
| ---- | -------------- | ------ | -------- | ------- | ------------------------------------- |
| `-c` | `--config`     | string | Yes      | -       | Path to agent configuration JSON file |
| `-o` | `--output-dir` | string | No       | `./out` | Path to output directory              |

### Example

```bash
calibrate agent test -c ./config.json -o ./out/run
```

### Configuration

```json
{
  "system_prompt": "You are a helpful assistant.",
  "language": "english",
  "stt": { "provider": "deepgram" },
  "tts": {
    "provider": "cartesia",
    "voice_id": "YOUR_VOICE_ID"
  },
  "llm": {
    "provider": "openrouter",
    "model": "openai/gpt-4o-2024-11-20"
  },
  "tools": []
}
```

### Usage

1. Run the command to start the agent server
2. Open `http://localhost:7860/client/` in your browser
3. Click **Connect** and start talking to the agent

<Warning>
  Avoid using your laptop's speaker and microphone at the same time. Audio from
  the speaker can be picked up by the microphone, interrupting the agent with
  its own voice. **Use a headphone with a built-in microphone.**
</Warning>

---

## Environment Variables

Set API keys for your chosen providers:

```bash
# Speech to Text Providers
export DEEPGRAM_API_KEY=your_key
export GOOGLE_APPLICATION_CREDENTIALS=/path/to/credentials.json
export OPENAI_API_KEY=your_key
export ELEVENLABS_API_KEY=your_key
export SARVAM_API_KEY=your_key
export CARTESIA_API_KEY=your_key

# LLM Providers
export OPENAI_API_KEY=your_key
export OPENROUTER_API_KEY=your_key
```

<Note>
  You only need to set API keys for the providers you configure in your config
  file.
</Note>
