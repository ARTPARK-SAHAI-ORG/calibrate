---
title: "Introduction"
description: "Learn about Pense and how to get started."
---

Pense is an open-source framework for automated, repeatable and systematic evaluation of voice agents at scale.

You can evaluate individual components (Speech to Text, Text to Text, Text to Speech) and run end-to-end voice agent simulations across thousands of scenarios with user personas defined by you to identify where your agent fails before deploying it to production, continuously improve it and ensure a bug never repeats as you make changes.

## What can you do with Pense?

<CardGroup cols={2}>
  <Card title="Evaluate Speech to Text" icon="microphone">
    Compare transcription accuracy and latency across providers like Deepgram,
    OpenAI, Google, Sarvam, and more.
  </Card>
  <Card title="Test Text to Text" icon="brain">
    Create test suites that verify model responses and tool calling behavior
    against expected outputs.
  </Card>
  <Card title="Evaluate Text to Speech" icon="volume-high">
    Benchmark pronunciation quality and performance across Cartesia, ElevenLabs,
    Google, and other providers.
  </Card>
  <Card title="Run Simulations" icon="comments">
    Run automated text and voice agent simulations with customizable personas
    and scenarios.
  </Card>
</CardGroup>

## Why Pense?

Testing voice agents manually is slow, inconsistent, and doesn't scale. Pense solves this by providing:

- **Component-level evaluation**: Test Speech to Text, Text to Text, and Text to Speech independently to identify bottlenecks
- **Comprehensive metrics**: WER, string similarity, LLM Judge scores, TTFB, and processing time
- **Persona-based simulations**: Define user personas and scenarios to test diverse conversation flows
- **Automated evaluation**: LLM judges assess transcript quality and agent behavior
- **Leaderboards**: Compare providers side-by-side with generated reports and visualizations

## Get Started

<CardGroup cols={2}>
  <Card
    title="Speech to Text"
    icon="microphone"
    href="/quickstart/speech-to-text"
  >
    Evaluate and compare Speech to Text providers.
  </Card>
  <Card title="Text to Text" icon="brain" href="/quickstart/text-to-text">
    Test model behavior with test cases.
  </Card>
  <Card
    title="Text to Speech"
    icon="volume-high"
    href="/quickstart/text-to-speech"
  >
    Evaluate Text to Speech providers.
  </Card>
  <Card title="Simulations" icon="robot" href="/quickstart/simulations">
    Run automated conversations.
  </Card>
</CardGroup>

## Learn More

<CardGroup cols={2}>
  <Card title="Core Concepts" icon="book" href="/core-concepts/speech-to-text">
    Understand metrics and evaluation concepts.
  </Card>
  <Card title="Python SDK" icon="code" href="/python-sdk/overview">
    Use Pense programmatically.
  </Card>
  <Card title="CLI Reference" icon="terminal" href="/cli/overview">
    Run evaluations from the command line.
  </Card>
  <Card title="Integrations" icon="plug" href="/integrations/stt">
    See all supported providers.
  </Card>
</CardGroup>
